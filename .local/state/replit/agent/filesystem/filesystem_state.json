{"file_contents":{"drizzle.config.ts":{"content":"// import { defineConfig } from \"drizzle-kit\";\n\n// if (!process.env.DATABASE_URL) {\n//   throw new Error(\"DATABASE_URL, ensure the database is provisioned\");\n// }\n\n// export default defineConfig({\n//   out: \"./migrations\",\n//   schema: \"./shared/schema.ts\",\n//   dialect: \"postgresql\",\n//   dbCredentials: {\n//     url: process.env.DATABASE_URL,\n//   },\n// });\n","size_bytes":361},"postcss.config.js":{"content":"export default {\n  plugins: {\n    tailwindcss: {},\n    autoprefixer: {},\n  },\n}\n","size_bytes":80},"replit.md":{"content":"## ðŸš€ ZERO-SETUP IMPORT\n\nThis project is 100% ready to run:\n\n1. Dependencies: âœ… Already installed\n2. Configuration: âœ… Pre-configured for Replit\n3. Database: âœ… Auto-connects\n4. Run command: `npm run dev`\n5. No agent setup needed - just run!\n\nOverview\nSQLGym is a gamified SQL learning platform that combines coding practice with fitness-themed motivation. The application allows users to solve SQL problems, track their progress through an XP system, compete on leaderboards, and participate in a community forum. The platform features a comprehensive problem set with different difficulty levels, submission tracking, and a badge system to reward achievements.\n\nUser Preferences\nPreferred communication style: Simple, everyday language.\n\nSystem Architecture\nFrontend Architecture\nThe client uses React with TypeScript, built with Vite for fast development. The UI is constructed with shadcn/ui components and Radix UI primitives, providing a consistent design system with Tailwind CSS for styling. The application uses Wouter for lightweight client-side routing and TanStack Query for server state management and caching. Form handling is implemented with React Hook Form and Zod for validation.\n\nBackend Architecture\nThe server is built with FastAPI and Python, following a RESTful API pattern. The architecture uses SQLAlchemy ORM with Pydantic schemas for type safety and automatic API documentation. JWT tokens handle authentication with bcrypt for password hashing. The server includes middleware for CORS, request logging, and error handling.\n\nDatabase Design\nThe system uses SQLAlchemy ORM with PostgreSQL as the primary database. The schema includes tables for users, problems, submissions, community posts, post comments, post likes, and user badges. The database supports user progression tracking, problem solving statistics, and social features like community posts and comments.\n\nAuthentication System\nAuthentication is implemented using JWT tokens stored in localStorage on the client side. The server validates tokens using middleware that checks for Authorization headers. User registration includes password hashing with bcrypt, and the system checks for existing usernames and emails to prevent duplicates.\n\n**Development Mode**: Authentication is automatically bypassed in development mode (when `import.meta.env.DEV` is true). The app automatically logs in with a fake developer user, eliminating the need to go through the OAuth login flow during development.\n\nKey Features\nGamification: XP system with levels (SQL Beginner, Trainee, Athlete, Powerlifter) and badge rewards\nProblem Management: SQL problems categorized by difficulty with hints and expected outputs\nCode Execution: SQL query submission and validation system\nSocial Features: Community posts with likes and comments\nProgress Tracking: User submissions history and leaderboards\nResponsive Design: Mobile-friendly interface with proper breakpoints\nState Management\nClient-side state is managed through TanStack Query for server state and React's built-in state management for UI state. Authentication state is handled through a custom AuthContext provider that persists user sessions in localStorage.\n\nExternal Dependencies\nDatabase Services\nNeon Database: PostgreSQL hosting service accessed via @neondatabase/serverless driver\nSQLAlchemy ORM: Type-safe database operations with automatic schema migration support\nUI Libraries\nRadix UI: Unstyled, accessible UI primitives for complex components\nshadcn/ui: Pre-built component library built on Radix UI\nTailwind CSS: Utility-first CSS framework for styling\nLucide React: Icon library for consistent iconography\nDevelopment Tools\nVite: Build tool with hot module replacement for development\nTypeScript: Type safety across the entire application\nTanStack Query: Server state management and caching\nReact Hook Form: Form handling with validation\nZod: Schema validation for forms and API data\nAuthentication & Security\nJSON Web Tokens (jsonwebtoken): Token-based authentication\nbcrypt: Password hashing and verification\nWouter: Lightweight client-side routing\nDevelopment Environment\nReplit Integration: Special development tools and error overlays for Replit environment\nESBuild: Fast bundling for production builds\nPostCSS: CSS processing with Autoprefixer\nðŸš€ QUICK SETUP FOR FUTURE IMPORTS (Reduces Agent Usage)\nOne-Command Setup\nFor future GitHub imports of this project, run this command to automate everything:\n\nbash scripts/replit-setup.sh && npm run dev\nWhat This Automates\nâœ… Node.js dependency installation\nâœ… Python dependency installation\nâœ… Database connection verification\nâœ… Environment configuration\nâœ… Directory creation\nâœ… Configuration validation\nâœ… Basic functionality testing\nManual Setup Steps (if needed)\nDependencies: npm install && pip install -r requirements.txt\nDatabase: Ensure DATABASE_URL environment variable is set\nEnvironment: Copy .env.example to .env if needed\nRun: npm run dev (starts frontend Vite dev server on :5000 and FastAPI backend on :8000)\nProduction Deployment\nBuild: npm run build (builds frontend to dist/public)\nStart: npm run start (serves both frontend and backend on port 5000)\nTarget: Already configured for autoscale deployment\nAgent Usage Optimization\nThis project has comprehensive .replit configuration\nAll modules, workflows, and integrations pre-configured\nUse the setup script for zero-analysis imports\nExpert mode enabled for faster agent operations\n\n## Recent Changes\n- **September 25, 2025**: âœ… **Successful Replit Import Setup Complete**\n  - **Project Type**: Fullstack SQL Learning Platform (SQLGym) - React frontend + Python FastAPI backend\n  - **Frontend**: React + Vite running on port 5000 with proper 0.0.0.0 host configuration for Replit proxy\n  - **Backend**: Python FastAPI running on port 8000 with auto-installed dependencies (uvicorn, fastapi, etc.)\n  - **Bug Fix**: Resolved JavaScript error in SolutionsTab component - fixed undefined .trim() calls with proper null checking\n  - **Workflow**: Configured with webview output type for port 5000 frontend preview\n  - **Deployment**: âœ… Configured for autoscale deployment (build: npm run build, run: python uvicorn on port 5000)\n  - **Status**: âœ… **Fully operational** - API endpoints working, no console errors, hot reload functioning\n- **September 24, 2025**: Fixed s3_datasets query failure issue with partial success support\n  - **Issue**: \"Query failed\" errors when users tried to query tables (e.g., `SELECT * FROM s1`) from problems using s3_datasets configuration  \n    - **Root Cause**: s3_datasets had all-or-nothing behavior - if ANY single dataset failed to load, the entire sandbox setup would fail and no tables would be created\n    - **Problem**: Users couldn't query any tables, even ones that should have loaded successfully, because the sandbox setup aborted completely on first dataset error\n    - **Fix**: Implemented partial success support in `api/duckdb_sandbox.py` setup_problem_data method for s3_datasets processing\n    - **Solution**: Added per-dataset error tracking, continue-on-failure behavior, and three outcome paths (complete success, partial success, complete failure)\n    - **Impact**: âœ… Users can now query tables that load successfully even if other datasets in the same problem fail\n  - **Technical Details**: Enhanced error handling with structured error responses, improved logging with exc_info=True, and consolidated error reporting\n  - **Status**: âœ… s3_datasets now works reliably with same robustness as s3_data_source (legacy single-table support)\n- **September 23, 2025**: Fixed critical admin panel JSON parsing error during question creation\n  - **Issue**: \"Failed to execute 'json' on 'Response': Unexpected token 'I'\" error when creating questions\n    - **Root Cause**: `TypeError: 'solution_source' is an invalid keyword argument for Problem` causing 500 errors\n    - **Problem**: Backend returned HTML error pages instead of JSON, causing frontend parsing failures\n    - **Fix**: Removed invalid `solution_source` and `s3_solution_source` parameters from Problem constructor in `admin_routes.py`\n    - **Solution**: Problem model doesn't have these fields; removed lines 469-470 from create_problem function\n    - **Impact**: âœ… Admin panel now works correctly, returns proper JSON responses, 200 OK status codes\n  - **Verification**: Successfully created test problem with proper authentication using Bearer token\n  - **Status**: âœ… Admin panel problem creation fully functional\n- **September 21, 2025**: Successfully completed GitHub import and resolved critical encoding issues\n  - **Issue**: UnicodeDecodeError causing JSON parsing failures in sandbox API routes\n    - **Root Cause**: UTF-8 encoding errors when processing query results containing non-UTF-8 characters (byte 0xa0)\n    - **Fix**: Enhanced `sanitize_json_data` function in `secure_execution.py` to handle string encoding issues\n    - **Solution**: Added UTF-8 validation, multi-encoding fallback support, and proper bytes-to-string conversion\n    - **Impact**: All API endpoints now working correctly, sandbox queries execute successfully\n  - **Workflow Configuration**: Fixed workflow setup with proper webview output type for port 5000\n  - **Application Status**: âœ… Running correctly - Frontend on port 5000, Backend on port 8000, Database connected\n  - **Multi-table Support**: All previous multi-table question creation issues resolved with encoding fixes\n- **September 20, 2025**: Initial GitHub project import with basic Replit environment configuration\n- **Deployment**: âœ… Configured for autoscale deployment\n- **Workflows**: âœ… Configured with webview output for frontend development\n\n## Known Issues\n### Resolved âœ…: Multi-table Dataset Validation (September 21, 2025)\n- **Status**: Fixed - All encoding and parquet solution issues resolved\n- **Previous Issues**: UTF-8 decoding errors, missing methods, parquet solution support\n- **Current Status**: Multi-table question creation fully functional\n\n### Critical: \"kumbhar\" Question Data Mismatch  \n- **Problem ID**: `30ff47d8-e9a6-4b13-810d-cbea2915d73d`\n- **Issue**: Question asks for \"sales data analysis by region\" but dataset is Titanic passenger data\n- **Impact**: All user submissions fail validation regardless of correctness\n- **Root Cause**: Question description and expected output don't match the actual loaded dataset\n- **Fix Required**: Either update question to match Titanic data OR load correct sales dataset\n\n### Anti-Hardcode Detection System: Foundation Complete âœ… (September 22, 2025)\n- **Problem**: Students could cheat by hardcoding expected values (e.g., `SELECT 355 as \"sum(passanger)\"`) instead of writing proper analytical SQL\n- **Solution**: Implemented comprehensive three-layer defense system:\n  - **Layer 1 - Static Analysis**: Detects constant-only queries, validates table/column references\n  - **Layer 2 - Execution Plan Analysis**: Uses DuckDB EXPLAIN to verify actual data scanning  \n  - **Layer 3 - Data Dependency Testing**: Creates dataset variants to catch hardcoded results\n- **Status**: Core components implemented in `api/query_validator.py` and `api/duckdb_sandbox.py`\n- **Integration Needed**: Coordinate layers in SecureQueryExecutor pipeline with time budgets and JSON plan parsing\n- **Impact**: Major advancement in educational SQL platform integrity\n","size_bytes":11370},"tailwind.config.ts":{"content":"import type { Config } from \"tailwindcss\";\n\nexport default {\n  darkMode: [\"class\"],\n  content: [\"./client/index.html\", \"./client/src/**/*.{js,jsx,ts,tsx}\"],\n  theme: {\n    extend: {\n      borderRadius: {\n        lg: \"var(--radius)\",\n        md: \"calc(var(--radius) - 2px)\",\n        sm: \"calc(var(--radius) - 4px)\",\n      },\n      colors: {\n        background: \"var(--background)\",\n        foreground: \"var(--foreground)\",\n        card: {\n          DEFAULT: \"var(--card)\",\n          foreground: \"var(--card-foreground)\",\n        },\n        popover: {\n          DEFAULT: \"var(--popover)\",\n          foreground: \"var(--popover-foreground)\",\n        },\n        primary: {\n          DEFAULT: \"var(--primary)\",\n          foreground: \"var(--primary-foreground)\",\n        },\n        secondary: {\n          DEFAULT: \"var(--secondary)\",\n          foreground: \"var(--secondary-foreground)\",\n        },\n        muted: {\n          DEFAULT: \"var(--muted)\",\n          foreground: \"var(--muted-foreground)\",\n        },\n        accent: {\n          DEFAULT: \"var(--accent)\",\n          foreground: \"var(--accent-foreground)\",\n        },\n        destructive: {\n          DEFAULT: \"var(--destructive)\",\n          foreground: \"var(--destructive-foreground)\",\n        },\n        border: \"var(--border)\",\n        input: \"var(--input)\",\n        ring: \"var(--ring)\",\n        chart: {\n          \"1\": \"var(--chart-1)\",\n          \"2\": \"var(--chart-2)\",\n          \"3\": \"var(--chart-3)\",\n          \"4\": \"var(--chart-4)\",\n          \"5\": \"var(--chart-5)\",\n        },\n        sidebar: {\n          DEFAULT: \"var(--sidebar)\",\n          foreground: \"var(--sidebar-foreground)\",\n          primary: \"var(--sidebar-primary)\",\n          \"primary-foreground\": \"var(--sidebar-primary-foreground)\",\n          accent: \"var(--sidebar-accent)\",\n          \"accent-foreground\": \"var(--sidebar-accent-foreground)\",\n          border: \"var(--sidebar-border)\",\n          ring: \"var(--sidebar-ring)\",\n        },\n      },\n      fontFamily: {\n        sans: [\"var(--font-sans)\"],\n        serif: [\"var(--font-serif)\"],\n        mono: [\"var(--font-mono)\"],\n      },\n      keyframes: {\n        \"accordion-down\": {\n          from: {\n            height: \"0\",\n          },\n          to: {\n            height: \"var(--radix-accordion-content-height)\",\n          },\n        },\n        \"accordion-up\": {\n          from: {\n            height: \"var(--radix-accordion-content-height)\",\n          },\n          to: {\n            height: \"0\",\n          },\n        },\n        fillProgress: {\n          from: {\n            width: \"0%\",\n          },\n          to: {\n            width: \"var(--progress-width)\",\n          },\n        },\n      },\n      animation: {\n        \"accordion-down\": \"accordion-down 0.2s ease-out\",\n        \"accordion-up\": \"accordion-up 0.2s ease-out\",\n        \"fill-progress\": \"fillProgress 2s ease-in-out\",\n      },\n    },\n  },\n  plugins: [require(\"tailwindcss-animate\"), require(\"@tailwindcss/typography\")],\n} satisfies Config;\n","size_bytes":2975},"vite.config.ts":{"content":"import { defineConfig } from \"vite\";\nimport react from \"@vitejs/plugin-react\";\nimport path from \"path\";\nimport runtimeErrorOverlay from \"@replit/vite-plugin-runtime-error-modal\";\n\nexport default defineConfig({\n  plugins: [\n    react(),\n    runtimeErrorOverlay(),\n    // Temporarily disabled cartographer plugin due to \"traverse is not a function\" error\n    // ...(process.env.NODE_ENV !== \"production\" &&\n    // process.env.REPL_ID !== undefined\n    //   ? [\n    //       await import(\"@replit/vite-plugin-cartographer\").then((m) =>\n    //         m.cartographer()\n    //       ),\n    //     ]\n    //   : []),\n  ],\n  optimizeDeps: {\n    include: ['framer-motion']\n  },\n  resolve: {\n    alias: {\n      \"@\": path.resolve(import.meta.dirname, \"client\", \"src\"),\n      \"@shared\": path.resolve(import.meta.dirname, \"shared\"),\n      \"@assets\": path.resolve(import.meta.dirname, \"attached_assets\"),\n    },\n  },\n  root: path.resolve(import.meta.dirname, \"client\"),\n  build: {\n    outDir: path.resolve(import.meta.dirname, \"dist/public\"),\n    emptyOutDir: true,\n  },\n  server: {\n    fs: {\n      strict: true,\n      deny: [\"**/.*\"],\n    },\n    allowedHosts: true,\n    host: \"0.0.0.0\",\n    port: 5000,\n    proxy: {\n      \"/api\": {\n        target: \"http://localhost:8000\",\n        changeOrigin: true,\n      },\n    },\n  },\n});\n","size_bytes":1313},"server/db.ts":{"content":"import { Pool, neonConfig } from '@neondatabase/serverless';\nimport { drizzle } from 'drizzle-orm/neon-serverless';\nimport ws from \"ws\";\nimport * as schema from \"@shared/schema\";\n\n// Environment detection\nconst isReplit = !!(process.env.REPL_ID || process.env.REPLIT_DEV_DOMAIN);\nconst isDevelopment = process.env.NODE_ENV === 'development';\nconst isProduction = process.env.NODE_ENV === 'production';\n\n// Neon configuration\nneonConfig.webSocketConstructor = ws;\nneonConfig.pipelineConnect = false;\n\n// SSL Configuration based on environment\nif (isDevelopment) {\n  // For development (both local and Replit), disable strict SSL verification\n  process.env[\"NODE_TLS_REJECT_UNAUTHORIZED\"] = \"0\";\n  console.log(\"ðŸ”“ SSL verification disabled for development\");\n}\n\nif (!process.env.DATABASE_URL) {\n  const environmentHelp = isReplit \n    ? \"Make sure PostgreSQL is enabled in your Replit environment\" \n    : \"Set DATABASE_URL in your local environment (.env file)\";\n  \n  throw new Error(\n    `DATABASE_URL must be set. ${environmentHelp}`\n  );\n}\n\n// Database connection configuration\nconst dbConfig: any = {\n  connectionString: process.env.DATABASE_URL,\n};\n\n// SSL configuration based on environment\nif (isProduction) {\n  // Production: Enable SSL but don't reject unauthorized (for compatibility)\n  dbConfig.ssl = { rejectUnauthorized: false };\n} else if (isReplit) {\n  // Replit development: No SSL for internal connections\n  dbConfig.ssl = false;\n} else {\n  // Local development: Typically no SSL needed\n  dbConfig.ssl = false;\n}\n\n// Log connection info (without exposing sensitive data)\nconst dbUrl = new URL(process.env.DATABASE_URL);\nconsole.log(`ðŸ—„ï¸  Database: ${dbUrl.hostname}:${dbUrl.port}${dbUrl.pathname}`);\nconsole.log(`ðŸ”§ Environment: ${isReplit ? 'Replit' : 'Local'} (${process.env.NODE_ENV || 'development'})`);\n\nexport const pool = new Pool(dbConfig);\nexport const db = drizzle({ client: pool, schema });","size_bytes":1924},"server/index.ts":{"content":"import \"dotenv/config\";\nimport express, { type Request, Response, NextFunction } from \"express\";\nimport { registerRoutes } from \"./routes\";\nimport { setupVite, serveStatic, log } from \"./vite\";\n\nconst app = express();\napp.use(express.json());\napp.use(express.urlencoded({ extended: false }));\n\napp.use((req, res, next) => {\n  const start = Date.now();\n  const path = req.path;\n  let capturedJsonResponse: Record<string, any> | undefined = undefined;\n\n  const originalResJson = res.json;\n  res.json = function (bodyJson, ...args) {\n    capturedJsonResponse = bodyJson;\n    return originalResJson.apply(res, [bodyJson, ...args]);\n  };\n\n  res.on(\"finish\", () => {\n    const duration = Date.now() - start;\n    if (path.startsWith(\"/api\")) {\n      let logLine = `${req.method} ${path} ${res.statusCode} in ${duration}ms`;\n      if (capturedJsonResponse) {\n        logLine += ` :: ${JSON.stringify(capturedJsonResponse)}`;\n      }\n\n      if (logLine.length > 80) {\n        logLine = logLine.slice(0, 79) + \"â€¦\";\n      }\n\n      log(logLine);\n    }\n  });\n\n  next();\n});\n\n(async () => {\n  const server = await registerRoutes(app);\n\n  app.use((err: any, _req: Request, res: Response, _next: NextFunction) => {\n    const status = err.status || err.statusCode || 500;\n    const message = err.message || \"Internal Server Error\";\n\n    res.status(status).json({ message });\n    throw err;\n  });\n\n  // importantly only setup vite in development and after\n  // setting up all the other routes so the catch-all route\n  // doesn't interfere with the other routes\n  if (app.get(\"env\") === \"development\") {\n    await setupVite(app, server);\n  } else {\n    serveStatic(app);\n  }\n\n  // Environment detection\n  const isReplit = process.env.REPL_ID || process.env.REPLIT_DEV_DOMAIN;\n  const isProduction = process.env.NODE_ENV === \"production\";\n\n  // Port configuration - flexible for local and Replit\n  const port = parseInt(\n    process.env.PORT || (isReplit ? \"5000\" : \"3000\"), // Default to 5000 for Replit, 3000 for local\n    10\n  );\n\n  // Host configuration - 0.0.0.0 for Replit, localhost for local\n  const host = isReplit ? \"0.0.0.0\" : \"localhost\";\n\n  // Server options\n  const serverOptions: any = {\n    port,\n    host,\n  };\n\n  // Only add reusePort for Replit to avoid local conflicts\n  if (isReplit) {\n    serverOptions.reusePort = true;\n  }\n\n  server.listen(serverOptions, () => {\n    const environment = isReplit ? \"Replit\" : \"Local\";\n    log(`ðŸš€ ${environment} server running at http://${host}:${port}`);\n    log(`ðŸ“Š Environment: ${process.env.NODE_ENV || \"development\"}`);\n    log(\n      `ðŸ”— Database: ${\n        process.env.DATABASE_URL ? \"Connected\" : \"Not configured\"\n      }`\n    );\n  });\n})();\n","size_bytes":2696},"server/oauth.ts":{"content":"import passport from 'passport';\nimport { Strategy as GoogleStrategy } from 'passport-google-oauth20';\nimport { Strategy as GitHubStrategy } from 'passport-github2';\nimport { storage } from './storage';\nimport jwt from 'jsonwebtoken';\n\nconst JWT_SECRET = process.env.JWT_SECRET || \"your-jwt-secret-key\";\n\nexport function setupOAuth() {\n  // Only setup OAuth if environment variables are provided\n  const googleClientId = process.env.GOOGLE_CLIENT_ID;\n  const googleClientSecret = process.env.GOOGLE_CLIENT_SECRET;\n  const githubClientId = process.env.GITHUB_CLIENT_ID;\n  const githubClientSecret = process.env.GITHUB_CLIENT_SECRET;\n\n  // Google OAuth Strategy\n  if (googleClientId && googleClientSecret) {\n    passport.use(new GoogleStrategy({\n      clientID: googleClientId,\n      clientSecret: googleClientSecret,\n      callbackURL: \"/api/auth/google/callback\"\n    },\n    async (accessToken: string, refreshToken: string, profile: any, done: any) => {\n    try {\n      let user = await storage.getUserByGoogleId(profile.id);\n      \n      if (user) {\n        return done(null, user);\n      }\n      \n      // Check if user exists with same email\n      if (profile.emails && profile.emails[0]) {\n        user = await storage.getUserByEmail(profile.emails[0].value);\n        if (user) {\n          // Update existing user with Google ID\n          user = await storage.updateUser(user.id, {\n            googleId: profile.id,\n            authProvider: 'google',\n            profileImageUrl: user.profileImageUrl || profile.photos?.[0]?.value,\n          });\n          return done(null, user);\n        }\n      }\n      \n      // Create new user\n      const newUser = await storage.createUser({\n        username: profile.displayName || `user_${profile.id}`,\n        email: profile.emails?.[0]?.value || '',\n        firstName: profile.name?.givenName,\n        lastName: profile.name?.familyName,\n        profileImageUrl: profile.photos?.[0]?.value,\n        googleId: profile.id,\n        authProvider: 'google',\n      });\n      \n      return done(null, newUser);\n    } catch (error) {\n      return done(error, undefined);\n    }\n    }));\n  }\n\n  // GitHub OAuth Strategy\n  if (githubClientId && githubClientSecret) {\n    passport.use(new GitHubStrategy({\n      clientID: githubClientId,\n      clientSecret: githubClientSecret,\n      callbackURL: \"/api/auth/github/callback\"\n    },\n    async (accessToken: string, refreshToken: string, profile: any, done: any) => {\n    try {\n      let user = await storage.getUserByGithubId(profile.id);\n      \n      if (user) {\n        return done(null, user);\n      }\n      \n      // Check if user exists with same email\n      if (profile.emails && profile.emails[0]) {\n        user = await storage.getUserByEmail(profile.emails[0].value);\n        if (user) {\n          // Update existing user with GitHub ID\n          user = await storage.updateUser(user.id, {\n            githubId: profile.id,\n            authProvider: 'github',\n            profileImageUrl: user.profileImageUrl || profile.photos?.[0]?.value,\n          });\n          return done(null, user);\n        }\n      }\n      \n      // Create new user\n      const newUser = await storage.createUser({\n        username: profile.username || `user_${profile.id}`,\n        email: profile.emails?.[0]?.value || '',\n        firstName: profile.displayName?.split(' ')[0],\n        lastName: profile.displayName?.split(' ').slice(1).join(' '),\n        profileImageUrl: profile.photos?.[0]?.value,\n        githubId: profile.id,\n        authProvider: 'github',\n      });\n      \n      return done(null, newUser);\n    } catch (error) {\n      return done(error, undefined);\n    }\n    }));\n  }\n\n  passport.serializeUser((user: any, done) => {\n    done(null, user.id);\n  });\n\n  passport.deserializeUser(async (id: string, done) => {\n    try {\n      const user = await storage.getUserById(id);\n      done(null, user);\n    } catch (error) {\n      done(error, null);\n    }\n  });\n}","size_bytes":3942},"server/routes.ts":{"content":"import type { Express } from \"express\";\nimport { createServer, type Server } from \"http\";\nimport { storage } from \"./storage\";\nimport {\n  insertUserSchema,\n  insertSubmissionSchema,\n  insertCommunityPostSchema,\n  insertPostCommentSchema,\n} from \"@shared/schema\";\nimport bcrypt from \"bcrypt\";\nimport jwt from \"jsonwebtoken\";\nimport passport from \"passport\";\nimport session from \"express-session\";\nimport { setupOAuth } from \"./oauth\";\n\nconst JWT_SECRET = process.env.JWT_SECRET || \"your-jwt-secret-key\";\n\n// Middleware to verify JWT token\nconst authenticateToken = (req: any, res: any, next: any) => {\n  const authHeader = req.headers[\"authorization\"];\n  const token = authHeader && authHeader.split(\" \")[1];\n\n  if (!token) {\n    return res.status(401).json({ message: \"Access token required\" });\n  }\n\n  jwt.verify(token, JWT_SECRET, (err: any, user: any) => {\n    if (err) {\n      return res.status(403).json({ message: \"Invalid or expired token\" });\n    }\n    req.user = user;\n    next();\n  });\n};\n\nexport async function registerRoutes(app: Express): Promise<Server> {\n  // Configure session middleware\n  app.use(\n    session({\n      secret: process.env.SESSION_SECRET || \"fallback-secret\",\n      resave: false,\n      saveUninitialized: false,\n      cookie: { secure: false }, // Set to true in production with HTTPS\n    })\n  );\n\n  // Initialize passport and session\n  app.use(passport.initialize());\n  app.use(passport.session());\n  setupOAuth();\n\n  // Auth routes\n  app.post(\"/api/auth/register\", async (req, res) => {\n    try {\n      const userData = insertUserSchema.parse(req.body);\n\n      // Check if user already exists\n      const existingUser = await storage.getUserByEmail(userData.email);\n      if (existingUser) {\n        return res.status(400).json({ message: \"User already exists\" });\n      }\n\n      const existingUsername = await storage.getUserByUsername(\n        userData.username\n      );\n      if (existingUsername) {\n        return res.status(400).json({ message: \"Username already taken\" });\n      }\n\n      // Hash password\n      const saltRounds = 10;\n      const passwordHash = userData.passwordHash\n        ? await bcrypt.hash(userData.passwordHash, saltRounds)\n        : undefined;\n\n      // Create user\n      const user = await storage.createUser({\n        ...userData,\n        passwordHash,\n      });\n\n      // Generate JWT token\n      const token = jwt.sign(\n        { userId: user.id, username: user.username },\n        JWT_SECRET,\n        {\n          expiresIn: \"24h\",\n        }\n      );\n\n      res.status(201).json({\n        message: \"User created successfully\",\n        token,\n        user: {\n          id: user.id,\n          username: user.username,\n          email: user.email,\n          firstName: user.firstName,\n          lastName: user.lastName,\n          profileImageUrl: user.profileImageUrl,\n          problemsSolved: user.problemsSolved,\n        },\n      });\n    } catch (error) {\n      console.error(\"Registration error:\", error);\n      res.status(500).json({ message: \"Failed to create user\" });\n    }\n  });\n\n  app.post(\"/api/auth/login\", async (req, res) => {\n    try {\n      const { email, password } = req.body;\n\n      // Find user by email\n      const user = await storage.getUserByEmail(email);\n      if (!user) {\n        return res.status(401).json({ message: \"Invalid credentials\" });\n      }\n\n      // Verify password\n      if (!user.passwordHash) {\n        return res.status(401).json({ message: \"Invalid credentials\" });\n      }\n      const isValidPassword = await bcrypt.compare(password, user.passwordHash);\n      if (!isValidPassword) {\n        return res.status(401).json({ message: \"Invalid credentials\" });\n      }\n\n      // Generate JWT token\n      const token = jwt.sign(\n        { userId: user.id, username: user.username },\n        JWT_SECRET,\n        {\n          expiresIn: \"24h\",\n        }\n      );\n\n      res.json({\n        token,\n        user: {\n          id: user.id,\n          username: user.username,\n          email: user.email,\n          firstName: user.firstName,\n          lastName: user.lastName,\n          profileImageUrl: user.profileImageUrl,\n          problemsSolved: user.problemsSolved,\n        },\n      });\n    } catch (error) {\n      console.error(\"Login error:\", error);\n      res.status(500).json({ message: \"Login failed\" });\n    }\n  });\n\n  // Get current user\n  app.get(\"/api/auth/user\", authenticateToken, async (req: any, res) => {\n    try {\n      const user = await storage.getUserById(req.user.userId);\n      if (!user) {\n        return res.status(404).json({ message: \"User not found\" });\n      }\n\n      res.json({\n        id: user.id,\n        username: user.username,\n        email: user.email,\n        firstName: user.firstName,\n        lastName: user.lastName,\n        profileImageUrl: user.profileImageUrl,\n        problemsSolved: user.problemsSolved,\n      });\n    } catch (error) {\n      console.error(\"Get user error:\", error);\n      res.status(500).json({ message: \"Failed to fetch user\" });\n    }\n  });\n\n  // Problem routes\n  app.get(\"/api/problems\", async (req, res) => {\n    try {\n      const { difficulty } = req.query;\n      const authHeader = req.headers[\"authorization\"];\n      const token = authHeader && authHeader.split(\" \")[1];\n      let problems;\n\n      // If user is authenticated, include solve status\n      if (token) {\n        try {\n          const decoded = jwt.verify(token, JWT_SECRET) as any;\n          const userId = decoded.userId;\n\n          if (difficulty && typeof difficulty === \"string\") {\n            problems = await storage.getProblemsByDifficultyForUser(\n              difficulty,\n              userId\n            );\n          } else {\n            problems = await storage.getAllProblemsForUser(userId);\n          }\n        } catch (jwtError) {\n          // If token is invalid, fall back to unauthenticated response\n          if (difficulty && typeof difficulty === \"string\") {\n            problems = await storage.getProblemsByDifficulty(difficulty);\n          } else {\n            problems = await storage.getAllProblems();\n          }\n        }\n      } else {\n        // Unauthenticated user\n        if (difficulty && typeof difficulty === \"string\") {\n          problems = await storage.getProblemsByDifficulty(difficulty);\n        } else {\n          problems = await storage.getAllProblems();\n        }\n      }\n\n      res.json(problems);\n    } catch (error) {\n      console.error(\"Get problems error:\", error);\n      res.status(500).json({ message: \"Failed to fetch problems\" });\n    }\n  });\n\n  app.get(\"/api/problems/:id\", async (req, res) => {\n    try {\n      const problem = await storage.getProblemById(req.params.id);\n      if (!problem) {\n        return res.status(404).json({ message: \"Problem not found\" });\n      }\n      res.json(problem);\n    } catch (error) {\n      console.error(\"Get problem error:\", error);\n      res.status(500).json({ message: \"Failed to fetch problem\" });\n    }\n  });\n\n  // OAuth routes\n  app.get(\n    \"/api/auth/google\",\n    passport.authenticate(\"google\", { scope: [\"profile\", \"email\"] })\n  );\n\n  app.get(\n    \"/api/auth/google/callback\",\n    passport.authenticate(\"google\", { failureRedirect: \"/\" }),\n    (req, res) => {\n      // Successful authentication, create JWT and redirect\n      const user = req.user as any;\n      const token = jwt.sign({ userId: user.id }, JWT_SECRET, {\n        expiresIn: \"7d\",\n      });\n      res.redirect(`/?token=${token}`);\n    }\n  );\n\n  app.get(\n    \"/api/auth/github\",\n    passport.authenticate(\"github\", { scope: [\"user:email\"] })\n  );\n\n  app.get(\n    \"/api/auth/github/callback\",\n    passport.authenticate(\"github\", { failureRedirect: \"/\" }),\n    (req, res) => {\n      // Successful authentication, create JWT and redirect\n      const user = req.user as any;\n      const token = jwt.sign({ userId: user.id }, JWT_SECRET, {\n        expiresIn: \"7d\",\n      });\n      res.redirect(`/?token=${token}`);\n    }\n  );\n\n  // Submission routes\n  app.post(\"/api/submissions\", authenticateToken, async (req: any, res) => {\n    try {\n      const submissionData = insertSubmissionSchema.parse({\n        ...req.body,\n        userId: req.user.userId,\n      });\n\n      // Simulate SQL query execution\n      const isCorrect = await simulateQueryExecution(\n        submissionData.query,\n        submissionData.problemId\n      );\n      const executionTime = Math.floor(Math.random() * 500) + 50; // Random execution time\n\n      const submission = await storage.createSubmission({\n        ...submissionData,\n        isCorrect,\n        executionTime,\n      });\n\n      // If correct, update user progress\n      if (isCorrect) {\n        await storage.updateUserProgress(req.user.userId);\n      }\n\n      res.json({\n        ...submission,\n        message: isCorrect\n          ? \"Query executed successfully!\"\n          : \"Query has errors or incorrect result\",\n      });\n    } catch (error) {\n      console.error(\"Submission error:\", error);\n      res.status(500).json({ message: \"Failed to submit solution\" });\n    }\n  });\n\n  app.get(\n    \"/api/submissions/user/:userId\",\n    authenticateToken,\n    async (req: any, res) => {\n      try {\n        // Users can only view their own submissions\n        if (req.params.userId !== req.user.userId) {\n          return res.status(403).json({ message: \"Access denied\" });\n        }\n\n        const submissions = await storage.getUserSubmissions(req.params.userId);\n        res.json(submissions);\n      } catch (error) {\n        console.error(\"Get submissions error:\", error);\n        res.status(500).json({ message: \"Failed to fetch submissions\" });\n      }\n    }\n  );\n\n  // Leaderboard routes\n  app.get(\"/api/leaderboard\", async (req, res) => {\n    try {\n      const { limit } = req.query;\n      const leaderboard = await storage.getLeaderboard(\n        limit ? parseInt(limit as string) : undefined\n      );\n\n      res.json(\n        leaderboard.map((user) => ({\n          id: user.id,\n          username: user.username,\n          firstName: user.firstName,\n          lastName: user.lastName,\n          profileImageUrl: user.profileImageUrl,\n          problemsSolved: user.problemsSolved,\n        }))\n      );\n    } catch (error) {\n      console.error(\"Get leaderboard error:\", error);\n      res.status(500).json({ message: \"Failed to fetch leaderboard\" });\n    }\n  });\n\n  // Community routes\n  app.get(\"/api/community/posts\", async (req, res) => {\n    try {\n      const posts = await storage.getAllCommunityPosts();\n      res.json(\n        posts.map((post) => ({\n          ...post,\n          user: {\n            id: post.user.id,\n            username: post.user.username,\n            firstName: post.user.firstName,\n            lastName: post.user.lastName,\n            profileImageUrl: post.user.profileImageUrl,\n          },\n        }))\n      );\n    } catch (error) {\n      console.error(\"Get community posts error:\", error);\n      res.status(500).json({ message: \"Failed to fetch community posts\" });\n    }\n  });\n\n  app.post(\"/api/community/posts\", authenticateToken, async (req: any, res) => {\n    try {\n      const postData = insertCommunityPostSchema.parse({\n        ...req.body,\n        userId: req.user.userId,\n      });\n\n      const post = await storage.createCommunityPost(postData);\n      res.status(201).json(post);\n    } catch (error) {\n      console.error(\"Create post error:\", error);\n      res.status(500).json({ message: \"Failed to create post\" });\n    }\n  });\n\n  app.post(\n    \"/api/community/posts/:postId/like\",\n    authenticateToken,\n    async (req: any, res) => {\n      try {\n        await storage.likeCommunityPost(req.user.userId, req.params.postId);\n        res.json({ message: \"Post liked successfully\" });\n      } catch (error) {\n        console.error(\"Like post error:\", error);\n        res.status(500).json({ message: \"Failed to like post\" });\n      }\n    }\n  );\n\n  app.delete(\n    \"/api/community/posts/:postId/like\",\n    authenticateToken,\n    async (req: any, res) => {\n      try {\n        await storage.unlikeCommunityPost(req.user.userId, req.params.postId);\n        res.json({ message: \"Post unliked successfully\" });\n      } catch (error) {\n        console.error(\"Unlike post error:\", error);\n        res.status(500).json({ message: \"Failed to unlike post\" });\n      }\n    }\n  );\n\n  app.get(\"/api/community/posts/:postId/comments\", async (req, res) => {\n    try {\n      const comments = await storage.getPostComments(req.params.postId);\n      res.json(\n        comments.map((comment) => ({\n          ...comment,\n          user: {\n            id: comment.user.id,\n            username: comment.user.username,\n            firstName: comment.user.firstName,\n            lastName: comment.user.lastName,\n            profileImageUrl: comment.user.profileImageUrl,\n          },\n        }))\n      );\n    } catch (error) {\n      console.error(\"Get comments error:\", error);\n      res.status(500).json({ message: \"Failed to fetch comments\" });\n    }\n  });\n\n  app.post(\n    \"/api/community/posts/:postId/comments\",\n    authenticateToken,\n    async (req: any, res) => {\n      try {\n        const commentData = insertPostCommentSchema.parse({\n          ...req.body,\n          userId: req.user.userId,\n          postId: req.params.postId,\n        });\n\n        const comment = await storage.createPostComment(commentData);\n        res.status(201).json(comment);\n      } catch (error) {\n        console.error(\"Create comment error:\", error);\n        res.status(500).json({ message: \"Failed to create comment\" });\n      }\n    }\n  );\n\n  const httpServer = createServer(app);\n  return httpServer;\n}\n\n// Helper functions\nasync function simulateQueryExecution(\n  query: string,\n  problemId: string\n): Promise<boolean> {\n  // This is a simplified simulation. In a real app, you'd run the query against a sandbox database.\n  const problem = await storage.getProblemById(problemId);\n  if (!problem) return false;\n\n  // Simple validation: check if query contains basic SQL keywords and structure\n  const normalizedQuery = query.toLowerCase().trim();\n\n  // Basic checks for different problem types\n  if (problem.title.toLowerCase().includes(\"sum\")) {\n    return (\n      normalizedQuery.includes(\"select\") &&\n      normalizedQuery.includes(\"from\") &&\n      (normalizedQuery.includes(\"sum\") || normalizedQuery.includes(\"+\"))\n    );\n  }\n\n  if (problem.title.toLowerCase().includes(\"join\")) {\n    return (\n      normalizedQuery.includes(\"select\") &&\n      normalizedQuery.includes(\"from\") &&\n      normalizedQuery.includes(\"join\")\n    );\n  }\n\n  // Default validation: must contain SELECT and FROM\n  return normalizedQuery.includes(\"select\") && normalizedQuery.includes(\"from\");\n}\n","size_bytes":14613},"server/storage.ts":{"content":"import {\n  users,\n  problems,\n  submissions,\n  communityPosts,\n  postLikes,\n  postComments,\n  type User,\n  type InsertUser,\n  type Problem,\n  type InsertProblem,\n  type Submission,\n  type InsertSubmission,\n  type CommunityPost,\n  type InsertCommunityPost,\n  type PostComment,\n  type InsertPostComment,\n} from \"@shared/schema\";\nimport { db } from \"./db\";\nimport { eq, desc, sql, and } from \"drizzle-orm\";\n\nexport interface IStorage {\n  // User operations\n  getUserById(id: string): Promise<User | undefined>;\n  getUserByEmail(email: string): Promise<User | undefined>;\n  getUserByUsername(username: string): Promise<User | undefined>;\n  getUserByGoogleId(googleId: string): Promise<User | undefined>;\n  getUserByGithubId(githubId: string): Promise<User | undefined>;\n  createUser(user: InsertUser): Promise<User>;\n  updateUser(id: string, user: Partial<InsertUser>): Promise<User>;\n  getLeaderboard(limit?: number): Promise<User[]>;\n  updateUserProgress(userId: string): Promise<void>;\n\n  // Problem operations\n  getAllProblems(): Promise<(Problem & { solvedCount: number })[]>;\n  getAllProblemsForUser(userId: string): Promise<(Problem & { solvedCount: number; isUserSolved: boolean })[]>;\n  getProblemById(id: string): Promise<Problem | undefined>;\n  getProblemsByDifficulty(difficulty: string): Promise<(Problem & { solvedCount: number })[]>;\n  getProblemsByDifficultyForUser(difficulty: string, userId: string): Promise<(Problem & { solvedCount: number; isUserSolved: boolean })[]>;\n  createProblem(problem: InsertProblem): Promise<Problem>;\n\n  // Submission operations\n  createSubmission(submission: InsertSubmission): Promise<Submission>;\n  getUserSubmissions(userId: string): Promise<Submission[]>;\n  getUserSubmissionForProblem(userId: string, problemId: string): Promise<Submission[]>;\n\n  // Community operations\n  getAllCommunityPosts(): Promise<(CommunityPost & { user: User })[]>;\n  createCommunityPost(post: InsertCommunityPost): Promise<CommunityPost>;\n  likeCommunityPost(userId: string, postId: string): Promise<void>;\n  unlikeCommunityPost(userId: string, postId: string): Promise<void>;\n  getPostComments(postId: string): Promise<(PostComment & { user: User })[]>;\n  createPostComment(comment: InsertPostComment): Promise<PostComment>;\n\n}\n\nexport class DatabaseStorage implements IStorage {\n  // User operations\n  async getUserById(id: string): Promise<User | undefined> {\n    const [user] = await db.select().from(users).where(eq(users.id, id));\n    return user;\n  }\n\n  async getUserByEmail(email: string): Promise<User | undefined> {\n    const [user] = await db.select().from(users).where(eq(users.email, email));\n    return user;\n  }\n\n  async getUserByUsername(username: string): Promise<User | undefined> {\n    const [user] = await db.select().from(users).where(eq(users.username, username));\n    return user;\n  }\n\n  async getUserByGoogleId(googleId: string): Promise<User | undefined> {\n    const [user] = await db.select().from(users).where(eq(users.googleId, googleId));\n    return user;\n  }\n\n  async getUserByGithubId(githubId: string): Promise<User | undefined> {\n    const [user] = await db.select().from(users).where(eq(users.githubId, githubId));\n    return user;\n  }\n\n  async createUser(userData: InsertUser): Promise<User> {\n    const [user] = await db.insert(users).values(userData).returning();\n    return user;\n  }\n\n  async updateUser(id: string, userData: Partial<InsertUser>): Promise<User> {\n    const [user] = await db\n      .update(users)\n      .set({ ...userData, updatedAt: new Date() })\n      .where(eq(users.id, id))\n      .returning();\n    return user;\n  }\n\n  async getLeaderboard(limit: number = 50): Promise<User[]> {\n    return await db\n      .select()\n      .from(users)\n      .orderBy(desc(users.problemsSolved))\n      .limit(limit);\n  }\n\n  async updateUserProgress(userId: string): Promise<void> {\n    await db\n      .update(users)\n      .set({\n        problemsSolved: sql`${users.problemsSolved} + 1`,\n        updatedAt: new Date(),\n      })\n      .where(eq(users.id, userId));\n  }\n\n  // Problem operations\n  async getAllProblems(): Promise<(Problem & { solvedCount: number })[]> {\n    const result = await db\n      .select({\n        id: problems.id,\n        title: problems.title,\n        description: problems.description,\n        difficulty: problems.difficulty,\n        tags: problems.tags,\n        companies: problems.companies,\n        schema: problems.schema,\n        expectedOutput: problems.expectedOutput,\n        hints: problems.hints,\n        createdAt: problems.createdAt,\n        updatedAt: problems.updatedAt,\n        solvedCount: sql<number>`COALESCE(COUNT(DISTINCT CASE WHEN ${submissions.isCorrect} = true THEN ${submissions.userId} END), 0)`,\n      })\n      .from(problems)\n      .leftJoin(submissions, eq(problems.id, submissions.problemId))\n      .groupBy(problems.id)\n      .orderBy(problems.title);\n    \n    return result.map(row => ({\n      ...row,\n      solvedCount: Number(row.solvedCount)\n    }));\n  }\n\n  async getProblemById(id: string): Promise<Problem | undefined> {\n    const [problem] = await db.select().from(problems).where(eq(problems.id, id));\n    return problem;\n  }\n\n  async getProblemsByDifficulty(difficulty: string): Promise<(Problem & { solvedCount: number })[]> {\n    const result = await db\n      .select({\n        id: problems.id,\n        title: problems.title,\n        description: problems.description,\n        difficulty: problems.difficulty,\n        tags: problems.tags,\n        companies: problems.companies,\n        schema: problems.schema,\n        expectedOutput: problems.expectedOutput,\n        hints: problems.hints,\n        createdAt: problems.createdAt,\n        updatedAt: problems.updatedAt,\n        solvedCount: sql<number>`COALESCE(COUNT(DISTINCT CASE WHEN ${submissions.isCorrect} = true THEN ${submissions.userId} END), 0)`,\n      })\n      .from(problems)\n      .leftJoin(submissions, eq(problems.id, submissions.problemId))\n      .where(eq(problems.difficulty, difficulty))\n      .groupBy(problems.id)\n      .orderBy(problems.title);\n    \n    return result.map(row => ({\n      ...row,\n      solvedCount: Number(row.solvedCount)\n    }));\n  }\n\n  async getAllProblemsForUser(userId: string): Promise<(Problem & { solvedCount: number; isUserSolved: boolean })[]> {\n    const result = await db\n      .select({\n        id: problems.id,\n        title: problems.title,\n        description: problems.description,\n        difficulty: problems.difficulty,\n        tags: problems.tags,\n        companies: problems.companies,\n        schema: problems.schema,\n        expectedOutput: problems.expectedOutput,\n        hints: problems.hints,\n        createdAt: problems.createdAt,\n        updatedAt: problems.updatedAt,\n        solvedCount: sql<number>`COALESCE(COUNT(DISTINCT CASE WHEN ${submissions.isCorrect} = true THEN ${submissions.userId} END), 0)`,\n        isUserSolved: sql<boolean>`COALESCE(MAX(CASE WHEN ${submissions.userId} = ${userId} AND ${submissions.isCorrect} = true THEN 1 ELSE 0 END), 0) = 1`,\n      })\n      .from(problems)\n      .leftJoin(submissions, eq(problems.id, submissions.problemId))\n      .groupBy(problems.id)\n      .orderBy(problems.title);\n    \n    return result.map(row => ({\n      ...row,\n      solvedCount: Number(row.solvedCount),\n      isUserSolved: Boolean(row.isUserSolved)\n    }));\n  }\n\n  async getProblemsByDifficultyForUser(difficulty: string, userId: string): Promise<(Problem & { solvedCount: number; isUserSolved: boolean })[]> {\n    const result = await db\n      .select({\n        id: problems.id,\n        title: problems.title,\n        description: problems.description,\n        difficulty: problems.difficulty,\n        tags: problems.tags,\n        companies: problems.companies,\n        schema: problems.schema,\n        expectedOutput: problems.expectedOutput,\n        hints: problems.hints,\n        createdAt: problems.createdAt,\n        updatedAt: problems.updatedAt,\n        solvedCount: sql<number>`COALESCE(COUNT(DISTINCT CASE WHEN ${submissions.isCorrect} = true THEN ${submissions.userId} END), 0)`,\n        isUserSolved: sql<boolean>`COALESCE(MAX(CASE WHEN ${submissions.userId} = ${userId} AND ${submissions.isCorrect} = true THEN 1 ELSE 0 END), 0) = 1`,\n      })\n      .from(problems)\n      .leftJoin(submissions, eq(problems.id, submissions.problemId))\n      .where(eq(problems.difficulty, difficulty))\n      .groupBy(problems.id)\n      .orderBy(problems.title);\n    \n    return result.map(row => ({\n      ...row,\n      solvedCount: Number(row.solvedCount),\n      isUserSolved: Boolean(row.isUserSolved)\n    }));\n  }\n\n  async createProblem(problemData: InsertProblem): Promise<Problem> {\n    const [problem] = await db.insert(problems).values([problemData]).returning();\n    return problem;\n  }\n\n\n  // Submission operations\n  async createSubmission(submissionData: InsertSubmission): Promise<Submission> {\n    const [submission] = await db.insert(submissions).values(submissionData).returning();\n    return submission;\n  }\n\n  async getUserSubmissions(userId: string): Promise<Submission[]> {\n    return await db\n      .select()\n      .from(submissions)\n      .where(eq(submissions.userId, userId))\n      .orderBy(desc(submissions.submittedAt));\n  }\n\n  async getUserSubmissionForProblem(userId: string, problemId: string): Promise<Submission[]> {\n    return await db\n      .select()\n      .from(submissions)\n      .where(and(eq(submissions.userId, userId), eq(submissions.problemId, problemId)))\n      .orderBy(desc(submissions.submittedAt));\n  }\n\n  // Community operations\n  async getAllCommunityPosts(): Promise<(CommunityPost & { user: User })[]> {\n    return await db\n      .select({\n        id: communityPosts.id,\n        userId: communityPosts.userId,\n        content: communityPosts.content,\n        codeSnippet: communityPosts.codeSnippet,\n        likes: communityPosts.likes,\n        comments: communityPosts.comments,\n        createdAt: communityPosts.createdAt,\n        updatedAt: communityPosts.updatedAt,\n        user: users,\n      })\n      .from(communityPosts)\n      .innerJoin(users, eq(communityPosts.userId, users.id))\n      .orderBy(desc(communityPosts.createdAt));\n  }\n\n  async createCommunityPost(postData: InsertCommunityPost): Promise<CommunityPost> {\n    const [post] = await db.insert(communityPosts).values(postData).returning();\n    return post;\n  }\n\n  async likeCommunityPost(userId: string, postId: string): Promise<void> {\n    await db.insert(postLikes).values({ userId, postId });\n    await db\n      .update(communityPosts)\n      .set({ likes: sql`${communityPosts.likes} + 1` })\n      .where(eq(communityPosts.id, postId));\n  }\n\n  async unlikeCommunityPost(userId: string, postId: string): Promise<void> {\n    await db\n      .delete(postLikes)\n      .where(and(eq(postLikes.userId, userId), eq(postLikes.postId, postId)));\n    await db\n      .update(communityPosts)\n      .set({ likes: sql`${communityPosts.likes} - 1` })\n      .where(eq(communityPosts.id, postId));\n  }\n\n  async getPostComments(postId: string): Promise<(PostComment & { user: User })[]> {\n    return await db\n      .select({\n        id: postComments.id,\n        userId: postComments.userId,\n        postId: postComments.postId,\n        content: postComments.content,\n        createdAt: postComments.createdAt,\n        user: users,\n      })\n      .from(postComments)\n      .innerJoin(users, eq(postComments.userId, users.id))\n      .where(eq(postComments.postId, postId))\n      .orderBy(postComments.createdAt);\n  }\n\n  async createPostComment(commentData: InsertPostComment): Promise<PostComment> {\n    const [comment] = await db.insert(postComments).values(commentData).returning();\n    await db\n      .update(communityPosts)\n      .set({ comments: sql`${communityPosts.comments} + 1` })\n      .where(eq(communityPosts.id, commentData.postId));\n    return comment;\n  }\n\n}\n\nexport const storage = new DatabaseStorage();\n","size_bytes":11877},"server/vite.ts":{"content":"import express, { type Express } from \"express\";\nimport fs from \"fs\";\nimport path from \"path\";\nimport { createServer as createViteServer, createLogger } from \"vite\";\nimport { type Server } from \"http\";\nimport viteConfig from \"../vite.config\";\nimport { nanoid } from \"nanoid\";\n\nconst viteLogger = createLogger();\n\nexport function log(message: string, source = \"express\") {\n  const formattedTime = new Date().toLocaleTimeString(\"en-US\", {\n    hour: \"numeric\",\n    minute: \"2-digit\",\n    second: \"2-digit\",\n    hour12: true,\n  });\n\n  console.log(`${formattedTime} [${source}] ${message}`);\n}\n\nexport async function setupVite(app: Express, server: Server) {\n  // Environment detection for Vite configuration\n  const isReplit = !!(process.env.REPL_ID || process.env.REPLIT_DEV_DOMAIN);\n  \n  const serverOptions = {\n    middlewareMode: true,\n    hmr: { server },\n    // allowedHosts: true is crucial for Replit but also safe for local\n    allowedHosts: true as const,\n    // For local development, you might want to enable these for better debugging\n    ...(isReplit ? {} : {\n      cors: true,\n      strictPort: false,\n    }),\n  };\n\n  log(`ðŸ”§ Setting up Vite for ${isReplit ? 'Replit' : 'Local'} environment`);\n\n  const vite = await createViteServer({\n    ...viteConfig,\n    configFile: false,\n    customLogger: {\n      ...viteLogger,\n      error: (msg, options) => {\n        viteLogger.error(msg, options);\n        if (isReplit) {\n          // In Replit, exit on error to trigger restart\n          process.exit(1);\n        } else {\n          // In local development, just log the error but don't exit\n          console.error('Vite error:', msg);\n        }\n      },\n    },\n    server: serverOptions,\n    appType: \"custom\",\n  });\n\n  app.use(vite.middlewares);\n  app.use(\"*\", async (req, res, next) => {\n    const url = req.originalUrl;\n\n    try {\n      const clientTemplate = path.resolve(\n        import.meta.dirname,\n        \"..\",\n        \"client\",\n        \"index.html\",\n      );\n\n      // always reload the index.html file from disk incase it changes\n      let template = await fs.promises.readFile(clientTemplate, \"utf-8\");\n      template = template.replace(\n        `src=\"/src/main.tsx\"`,\n        `src=\"/src/main.tsx?v=${nanoid()}\"`,\n      );\n      const page = await vite.transformIndexHtml(url, template);\n      res.status(200).set({ \"Content-Type\": \"text/html\" }).end(page);\n    } catch (e) {\n      vite.ssrFixStacktrace(e as Error);\n      next(e);\n    }\n  });\n}\n\nexport function serveStatic(app: Express) {\n  const distPath = path.resolve(import.meta.dirname, \"public\");\n\n  if (!fs.existsSync(distPath)) {\n    throw new Error(\n      `Could not find the build directory: ${distPath}, make sure to build the client first`,\n    );\n  }\n\n  app.use(express.static(distPath));\n\n  // fall through to index.html if the file doesn't exist\n  app.use(\"*\", (_req, res) => {\n    res.sendFile(path.resolve(distPath, \"index.html\"));\n  });\n}\n","size_bytes":2929},"shared/schema.ts":{"content":"import { sql } from \"drizzle-orm\";\nimport { pgTable, text, varchar, integer, timestamp, boolean, jsonb, index } from \"drizzle-orm/pg-core\";\nimport { relations } from \"drizzle-orm\";\nimport { createInsertSchema } from \"drizzle-zod\";\nimport { z } from \"zod\";\n\n// Users table\nexport const users = pgTable(\"users\", {\n  id: varchar(\"id\").primaryKey().default(sql`gen_random_uuid()`),\n  username: varchar(\"username\", { length: 50 }).notNull().unique(),\n  email: varchar(\"email\", { length: 255 }).notNull().unique(),\n  passwordHash: text(\"password_hash\"),\n  firstName: varchar(\"first_name\", { length: 50 }),\n  lastName: varchar(\"last_name\", { length: 50 }),\n  profileImageUrl: text(\"profile_image_url\"),\n  googleId: varchar(\"google_id\", { length: 255 }),\n  githubId: varchar(\"github_id\", { length: 255 }),\n  authProvider: varchar(\"auth_provider\", { length: 20 }).default(\"email\").notNull(),\n  problemsSolved: integer(\"problems_solved\").default(0).notNull(),\n  createdAt: timestamp(\"created_at\").defaultNow().notNull(),\n  updatedAt: timestamp(\"updated_at\").defaultNow().notNull(),\n});\n\n// SQL Problems table\nexport const problems = pgTable(\"problems\", {\n  id: varchar(\"id\").primaryKey().default(sql`gen_random_uuid()`),\n  title: varchar(\"title\", { length: 200 }).notNull(),\n  description: text(\"description\").notNull(),\n  difficulty: varchar(\"difficulty\", { length: 20 }).notNull(), // Easy, Medium, Hard\n  tags: jsonb(\"tags\").$type<string[]>().default([]).notNull(),\n  companies: jsonb(\"companies\").$type<string[]>().default([]).notNull(),\n  schema: text(\"schema\").notNull(), // SQL schema definition\n  expectedOutput: text(\"expected_output\").notNull(),\n  hints: jsonb(\"hints\").$type<string[]>().default([]).notNull(),\n  createdAt: timestamp(\"created_at\").defaultNow().notNull(),\n  updatedAt: timestamp(\"updated_at\").defaultNow().notNull(),\n});\n\n// User submissions table\nexport const submissions = pgTable(\"submissions\", {\n  id: varchar(\"id\").primaryKey().default(sql`gen_random_uuid()`),\n  userId: varchar(\"user_id\").notNull().references(() => users.id),\n  problemId: varchar(\"problem_id\").notNull().references(() => problems.id),\n  query: text(\"query\").notNull(),\n  isCorrect: boolean(\"is_correct\").notNull(),\n  executionTime: integer(\"execution_time\"), // in milliseconds\n  submittedAt: timestamp(\"submitted_at\").defaultNow().notNull(),\n});\n\n// Community posts table\nexport const communityPosts = pgTable(\"community_posts\", {\n  id: varchar(\"id\").primaryKey().default(sql`gen_random_uuid()`),\n  userId: varchar(\"user_id\").notNull().references(() => users.id),\n  content: text(\"content\").notNull(),\n  codeSnippet: text(\"code_snippet\"),\n  likes: integer(\"likes\").default(0).notNull(),\n  comments: integer(\"comments\").default(0).notNull(),\n  createdAt: timestamp(\"created_at\").defaultNow().notNull(),\n  updatedAt: timestamp(\"updated_at\").defaultNow().notNull(),\n});\n\n// Post likes table\nexport const postLikes = pgTable(\"post_likes\", {\n  id: varchar(\"id\").primaryKey().default(sql`gen_random_uuid()`),\n  userId: varchar(\"user_id\").notNull().references(() => users.id),\n  postId: varchar(\"post_id\").notNull().references(() => communityPosts.id),\n  createdAt: timestamp(\"created_at\").defaultNow().notNull(),\n});\n\n// Post comments table\nexport const postComments = pgTable(\"post_comments\", {\n  id: varchar(\"id\").primaryKey().default(sql`gen_random_uuid()`),\n  userId: varchar(\"user_id\").notNull().references(() => users.id),\n  postId: varchar(\"post_id\").notNull().references(() => communityPosts.id),\n  content: text(\"content\").notNull(),\n  createdAt: timestamp(\"created_at\").defaultNow().notNull(),\n});\n\n\n// Relations\nexport const usersRelations = relations(users, ({ many }) => ({\n  submissions: many(submissions),\n  communityPosts: many(communityPosts),\n  postLikes: many(postLikes),\n  postComments: many(postComments),\n}));\n\nexport const problemsRelations = relations(problems, ({ many }) => ({\n  submissions: many(submissions),\n}));\n\nexport const submissionsRelations = relations(submissions, ({ one }) => ({\n  user: one(users, {\n    fields: [submissions.userId],\n    references: [users.id],\n  }),\n  problem: one(problems, {\n    fields: [submissions.problemId],\n    references: [problems.id],\n  }),\n}));\n\nexport const communityPostsRelations = relations(communityPosts, ({ one, many }) => ({\n  user: one(users, {\n    fields: [communityPosts.userId],\n    references: [users.id],\n  }),\n  likes: many(postLikes),\n  comments: many(postComments),\n}));\n\nexport const postLikesRelations = relations(postLikes, ({ one }) => ({\n  user: one(users, {\n    fields: [postLikes.userId],\n    references: [users.id],\n  }),\n  post: one(communityPosts, {\n    fields: [postLikes.postId],\n    references: [communityPosts.id],\n  }),\n}));\n\nexport const postCommentsRelations = relations(postComments, ({ one }) => ({\n  user: one(users, {\n    fields: [postComments.userId],\n    references: [users.id],\n  }),\n  post: one(communityPosts, {\n    fields: [postComments.postId],\n    references: [communityPosts.id],\n  }),\n}));\n\n\n// Insert schemas\nexport const insertUserSchema = createInsertSchema(users).omit({\n  id: true,\n  createdAt: true,\n  updatedAt: true,\n}).extend({\n  passwordHash: z.string().optional(),\n});\n\nexport const insertProblemSchema = createInsertSchema(problems).omit({\n  id: true,\n  createdAt: true,\n  updatedAt: true,\n});\n\nexport const insertSubmissionSchema = createInsertSchema(submissions).omit({\n  id: true,\n  submittedAt: true,\n});\n\nexport const insertCommunityPostSchema = createInsertSchema(communityPosts).omit({\n  id: true,\n  likes: true,\n  comments: true,\n  createdAt: true,\n  updatedAt: true,\n});\n\nexport const insertPostCommentSchema = createInsertSchema(postComments).omit({\n  id: true,\n  createdAt: true,\n});\n\n\n// Types\nexport type User = typeof users.$inferSelect;\nexport type InsertUser = z.infer<typeof insertUserSchema>;\n\nexport type Problem = typeof problems.$inferSelect;\nexport type InsertProblem = z.infer<typeof insertProblemSchema>;\n\nexport type Submission = typeof submissions.$inferSelect;\nexport type InsertSubmission = z.infer<typeof insertSubmissionSchema>;\n\nexport type CommunityPost = typeof communityPosts.$inferSelect;\nexport type InsertCommunityPost = z.infer<typeof insertCommunityPostSchema>;\n\nexport type PostComment = typeof postComments.$inferSelect;\nexport type InsertPostComment = z.infer<typeof insertPostCommentSchema>;\n\n","size_bytes":6349},"client/src/App.tsx":{"content":"import { Switch, Route, useLocation } from \"wouter\";\nimport { QueryClientProvider } from \"@tanstack/react-query\";\nimport { queryClient } from \"./lib/queryClient\";\nimport { Toaster } from \"@/components/ui/toaster\";\nimport { TooltipProvider } from \"@/components/ui/tooltip\";\nimport { AuthProvider, useAuth } from \"@/hooks/use-auth\";\nimport Landing from \"@/pages/landing\";\nimport Home from \"@/pages/home\";\nimport Problems from \"@/pages/problems\";\nimport ProblemDetail from \"@/pages/problem-detail\";\nimport Leaderboard from \"@/pages/leaderboard\";\nimport Community from \"@/pages/community\";\nimport Submissions from \"@/pages/submissions\";\nimport AdminPanel from \"@/pages/admin-panel\";\nimport NotFound from \"@/pages/not-found\";\nimport Navbar from \"@/components/navbar\";\n\nfunction AppRouter() {\n  const { isAuthenticated, isLoading } = useAuth();\n  const [location] = useLocation();\n\n  if (isLoading) {\n    return (\n      <div className=\"min-h-screen flex items-center justify-center\">\n        <div className=\"text-center\">\n          <div className=\"w-8 h-8 border-4 border-primary border-t-transparent rounded-full animate-spin mx-auto mb-4\"></div>\n          <p className=\"text-muted-foreground\">Loading SQLGym...</p>\n        </div>\n      </div>\n    );\n  }\n\n  // Hide navbar on problem detail pages (routes like /problems/:id)\n  const isOnProblemDetailPage = location.startsWith('/problems/');\n\n  return (\n    <>\n      {isAuthenticated && !isOnProblemDetailPage && <Navbar />}\n      <Switch>\n        {!isAuthenticated ? (\n          <Route path=\"/\" component={Landing} />\n        ) : (\n          <>\n            <Route path=\"/\" component={Home} />\n            <Route path=\"/problems\" component={Problems} />\n            <Route path=\"/problems/:id\" component={ProblemDetail} />\n            <Route path=\"/leaderboard\" component={Leaderboard} />\n            <Route path=\"/community\" component={Community} />\n            <Route path=\"/submissions\" component={Submissions} />\n            <Route path=\"/admin-panel\" component={AdminPanel} />\n          </>\n        )}\n        <Route component={NotFound} />\n      </Switch>\n    </>\n  );\n}\n\nfunction App() {\n  return (\n    <QueryClientProvider client={queryClient}>\n      <TooltipProvider>\n        <AuthProvider>\n          <Toaster />\n          <AppRouter />\n        </AuthProvider>\n      </TooltipProvider>\n    </QueryClientProvider>\n  );\n}\n\nexport default App;\n","size_bytes":2395},"client/src/index.css":{"content":"@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');\n@tailwind base;\n@tailwind components;\n@tailwind utilities;\n\n:root {\n  --background: hsl(0 0% 100%);\n  --foreground: hsl(222 84% 4.9%);\n  --card: hsl(0 0% 100%);\n  --card-foreground: hsl(222 84% 4.9%);\n  --popover: hsl(0 0% 100%);\n  --popover-foreground: hsl(222 84% 4.9%);\n  --primary: hsl(24 95% 53%);\n  --primary-foreground: hsl(210 40% 98%);\n  --secondary: hsl(210 40% 96%);\n  --secondary-foreground: hsl(222 47% 11%);\n  --muted: hsl(210 40% 96%);\n  --muted-foreground: hsl(215 16% 47%);\n  --accent: hsl(210 40% 96%);\n  --accent-foreground: hsl(222 47% 11%);\n  --destructive: hsl(0 84% 60%);\n  --destructive-foreground: hsl(210 40% 98%);\n  --border: hsl(214 32% 91%);\n  --input: hsl(214 32% 91%);\n  --ring: hsl(24 95% 53%);\n  --chart-1: hsl(24 95% 53%);\n  --chart-2: hsl(159.7826 100% 36.0784%);\n  --chart-3: hsl(42.0290 92.8251% 56.2745%);\n  --chart-4: hsl(147.1429 78.5047% 41.9608%);\n  --chart-5: hsl(341.4894 75.2000% 50.9804%);\n  --sidebar: hsl(210 40% 96%);\n  --sidebar-foreground: hsl(222 84% 4.9%);\n  --sidebar-primary: hsl(24 95% 53%);\n  --sidebar-primary-foreground: hsl(210 40% 98%);\n  --sidebar-accent: hsl(210 40% 96%);\n  --sidebar-accent-foreground: hsl(222 47% 11%);\n  --sidebar-border: hsl(214 32% 91%);\n  --sidebar-ring: hsl(24 95% 53%);\n  --font-sans: 'Inter', system-ui, sans-serif;\n  --font-serif: Georgia, serif;\n  --font-mono: 'Courier New', monospace;\n  --radius: 8px;\n  --shadow-2xs: 0px 2px 0px 0px hsl(24 95% 53% / 0.00);\n  --shadow-xs: 0px 2px 0px 0px hsl(24 95% 53% / 0.00);\n  --shadow-sm: 0px 2px 0px 0px hsl(24 95% 53% / 0.00), 0px 1px 2px -1px hsl(24 95% 53% / 0.00);\n  --shadow: 0px 2px 0px 0px hsl(24 95% 53% / 0.00), 0px 1px 2px -1px hsl(24 95% 53% / 0.00);\n  --shadow-md: 0px 2px 0px 0px hsl(24 95% 53% / 0.00), 0px 2px 4px -1px hsl(24 95% 53% / 0.00);\n  --shadow-lg: 0px 2px 0px 0px hsl(24 95% 53% / 0.00), 0px 4px 6px -1px hsl(24 95% 53% / 0.00);\n  --shadow-xl: 0px 2px 0px 0px hsl(24 95% 53% / 0.00), 0px 8px 10px -1px hsl(24 95% 53% / 0.00);\n  --shadow-2xl: 0px 2px 0px 0px hsl(24 95% 53% / 0.00);\n  --tracking-normal: 0em;\n  --spacing: 0.25rem;\n}\n\n.dark {\n  --background: hsl(0 0% 0%);\n  --foreground: hsl(200 6.6667% 91.1765%);\n  --card: hsl(228 9.8039% 10%);\n  --card-foreground: hsl(0 0% 85.0980%);\n  --popover: hsl(0 0% 0%);\n  --popover-foreground: hsl(200 6.6667% 91.1765%);\n  --primary: hsl(24 95% 53%);\n  --primary-foreground: hsl(210 40% 98%);\n  --secondary: hsl(195.0000 15.3846% 94.9020%);\n  --secondary-foreground: hsl(210 25% 7.8431%);\n  --muted: hsl(0 0% 9.4118%);\n  --muted-foreground: hsl(210 3.3898% 46.2745%);\n  --accent: hsl(205.7143 70% 7.8431%);\n  --accent-foreground: hsl(24 95% 53%);\n  --destructive: hsl(0 84% 60%);\n  --destructive-foreground: hsl(210 40% 98%);\n  --border: hsl(210 5.2632% 14.9020%);\n  --input: hsl(207.6923 27.6596% 18.4314%);\n  --ring: hsl(24 95% 53%);\n}\n\n@layer base {\n  * {\n    @apply border-border;\n  }\n\n  body {\n    @apply font-sans antialiased bg-background text-foreground;\n  }\n}\n\n/* Gym-inspired custom styles */\n.dumbbell-btn {\n  position: relative;\n  transition: all 0.3s ease;\n}\n\n.dumbbell-btn:hover {\n  transform: translateY(-2px);\n}\n\n.progress-weight {\n  background: linear-gradient(90deg, var(--primary) 0%, #f59e0b 100%);\n  animation: fillProgress 2s ease-in-out;\n  transition: width 0.3s ease;\n}\n\n@keyframes fillProgress {\n  from {\n    width: 0%;\n  }\n\n  to {\n    width: var(--progress-width);\n  }\n}\n\n.weight-plate {\n  width: 12px;\n  height: 12px;\n  border-radius: 50%;\n  background: var(--primary);\n  position: relative;\n}\n\n.weight-plate::before {\n  content: '';\n  position: absolute;\n  top: 50%;\n  left: 50%;\n  transform: translate(-50%, -50%);\n  width: 6px;\n  height: 6px;\n  border-radius: 50%;\n  background: white;\n}\n\n.syntax-highlight {\n  font-family: var(--font-mono);\n  background: var(--muted);\n  padding: 1rem;\n  border-radius: 6px;\n  border-left: 4px solid var(--primary);\n  overflow-x: auto;\n  /* Adds horizontal scroll for very long content */\n  max-width: 100%;\n  /* Ensures it doesn't break container */\n}\n\n.syntax-highlight pre {\n  white-space: pre-wrap;\n  /* Allows wrapping while preserving formatting */\n  overflow-wrap: break-word;\n  /* Breaks long words if needed */\n  word-break: break-all;\n  /* Breaks long SQL statements at any character */\n  margin: 0;\n  /* Remove default pre margin */\n}\n\n.code-editor {\n  font-family: var(--font-mono);\n  background: hsl(222 47% 11%);\n  color: hsl(210 40% 98%);\n}\n\n/* Smooth scrolling */\nhtml {\n  scroll-behavior: smooth;\n}\n\n/* Custom scrollbar */\n::-webkit-scrollbar {\n  width: 8px;\n}\n\n::-webkit-scrollbar-track {\n  background: var(--muted);\n}\n\n::-webkit-scrollbar-thumb {\n  background: var(--border);\n  border-radius: 4px;\n}\n\n::-webkit-scrollbar-thumb:hover {\n  background: var(--muted-foreground);\n}\n\n/* Console output styling */\n.console-output {\n  background: #1a1a1a;\n  color: #e0e0e0;\n  font-family: 'JetBrains Mono', 'Fira Code', 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;\n  font-size: 13px;\n  line-height: 1.4;\n  padding: 16px;\n  border-radius: 6px;\n  white-space: pre-wrap;\n  overflow-x: auto;\n  border: 1px solid #333;\n}\n\n.console-output.error {\n  color: #ff6b6b;\n  background: #2d1b1b;\n  border-color: #8b0000;\n}\n\n.console-output.success {\n  border-left: 4px solid #28ca42;\n}\n\n/* Make sure pre elements don't have conflicting styles */\npre.console-output {\n  margin: 0;\n  font-family: inherit;\n}","size_bytes":5468},"client/src/main.tsx":{"content":"import { createRoot } from \"react-dom/client\";\nimport App from \"./App\";\nimport \"./index.css\";\n\ncreateRoot(document.getElementById(\"root\")!).render(<App />);\n","size_bytes":157},"client/src/components/navbar.tsx":{"content":"import { Link, useLocation } from 'wouter';\nimport { Dumbbell, User, LogOut } from 'lucide-react';\nimport { Button } from '@/components/ui/button';\nimport {\n  DropdownMenu,\n  DropdownMenuContent,\n  DropdownMenuItem,\n  DropdownMenuTrigger,\n} from '@/components/ui/dropdown-menu';\nimport { useAuth } from '@/hooks/use-auth';\nimport { Avatar, AvatarFallback, AvatarImage } from '@/components/ui/avatar';\n\nexport default function Navbar() {\n  const [location] = useLocation();\n  const { user, logout } = useAuth();\n\n  const handleLogout = () => {\n    logout();\n  };\n\n  const navItems = [\n    { href: '/', label: 'Home' },\n    { href: '/problems', label: 'Problems' },\n    { href: '/leaderboard', label: 'Leaderboard' },\n    { href: '/community', label: 'Community' },\n    { href: '/submissions', label: 'Submissions' },\n  ];\n\n  return (\n    <nav className=\"bg-white border-b border-border shadow-sm sticky top-0 z-50\">\n      <div className=\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8\">\n        <div className=\"flex justify-between items-center h-12\">\n          <div className=\"flex items-center space-x-8\">\n            <Link href=\"/\" className=\"flex items-center space-x-2\" data-testid=\"link-home\">\n              <Dumbbell className=\"text-primary text-xl\" />\n              <span className=\"text-xl font-bold text-foreground\">SQLGym</span>\n            </Link>\n            \n            <div className=\"hidden md:flex items-center space-x-6\">\n              {navItems.map((item) => (\n                <Link\n                  key={item.href}\n                  href={item.href}\n                  className={`font-medium transition-colors text-sm ${\n                    location === item.href\n                      ? 'text-primary'\n                      : 'text-foreground hover:text-primary'\n                  }`}\n                  data-testid={`link-${item.label.toLowerCase()}`}\n                >\n                  {item.label}\n                </Link>\n              ))}\n            </div>\n          </div>\n          \n          <div className=\"flex items-center space-x-3\">\n            <DropdownMenu>\n              <DropdownMenuTrigger asChild>\n                <Button variant=\"ghost\" className=\"relative h-8 w-8 rounded-full\" data-testid=\"button-profile\">\n                  <Avatar className=\"h-8 w-8\">\n                    <AvatarImage src={user?.profileImageUrl} alt={user?.username} />\n                    <AvatarFallback>\n                      {user?.username?.charAt(0).toUpperCase() || 'U'}\n                    </AvatarFallback>\n                  </Avatar>\n                </Button>\n              </DropdownMenuTrigger>\n              <DropdownMenuContent className=\"w-56\" align=\"end\" forceMount>\n                <div className=\"flex items-center space-x-2 p-2\">\n                  <Avatar className=\"h-8 w-8\">\n                    <AvatarImage src={user?.profileImageUrl} alt={user?.username} />\n                    <AvatarFallback>\n                      {user?.username?.charAt(0).toUpperCase() || 'U'}\n                    </AvatarFallback>\n                  </Avatar>\n                  <div className=\"flex flex-col space-y-1\">\n                    <p className=\"text-sm font-medium\">{user?.username}</p>\n                    <p className=\"text-xs text-muted-foreground\">{user?.problemsSolved || 0} problems solved</p>\n                  </div>\n                </div>\n                <DropdownMenuItem onClick={handleLogout} data-testid=\"button-logout\">\n                  <LogOut className=\"mr-2 h-4 w-4\" />\n                  <span>Log out</span>\n                </DropdownMenuItem>\n              </DropdownMenuContent>\n            </DropdownMenu>\n          </div>\n        </div>\n      </div>\n    </nav>\n  );\n}\n","size_bytes":3700},"client/src/components/progress-bar.tsx":{"content":"import { useEffect, useRef } from 'react';\n\ninterface ProgressBarProps {\n  value: number;\n  max: number;\n  className?: string;\n  showText?: boolean;\n}\n\nexport default function ProgressBar({ value, max, className = '', showText = true }: ProgressBarProps) {\n  const progressRef = useRef<HTMLDivElement>(null);\n  const percentage = Math.min((value / max) * 100, 100);\n\n  useEffect(() => {\n    if (progressRef.current) {\n      progressRef.current.style.setProperty('--progress-width', `${percentage}%`);\n      // Trigger animation\n      progressRef.current.classList.add('progress-weight');\n    }\n  }, [percentage]);\n\n  return (\n    <div className={`space-y-2 ${className}`}>\n      {showText && (\n        <div className=\"flex justify-between text-sm\">\n          <span className=\"text-muted-foreground\">Progress</span>\n          <span className=\"font-medium text-foreground\">{Math.round(percentage)}%</span>\n        </div>\n      )}\n      <div className=\"w-full bg-muted rounded-full h-3\">\n        <div \n          ref={progressRef}\n          className=\"h-3 rounded-full transition-all duration-300\"\n          style={{ \n            background: 'linear-gradient(90deg, var(--primary) 0%, #f59e0b 100%)',\n            width: `${percentage}%`\n          }}\n        />\n      </div>\n      {showText && (\n        <div className=\"flex items-center space-x-2 mt-2\">\n          <div className=\"weight-plate\" />\n          <span className=\"text-xs text-muted-foreground\">{value}/{max} completed</span>\n        </div>\n      )}\n    </div>\n  );\n}\n","size_bytes":1524},"client/src/components/sql-editor.tsx":{"content":"import { useState, useMemo, useCallback, useEffect } from 'react';\nimport { Play, Save, Lightbulb, Dumbbell, TrendingUp, ChevronDown } from 'lucide-react';\nimport { Button } from '@/components/ui/button';\nimport { Card, CardContent, CardHeader } from '@/components/ui/card';\nimport { Alert, AlertDescription } from '@/components/ui/alert';\nimport CodeMirror from '@uiw/react-codemirror';\nimport { sql, PostgreSQL } from '@codemirror/lang-sql';\nimport { autocompletion } from '@codemirror/autocomplete';\nimport { EditorView, keymap, placeholder } from '@codemirror/view';\nimport { defaultKeymap, indentWithTab } from '@codemirror/commands';\nimport { oneDark } from '@codemirror/theme-one-dark';\n\ninterface SQLEditorProps {\n  initialQuery?: string;\n  onRunQuery: (query: string) => Promise<any>;\n  onSubmitSolution: (query: string) => Promise<any>;\n  hints?: string[];\n  className?: string;\n  problem?: any; // Add problem prop to determine database type\n}\n\nexport default function SQLEditor({ \n  initialQuery = '', \n  onRunQuery,\n  onSubmitSolution,\n  hints = [],\n  className = '',\n  problem\n}: SQLEditorProps) {\n  const [query, setQuery] = useState(initialQuery);\n  const [result, setResult] = useState<any>(null);\n  const [isRunning, setIsRunning] = useState(false);\n  const [isSubmitting, setIsSubmitting] = useState(false);\n  const [showHint, setShowHint] = useState(false);\n  const [hintIndex, setHintIndex] = useState(0);\n\n  // Detect dark mode with reactivity\n  const [isDarkMode, setIsDarkMode] = useState(() => {\n    if (typeof window !== 'undefined') {\n      return document.documentElement.classList.contains('dark');\n    }\n    return false;\n  });\n\n  useEffect(() => {\n    const observer = new MutationObserver(() => {\n      setIsDarkMode(document.documentElement.classList.contains('dark'));\n    });\n    \n    observer.observe(document.documentElement, {\n      attributes: true,\n      attributeFilter: ['class']\n    });\n    \n    return () => observer.disconnect();\n  }, []);\n\n  const handleRunQuery = useCallback(async () => {\n    if (!query.trim()) return;\n    \n    setIsRunning(true);\n    try {\n      const result = await onRunQuery(query);\n      setResult(result);\n    } catch (error) {\n      setResult({\n        error: true,\n        message: error instanceof Error ? error.message : 'Query execution failed',\n      });\n    } finally {\n      setIsRunning(false);\n    }\n  }, [query, onRunQuery]);\n\n  const handleSubmitSolution = useCallback(async () => {\n    if (!query.trim()) return;\n    \n    setIsSubmitting(true);\n    try {\n      const result = await onSubmitSolution(query);\n      setResult(result);\n      // Also save to localStorage as backup\n      localStorage.setItem('sqlgym_last_query', query);\n    } catch (error) {\n      setResult({\n        error: true,\n        message: error instanceof Error ? error.message : 'Submission failed',\n      });\n    } finally {\n      setIsSubmitting(false);\n    }\n  }, [query, onSubmitSolution]);\n\n  const handleSave = () => {\n    localStorage.setItem('sqlgym_last_query', query);\n    console.log('Saving query:', query);\n  };\n\n\n  const handleShowHint = () => {\n    setShowHint(true);\n  };\n\n  const handleNextHint = () => {\n    if (hintIndex < hints.length - 1) {\n      setHintIndex(hintIndex + 1);\n    }\n  };\n\n  // Configure CodeMirror extensions and theme\n  const extensions = useMemo(() => [\n    sql({\n      dialect: PostgreSQL,\n      upperCaseKeywords: true,\n      schema: {\n        customers: ['id', 'name', 'email'],\n        employees: ['id', 'name', 'department'],\n        orders: ['id', 'customer_id', 'total'],\n        order_items: ['id', 'order_id', 'price', 'quantity'],\n      }\n    }),\n    autocompletion(),\n    EditorView.lineWrapping,\n    placeholder('-- Write your SQL query here\\nSELECT \\n    column1,\\n    column2\\nFROM table_name\\nWHERE condition;'),\n    keymap.of([\n      ...defaultKeymap,\n      indentWithTab,\n      {\n        key: 'Mod-Enter',\n        run: () => {\n          handleRunQuery();\n          return true;\n        }\n      }\n    ])\n  ], [handleRunQuery]);\n\n  const theme = useMemo(() => {\n    if (isDarkMode) {\n      return [oneDark];\n    }\n    return [\n      EditorView.theme({\n        '&': {\n          color: 'hsl(var(--foreground))',\n          backgroundColor: 'hsl(var(--background))',\n        },\n        '.cm-content': {\n          padding: '16px',\n          fontSize: '14px',\n          fontFamily: 'var(--font-mono)',\n          minHeight: '200px', // Reduced height\n        },\n        '.cm-focused': {\n          outline: 'none',\n        },\n        '.cm-editor': {\n          borderRadius: '0',\n        },\n        '.cm-scroller': {\n          fontFamily: 'var(--font-mono)',\n        },\n        '.cm-line': {\n          lineHeight: '1.5',\n        },\n        '&.cm-focused .cm-cursor': {\n          borderLeftColor: 'hsl(var(--primary))',\n        },\n        '&.cm-focused .cm-selectionBackground, .cm-selectionBackground': {\n          backgroundColor: 'hsl(var(--primary) / 0.2)',\n        }\n      })\n    ];\n  }, [isDarkMode]);\n\n  return (\n    <div className={`w-full max-w-6xl mx-auto ${className}`}>\n      {/* Training Zone (Input Section) - Reduced spacing */}\n      <div className=\"mb-3\">\n        <Card className=\"overflow-hidden\">\n          {/* Input Header - Reduced padding */}\n          <CardHeader className=\"bg-muted/50 px-4 py-2 border-b border-border\">\n            <div className=\"flex items-center justify-between\">\n              <div className=\"flex items-center space-x-2\">\n                <Dumbbell className=\"h-4 w-4 text-primary\" />\n                <h3 className=\"text-base font-semibold text-foreground\">Training Zone</h3>\n              </div>\n              <div className=\"flex items-center space-x-2 text-sm text-muted-foreground\">\n                <span>{problem?.parquet_data_source ? 'DuckDB' : 'PostgreSQL 14'}</span>\n                <ChevronDown className=\"h-4 w-4\" />\n              </div>\n            </div>\n          </CardHeader>\n          \n          {/* Code Editor - Reduced height */}\n          <CardContent className=\"p-0\">\n            <div className=\"relative\">\n              <CodeMirror\n                value={query}\n                onChange={(value) => setQuery(value)}\n                height=\"200px\" // Fixed compact height\n                theme={theme}\n                extensions={extensions}\n                basicSetup={{\n                  lineNumbers: true,\n                  foldGutter: true,\n                  dropCursor: false,\n                  allowMultipleSelections: false,\n                  indentOnInput: true,\n                  bracketMatching: true,\n                  closeBrackets: true,\n                  autocompletion: false,\n                  highlightSelectionMatches: false,\n                  searchKeymap: true,\n                  tabSize: 2,\n                }}\n                data-testid=\"editor-sql\"\n                className=\"sqlgym-editor\"\n              />\n              <div className=\"absolute top-2 right-2 text-xs text-muted-foreground\">\n                Ctrl/Cmd + Enter to run\n              </div>\n            </div>\n          </CardContent>\n        </Card>\n      </div>\n\n      {/* Gym Controls - Moved up and made more compact */}\n      <div className=\"flex flex-wrap gap-2 mb-3\">\n        <Button\n          onClick={handleRunQuery}\n          disabled={isRunning || !query.trim()}\n          className=\"bg-primary text-primary-foreground hover:bg-primary/90 font-semibold flex items-center\"\n          data-testid=\"button-run-query\"\n        >\n          <Dumbbell className=\"mr-2 h-4 w-4\" />\n          {isRunning ? 'Running...' : 'Run Code'}\n        </Button>\n        \n        <Button \n          onClick={handleSave} \n          variant=\"outline\"\n          className=\"flex items-center\"\n        >\n          <Save className=\"mr-2 h-4 w-4\" />\n          Save Query\n        </Button>\n        \n\n        {hints.length > 0 && (\n          <Button \n            onClick={handleShowHint} \n            variant=\"outline\"\n            className=\"text-primary hover:bg-primary/10 flex items-center\"\n          >\n            <Lightbulb className=\"mr-2 h-4 w-4\" />\n            Get Hint\n          </Button>\n        )}\n\n        {/* Check Solution button like in your screenshot */}\n        <Button\n          onClick={handleSubmitSolution}\n          disabled={isSubmitting || !query.trim()}\n          className=\"bg-green-600 text-white hover:bg-green-700 font-semibold flex items-center ml-auto\"\n          data-testid=\"button-submit\"\n        >\n          âœ“ {isSubmitting ? 'Submitting...' : 'Check Solution'}\n        </Button>\n      </div>\n\n      {/* Trainer Tips - More compact */}\n      {showHint && hints.length > 0 && (\n        <Alert className=\"border-primary/20 bg-primary/5 mb-3 py-3\">\n          <div className=\"flex\">\n            <Lightbulb className=\"h-4 w-4 text-primary mt-0.5 mr-2 flex-shrink-0\" />\n            <AlertDescription className=\"text-foreground\">\n              <strong>ðŸ’¡ Hint {hintIndex + 1}:</strong> {hints[hintIndex]}\n              {hintIndex < hints.length - 1 && (\n                <Button \n                  onClick={handleNextHint}\n                  variant=\"link\" \n                  className=\"p-0 ml-2 text-primary underline text-sm\"\n                >\n                  Next hint â†’\n                </Button>\n              )}\n            </AlertDescription>\n          </div>\n        </Alert>\n      )}\n\n      {/* Performance Report (Output Section) - Only appears when there are results */}\n      {result && (\n        <div className=\"mb-4\">\n          <Card className=\"overflow-hidden\">\n            <CardHeader className=\"bg-muted/50 px-4 py-2 border-b border-border\">\n              <div className=\"flex items-center justify-between\">\n                <div className=\"flex items-center space-x-2\">\n                  <TrendingUp className=\"h-4 w-4 text-primary\" />\n                  <h3 className=\"text-base font-semibold text-foreground\">Query Results</h3>\n                </div>\n                {result && !result.error && (\n                  <div className=\"text-sm text-muted-foreground\">\n                    Execution: {result.executionTime || 0}ms\n                  </div>\n                )}\n              </div>\n            </CardHeader>\n            \n            <CardContent className=\"p-4\">\n              {result.error ? (\n                <div className=\"space-y-3\">\n                  <div className=\"flex items-center space-x-2 text-red-600 dark:text-red-400\">\n                    <div className=\"w-2 h-2 bg-red-500 rounded-full\"></div>\n                    <span className=\"font-medium text-sm\">Query Failed</span>\n                  </div>\n                  <div className=\"bg-red-50 dark:bg-red-950/30 border border-red-200 dark:border-red-800 rounded p-3\">\n                    <p className=\"text-red-800 dark:text-red-200 text-sm font-mono\">{result.message}</p>\n                  </div>\n                </div>\n              ) : (\n                <div className=\"space-y-3\">\n                  <div className=\"flex items-center space-x-2 text-green-600 dark:text-green-400\">\n                    <div className=\"w-2 h-2 bg-green-500 rounded-full\"></div>\n                    <span className=\"font-medium text-sm\">\n                      {result.isCorrect ? 'Perfect! ðŸ†' : 'Query Executed'}\n                    </span>\n                  </div>\n                  \n                  {result.isCorrect && (\n                    <div className=\"bg-green-50 dark:bg-green-950/30 border border-green-200 dark:border-green-800 rounded p-3\">\n                      <div className=\"flex items-center space-x-2\">\n                        <span className=\"text-lg\">ðŸŽ‰</span>\n                        <div>\n                          <p className=\"text-green-800 dark:text-green-200 font-medium text-sm\">Excellent work!</p>\n                          <p className=\"text-green-700 dark:text-green-300 text-sm\">Solution is correct!</p>\n                        </div>\n                      </div>\n                    </div>\n                  )}\n                  \n                  <div className=\"bg-muted/50 rounded p-3\">\n                    <p className=\"text-sm text-muted-foreground mb-2\">ðŸ“Š Results:</p>\n                    <div className=\"font-mono text-sm bg-background rounded border p-2\">\n                      <p className=\"mb-2\">Status: {result.isCorrect ? 'Correct' : 'Check again'}</p>\n                      <p className=\"mb-2\">Performance: {result.query_result?.execution_time_ms || result.executionTime || 0}ms</p>\n                      {result.query_result?.result && result.query_result.result.length > 0 ? (\n                        <div className=\"overflow-x-auto mt-2\">\n                          <table className=\"w-full text-xs border-collapse\">\n                            <thead>\n                              <tr>\n                                {Object.keys(result.query_result.result[0]).map((column) => (\n                                  <th key={column} className=\"border border-border px-2 py-1 bg-muted font-semibold text-left\">\n                                    {column}\n                                  </th>\n                                ))}\n                              </tr>\n                            </thead>\n                            <tbody>\n                              {result.query_result.result.slice(0, 10).map((row, index) => (\n                                <tr key={index}>\n                                  {Object.values(row).map((value, colIndex) => (\n                                    <td key={colIndex} className=\"border border-border px-2 py-1\">\n                                      {String(value)}\n                                    </td>\n                                  ))}\n                                </tr>\n                              ))}\n                            </tbody>\n                          </table>\n                          {result.query_result.result.length > 10 && (\n                            <p className=\"text-muted-foreground mt-2 text-xs\">\n                              Showing first 10 of {result.query_result.rows_affected} rows\n                            </p>\n                          )}\n                          <p className=\"text-muted-foreground mt-1 text-xs\">\n                            {result.query_result.rows_affected} rows returned\n                          </p>\n                        </div>\n                      ) : (\n                        <p className=\"text-muted-foreground mt-1 text-xs\">\n                          No data returned\n                        </p>\n                      )}\n                    </div>\n                  </div>\n                </div>\n              )}\n            </CardContent>\n          </Card>\n        </div>\n      )}\n\n      {/* Empty state hint when no result - Only shows when no results */}\n      {!result && (\n        <div className=\"text-center py-4 text-muted-foreground text-sm\">\n          ðŸ’¡ Write your SQL query above and click \"Run Code\" to see results\n        </div>\n      )}\n    </div>\n  );\n}","size_bytes":15006},"client/src/hooks/use-auth.tsx":{"content":"import { useState, useEffect, createContext, useContext } from 'react';\nimport { authApi } from '@/lib/auth';\n\ninterface User {\n  id: string;\n  username: string;\n  email: string;\n  firstName?: string;\n  lastName?: string;\n  profileImageUrl?: string;\n  xp: number;\n  level: string;\n  problemsSolved: number;\n  premium?: boolean;\n}\n\ninterface AuthContextType {\n  user: User | null;\n  token: string | null;\n  login: (token: string, user: User) => void;\n  logout: () => void;\n  isAuthenticated: boolean;\n  isLoading: boolean;\n}\n\nconst AuthContext = createContext<AuthContextType | undefined>(undefined);\n\nexport function AuthProvider({ children }: { children: React.ReactNode }) {\n  const [user, setUser] = useState<User | null>(null);\n  const [token, setToken] = useState<string | null>(null);\n  const [isLoading, setIsLoading] = useState(true);\n\n  useEffect(() => {\n    const initializeAuth = async () => {\n      // Development bypass - automatically log in as a fake user\n      if (import.meta.env.DEV) {\n        const fakeUser: User = {\n          id: 'dev-user-1',\n          username: 'developer',\n          email: 'dev@sqlgym.dev',\n          firstName: 'Dev',\n          lastName: 'User',\n          xp: 1000,\n          level: 'Advanced',\n          problemsSolved: 25,\n          premium: true\n        };\n        const fakeToken = 'dev-token-123';\n        \n        setUser(fakeUser);\n        setToken(fakeToken);\n        localStorage.setItem('auth_token', fakeToken);\n        localStorage.setItem('auth_user', JSON.stringify(fakeUser));\n        setIsLoading(false);\n        return;\n      }\n\n      try {\n        // Always attempt to fetch current user data from backend\n        // This supports both token-based and cookie-based authentication\n        const userData = await authApi.getCurrentUser();\n        setUser(userData);\n        \n        // Get token from localStorage if available (for token-based auth)\n        const storedToken = localStorage.getItem('auth_token');\n        if (storedToken) {\n          setToken(storedToken);\n        }\n        \n        // Update localStorage with fresh user data\n        localStorage.setItem('auth_user', JSON.stringify(userData));\n      } catch (error) {\n        // Authentication failed - clear all auth state\n        setToken(null);\n        setUser(null);\n        localStorage.removeItem('auth_token');\n        localStorage.removeItem('auth_user');\n      } finally {\n        setIsLoading(false);\n      }\n    };\n\n    initializeAuth();\n  }, []);\n\n  const login = (newToken: string, newUser: User) => {\n    setToken(newToken);\n    setUser(newUser);\n    localStorage.setItem('auth_token', newToken);\n    localStorage.setItem('auth_user', JSON.stringify(newUser));\n  };\n\n  const logout = () => {\n    setToken(null);\n    setUser(null);\n    localStorage.removeItem('auth_token');\n    localStorage.removeItem('auth_user');\n  };\n\n  const value = {\n    user,\n    token,\n    login,\n    logout,\n    isAuthenticated: !!user && !!token,\n    isLoading,\n  };\n\n  return (\n    <AuthContext.Provider value={value}>\n      {children}\n    </AuthContext.Provider>\n  );\n}\n\nexport function useAuth() {\n  const context = useContext(AuthContext);\n  if (context === undefined) {\n    throw new Error('useAuth must be used within an AuthProvider');\n  }\n  return context;\n}\n","size_bytes":3287},"client/src/hooks/use-mobile.tsx":{"content":"import * as React from \"react\"\n\nconst MOBILE_BREAKPOINT = 768\n\nexport function useIsMobile() {\n  const [isMobile, setIsMobile] = React.useState<boolean | undefined>(undefined)\n\n  React.useEffect(() => {\n    const mql = window.matchMedia(`(max-width: ${MOBILE_BREAKPOINT - 1}px)`)\n    const onChange = () => {\n      setIsMobile(window.innerWidth < MOBILE_BREAKPOINT)\n    }\n    mql.addEventListener(\"change\", onChange)\n    setIsMobile(window.innerWidth < MOBILE_BREAKPOINT)\n    return () => mql.removeEventListener(\"change\", onChange)\n  }, [])\n\n  return !!isMobile\n}\n","size_bytes":565},"client/src/hooks/use-toast.ts":{"content":"import * as React from \"react\"\n\nimport type {\n  ToastActionElement,\n  ToastProps,\n} from \"@/components/ui/toast\"\n\nconst TOAST_LIMIT = 1\nconst TOAST_REMOVE_DELAY = 1000000\n\ntype ToasterToast = ToastProps & {\n  id: string\n  title?: React.ReactNode\n  description?: React.ReactNode\n  action?: ToastActionElement\n}\n\nconst actionTypes = {\n  ADD_TOAST: \"ADD_TOAST\",\n  UPDATE_TOAST: \"UPDATE_TOAST\",\n  DISMISS_TOAST: \"DISMISS_TOAST\",\n  REMOVE_TOAST: \"REMOVE_TOAST\",\n} as const\n\nlet count = 0\n\nfunction genId() {\n  count = (count + 1) % Number.MAX_SAFE_INTEGER\n  return count.toString()\n}\n\ntype ActionType = typeof actionTypes\n\ntype Action =\n  | {\n      type: ActionType[\"ADD_TOAST\"]\n      toast: ToasterToast\n    }\n  | {\n      type: ActionType[\"UPDATE_TOAST\"]\n      toast: Partial<ToasterToast>\n    }\n  | {\n      type: ActionType[\"DISMISS_TOAST\"]\n      toastId?: ToasterToast[\"id\"]\n    }\n  | {\n      type: ActionType[\"REMOVE_TOAST\"]\n      toastId?: ToasterToast[\"id\"]\n    }\n\ninterface State {\n  toasts: ToasterToast[]\n}\n\nconst toastTimeouts = new Map<string, ReturnType<typeof setTimeout>>()\n\nconst addToRemoveQueue = (toastId: string) => {\n  if (toastTimeouts.has(toastId)) {\n    return\n  }\n\n  const timeout = setTimeout(() => {\n    toastTimeouts.delete(toastId)\n    dispatch({\n      type: \"REMOVE_TOAST\",\n      toastId: toastId,\n    })\n  }, TOAST_REMOVE_DELAY)\n\n  toastTimeouts.set(toastId, timeout)\n}\n\nexport const reducer = (state: State, action: Action): State => {\n  switch (action.type) {\n    case \"ADD_TOAST\":\n      return {\n        ...state,\n        toasts: [action.toast, ...state.toasts].slice(0, TOAST_LIMIT),\n      }\n\n    case \"UPDATE_TOAST\":\n      return {\n        ...state,\n        toasts: state.toasts.map((t) =>\n          t.id === action.toast.id ? { ...t, ...action.toast } : t\n        ),\n      }\n\n    case \"DISMISS_TOAST\": {\n      const { toastId } = action\n\n      // ! Side effects ! - This could be extracted into a dismissToast() action,\n      // but I'll keep it here for simplicity\n      if (toastId) {\n        addToRemoveQueue(toastId)\n      } else {\n        state.toasts.forEach((toast) => {\n          addToRemoveQueue(toast.id)\n        })\n      }\n\n      return {\n        ...state,\n        toasts: state.toasts.map((t) =>\n          t.id === toastId || toastId === undefined\n            ? {\n                ...t,\n                open: false,\n              }\n            : t\n        ),\n      }\n    }\n    case \"REMOVE_TOAST\":\n      if (action.toastId === undefined) {\n        return {\n          ...state,\n          toasts: [],\n        }\n      }\n      return {\n        ...state,\n        toasts: state.toasts.filter((t) => t.id !== action.toastId),\n      }\n  }\n}\n\nconst listeners: Array<(state: State) => void> = []\n\nlet memoryState: State = { toasts: [] }\n\nfunction dispatch(action: Action) {\n  memoryState = reducer(memoryState, action)\n  listeners.forEach((listener) => {\n    listener(memoryState)\n  })\n}\n\ntype Toast = Omit<ToasterToast, \"id\">\n\nfunction toast({ ...props }: Toast) {\n  const id = genId()\n\n  const update = (props: ToasterToast) =>\n    dispatch({\n      type: \"UPDATE_TOAST\",\n      toast: { ...props, id },\n    })\n  const dismiss = () => dispatch({ type: \"DISMISS_TOAST\", toastId: id })\n\n  dispatch({\n    type: \"ADD_TOAST\",\n    toast: {\n      ...props,\n      id,\n      open: true,\n      onOpenChange: (open) => {\n        if (!open) dismiss()\n      },\n    },\n  })\n\n  return {\n    id: id,\n    dismiss,\n    update,\n  }\n}\n\nfunction useToast() {\n  const [state, setState] = React.useState<State>(memoryState)\n\n  React.useEffect(() => {\n    listeners.push(setState)\n    return () => {\n      const index = listeners.indexOf(setState)\n      if (index > -1) {\n        listeners.splice(index, 1)\n      }\n    }\n  }, [state])\n\n  return {\n    ...state,\n    toast,\n    dismiss: (toastId?: string) => dispatch({ type: \"DISMISS_TOAST\", toastId }),\n  }\n}\n\nexport { useToast, toast }\n","size_bytes":3895},"client/src/lib/auth.ts":{"content":"// Use proxy for API calls - Vite will proxy /api to the backend\nexport const API_BASE_URL = \"/api\";\n\nexport interface LoginCredentials {\n  email: string;\n  password: string;\n}\n\nexport interface RegisterCredentials {\n  username: string;\n  email: string;\n  password: string;\n  firstName?: string;\n  lastName?: string;\n}\n\nexport interface ApiResponse<T = any> {\n  message?: string;\n  token?: string;\n  user?: T;\n  [key: string]: any;\n}\n\nclass ApiError extends Error {\n  constructor(public status: number, message: string) {\n    super(message);\n    this.name = \"ApiError\";\n  }\n}\n\nasync function apiRequest<T = any>(\n  endpoint: string,\n  options: RequestInit = {}\n): Promise<T> {\n  const url = `${API_BASE_URL}${endpoint}`;\n\n  const token = localStorage.getItem(\"auth_token\");\n  const headers: Record<string, string> = {\n    \"Content-Type\": \"application/json\",\n    ...(options.headers as Record<string, string>),\n  };\n\n  if (token) {\n    headers.Authorization = `Bearer ${token}`;\n  }\n\n  const response = await fetch(url, {\n    ...options,\n    headers,\n  });\n\n  const data = await response.json();\n\n  if (!response.ok) {\n    throw new ApiError(response.status, data.message || \"An error occurred\");\n  }\n\n  return data;\n}\n\nexport const authApi = {\n  async login(credentials: LoginCredentials): Promise<ApiResponse> {\n    return apiRequest(\"/auth/login\", {\n      method: \"POST\",\n      body: JSON.stringify(credentials),\n    });\n  },\n\n  async register(credentials: RegisterCredentials): Promise<ApiResponse> {\n    return apiRequest(\"/auth/register\", {\n      method: \"POST\",\n      body: JSON.stringify(credentials),\n    });\n  },\n\n  async getCurrentUser(): Promise<any> {\n    return apiRequest(\"/auth/user\");\n  },\n};\n\nexport const problemsApi = {\n  async getAll(difficulty?: string): Promise<any[]> {\n    const query = difficulty ? `?difficulty=${difficulty}` : \"\";\n    return apiRequest(`/problems${query}`);\n  },\n\n  async getFiltered(filters?: { difficulty?: string; company?: string }): Promise<any[]> {\n    const queryParams = new URLSearchParams();\n    if (filters?.difficulty) {\n      queryParams.append('difficulty', filters.difficulty);\n    }\n    if (filters?.company) {\n      queryParams.append('company', filters.company);\n    }\n    const query = queryParams.toString() ? `?${queryParams.toString()}` : \"\";\n    return apiRequest(`/problems${query}`);\n  },\n\n  async getById(id: string): Promise<any> {\n    return apiRequest(`/problems/${id}`);\n  },\n\n  async toggleBookmark(problemId: string): Promise<any> {\n    return apiRequest(`/problems/${problemId}/bookmark`, {\n      method: \"POST\",\n    });\n  },\n\n  async toggleLike(problemId: string): Promise<any> {\n    return apiRequest(`/problems/${problemId}/like`, {\n      method: \"POST\",\n    });\n  },\n\n  async toggleUpvote(problemId: string): Promise<any> {\n    return apiRequest(`/problems/${problemId}/upvote`, {\n      method: \"POST\",\n    });\n  },\n\n  async toggleDownvote(problemId: string): Promise<any> {\n    return apiRequest(`/problems/${problemId}/downvote`, {\n      method: \"POST\",\n    });\n  },\n};\n\nexport const submissionsApi = {\n  async create(submission: { problemId: string; query: string }): Promise<any> {\n    return apiRequest(\"/submissions\", {\n      method: \"POST\",\n      body: JSON.stringify(submission),\n    });\n  },\n\n  async submit(problemId: string, query: string): Promise<any> {\n    return apiRequest(`/problems/${problemId}/submit`, {\n      method: \"POST\",\n      body: JSON.stringify({ query: query.trim() }),\n    });\n  },\n\n  async getUserSubmissions(userId: string): Promise<any[]> {\n    return apiRequest(`/submissions/user/${userId}`);\n  },\n\n  async getByProblemId(problemId: string): Promise<any[]> {\n    return apiRequest(`/problems/${problemId}/submissions`);\n  },\n\n  async testQuery(problemId: string, query: string, includeHidden: boolean = false): Promise<any> {\n    return apiRequest(`/problems/${problemId}/test`, {\n      method: \"POST\",\n      body: JSON.stringify({ \n        query: query.trim(),\n        include_hidden: includeHidden \n      }),\n    });\n  },\n\n  async testDuckDBQuery(problemId: string, query: string): Promise<any> {\n    return apiRequest(`/sandbox/duckdb/${problemId}/execute`, {\n      method: \"POST\",\n      body: JSON.stringify({ \n        query: query.trim()\n      }),\n    });\n  },\n};\n\nexport const leaderboardApi = {\n  async get(limit?: number): Promise<any[]> {\n    const query = limit ? `?limit=${limit}` : \"\";\n    return apiRequest(`/leaderboard${query}`);\n  },\n};\n\nexport const communityApi = {\n  async getPosts(): Promise<any[]> {\n    return apiRequest(\"/community/posts\");\n  },\n\n  async createPost(post: {\n    content: string;\n    codeSnippet?: string;\n  }): Promise<any> {\n    return apiRequest(\"/community/posts\", {\n      method: \"POST\",\n      body: JSON.stringify(post),\n    });\n  },\n\n  async likePost(postId: string): Promise<void> {\n    return apiRequest(`/community/posts/${postId}/like`, {\n      method: \"POST\",\n    });\n  },\n\n  async unlikePost(postId: string): Promise<void> {\n    return apiRequest(`/community/posts/${postId}/like`, {\n      method: \"DELETE\",\n    });\n  },\n\n  async getComments(postId: string): Promise<any[]> {\n    return apiRequest(`/community/posts/${postId}/comments`);\n  },\n\n  async createComment(postId: string, content: string): Promise<any> {\n    return apiRequest(`/community/posts/${postId}/comments`, {\n      method: \"POST\",\n      body: JSON.stringify({ content }),\n    });\n  },\n\n  async checkLikeStatus(postId: string): Promise<{ isLiked: boolean }> {\n    return apiRequest(`/community/posts/${postId}/like/status`);\n  },\n};\n\nexport const badgesApi = {\n  async getUserBadges(userId: string): Promise<any[]> {\n    return apiRequest(`/badges/user/${userId}`);\n  },\n};\n\nexport { ApiError };\n","size_bytes":5731},"client/src/lib/queryClient.ts":{"content":"import { QueryClient, QueryFunction } from \"@tanstack/react-query\";\n\n// API Base URL - Use proxy in development, environment variable in production\nconst API_BASE_URL = import.meta.env.VITE_API_URL || '/api';\n\nasync function throwIfResNotOk(res: Response) {\n  if (!res.ok) {\n    const text = (await res.text()) || res.statusText;\n    throw new Error(`${res.status}: ${text}`);\n  }\n}\n\nfunction getFullUrl(url: string | unknown): string {\n  // Ensure url is a string\n  const urlString = String(url);\n  \n  // If URL is already absolute, return as-is\n  if (urlString.startsWith('http')) {\n    return urlString;\n  }\n  // If URL already starts with /api, return as-is (avoid double /api/api)\n  if (urlString.startsWith('/api')) {\n    return urlString;\n  }\n  // Convert relative URLs to absolute using API base URL\n  return `${API_BASE_URL}${urlString.startsWith('/') ? urlString : `/${urlString}`}`;\n}\n\nexport async function apiRequest(\n  method: string,\n  url: string,\n  data?: unknown | undefined,\n): Promise<Response> {\n  const token = localStorage.getItem(\"auth_token\");\n  const headers: Record<string, string> = {};\n  \n  if (token) {\n    headers.Authorization = `Bearer ${token}`;\n  }\n\n  const fullUrl = getFullUrl(url);\n  \n  let body: string | FormData | undefined;\n  if (data instanceof FormData) {\n    // For FormData, don't set Content-Type - let the browser set it with boundary\n    body = data;\n  } else if (data) {\n    headers[\"Content-Type\"] = \"application/json\";\n    body = JSON.stringify(data);\n  }\n  \n  const res = await fetch(fullUrl, {\n    method,\n    headers,\n    body,\n    credentials: \"include\",\n  });\n\n  await throwIfResNotOk(res);\n  return res;\n}\n\ntype UnauthorizedBehavior = \"returnNull\" | \"throw\";\nexport const getQueryFn: <T>(options: {\n  on401: UnauthorizedBehavior;\n}) => QueryFunction<T> =\n  ({ on401: unauthorizedBehavior }) =>\n  async ({ queryKey }) => {\n    const token = localStorage.getItem(\"auth_token\");\n    const headers: Record<string, string> = {};\n    \n    if (token) {\n      headers.Authorization = `Bearer ${token}`;\n    }\n\n    const url = queryKey.join(\"/\") as string;\n    const fullUrl = getFullUrl(url);\n\n    const res = await fetch(fullUrl, {\n      headers,\n      credentials: \"include\",\n    });\n\n    if (unauthorizedBehavior === \"returnNull\" && res.status === 401) {\n      return null;\n    }\n\n    await throwIfResNotOk(res);\n    return await res.json();\n  };\n\nexport const queryClient = new QueryClient({\n  defaultOptions: {\n    queries: {\n      queryFn: getQueryFn({ on401: \"throw\" }),\n      refetchInterval: false,\n      refetchOnWindowFocus: false,\n      staleTime: Infinity,\n      retry: false,\n    },\n    mutations: {\n      retry: false,\n    },\n  },\n});\n","size_bytes":2700},"client/src/lib/utils.ts":{"content":"import { clsx, type ClassValue } from \"clsx\"\nimport { twMerge } from \"tailwind-merge\"\n\nexport function cn(...inputs: ClassValue[]) {\n  return twMerge(clsx(inputs))\n}\n","size_bytes":166},"client/src/pages/community.tsx":{"content":"import { useState } from 'react';\nimport { useQuery, useMutation, useQueryClient } from '@tanstack/react-query';\nimport { Heart, MessageCircle, Share, Code, Trophy, Image, Users, Activity, Send } from 'lucide-react';\nimport { Button } from '@/components/ui/button';\nimport { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';\nimport { Textarea } from '@/components/ui/textarea';\nimport { Avatar, AvatarFallback, AvatarImage } from '@/components/ui/avatar';\nimport { Badge } from '@/components/ui/badge';\nimport { Dialog, DialogContent, DialogHeader, DialogTitle, DialogTrigger } from '@/components/ui/dialog';\nimport { Separator } from '@/components/ui/separator';\nimport { useAuth } from '@/hooks/use-auth';\nimport { communityApi } from '@/lib/auth';\nimport { useToast } from '@/hooks/use-toast';\n\nexport default function Community() {\n  const [newPostContent, setNewPostContent] = useState('');\n  const [newPostCodeSnippet, setNewPostCodeSnippet] = useState('');\n  const [selectedPostComments, setSelectedPostComments] = useState<string | null>(null);\n  const [newComment, setNewComment] = useState('');\n  const [pendingLikes, setPendingLikes] = useState<Set<string>>(new Set());\n  const { user } = useAuth();\n  const { toast } = useToast();\n  const queryClient = useQueryClient();\n\n  const { data: posts, isLoading: postsLoading } = useQuery({\n    queryKey: ['/api/community/posts'],\n    queryFn: () => communityApi.getPosts(),\n  });\n\n  const createPostMutation = useMutation({\n    mutationFn: (postData: { content: string; codeSnippet?: string }) => \n      communityApi.createPost(postData),\n    onSuccess: () => {\n      setNewPostContent('');\n      setNewPostCodeSnippet('');\n      queryClient.invalidateQueries({ queryKey: ['/api/community/posts'] });\n      toast({\n        title: 'Success!',\n        description: 'Your post has been shared with the community.',\n      });\n    },\n    onError: (error) => {\n      toast({\n        title: 'Failed to create post',\n        description: error instanceof Error ? error.message : 'Please try again.',\n        variant: 'destructive',\n      });\n    },\n  });\n\n  const likePostMutation = useMutation({\n    mutationFn: ({ postId, isLiked }: { postId: string; isLiked: boolean }) =>\n      isLiked ? communityApi.unlikePost(postId) : communityApi.likePost(postId),\n    onMutate: async ({ postId, isLiked }) => {\n      // Add to pending likes\n      setPendingLikes(prev => new Set(prev).add(postId));\n      \n      // Cancel outgoing queries\n      await queryClient.cancelQueries({ queryKey: ['/api/community/posts'] });\n      \n      // Snapshot previous value\n      const previousPosts = queryClient.getQueryData(['/api/community/posts']);\n      \n      // Optimistically update the cache\n      queryClient.setQueryData(['/api/community/posts'], (old: any) => {\n        if (!old) return old;\n        return old.map((post: any) => {\n          if (post.id === postId) {\n            return {\n              ...post,\n              likedByCurrentUser: !isLiked,\n              likes: isLiked ? post.likes - 1 : post.likes + 1\n            };\n          }\n          return post;\n        });\n      });\n      \n      return { previousPosts };\n    },\n    onError: (error, { postId }, context) => {\n      // Revert optimistic update\n      if (context?.previousPosts) {\n        queryClient.setQueryData(['/api/community/posts'], context.previousPosts);\n      }\n      \n      toast({\n        title: 'Action failed',\n        description: error instanceof Error ? error.message : 'Please try again.',\n        variant: 'destructive',\n      });\n    },\n    onSettled: (data, error, { postId }) => {\n      // Remove from pending likes\n      setPendingLikes(prev => {\n        const newSet = new Set(prev);\n        newSet.delete(postId);\n        return newSet;\n      });\n      \n      // Invalidate and refetch\n      queryClient.invalidateQueries({ queryKey: ['/api/community/posts'] });\n    },\n  });\n\n  // Fetch comments for a specific post\n  const { data: comments = [] } = useQuery({\n    queryKey: [`/api/community/posts/${selectedPostComments}/comments`],\n    queryFn: () => communityApi.getComments(selectedPostComments!),\n    enabled: !!selectedPostComments,\n  });\n\n  // Create comment mutation\n  const createCommentMutation = useMutation({\n    mutationFn: ({ postId, content }: { postId: string; content: string }) =>\n      communityApi.createComment(postId, content),\n    onSuccess: () => {\n      setNewComment('');\n      queryClient.invalidateQueries({ queryKey: [`/api/community/posts/${selectedPostComments}/comments`] });\n      queryClient.invalidateQueries({ queryKey: ['/api/community/posts'] });\n      toast({\n        title: 'Comment posted!',\n        description: 'Your comment has been added.',\n      });\n    },\n    onError: (error) => {\n      toast({\n        title: 'Failed to post comment',\n        description: error instanceof Error ? error.message : 'Please try again.',\n        variant: 'destructive',\n      });\n    },\n  });\n\n  const handleCreatePost = () => {\n    if (!newPostContent.trim()) return;\n    \n    createPostMutation.mutate({\n      content: newPostContent,\n      codeSnippet: newPostCodeSnippet || undefined,\n    });\n  };\n\n  const handleLikePost = (postId: string, currentlyLiked: boolean) => {\n    likePostMutation.mutate({ postId, isLiked: currentlyLiked });\n  };\n\n  const handleOpenComments = (postId: string) => {\n    setSelectedPostComments(postId);\n  };\n\n  const handleCreateComment = () => {\n    if (!newComment.trim() || !selectedPostComments) return;\n    createCommentMutation.mutate({ \n      postId: selectedPostComments, \n      content: newComment \n    });\n  };\n\n  const formatTimeAgo = (dateString: string) => {\n    const date = new Date(dateString);\n    const now = new Date();\n    const diffInHours = Math.floor((now.getTime() - date.getTime()) / (1000 * 60 * 60));\n    \n    if (diffInHours < 1) return 'Just now';\n    if (diffInHours < 24) return `${diffInHours}h ago`;\n    if (diffInHours < 168) return `${Math.floor(diffInHours / 24)}d ago`;\n    return date.toLocaleDateString();\n  };\n\n  const getLevelBadgeColor = (level: string) => {\n    switch (level) {\n      case 'SQL Powerlifter': return 'bg-purple-100 text-purple-800';\n      case 'SQL Athlete': return 'bg-blue-100 text-blue-800';\n      case 'SQL Trainee': return 'bg-green-100 text-green-800';\n      default: return 'bg-gray-100 text-gray-800';\n    }\n  };\n\n  // Mock data for active members and study groups\n  const activeMembers = [\n    { id: '1', username: 'alex_chen', status: 'online', lastActive: 'Online now' },\n    { id: '2', username: 'sarah_j', status: 'away', lastActive: '5 min ago' },\n    { id: '3', username: 'mike_db', status: 'online', lastActive: 'Online now' },\n  ];\n\n  const studyGroups = [\n    { name: 'Advanced Window Functions', members: 12 },\n    { name: 'SQL Performance Tuning', members: 8 },\n    { name: 'Database Design Patterns', members: 15 },\n  ];\n\n  return (\n    <div className=\"min-h-screen bg-background\">\n      <div className=\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\">\n        {/* Header */}\n        <div className=\"text-center mb-12\">\n          <h1 className=\"text-4xl font-bold text-foreground mb-4\">SQL Gym Community</h1>\n          <p className=\"text-xl text-muted-foreground\">Connect, share, and motivate each other</p>\n        </div>\n\n        <div className=\"grid lg:grid-cols-3 gap-8\">\n          {/* Main Feed */}\n          <div className=\"lg:col-span-2 space-y-6\">\n            {/* Create Post */}\n            {user && (\n              <Card>\n                <CardContent className=\"p-6\">\n                  <div className=\"flex items-start space-x-4\">\n                    <Avatar className=\"w-12 h-12\">\n                      <AvatarImage src={user.profileImageUrl} alt={user.username} />\n                      <AvatarFallback>\n                        {user.username?.charAt(0).toUpperCase() || 'U'}\n                      </AvatarFallback>\n                    </Avatar>\n                    <div className=\"flex-1\">\n                      <Textarea\n                        placeholder=\"Share your SQL journey, tips, or celebrate your achievements...\"\n                        value={newPostContent}\n                        onChange={(e) => setNewPostContent(e.target.value)}\n                        rows={3}\n                        className=\"resize-none mb-3\"\n                        data-testid=\"textarea-new-post\"\n                      />\n                      \n                      {/* Code Snippet Input */}\n                      <details className=\"mb-3\">\n                        <summary className=\"cursor-pointer text-sm text-muted-foreground hover:text-foreground\">\n                          Add code snippet (optional)\n                        </summary>\n                        <Textarea\n                          placeholder=\"-- Add your SQL code here\nSELECT column1, column2\nFROM table_name\nWHERE condition;\"\n                          value={newPostCodeSnippet}\n                          onChange={(e) => setNewPostCodeSnippet(e.target.value)}\n                          rows={4}\n                          className=\"mt-2 font-mono text-sm resize-none\"\n                          data-testid=\"textarea-code-snippet\"\n                        />\n                      </details>\n                      \n                      <div className=\"flex justify-between items-center\">\n                        <div className=\"flex items-center space-x-3\">\n                          <Button variant=\"ghost\" size=\"sm\" className=\"text-muted-foreground hover:text-primary\">\n                            <Image className=\"w-4 h-4\" />\n                          </Button>\n                          <Button variant=\"ghost\" size=\"sm\" className=\"text-muted-foreground hover:text-primary\">\n                            <Code className=\"w-4 h-4\" />\n                          </Button>\n                          <Button variant=\"ghost\" size=\"sm\" className=\"text-muted-foreground hover:text-primary\">\n                            <Trophy className=\"w-4 h-4\" />\n                          </Button>\n                        </div>\n                        <Button\n                          onClick={handleCreatePost}\n                          disabled={!newPostContent.trim() || createPostMutation.isPending}\n                          className=\"dumbbell-btn bg-primary text-primary-foreground hover:bg-primary/90\"\n                          data-testid=\"button-share-post\"\n                        >\n                          {createPostMutation.isPending ? 'Sharing...' : 'Share'}\n                        </Button>\n                      </div>\n                    </div>\n                  </div>\n                </CardContent>\n              </Card>\n            )}\n\n            {/* Community Posts */}\n            {postsLoading ? (\n              <div className=\"space-y-6\">\n                {[...Array(3)].map((_, i) => (\n                  <Card key={i} className=\"animate-pulse\">\n                    <CardContent className=\"p-6\">\n                      <div className=\"flex items-start space-x-4\">\n                        <div className=\"w-12 h-12 bg-muted rounded-full\" />\n                        <div className=\"flex-1 space-y-3\">\n                          <div className=\"h-4 bg-muted rounded w-1/3\" />\n                          <div className=\"h-4 bg-muted rounded\" />\n                          <div className=\"h-4 bg-muted rounded w-4/5\" />\n                          <div className=\"h-20 bg-muted rounded\" />\n                          <div className=\"flex space-x-4\">\n                            <div className=\"h-8 bg-muted rounded w-16\" />\n                            <div className=\"h-8 bg-muted rounded w-16\" />\n                            <div className=\"h-8 bg-muted rounded w-16\" />\n                          </div>\n                        </div>\n                      </div>\n                    </CardContent>\n                  </Card>\n                ))}\n              </div>\n            ) : posts?.length === 0 ? (\n              <Card>\n                <CardContent className=\"p-12 text-center\">\n                  <div className=\"w-16 h-16 bg-muted rounded-full flex items-center justify-center mx-auto mb-4\">\n                    <MessageCircle className=\"w-8 h-8 text-muted-foreground\" />\n                  </div>\n                  <h3 className=\"text-lg font-semibold text-foreground mb-2\">No posts yet</h3>\n                  <p className=\"text-muted-foreground\">Be the first to share something with the community!</p>\n                </CardContent>\n              </Card>\n            ) : (\n              <div className=\"space-y-6\">\n                {posts?.map((post) => (\n                  <Card key={post.id} data-testid={`post-${post.id}`}>\n                    <CardContent className=\"p-6\">\n                      <div className=\"flex items-start space-x-4\">\n                        <Avatar className=\"w-12 h-12\">\n                          <AvatarImage src={post.user.profileImageUrl} alt={post.user.username} />\n                          <AvatarFallback>\n                            {post.user.username?.charAt(0).toUpperCase() || 'U'}\n                          </AvatarFallback>\n                        </Avatar>\n                        \n                        <div className=\"flex-1\">\n                          <div className=\"flex items-center space-x-2 mb-2\">\n                            <h4 className=\"font-semibold text-foreground\" data-testid={`text-post-author-${post.id}`}>\n                              {post.user.firstName && post.user.lastName \n                                ? `${post.user.firstName} ${post.user.lastName}`\n                                : post.user.username}\n                            </h4>\n                            <span className=\"text-sm text-muted-foreground\">â€¢</span>\n                            <span className=\"text-sm text-muted-foreground\" data-testid={`text-post-time-${post.id}`}>\n                              {formatTimeAgo(post.createdAt)}\n                            </span>\n                            <Badge className={`text-xs ${getLevelBadgeColor(post.user.level)}`}>\n                              {post.user.level}\n                            </Badge>\n                          </div>\n                          \n                          {/* Problem Information - Only show on community page */}\n                          {post.problem && (\n                            <div className=\"flex items-center space-x-2 mb-3\">\n                              <span className=\"text-sm text-muted-foreground\">Discussing:</span>\n                              <span className=\"text-sm font-medium text-primary\" data-testid={`text-problem-title-${post.id}`}>\n                                {post.problem.title}\n                              </span>\n                              {post.problem.company && (\n                                <>\n                                  <span className=\"text-sm text-muted-foreground\">â€¢</span>\n                                  <Badge variant=\"secondary\" className=\"text-xs\" data-testid={`badge-company-${post.id}`}>\n                                    {post.problem.company}\n                                  </Badge>\n                                </>\n                              )}\n                              <Badge \n                                variant=\"outline\" \n                                className={`text-xs ${\n                                  post.problem.difficulty === 'Easy' ? 'text-green-600 border-green-300' :\n                                  post.problem.difficulty === 'Medium' ? 'text-yellow-600 border-yellow-300' :\n                                  'text-red-600 border-red-300'\n                                }`}\n                                data-testid={`badge-difficulty-${post.id}`}\n                              >\n                                {post.problem.difficulty}\n                              </Badge>\n                            </div>\n                          )}\n                          \n                          <p className=\"text-foreground mb-4 leading-relaxed\" data-testid={`text-post-content-${post.id}`}>\n                            {post.content}\n                          </p>\n                          \n                          {/* Code Snippet */}\n                          {post.codeSnippet && (\n                            <div className=\"bg-muted rounded-lg p-3 mb-4 overflow-x-auto\">\n                              <pre className=\"text-sm text-muted-foreground font-mono\">\n                                <code data-testid={`code-snippet-${post.id}`}>{post.codeSnippet}</code>\n                              </pre>\n                            </div>\n                          )}\n                          \n                          {/* Actions */}\n                          <div className=\"flex items-center justify-between\">\n                            <div className=\"flex items-center space-x-6\">\n                              <Button\n                                variant=\"ghost\"\n                                size=\"sm\"\n                                onClick={() => handleLikePost(post.id, post.likedByCurrentUser)}\n                                className={`flex items-center space-x-2 transition-colors ${\n                                  post.likedByCurrentUser \n                                    ? 'text-red-500 hover:text-red-600' \n                                    : 'text-muted-foreground hover:text-red-500'\n                                }`}\n                                data-testid={`button-like-${post.id}`}\n                                disabled={pendingLikes.has(post.id)}\n                              >\n                                <Heart className={`w-4 h-4 ${post.likedByCurrentUser ? 'fill-current' : ''}`} />\n                                <span className=\"text-sm\">{post.likes}</span>\n                              </Button>\n                              \n                              <Dialog \n                                open={selectedPostComments === post.id}\n                                onOpenChange={(open) => {\n                                  if (open) {\n                                    handleOpenComments(post.id);\n                                  } else {\n                                    setSelectedPostComments(null);\n                                    setNewComment('');\n                                  }\n                                }}\n                              >\n                                <DialogTrigger asChild>\n                                  <Button\n                                    variant=\"ghost\"\n                                    size=\"sm\"\n                                    className=\"flex items-center space-x-2 text-muted-foreground hover:text-blue-500 transition-colors\"\n                                    data-testid={`button-comment-${post.id}`}\n                                  >\n                                    <MessageCircle className=\"w-4 h-4\" />\n                                    <span className=\"text-sm\">{post.comments}</span>\n                                  </Button>\n                                </DialogTrigger>\n                                <DialogContent className=\"max-w-2xl max-h-[80vh] overflow-y-auto\">\n                                  <DialogHeader>\n                                    <DialogTitle>Comments</DialogTitle>\n                                  </DialogHeader>\n                                  \n                                  {/* Comments List */}\n                                  <div className=\"space-y-4 mb-4\">\n                                    {selectedPostComments === post.id && comments.length > 0 ? (\n                                      comments.map((comment: any) => (\n                                        <div key={comment.id} className=\"border-b pb-3\">\n                                          <div className=\"flex items-start space-x-3\">\n                                            <Avatar className=\"w-8 h-8\">\n                                              <AvatarImage src={comment.user.profileImageUrl} alt={comment.user.username} />\n                                              <AvatarFallback>\n                                                {comment.user.username?.charAt(0).toUpperCase() || 'U'}\n                                              </AvatarFallback>\n                                            </Avatar>\n                                            <div className=\"flex-1\">\n                                              <div className=\"flex items-center space-x-2 mb-1\">\n                                                <span className=\"font-semibold text-sm\">{comment.user.username}</span>\n                                                <span className=\"text-xs text-muted-foreground\">\n                                                  {formatTimeAgo(comment.createdAt)}\n                                                </span>\n                                              </div>\n                                              <p className=\"text-sm text-foreground\">{comment.content}</p>\n                                            </div>\n                                          </div>\n                                        </div>\n                                      ))\n                                    ) : (\n                                      <p className=\"text-muted-foreground text-sm text-center py-8\">\n                                        No comments yet. Be the first to comment!\n                                      </p>\n                                    )}\n                                  </div>\n                                  \n                                  {/* Add Comment */}\n                                  <div className=\"border-t pt-4\">\n                                    <div className=\"flex space-x-3\">\n                                      <Avatar className=\"w-8 h-8\">\n                                        <AvatarImage src={user?.profileImageUrl} alt={user?.username} />\n                                        <AvatarFallback>\n                                          {user?.username?.charAt(0).toUpperCase() || 'U'}\n                                        </AvatarFallback>\n                                      </Avatar>\n                                      <div className=\"flex-1 space-y-2\">\n                                        <Textarea\n                                          placeholder=\"Write a comment...\"\n                                          value={newComment}\n                                          onChange={(e) => setNewComment(e.target.value)}\n                                          className=\"min-h-[80px] resize-none\"\n                                        />\n                                        <div className=\"flex justify-end\">\n                                          <Button\n                                            onClick={handleCreateComment}\n                                            disabled={!newComment.trim() || createCommentMutation.isPending}\n                                            size=\"sm\"\n                                          >\n                                            <Send className=\"w-4 h-4 mr-2\" />\n                                            {createCommentMutation.isPending ? 'Posting...' : 'Post Comment'}\n                                          </Button>\n                                        </div>\n                                      </div>\n                                    </div>\n                                  </div>\n                                </DialogContent>\n                              </Dialog>\n                              \n                              <Button\n                                variant=\"ghost\"\n                                size=\"sm\"\n                                className=\"flex items-center space-x-2 text-muted-foreground hover:text-green-500 transition-colors\"\n                                data-testid={`button-share-${post.id}`}\n                              >\n                                <Share className=\"w-4 h-4\" />\n                                <span className=\"text-sm\">Share</span>\n                              </Button>\n                            </div>\n                          </div>\n                        </div>\n                      </div>\n                    </CardContent>\n                  </Card>\n                ))}\n              </div>\n            )}\n          </div>\n\n          {/* Sidebar */}\n          <div className=\"space-y-6\">\n            {/* Active Members */}\n            <Card>\n              <CardHeader>\n                <CardTitle className=\"flex items-center space-x-2\">\n                  <Activity className=\"w-5 h-5 text-primary\" />\n                  <span>Active Members</span>\n                </CardTitle>\n              </CardHeader>\n              <CardContent className=\"space-y-3\">\n                {activeMembers.map((member) => (\n                  <div key={member.id} className=\"flex items-center space-x-3\" data-testid={`active-member-${member.username}`}>\n                    <Avatar className=\"w-10 h-10\">\n                      <AvatarFallback>\n                        {member.username.charAt(0).toUpperCase()}\n                      </AvatarFallback>\n                    </Avatar>\n                    <div className=\"flex-1\">\n                      <p className=\"font-medium text-foreground text-sm\">{member.username}</p>\n                      <p className=\"text-xs text-muted-foreground\">{member.lastActive}</p>\n                    </div>\n                    <div className={`w-3 h-3 rounded-full ${\n                      member.status === 'online' ? 'bg-green-400' : 'bg-yellow-400'\n                    }`} />\n                  </div>\n                ))}\n              </CardContent>\n            </Card>\n\n            {/* Weekly Challenge */}\n            <Card className=\"bg-gradient-to-br from-primary to-orange-400 text-white\">\n              <CardHeader>\n                <CardTitle className=\"text-white\">Weekly Challenge</CardTitle>\n              </CardHeader>\n              <CardContent>\n                <p className=\"text-sm opacity-90 mb-4\">\n                  Share 3 helpful SQL tips this week to earn the \"Community Helper\" badge!\n                </p>\n                <div className=\"space-y-2\">\n                  <div className=\"flex justify-between text-sm\">\n                    <span>Progress</span>\n                    <span>1/3</span>\n                  </div>\n                  <div className=\"w-full bg-white/20 rounded-full h-2\">\n                    <div className=\"bg-white h-2 rounded-full\" style={{ width: '33%' }} />\n                  </div>\n                </div>\n              </CardContent>\n            </Card>\n\n            {/* Study Groups */}\n            <Card>\n              <CardHeader>\n                <CardTitle className=\"flex items-center space-x-2\">\n                  <Users className=\"w-5 h-5 text-primary\" />\n                  <span>Study Groups</span>\n                </CardTitle>\n              </CardHeader>\n              <CardContent className=\"space-y-3\">\n                {studyGroups.map((group, index) => (\n                  <div key={index} className=\"flex items-center justify-between\" data-testid={`study-group-${index}`}>\n                    <div>\n                      <p className=\"font-medium text-foreground text-sm\">{group.name}</p>\n                      <p className=\"text-xs text-muted-foreground\">{group.members} members</p>\n                    </div>\n                    <Button \n                      variant=\"ghost\" \n                      size=\"sm\" \n                      className=\"text-primary hover:bg-primary/10\"\n                      data-testid={`button-join-group-${index}`}\n                    >\n                      Join\n                    </Button>\n                  </div>\n                ))}\n              </CardContent>\n            </Card>\n\n            {/* Community Stats */}\n            <Card>\n              <CardHeader>\n                <CardTitle>Community Stats</CardTitle>\n              </CardHeader>\n              <CardContent className=\"space-y-4\">\n                <div className=\"flex justify-between items-center\">\n                  <span className=\"text-muted-foreground\">Total Posts</span>\n                  <span className=\"font-bold text-foreground\">{posts?.length || 0}</span>\n                </div>\n                <div className=\"flex justify-between items-center\">\n                  <span className=\"text-muted-foreground\">Active Today</span>\n                  <span className=\"font-bold text-foreground\">{activeMembers.length}</span>\n                </div>\n                <div className=\"flex justify-between items-center\">\n                  <span className=\"text-muted-foreground\">Study Groups</span>\n                  <span className=\"font-bold text-foreground\">{studyGroups.length}</span>\n                </div>\n              </CardContent>\n            </Card>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n","size_bytes":29088},"client/src/pages/home.tsx":{"content":"import { useQuery } from '@tanstack/react-query';\nimport { Play, TrendingUp, Users, Target } from 'lucide-react';\nimport { Link } from 'wouter';\nimport { Button } from '@/components/ui/button';\nimport { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';\nimport { useAuth } from '@/hooks/use-auth';\nimport { problemsApi, leaderboardApi } from '@/lib/auth';\nimport { DifficultyBadge } from '@/components/DifficultyBadge';\nimport { CompanyLogo } from '@/components/CompanyLogo';\n\nexport default function Home() {\n  const { user } = useAuth();\n\n  const { data: problems, isLoading: problemsLoading } = useQuery({\n    queryKey: ['/api/problems'],\n    queryFn: () => problemsApi.getAll(),\n  });\n\n  const { data: leaderboard, isLoading: leaderboardLoading } = useQuery({\n    queryKey: ['/api/leaderboard'],\n    queryFn: () => leaderboardApi.get(5),\n  });\n\n\n\n  const recentProblems = problems?.slice(0, 3) || [];\n  const topUsers = leaderboard?.slice(0, 3) || [];\n\n  return (\n    <div className=\"min-h-screen bg-background\">\n      <div className=\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\">\n        {/* Header */}\n        <div className=\"mb-8\">\n          <h1 className=\"text-4xl font-bold text-foreground mb-2\">\n            Welcome back, <span className=\"text-primary\">{user?.username}</span>! ðŸ’ª\n          </h1>\n          <p className=\"text-xl text-muted-foreground\">\n            Ready to continue your SQL training journey?\n          </p>\n        </div>\n\n        <div className=\"grid lg:grid-cols-3 gap-8\">\n          {/* Main Content */}\n          <div className=\"lg:col-span-2 space-y-8\">\n            {/* Progress Overview */}\n            <Card>\n              <CardHeader>\n                <CardTitle className=\"flex items-center space-x-2\">\n                  <TrendingUp className=\"w-5 h-5 text-primary\" />\n                  <span>Your Progress</span>\n                </CardTitle>\n              </CardHeader>\n              <CardContent className=\"space-y-6\">\n                <div className=\"text-center\">\n                  <div className=\"text-3xl font-bold text-green-600\">{user?.problemsSolved || 0}</div>\n                  <div className=\"text-sm text-muted-foreground\">Problems Solved</div>\n                  <p className=\"text-sm text-muted-foreground mt-2\">Keep solving problems to improve your skills!</p>\n                </div>\n              </CardContent>\n            </Card>\n\n            {/* Quick Actions */}\n            <Card>\n              <CardHeader>\n                <CardTitle className=\"flex items-center space-x-2\">\n                  <Target className=\"w-5 h-5 text-primary\" />\n                  <span>Quick Actions</span>\n                </CardTitle>\n              </CardHeader>\n              <CardContent>\n                <div className=\"grid md:grid-cols-2 gap-4\">\n                  <Link href=\"/problems\">\n                    <Button \n                      className=\"w-full dumbbell-btn bg-primary text-primary-foreground hover:bg-primary/90 h-16\"\n                      data-testid=\"button-browse-problems\"\n                    >\n                      <Play className=\"mr-2 h-5 w-5\" />\n                      <div className=\"text-left\">\n                        <div className=\"font-semibold\">Browse Problems</div>\n                        <div className=\"text-sm opacity-90\">Find your next challenge</div>\n                      </div>\n                    </Button>\n                  </Link>\n                  \n                  <Link href=\"/community\">\n                    <Button \n                      variant=\"outline\" \n                      className=\"w-full h-16\"\n                      data-testid=\"button-join-community\"\n                    >\n                      <Users className=\"mr-2 h-5 w-5\" />\n                      <div className=\"text-left\">\n                        <div className=\"font-semibold\">Join Community</div>\n                        <div className=\"text-sm opacity-70\">Share and learn together</div>\n                      </div>\n                    </Button>\n                  </Link>\n                </div>\n              </CardContent>\n            </Card>\n\n            {/* Recent Problems */}\n            <Card>\n              <CardHeader>\n                <div className=\"flex justify-between items-center\">\n                  <CardTitle>Recommended Problems</CardTitle>\n                  <Link href=\"/problems\">\n                    <Button variant=\"ghost\" size=\"sm\" data-testid=\"link-view-all-problems\">\n                      View All\n                    </Button>\n                  </Link>\n                </div>\n              </CardHeader>\n              <CardContent>\n                {problemsLoading ? (\n                  <div className=\"space-y-4\">\n                    {[...Array(3)].map((_, i) => (\n                      <div key={i} className=\"h-20 bg-muted rounded-lg animate-pulse\" />\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"space-y-4\">\n                    {recentProblems.map((problem) => (\n                      <Link key={problem.id} href={`/problems/${problem.id}`}>\n                        <Card className=\"hover:shadow-md transition-shadow cursor-pointer\" data-testid={`card-problem-${problem.id}`}>\n                          <CardContent className=\"p-4\">\n                            <div className=\"flex items-start justify-between\">\n                              <div className=\"flex-1\">\n                                <h3 className=\"font-semibold text-foreground mb-2\">{problem.title}</h3>\n                                <p className=\"text-sm text-muted-foreground line-clamp-2\">\n                                  {problem.description}\n                                </p>\n                              </div>\n                              <div className=\"ml-4\">\n                                <DifficultyBadge\n                                  difficulty={problem.difficulty}\n                                  variant=\"badge\"\n                                  size=\"sm\"\n                                  showIcon={true}\n                                  data-testid={`difficulty-badge-home-${problem.id}`}\n                                />\n                              </div>\n                            </div>\n                            <div className=\"flex items-center justify-between mt-3\">\n                              <div className=\"flex items-center space-x-4\">\n                                {problem.company && (\n                                  <CompanyLogo\n                                    companyName={problem.company}\n                                    variant=\"minimal\"\n                                    size=\"sm\"\n                                    data-testid={`company-logo-home-${problem.id}`}\n                                  />\n                                )}\n                                <span className=\"text-xs text-muted-foreground\">\n                                  {problem.solvedCount} solved\n                                </span>\n                              </div>\n                              <Button size=\"sm\" variant=\"ghost\" className=\"text-primary\">\n                                Start Training â†’\n                              </Button>\n                            </div>\n                          </CardContent>\n                        </Card>\n                      </Link>\n                    ))}\n                  </div>\n                )}\n              </CardContent>\n            </Card>\n          </div>\n\n          {/* Sidebar */}\n          <div className=\"space-y-6\">\n\n            {/* Leaderboard Preview */}\n            <Card>\n              <CardHeader>\n                <div className=\"flex justify-between items-center\">\n                  <CardTitle>Top Athletes</CardTitle>\n                  <Link href=\"/leaderboard\">\n                    <Button variant=\"ghost\" size=\"sm\" data-testid=\"link-view-leaderboard\">\n                      View All\n                    </Button>\n                  </Link>\n                </div>\n              </CardHeader>\n              <CardContent>\n                {leaderboardLoading ? (\n                  <div className=\"space-y-3\">\n                    {[...Array(3)].map((_, i) => (\n                      <div key={i} className=\"flex items-center space-x-3\">\n                        <div className=\"w-10 h-10 bg-muted rounded-full\" />\n                        <div className=\"flex-1 space-y-1\">\n                          <div className=\"h-4 bg-muted rounded w-3/4\" />\n                          <div className=\"h-3 bg-muted rounded w-1/2\" />\n                        </div>\n                      </div>\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"space-y-3\">\n                    {topUsers.map((topUser, index) => (\n                      <div key={topUser.id} className=\"flex items-center space-x-3\" data-testid={`user-rank-${index + 1}`}>\n                        <div className=\"w-10 h-10 bg-primary text-primary-foreground rounded-full flex items-center justify-center font-bold text-sm\">\n                          {index + 1}\n                        </div>\n                        <div className=\"flex-1\">\n                          <div className=\"font-medium text-foreground\">{topUser.username}</div>\n                          <div className=\"text-sm text-muted-foreground\">{topUser.problemsSolved} problems solved</div>\n                        </div>\n                      </div>\n                    ))}\n                  </div>\n                )}\n              </CardContent>\n            </Card>\n\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n","size_bytes":9673},"client/src/pages/landing.tsx":{"content":"import { useState, useEffect } from \"react\";\nimport { Play, Users, Code, CheckCircle } from \"lucide-react\";\nimport { FaGoogle, FaGithub } from \"react-icons/fa\";\nimport { Button } from \"@/components/ui/button\";\nimport { Card, CardContent } from \"@/components/ui/card\";\nimport {\n  Dialog,\n  DialogContent,\n  DialogHeader,\n  DialogTitle,\n  DialogTrigger,\n} from \"@/components/ui/dialog\";\nimport {\n  Form,\n  FormControl,\n  FormField,\n  FormItem,\n  FormLabel,\n  FormMessage,\n} from \"@/components/ui/form\";\nimport { Input } from \"@/components/ui/input\";\nimport { useForm } from \"react-hook-form\";\nimport { zodResolver } from \"@hookform/resolvers/zod\";\nimport { z } from \"zod\";\nimport { useAuth } from \"@/hooks/use-auth\";\nimport { authApi } from \"@/lib/auth\";\nimport { useToast } from \"@/hooks/use-toast\";\nimport ProgressBar from \"@/components/progress-bar\";\n\nconst loginSchema = z.object({\n  email: z.string().email(\"Invalid email address\"),\n  password: z.string().min(6, \"Password must be at least 6 characters\"),\n});\n\nconst registerSchema = z.object({\n  username: z.string().min(3, \"Username must be at least 3 characters\"),\n  email: z.string().email(\"Invalid email address\"),\n  password: z.string().min(6, \"Password must be at least 6 characters\"),\n  firstName: z.string().optional(),\n  lastName: z.string().optional(),\n});\n\nexport default function Landing() {\n  const [isLoginOpen, setIsLoginOpen] = useState(false);\n  const [isRegisterOpen, setIsRegisterOpen] = useState(false);\n  const [isLoading, setIsLoading] = useState(false);\n  const { login } = useAuth();\n  const { toast } = useToast();\n\n  // Handle OAuth callback tokens\n  useEffect(() => {\n    const urlParams = new URLSearchParams(window.location.search);\n    const token = urlParams.get(\"token\");\n\n    if (token) {\n      // Store the token and get user info\n      localStorage.setItem(\"auth_token\", token);\n\n      // Clean up URL\n      window.history.replaceState({}, document.title, \"/\");\n\n      // Get user info and complete login\n      authApi\n        .getCurrentUser()\n        .then((user) => {\n          login(token, user);\n          toast({\n            title: \"Welcome!\",\n            description: \"Successfully logged into SQL Practice Hub.\",\n          });\n        })\n        .catch(() => {\n          toast({\n            title: \"Authentication failed\",\n            description: \"Please try logging in again.\",\n            variant: \"destructive\",\n          });\n        });\n    }\n  }, [login, toast]);\n\n  const loginForm = useForm({\n    resolver: zodResolver(loginSchema),\n    defaultValues: {\n      email: \"\",\n      password: \"\",\n    },\n  });\n\n  const registerForm = useForm({\n    resolver: zodResolver(registerSchema),\n    defaultValues: {\n      username: \"\",\n      email: \"\",\n      password: \"\",\n      firstName: \"\",\n      lastName: \"\",\n    },\n  });\n\n  const handleLogin = async (data: z.infer<typeof loginSchema>) => {\n    setIsLoading(true);\n    try {\n      const response = await authApi.login(data);\n      login(response.token!, response.user!);\n      setIsLoginOpen(false);\n      toast({\n        title: \"Welcome back!\",\n        description: \"Successfully logged into SQL Practice Hub.\",\n      });\n    } catch (error) {\n      toast({\n        title: \"Login failed\",\n        description:\n          error instanceof Error\n            ? error.message\n            : \"Please check your credentials.\",\n        variant: \"destructive\",\n      });\n    } finally {\n      setIsLoading(false);\n    }\n  };\n\n  const handleRegister = async (data: z.infer<typeof registerSchema>) => {\n    setIsLoading(true);\n    try {\n      const response = await authApi.register(data);\n      login(response.token!, response.user!);\n      setIsRegisterOpen(false);\n      toast({\n        title: \"Welcome to SQL Practice Hub!\",\n        description: \"Your account has been created successfully.\",\n      });\n    } catch (error) {\n      toast({\n        title: \"Registration failed\",\n        description:\n          error instanceof Error ? error.message : \"Please try again.\",\n        variant: \"destructive\",\n      });\n    } finally {\n      setIsLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"bg-background\">\n      {/* Navigation */}\n      <nav className=\"bg-white border-b border-border shadow-sm\">\n        <div className=\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8\">\n          <div className=\"flex justify-between items-center h-16\">\n            <div className=\"flex items-center space-x-2\">\n              <Code className=\"text-primary text-2xl\" />\n              <span className=\"text-2xl font-bold text-foreground\">\n                SQL Practice Hub\n              </span>\n            </div>\n\n            <div className=\"flex items-center space-x-3\">\n              <Dialog open={isLoginOpen} onOpenChange={setIsLoginOpen}>\n                <DialogTrigger asChild>\n                  <Button variant=\"ghost\" data-testid=\"button-login\">\n                    Login\n                  </Button>\n                </DialogTrigger>\n                <DialogContent>\n                  <DialogHeader>\n                    <DialogTitle>Login to SQL Practice Hub</DialogTitle>\n                  </DialogHeader>\n                  <Form {...loginForm}>\n                    <form\n                      onSubmit={loginForm.handleSubmit(handleLogin)}\n                      className=\"space-y-4\"\n                    >\n                      <FormField\n                        control={loginForm.control}\n                        name=\"email\"\n                        render={({ field }) => (\n                          <FormItem>\n                            <FormLabel>Email</FormLabel>\n                            <FormControl>\n                              <Input\n                                {...field}\n                                type=\"email\"\n                                data-testid=\"input-email\"\n                              />\n                            </FormControl>\n                            <FormMessage />\n                          </FormItem>\n                        )}\n                      />\n                      <FormField\n                        control={loginForm.control}\n                        name=\"password\"\n                        render={({ field }) => (\n                          <FormItem>\n                            <FormLabel>Password</FormLabel>\n                            <FormControl>\n                              <Input\n                                {...field}\n                                type=\"password\"\n                                data-testid=\"input-password\"\n                              />\n                            </FormControl>\n                            <FormMessage />\n                          </FormItem>\n                        )}\n                      />\n                      <Button\n                        type=\"submit\"\n                        disabled={isLoading}\n                        className=\"w-full\"\n                        data-testid=\"button-submit-login\"\n                      >\n                        {isLoading ? \"Logging in...\" : \"Login\"}\n                      </Button>\n\n                      <div className=\"relative my-4\">\n                        <div className=\"absolute inset-0 flex items-center\">\n                          <div className=\"w-full border-t border-muted\"></div>\n                        </div>\n                        <div className=\"relative flex justify-center text-xs uppercase\">\n                          <span className=\"bg-background px-2 text-muted-foreground\">\n                            Or continue with\n                          </span>\n                        </div>\n                      </div>\n\n                      <div className=\"grid grid-cols-2 gap-2\">\n                        <Button\n                          type=\"button\"\n                          variant=\"outline\"\n                          className=\"w-full\"\n                          onClick={() =>\n                            (window.location.href = \"/api/auth/google\")\n                          }\n                          data-testid=\"button-google-login\"\n                        >\n                          <FaGoogle className=\"mr-2 h-4 w-4 text-red-500\" />\n                          Google\n                        </Button>\n                        <Button\n                          type=\"button\"\n                          variant=\"outline\"\n                          className=\"w-full\"\n                          onClick={() =>\n                            (window.location.href = \"/api/auth/github\")\n                          }\n                          data-testid=\"button-github-login\"\n                        >\n                          <FaGithub className=\"mr-2 h-4 w-4\" />\n                          GitHub\n                        </Button>\n                      </div>\n                    </form>\n                  </Form>\n                </DialogContent>\n              </Dialog>\n\n              <Dialog open={isRegisterOpen} onOpenChange={setIsRegisterOpen}>\n                <DialogTrigger asChild>\n                  <Button\n                    className=\"bg-primary text-primary-foreground hover:bg-primary/90\"\n                    data-testid=\"button-register\"\n                  >\n                    <Code className=\"mr-2 h-4 w-4\" />\n                    Start Practicing\n                  </Button>\n                </DialogTrigger>\n                <DialogContent>\n                  <DialogHeader>\n                    <DialogTitle>Join SQL Practice Hub</DialogTitle>\n                  </DialogHeader>\n                  <Form {...registerForm}>\n                    <form\n                      onSubmit={registerForm.handleSubmit(handleRegister)}\n                      className=\"space-y-4\"\n                    >\n                      <div className=\"grid grid-cols-2 gap-4\">\n                        <FormField\n                          control={registerForm.control}\n                          name=\"firstName\"\n                          render={({ field }) => (\n                            <FormItem>\n                              <FormLabel>First Name</FormLabel>\n                              <FormControl>\n                                <Input\n                                  {...field}\n                                  data-testid=\"input-firstName\"\n                                />\n                              </FormControl>\n                              <FormMessage />\n                            </FormItem>\n                          )}\n                        />\n                        <FormField\n                          control={registerForm.control}\n                          name=\"lastName\"\n                          render={({ field }) => (\n                            <FormItem>\n                              <FormLabel>Last Name</FormLabel>\n                              <FormControl>\n                                <Input\n                                  {...field}\n                                  data-testid=\"input-lastName\"\n                                />\n                              </FormControl>\n                              <FormMessage />\n                            </FormItem>\n                          )}\n                        />\n                      </div>\n                      <FormField\n                        control={registerForm.control}\n                        name=\"username\"\n                        render={({ field }) => (\n                          <FormItem>\n                            <FormLabel>Username</FormLabel>\n                            <FormControl>\n                              <Input {...field} data-testid=\"input-username\" />\n                            </FormControl>\n                            <FormMessage />\n                          </FormItem>\n                        )}\n                      />\n                      <FormField\n                        control={registerForm.control}\n                        name=\"email\"\n                        render={({ field }) => (\n                          <FormItem>\n                            <FormLabel>Email</FormLabel>\n                            <FormControl>\n                              <Input\n                                {...field}\n                                type=\"email\"\n                                data-testid=\"input-register-email\"\n                              />\n                            </FormControl>\n                            <FormMessage />\n                          </FormItem>\n                        )}\n                      />\n                      <FormField\n                        control={registerForm.control}\n                        name=\"password\"\n                        render={({ field }) => (\n                          <FormItem>\n                            <FormLabel>Password</FormLabel>\n                            <FormControl>\n                              <Input\n                                {...field}\n                                type=\"password\"\n                                data-testid=\"input-register-password\"\n                              />\n                            </FormControl>\n                            <FormMessage />\n                          </FormItem>\n                        )}\n                      />\n                      <Button\n                        type=\"submit\"\n                        disabled={isLoading}\n                        className=\"w-full\"\n                        data-testid=\"button-submit-register\"\n                      >\n                        {isLoading ? \"Creating account...\" : \"Create Account\"}\n                      </Button>\n\n                      <div className=\"relative my-4\">\n                        <div className=\"absolute inset-0 flex items-center\">\n                          <div className=\"w-full border-t border-muted\"></div>\n                        </div>\n                        <div className=\"relative flex justify-center text-xs uppercase\">\n                          <span className=\"bg-background px-2 text-muted-foreground\">\n                            Or sign up with\n                          </span>\n                        </div>\n                      </div>\n\n                      <div className=\"grid grid-cols-2 gap-2\">\n                        <Button\n                          type=\"button\"\n                          variant=\"outline\"\n                          className=\"w-full\"\n                          onClick={() =>\n                            (window.location.href = \"/api/auth/google\")\n                          }\n                          data-testid=\"button-google-register\"\n                        >\n                          <FaGoogle className=\"mr-2 h-4 w-4 text-red-500\" />\n                          Google\n                        </Button>\n                        <Button\n                          type=\"button\"\n                          variant=\"outline\"\n                          className=\"w-full\"\n                          onClick={() =>\n                            (window.location.href = \"/api/auth/github\")\n                          }\n                          data-testid=\"button-github-register\"\n                        >\n                          <FaGithub className=\"mr-2 h-4 w-4\" />\n                          GitHub\n                        </Button>\n                      </div>\n                    </form>\n                  </Form>\n                </DialogContent>\n              </Dialog>\n            </div>\n          </div>\n        </div>\n      </nav>\n\n      {/* Hero Section */}\n      <section className=\"bg-white\">\n        <div className=\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-20\">\n          <div className=\"grid lg:grid-cols-2 gap-12 items-center\">\n            <div className=\"space-y-8\">\n              <div>\n                <h1 className=\"text-5xl font-bold text-foreground leading-tight\">\n                  Master <span className=\"text-primary\">SQL Skills</span> for\n                  Interviews & Work\n                </h1>\n                <p className=\"text-xl text-muted-foreground mt-6 leading-relaxed\">\n                  Practice SQL with real-world problems designed for interviews\n                  and professional development. Progress from Junior to Senior\n                  level with our comprehensive platform.\n                </p>\n              </div>\n\n              {/* Progress Showcase */}\n              <Card className=\"p-6\">\n                <h3 className=\"font-semibold text-foreground mb-4\">\n                  Your Progress\n                </h3>\n                <ProgressBar value={15} max={20} />\n              </Card>\n\n              <div className=\"flex flex-col sm:flex-row gap-4\">\n                <Dialog>\n                  <DialogTrigger asChild>\n                    <Button\n                      size=\"lg\"\n                      className=\"bg-primary text-primary-foreground px-8 py-4 text-lg hover:bg-primary/90\"\n                      data-testid=\"button-start-practice\"\n                    >\n                      <Play className=\"mr-3 h-5 w-5\" />\n                      Start Practicing\n                    </Button>\n                  </DialogTrigger>\n                  <DialogContent>\n                    <DialogHeader>\n                      <DialogTitle>Join SQL Practice Hub</DialogTitle>\n                    </DialogHeader>\n                    <p className=\"text-muted-foreground mb-4\">\n                      Create your free account to access hundreds of\n                      interview-focused SQL problems and join our professional\n                      community.\n                    </p>\n                    <Button\n                      onClick={() => {\n                        setIsRegisterOpen(true);\n                      }}\n                      className=\"w-full\"\n                      data-testid=\"button-join-now\"\n                    >\n                      Join Now - It's Free!\n                    </Button>\n                  </DialogContent>\n                </Dialog>\n\n                <Button\n                  variant=\"outline\"\n                  size=\"lg\"\n                  className=\"px-8 py-4 text-lg\"\n                  onClick={() =>\n                    document\n                      .getElementById(\"community\")\n                      ?.scrollIntoView({ behavior: \"smooth\" })\n                  }\n                  data-testid=\"button-join-community\"\n                >\n                  <Users className=\"mr-3 h-5 w-5\" />\n                  Join Community\n                </Button>\n              </div>\n            </div>\n\n            <div className=\"relative\">\n              <img\n                src=\"https://images.unsplash.com/photo-1517077304055-6e89abbf09b0?ixlib=rb-4.0.3&auto=format&fit=crop&w=800&h=600\"\n                alt=\"Professional coding workspace\"\n                className=\"rounded-xl shadow-2xl w-full\"\n              />\n\n              {/* Floating achievement cards */}\n              <Card className=\"absolute -top-4 -right-4 p-4 shadow-lg\">\n                <div className=\"flex items-center space-x-3\">\n                  <div className=\"w-12 h-12 bg-primary/10 rounded-full flex items-center justify-center\">\n                    <CheckCircle className=\"text-primary text-xl\" />\n                  </div>\n                  <div>\n                    <p className=\"font-semibold text-foreground\">\n                      Senior Developer\n                    </p>\n                    <p className=\"text-sm text-muted-foreground\">\n                      Level Achieved!\n                    </p>\n                  </div>\n                </div>\n              </Card>\n\n              <Card className=\"absolute -bottom-4 -left-4 p-4 shadow-lg\">\n                <div className=\"flex items-center space-x-3\">\n                  <div className=\"w-12 h-12 bg-green-100 rounded-full flex items-center justify-center\">\n                    <CheckCircle className=\"text-green-600 text-xl\" />\n                  </div>\n                  <div>\n                    <p className=\"font-semibold text-foreground\">\n                      Problem Solved!\n                    </p>\n                    <p className=\"text-sm text-muted-foreground\">\n                      +50 XP Gained\n                    </p>\n                  </div>\n                </div>\n              </Card>\n            </div>\n          </div>\n        </div>\n      </section>\n\n      {/* Community Section */}\n      <section id=\"community\" className=\"bg-muted/30 py-20\">\n        <div className=\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 text-center\">\n          <h2 className=\"text-4xl font-bold text-foreground mb-4\">\n            Join the SQL Practice Community\n          </h2>\n          <p className=\"text-xl text-muted-foreground mb-8\">\n            Connect with fellow developers, share solutions, and advance your\n            career\n          </p>\n\n          <div className=\"grid md:grid-cols-3 gap-8 mb-12\">\n            <div className=\"text-center\">\n              <div className=\"w-16 h-16 bg-primary/10 rounded-full flex items-center justify-center mx-auto mb-4\">\n                <Code className=\"w-8 h-8 text-primary\" />\n              </div>\n              <h3 className=\"font-semibold text-foreground mb-2\">\n                Practice Together\n              </h3>\n              <p className=\"text-muted-foreground\">\n                Solve problems with peers and share your solutions\n              </p>\n            </div>\n\n            <div className=\"text-center\">\n              <div className=\"w-16 h-16 bg-green-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                <Users className=\"w-8 h-8 text-green-600\" />\n              </div>\n              <h3 className=\"font-semibold text-foreground mb-2\">\n                Learn from Experts\n              </h3>\n              <p className=\"text-muted-foreground\">\n                Get tips and tricks from senior developers\n              </p>\n            </div>\n\n            <div className=\"text-center\">\n              <div className=\"w-16 h-16 bg-yellow-100 rounded-full flex items-center justify-center mx-auto mb-4\">\n                <CheckCircle className=\"w-8 h-8 text-yellow-600\" />\n              </div>\n              <h3 className=\"font-semibold text-foreground mb-2\">\n                Track Progress\n              </h3>\n              <p className=\"text-muted-foreground\">\n                Earn badges and climb the leaderboards\n              </p>\n            </div>\n          </div>\n\n          <Button\n            onClick={() => setIsRegisterOpen(true)}\n            size=\"lg\"\n            className=\"bg-primary text-primary-foreground px-8 py-4 text-lg hover:bg-primary/90\"\n            data-testid=\"button-get-started\"\n          >\n            <Code className=\"mr-3 h-5 w-5\" />\n            Get Started Now\n          </Button>\n        </div>\n      </section>\n\n      {/* Footer */}\n      <footer className=\"bg-foreground text-background py-12\">\n        <div className=\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8\">\n          <div className=\"grid md:grid-cols-4 gap-8\">\n            <div className=\"space-y-4\">\n              <div className=\"flex items-center space-x-2\">\n                <Code className=\"text-primary text-2xl\" />\n                <span className=\"text-2xl font-bold\">SQL Practice Hub</span>\n              </div>\n              <p className=\"text-background/70\">\n                Master SQL skills for interviews and professional development\n                with our comprehensive platform.\n              </p>\n            </div>\n\n            <div>\n              <h3 className=\"font-semibold mb-4\">Platform</h3>\n              <div className=\"space-y-2 text-background/70\">\n                <a\n                  href=\"#\"\n                  className=\"block hover:text-primary transition-colors\"\n                >\n                  Problems\n                </a>\n                <a\n                  href=\"#\"\n                  className=\"block hover:text-primary transition-colors\"\n                >\n                  Leaderboard\n                </a>\n                <a\n                  href=\"#\"\n                  className=\"block hover:text-primary transition-colors\"\n                >\n                  Community\n                </a>\n                <a\n                  href=\"#\"\n                  className=\"block hover:text-primary transition-colors\"\n                >\n                  Submissions\n                </a>\n              </div>\n            </div>\n\n            <div>\n              <h3 className=\"font-semibold mb-4\">Resources</h3>\n              <div className=\"space-y-2 text-background/70\">\n                <a\n                  href=\"#\"\n                  className=\"block hover:text-primary transition-colors\"\n                >\n                  Documentation\n                </a>\n                <a\n                  href=\"#\"\n                  className=\"block hover:text-primary transition-colors\"\n                >\n                  SQL Guide\n                </a>\n                <a\n                  href=\"#\"\n                  className=\"block hover:text-primary transition-colors\"\n                >\n                  Video Tutorials\n                </a>\n                <a\n                  href=\"#\"\n                  className=\"block hover:text-primary transition-colors\"\n                >\n                  Blog\n                </a>\n              </div>\n            </div>\n\n            <div>\n              <h3 className=\"font-semibold mb-4\">Company</h3>\n              <div className=\"space-y-2 text-background/70\">\n                <a\n                  href=\"#\"\n                  className=\"block hover:text-primary transition-colors\"\n                >\n                  About\n                </a>\n                <a\n                  href=\"#\"\n                  className=\"block hover:text-primary transition-colors\"\n                >\n                  Contact\n                </a>\n                <a\n                  href=\"#\"\n                  className=\"block hover:text-primary transition-colors\"\n                >\n                  Privacy\n                </a>\n                <a\n                  href=\"#\"\n                  className=\"block hover:text-primary transition-colors\"\n                >\n                  Terms\n                </a>\n              </div>\n            </div>\n          </div>\n\n          <div className=\"border-t border-background/20 mt-8 pt-8 text-center text-background/70\">\n            <p>\n              &copy; 2024 SQL Practice Hub. All rights reserved. Practice smart,\n              code professionally.\n            </p>\n          </div>\n        </div>\n      </footer>\n    </div>\n  );\n}\n","size_bytes":26535},"client/src/pages/leaderboard.tsx":{"content":"import { useState } from 'react';\nimport { useQuery } from '@tanstack/react-query';\nimport { Trophy, Medal, Award, TrendingUp, Users, Target } from 'lucide-react';\nimport { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';\nimport { Avatar, AvatarFallback, AvatarImage } from '@/components/ui/avatar';\nimport { Badge } from '@/components/ui/badge';\nimport { Button } from '@/components/ui/button';\nimport { leaderboardApi } from '@/lib/auth';\nimport { useAuth } from '@/hooks/use-auth';\n\nexport default function Leaderboard() {\n  const [limit, setLimit] = useState(50);\n  const { user } = useAuth();\n\n  const { data: leaderboard, isLoading } = useQuery({\n    queryKey: ['/api/leaderboard', limit],\n    queryFn: () => leaderboardApi.get(limit),\n  });\n\n\n  const getRankIcon = (rank: number) => {\n    switch (rank) {\n      case 1: return <Trophy className=\"w-6 h-6 text-yellow-500\" />;\n      case 2: return <Medal className=\"w-6 h-6 text-gray-400\" />;\n      case 3: return <Award className=\"w-6 h-6 text-orange-400\" />;\n      default: return null;\n    }\n  };\n\n\n  const currentUserRank = leaderboard?.findIndex(u => u.id === user?.id) ?? -1;\n\n  return (\n    <div className=\"min-h-screen bg-background\">\n      <div className=\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\">\n        {/* Header */}\n        <div className=\"text-center mb-12\">\n          <h1 className=\"text-4xl font-bold text-foreground mb-4\">SQL Athletes Leaderboard</h1>\n          <p className=\"text-xl text-muted-foreground\">See who's crushing their SQL workouts</p>\n        </div>\n\n        <div className=\"grid lg:grid-cols-3 gap-8\">\n          {/* Main Leaderboard */}\n          <div className=\"lg:col-span-2\">\n            <Card className=\"overflow-hidden\">\n              <CardHeader className=\"bg-gradient-to-r from-primary to-orange-400 text-white\">\n                <CardTitle className=\"text-2xl font-bold mb-2\">Top SQL Athletes</CardTitle>\n                <p className=\"opacity-90\">This week's strongest performers</p>\n              </CardHeader>\n              \n              <CardContent className=\"p-6\">\n                {isLoading ? (\n                  <div className=\"space-y-4\">\n                    {[...Array(10)].map((_, i) => (\n                      <div key={i} className=\"flex items-center space-x-4 py-4 animate-pulse\">\n                        <div className=\"w-12 h-12 bg-muted rounded-full\" />\n                        <div className=\"w-12 h-12 bg-muted rounded-full\" />\n                        <div className=\"flex-1 space-y-2\">\n                          <div className=\"h-4 bg-muted rounded w-1/3\" />\n                          <div className=\"h-3 bg-muted rounded w-1/4\" />\n                        </div>\n                        <div className=\"space-y-2\">\n                          <div className=\"h-4 bg-muted rounded w-16\" />\n                          <div className=\"h-3 bg-muted rounded w-12\" />\n                        </div>\n                      </div>\n                    ))}\n                  </div>\n                ) : (\n                  <div className=\"space-y-2\">\n                    {leaderboard?.map((athlete, index) => (\n                      <div \n                        key={athlete.id} \n                        className={`flex items-center space-x-4 py-4 border-b border-border last:border-b-0 rounded-lg transition-colors ${\n                          athlete.id === user?.id ? 'bg-primary/5 border-primary/20' : 'hover:bg-muted/50'\n                        }`}\n                        data-testid={`leaderboard-rank-${index + 1}`}\n                      >\n                        {/* Rank */}\n                        <div className=\"flex items-center justify-center w-12 h-12\">\n                          {getRankIcon(index + 1) || (\n                            <div className={`flex items-center justify-center w-12 h-12 rounded-full font-bold text-lg ${\n                              index < 3 ? 'bg-primary text-primary-foreground' : 'bg-muted text-muted-foreground'\n                            }`}>\n                              {index + 1}\n                            </div>\n                          )}\n                        </div>\n\n                        {/* Avatar */}\n                        <Avatar className=\"w-12 h-12\">\n                          <AvatarImage src={athlete.profileImageUrl} alt={athlete.username} />\n                          <AvatarFallback>\n                            {athlete.username?.charAt(0).toUpperCase() || 'U'}\n                          </AvatarFallback>\n                        </Avatar>\n\n                        {/* User Info */}\n                        <div className=\"flex-1\">\n                          <div className=\"flex items-center space-x-2\">\n                            <h4 className=\"font-semibold text-foreground\" data-testid={`text-username-${index + 1}`}>\n                              {athlete.firstName && athlete.lastName \n                                ? `${athlete.firstName} ${athlete.lastName}` \n                                : athlete.username}\n                            </h4>\n                            {athlete.id === user?.id && (\n                              <Badge variant=\"outline\" className=\"text-xs\">You</Badge>\n                            )}\n                          </div>\n                          <div className=\"flex items-center space-x-2\">\n                            <span className=\"text-sm text-muted-foreground\">@{athlete.username}</span>\n                          </div>\n                        </div>\n\n                        {/* Stats */}\n                        <div className=\"text-right\">\n                          <p className=\"font-bold text-foreground\" data-testid={`text-problems-${index + 1}`}>\n                            {athlete.problemsSolved} solved\n                          </p>\n                        </div>\n\n                        {/* Achievement Icons */}\n                        <div className=\"flex items-center space-x-1\">\n                          {index === 0 && <Trophy className=\"w-4 h-4 text-yellow-400\" />}\n                          {index <= 1 && <Medal className=\"w-4 h-4 text-gray-400\" />}\n                          {index <= 2 && <Award className=\"w-4 h-4 text-orange-400\" />}\n                        </div>\n                      </div>\n                    ))}\n                  </div>\n                )}\n\n                {/* Load More */}\n                {!isLoading && leaderboard && leaderboard.length >= limit && (\n                  <div className=\"text-center mt-6\">\n                    <Button \n                      variant=\"outline\" \n                      onClick={() => setLimit(limit + 50)}\n                      data-testid=\"button-load-more\"\n                    >\n                      Load More Athletes\n                    </Button>\n                  </div>\n                )}\n              </CardContent>\n            </Card>\n          </div>\n\n          {/* Sidebar */}\n          <div className=\"space-y-6\">\n            {/* Your Stats */}\n            {user && (\n              <Card>\n                <CardHeader>\n                  <CardTitle className=\"flex items-center space-x-2\">\n                    <Target className=\"w-5 h-5 text-primary\" />\n                    <span>Your Stats</span>\n                  </CardTitle>\n                </CardHeader>\n                <CardContent className=\"space-y-4\">\n                  <div className=\"flex justify-between items-center\">\n                    <span className=\"text-muted-foreground\">Rank</span>\n                    <span className=\"font-bold text-foreground\" data-testid=\"text-user-rank\">\n                      #{currentUserRank >= 0 ? currentUserRank + 1 : '?'}\n                    </span>\n                  </div>\n                  <div className=\"flex justify-between items-center\">\n                    <span className=\"text-muted-foreground\">Problems Solved</span>\n                    <span className=\"font-bold text-foreground\" data-testid=\"text-user-problems\">\n                      {user.problemsSolved}\n                    </span>\n                  </div>\n                </CardContent>\n              </Card>\n            )}\n\n\n            {/* Weekly Challenge */}\n            <Card className=\"bg-gradient-to-br from-primary to-orange-400 text-white\">\n              <CardHeader>\n                <CardTitle className=\"text-white\">Weekly Challenge</CardTitle>\n              </CardHeader>\n              <CardContent>\n                <p className=\"text-sm opacity-90 mb-4\">\n                  Solve 5 problems this week to climb the leaderboard faster!\n                </p>\n                <div className=\"space-y-2\">\n                  <div className=\"flex justify-between text-sm\">\n                    <span>Progress</span>\n                    <span>{Math.min(user?.problemsSolved || 0, 5)}/5</span>\n                  </div>\n                  <div className=\"w-full bg-white/20 rounded-full h-2\">\n                    <div \n                      className=\"bg-white h-2 rounded-full transition-all duration-300\" \n                      style={{ width: `${Math.min(((user?.problemsSolved || 0) / 5) * 100, 100)}%` }} \n                    />\n                  </div>\n                </div>\n              </CardContent>\n            </Card>\n\n            {/* Leaderboard Stats */}\n            <Card>\n              <CardHeader>\n                <CardTitle className=\"flex items-center space-x-2\">\n                  <Users className=\"w-5 h-5 text-primary\" />\n                  <span>Community Stats</span>\n                </CardTitle>\n              </CardHeader>\n              <CardContent className=\"space-y-4\">\n                <div className=\"flex justify-between items-center\">\n                  <span className=\"text-muted-foreground\">Total Athletes</span>\n                  <span className=\"font-bold text-foreground\">\n                    {leaderboard?.length.toLocaleString() || 0}\n                  </span>\n                </div>\n                <div className=\"flex justify-between items-center\">\n                  <span className=\"text-muted-foreground\">Top Problems Solved</span>\n                  <span className=\"font-bold text-foreground\">\n                    {leaderboard?.[0]?.problemsSolved || 0}\n                  </span>\n                </div>\n              </CardContent>\n            </Card>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n","size_bytes":10376},"client/src/pages/not-found.tsx":{"content":"import { Card, CardContent } from \"@/components/ui/card\";\nimport { AlertCircle } from \"lucide-react\";\n\nexport default function NotFound() {\n  return (\n    <div className=\"min-h-screen w-full flex items-center justify-center bg-gray-50\">\n      <Card className=\"w-full max-w-md mx-4\">\n        <CardContent className=\"pt-6\">\n          <div className=\"flex mb-4 gap-2\">\n            <AlertCircle className=\"h-8 w-8 text-red-500\" />\n            <h1 className=\"text-2xl font-bold text-gray-900\">404 Page Not Found</h1>\n          </div>\n\n          <p className=\"mt-4 text-sm text-gray-600\">\n            Did you forget to add the page to the router?\n          </p>\n        </CardContent>\n      </Card>\n    </div>\n  );\n}\n","size_bytes":711},"client/src/pages/problem-detail.tsx":{"content":"import { useParams, useLocation } from \"wouter\";\nimport { useQuery, useMutation, useQueryClient } from \"@tanstack/react-query\";\nimport { useState, useEffect, useCallback, useMemo } from \"react\";\nimport { Lock, ArrowLeft } from \"lucide-react\";\nimport { Button } from \"@/components/ui/button\";\n\nimport { problemsApi, submissionsApi } from \"@/lib/auth\";\nimport { useAuth } from \"@/hooks/use-auth\";\nimport { useToast } from \"@/hooks/use-toast\";\nimport ResizableSplitter from \"@/components/resizable-splitter\";\nimport ProblemNavigation from \"@/components/ProblemNavigation\";\nimport ProblemTabsContent from \"@/components/ProblemTabsContent\";\nimport OptimizedEditorOutputSplit from \"@/components/OptimizedEditorOutputSplit\";\nimport \"../components/AnimatedFields.css\";\n\nexport default function ProblemDetail() {\n  const params = useParams();\n  const problemId = params.id as string;\n  const [, setLocation] = useLocation();\n  const { user } = useAuth();\n  const { toast } = useToast();\n  const queryClient = useQueryClient();\n  const [latestSubmissionResult, setLatestSubmissionResult] = useState<any>(null);\n  const [activeTab, setActiveTab] = useState<string>(\"problem\");\n\n  // Memoized navigation handlers to prevent recreation\n  const handleDifficultyClick = useCallback((difficulty: string) => {\n    setLocation(`/problems?difficulty=${encodeURIComponent(difficulty)}`);\n  }, [setLocation]);\n\n  const handleCompanyClick = useCallback((company: string) => {\n    setLocation(`/problems?company=${encodeURIComponent(company)}`);\n  }, [setLocation]);\n\n  // Optimized queries with proper memoization\n  const { data: problem, isLoading: problemLoading } = useQuery({\n    queryKey: [\"/api/problems\", problemId],\n    queryFn: () => problemsApi.getById(problemId),\n    enabled: !!problemId,\n  });\n\n  const { data: userSubmissions = [] } = useQuery({\n    queryKey: [\"/api/submissions\", problemId],\n    queryFn: () => submissionsApi.getByProblemId(problemId),\n    enabled: !!problemId && !!user,\n  });\n\n  // Memoized run query mutation with DuckDB/PostgreSQL detection\n  const runQueryMutation = useMutation({\n    mutationFn: async (query: string) => {\n      if (!problemId) throw new Error(\"No problem selected\");\n      \n      // Check if problem has parquet data source OR S3 data source(s) to determine which endpoint to use\n      const hasParquetData = problem?.parquetDataSource !== null && problem?.parquetDataSource !== undefined;\n      const hasS3Data = problem?.s3DataSource !== null && problem?.s3DataSource !== undefined;\n      const hasS3Datasets = problem?.s3Datasets && Array.isArray(problem.s3Datasets) && problem.s3Datasets.length > 0;\n      \n      if (hasParquetData || hasS3Data || hasS3Datasets) {\n        // Use DuckDB endpoint for parquet/S3 data\n        return submissionsApi.testDuckDBQuery(problemId, query);\n      } else {\n        // Use PostgreSQL endpoint for regular problems\n        return submissionsApi.testQuery(problemId, query);\n      }\n    },\n    onError: (error) => {\n      toast({\n        title: \"Query failed\",\n        description: error instanceof Error ? error.message : \"Unknown error\",\n        variant: \"destructive\",\n      });\n    },\n  });\n\n  // Memoized submit solution mutation\n  const submitSolutionMutation = useMutation({\n    mutationFn: async (query: string) => {\n      if (!problemId) throw new Error(\"No problem selected\");\n      return submissionsApi.submit(problemId, query);\n    },\n    onSuccess: (result) => {\n      // Store the latest submission result for the left panel\n      setLatestSubmissionResult(result);\n      // Invalidate submissions to refetch\n      queryClient.invalidateQueries({\n        queryKey: [\"/api/submissions\", problemId],\n      });\n      // Also invalidate the problems list to update the isUserSolved status\n      queryClient.invalidateQueries({\n        queryKey: [\"/api/problems\"],\n      });\n      // Auto-open submissions tab after successful submission\n      setActiveTab('submission');\n    },\n  });\n\n  // Memoized handlers\n  const handleRunQuery = useCallback(\n    async (query: string) => {\n      return runQueryMutation.mutateAsync(query);\n    },\n    [runQueryMutation]\n  );\n\n  const handleSubmitSolution = useCallback(\n    async (query: string) => {\n      return submitSolutionMutation.mutateAsync(query);\n    },\n    [submitSolutionMutation]\n  );\n\n  // Navigation handlers (placeholder - could be implemented with actual navigation logic)\n  const handlePrevious = useCallback(() => {\n    // Implement navigation to previous problem\n    console.log(\"Navigate to previous problem\");\n  }, []);\n\n  const handleNext = useCallback(() => {\n    // Implement navigation to next problem  \n    console.log(\"Navigate to next problem\");\n  }, []);\n\n  // Loading state\n  if (problemLoading) {\n    return (\n      <div className=\"h-screen flex items-center justify-center\">\n        <div className=\"text-center\">\n          <div className=\"animate-spin rounded-full h-8 w-8 border-b-2 border-primary mx-auto mb-4\"></div>\n          <p className=\"text-muted-foreground\">Loading problem...</p>\n        </div>\n      </div>\n    );\n  }\n\n  // Error state\n  if (!problem) {\n    return (\n      <div className=\"h-screen flex items-center justify-center\">\n        <div className=\"text-center\">\n          <h1 className=\"text-2xl font-bold mb-2\">Problem not found</h1>\n          <p className=\"text-muted-foreground mb-4\">\n            The problem you're looking for doesn't exist.\n          </p>\n          <button\n            onClick={() => setLocation(\"/problems\")}\n            className=\"text-primary hover:underline\"\n          >\n            Back to Problems\n          </button>\n        </div>\n      </div>\n    );\n  }\n\n  // Premium access check - block entire premium problems for non-premium users\n  if (problem.premium && (!user || !user.premium)) {\n    return (\n      <div className=\"h-screen flex items-center justify-center bg-background\">\n        <div className=\"text-center max-w-md mx-auto p-8\">\n          <div className=\"flex items-center justify-center w-20 h-20 bg-amber-100 dark:bg-amber-900/20 rounded-full mx-auto mb-6\">\n            <Lock className=\"w-10 h-10 text-amber-600 dark:text-amber-500\" />\n          </div>\n          <h1 className=\"text-3xl font-bold mb-4 text-foreground\">Premium Problem</h1>\n          <p className=\"text-muted-foreground mb-6 text-lg leading-relaxed\">\n            ðŸ”’ This is a premium problem. Upgrade to access the complete problem description, \n            hints, solutions, discussions, and coding environment.\n          </p>\n          <div className=\"space-y-3\">\n            <Button \n              className=\"w-full bg-amber-600 hover:bg-amber-700 text-white\"\n              onClick={() => {\n                if (!user) {\n                  // If not logged in, redirect to landing page (which shows auth forms)\n                  setLocation(\"/\");\n                } else {\n                  // If logged in but not premium, show upgrade message and redirect to landing\n                  toast({\n                    title: \"Premium Upgrade Required\",\n                    description: \"Contact support or visit our pricing page to upgrade to Premium.\",\n                    variant: \"default\",\n                  });\n                  // In a real app, this would redirect to billing/upgrade page\n                  setLocation(\"/\");\n                }\n              }}\n              data-testid=\"button-upgrade-premium\"\n            >\n              <Lock className=\"w-4 h-4 mr-2\" />\n              {!user ? \"Sign in to Access\" : \"Upgrade to Premium\"}\n            </Button>\n            <Button \n              variant=\"outline\" \n              onClick={() => setLocation(\"/problems\")}\n              className=\"w-full\"\n              data-testid=\"button-back-problems\"\n            >\n              <ArrowLeft className=\"w-4 h-4 mr-2\" />\n              Back to Problems\n            </Button>\n          </div>\n        </div>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"h-screen flex flex-col bg-background\">\n      {/* Navigation Header */}\n      <ProblemNavigation\n        problem={problem}\n        userSubmissions={userSubmissions}\n        onPrevious={handlePrevious}\n        onNext={handleNext}\n        hasPrevious={false} // TODO: Implement actual navigation logic\n        hasNext={false} // TODO: Implement actual navigation logic\n      />\n\n      {/* Main Content with Resizable Split */}\n      <div className=\"flex-1 min-h-0\">\n        <ResizableSplitter\n          leftPanel={\n            <ProblemTabsContent\n              problem={problem}\n              userSubmissions={userSubmissions}\n              latestSubmissionResult={latestSubmissionResult}\n              activeTab={activeTab}\n              onTabChange={setActiveTab}\n              problemId={problemId}\n            />\n          }\n          rightPanel={\n            <OptimizedEditorOutputSplit\n              problem={problem}\n              problemId={problemId}\n              handleRunQuery={handleRunQuery}\n              handleSubmitSolution={handleSubmitSolution}\n              onDifficultyClick={handleDifficultyClick}\n              onCompanyClick={handleCompanyClick}\n            />\n          }\n        />\n      </div>\n    </div>\n  );\n}","size_bytes":9187},"client/src/pages/problems.tsx":{"content":"import { useState, useEffect } from \"react\";\nimport { useQuery } from \"@tanstack/react-query\";\nimport { useLocation } from \"wouter\";\nimport { motion, AnimatePresence } from \"framer-motion\";\nimport {\n  Search,\n  Filter,\n  X,\n  ChevronDown,\n  Users,\n  Building2,\n  Tag,\n  Dumbbell,\n  CheckCircle,\n  Lock,\n} from \"lucide-react\";\nimport { CompanyLogo } from \"@/components/CompanyLogo\";\nimport { DifficultyBadge } from \"@/components/DifficultyBadge\";\nimport { Link } from \"wouter\";\nimport ReactMarkdown from 'react-markdown';\nimport remarkGfm from 'remark-gfm';\nimport { Button } from \"@/components/ui/button\";\nimport { Input } from \"@/components/ui/input\";\nimport { Card, CardContent } from \"@/components/ui/card\";\nimport { Badge } from \"@/components/ui/badge\";\nimport { Checkbox } from \"@/components/ui/checkbox\";\nimport {\n  Table,\n  TableBody,\n  TableCell,\n  TableHead,\n  TableHeader,\n  TableRow,\n} from \"@/components/ui/table\";\nimport {\n  Popover,\n  PopoverContent,\n  PopoverTrigger,\n} from \"@/components/ui/popover\";\nimport { problemsApi } from \"@/lib/auth\";\nimport { useAuth } from \"@/hooks/use-auth\";\n\ninterface Problem {\n  id: string;\n  title: string;\n  question: {\n    description: string;\n    tables: any[];\n    expectedOutput: any[];\n  };\n  difficulty: string;\n  tags: string[];\n  company?: string | null;\n  premium?: boolean | null;\n  solvedCount: number;\n  isUserSolved: boolean;\n}\n\ninterface FilterState {\n  difficulties: string[];\n  companies: string[];\n  tags: string[];\n  status: \"all\" | \"solved\" | \"unsolved\";\n  premium: \"all\" | \"free\" | \"premium\";\n}\n\nexport default function Problems() {\n  const { user } = useAuth();\n  const [location] = useLocation();\n  const [searchQuery, setSearchQuery] = useState(\"\");\n  const [filters, setFilters] = useState<FilterState>({\n    difficulties: [],\n    companies: [],\n    tags: [],\n    status: \"all\",\n    premium: \"all\",\n  });\n\n  // Handle URL search parameters for filtering\n  useEffect(() => {\n    const urlParams = new URLSearchParams(window.location.search);\n    const difficultyParam = urlParams.get('difficulty');\n    const companyParam = urlParams.get('company');\n    \n    if (difficultyParam || companyParam) {\n      setFilters(prev => ({\n        ...prev,\n        difficulties: difficultyParam ? [difficultyParam] : prev.difficulties,\n        companies: companyParam ? [companyParam] : prev.companies,\n      }));\n    }\n  }, [location]);\n\n  const { data: problems, isLoading } = useQuery<Problem[]>({\n    queryKey: [\"/api/problems\"],\n    queryFn: () => problemsApi.getAll(),\n  });\n\n  // Get unique values for filter options\n  const allCompanies = Array.from(\n    new Set((problems ?? []).map((p) => p.company).filter(Boolean))\n  ).sort();\n  const allTags = Array.from(\n    new Set((problems ?? []).flatMap((p) => p.tags || []))\n  ).sort();\n  // Normalize difficulties to handle case/whitespace differences\n  const difficulties = Array.from(\n    new Map(\n      (problems ?? [])\n        .map((p) => p.difficulty)\n        .filter(Boolean)\n        .map((d) => [d.trim().toLowerCase(), d.trim()])\n    ).values()\n  ).sort();\n\n  // Get tag counts for display\n  const getTagCount = (tag: string) => {\n    return problems?.filter((p) => p.tags?.includes(tag)).length || 0;\n  };\n\n  // Filter problems based on all criteria\n  const filteredProblems =\n    problems?.filter((problem) => {\n      // Search filter\n      const matchesSearch =\n        searchQuery === \"\" ||\n        problem.title.toLowerCase().includes(searchQuery.toLowerCase()) ||\n        problem.question.description.toLowerCase().includes(searchQuery.toLowerCase());\n\n      // Difficulty filter (case-insensitive comparison)\n      const matchesDifficulty =\n        filters.difficulties.length === 0 ||\n        filters.difficulties.some(filterDiff => \n          filterDiff.trim().toLowerCase() === problem.difficulty?.trim().toLowerCase()\n        );\n\n      // Company filter\n      const matchesCompany =\n        filters.companies.length === 0 ||\n        (problem.company && filters.companies.includes(problem.company));\n\n      // Tags filter - must have ALL selected tags (AND logic)\n      const matchesTags =\n        filters.tags.length === 0 ||\n        filters.tags.every((tag) => problem.tags?.includes(tag));\n\n      // Status filter - check if user has solved the problem\n      const matchesStatus =\n        filters.status === \"all\" ||\n        (filters.status === \"solved\" && problem.isUserSolved === true) ||\n        (filters.status === \"unsolved\" && problem.isUserSolved !== true);\n\n      // Premium filter\n      const matchesPremium =\n        filters.premium === \"all\" ||\n        (filters.premium === \"free\" && (problem.premium !== true)) ||\n        (filters.premium === \"premium\" && problem.premium === true);\n\n      return (\n        matchesSearch &&\n        matchesDifficulty &&\n        matchesCompany &&\n        matchesTags &&\n        matchesStatus &&\n        matchesPremium\n      );\n    }) || [];\n\n\n  const updateFilter = (key: keyof FilterState, value: any) => {\n    setFilters((prev) => ({ ...prev, [key]: value }));\n  };\n\n  const toggleArrayFilter = (\n    key: \"difficulties\" | \"companies\" | \"tags\",\n    value: string\n  ) => {\n    setFilters((prev) => ({\n      ...prev,\n      [key]: prev[key].includes(value)\n        ? prev[key].filter((item) => item !== value)\n        : [...prev[key], value],\n    }));\n  };\n\n  const clearFilters = () => {\n    setFilters({\n      difficulties: [],\n      companies: [],\n      tags: [],\n      status: \"all\",\n      premium: \"all\",\n    });\n    setSearchQuery(\"\");\n  };\n\n  const getActiveFilterCount = () => {\n    return (\n      filters.difficulties.length +\n      filters.companies.length +\n      filters.tags.length +\n      (filters.status !== \"all\" ? 1 : 0) +\n      (filters.premium !== \"all\" ? 1 : 0)\n    );\n  };\n\n  return (\n    <div className=\"min-h-screen bg-white\">\n      <div className=\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\">\n        {/* Header */}\n        <div className=\"mb-8\">\n          <h1 className=\"text-4xl font-bold text-gray-900 mb-4\">\n            SQL Practice Problems\n          </h1>\n          <p className=\"text-xl text-gray-600\">\n            Master SQL for interviews and professional development\n          </p>\n        </div>\n\n        {/* Search and Filters */}\n        <div className=\"mb-8 space-y-4\">\n          {/* Search Bar */}\n          <div className=\"relative\">\n            <Search className=\"absolute left-3 top-1/2 transform -translate-y-1/2 text-gray-400 w-5 h-5\" />\n            <Input\n              placeholder=\"Search problems by title or description...\"\n              value={searchQuery}\n              onChange={(e) => setSearchQuery(e.target.value)}\n              className=\"pl-10 h-12 text-lg border-gray-200 focus:border-orange-500 focus:ring-orange-500\"\n              data-testid=\"input-search-problems\"\n            />\n          </div>\n\n          {/* Filter Section */}\n          <div className=\"flex flex-wrap gap-3 items-center\">\n            {/* Difficulty Filter */}\n            <Popover>\n              <PopoverTrigger asChild>\n                <Button\n                  variant=\"outline\"\n                  className=\"h-10 border-gray-200 hover:border-orange-500\"\n                  data-testid=\"button-difficulty-filter\"\n                >\n                  <Filter className=\"w-4 h-4 mr-2\" />\n                  Difficulty\n                  {filters.difficulties.length > 0 && (\n                    <Badge\n                      variant=\"secondary\"\n                      className=\"ml-2 bg-orange-100 text-orange-700\"\n                    >\n                      {filters.difficulties.length}\n                    </Badge>\n                  )}\n                  <ChevronDown className=\"w-4 h-4 ml-2\" />\n                </Button>\n              </PopoverTrigger>\n              <PopoverContent className=\"w-64\" align=\"start\">\n                <div className=\"space-y-3\">\n                  <h4 className=\"font-medium text-gray-900\">\n                    Filter by Difficulty\n                  </h4>\n                  {difficulties.map((difficulty) => (\n                    <div\n                      key={difficulty}\n                      className=\"flex items-center space-x-2\"\n                    >\n                      <Checkbox\n                        checked={filters.difficulties.includes(difficulty)}\n                        onCheckedChange={() =>\n                          toggleArrayFilter(\"difficulties\", difficulty)\n                        }\n                        data-testid={`checkbox-difficulty-${difficulty.toLowerCase()}`}\n                      />\n                      <label className=\"text-sm font-medium cursor-pointer\">\n                        {difficulty}\n                      </label>\n                    </div>\n                  ))}\n                </div>\n              </PopoverContent>\n            </Popover>\n\n            {/* Companies Filter */}\n            <Popover>\n              <PopoverTrigger asChild>\n                <Button\n                  variant=\"outline\"\n                  className=\"h-10 border-gray-200 hover:border-orange-500\"\n                  data-testid=\"button-companies-filter\"\n                >\n                  <Building2 className=\"w-4 h-4 mr-2\" />\n                  Companies\n                  {filters.companies.length > 0 && (\n                    <Badge\n                      variant=\"secondary\"\n                      className=\"ml-2 bg-orange-100 text-orange-700\"\n                    >\n                      {filters.companies.length}\n                    </Badge>\n                  )}\n                  <ChevronDown className=\"w-4 h-4 ml-2\" />\n                </Button>\n              </PopoverTrigger>\n              <PopoverContent className=\"w-80\" align=\"start\">\n                <div className=\"space-y-3\">\n                  <h4 className=\"font-medium text-gray-900\">\n                    Filter by Companies\n                  </h4>\n                  <div className=\"max-h-64 overflow-y-auto space-y-2\">\n                    {allCompanies.map((company: string) => (\n                      <div\n                        key={company}\n                        className=\"flex items-center space-x-2\"\n                      >\n                        <Checkbox\n                          checked={filters.companies.includes(company)}\n                          onCheckedChange={() =>\n                            toggleArrayFilter(\"companies\", company)\n                          }\n                          data-testid={`checkbox-company-${company\n                            .toLowerCase()\n                            .replace(/\\s+/g, \"-\")}`}\n                        />\n                        <label className=\"text-sm font-medium cursor-pointer\">\n                          {company}\n                        </label>\n                      </div>\n                    ))}\n                  </div>\n                </div>\n              </PopoverContent>\n            </Popover>\n\n            {/* Premium Filter */}\n            <Popover>\n              <PopoverTrigger asChild>\n                <Button\n                  variant=\"outline\"\n                  className=\"h-10 border-gray-200 hover:border-orange-500\"\n                  data-testid=\"button-premium-filter\"\n                >\n                  <Lock className=\"w-4 h-4 mr-2\" />\n                  Type\n                  {filters.premium !== \"all\" && (\n                    <Badge\n                      variant=\"secondary\"\n                      className=\"ml-2 bg-orange-100 text-orange-700\"\n                    >\n                      1\n                    </Badge>\n                  )}\n                  <ChevronDown className=\"w-4 h-4 ml-2\" />\n                </Button>\n              </PopoverTrigger>\n              <PopoverContent className=\"w-64\" align=\"start\">\n                <div className=\"space-y-3\">\n                  <h4 className=\"font-medium text-gray-900\">\n                    Filter by Type\n                  </h4>\n                  {[\n                    { value: \"all\", label: \"All Problems\" },\n                    { value: \"free\", label: \"Free Problems\" },\n                    { value: \"premium\", label: \"Premium Problems ðŸ‹ï¸â€â™‚ï¸\" },\n                  ].map((option) => (\n                    <div\n                      key={option.value}\n                      className=\"flex items-center space-x-2\"\n                    >\n                      <Checkbox\n                        checked={filters.premium === option.value}\n                        onCheckedChange={() =>\n                          updateFilter(\"premium\", option.value)\n                        }\n                        data-testid={`checkbox-premium-${option.value}`}\n                      />\n                      <label className=\"text-sm font-medium cursor-pointer\">\n                        {option.label}\n                      </label>\n                    </div>\n                  ))}\n                </div>\n              </PopoverContent>\n            </Popover>\n\n            {/* Status Filter - Only show if user is authenticated */}\n            {user && (\n              <Popover>\n                <PopoverTrigger asChild>\n                  <Button\n                    variant=\"outline\"\n                    className=\"h-10 border-gray-200 hover:border-orange-500\"\n                    data-testid=\"button-status-filter\"\n                  >\n                    <CheckCircle className=\"w-4 h-4 mr-2\" />\n                    Status\n                    {filters.status !== \"all\" && (\n                      <Badge\n                        variant=\"secondary\"\n                        className=\"ml-2 bg-orange-100 text-orange-700\"\n                      >\n                        1\n                      </Badge>\n                    )}\n                    <ChevronDown className=\"w-4 h-4 ml-2\" />\n                  </Button>\n                </PopoverTrigger>\n                <PopoverContent className=\"w-64\" align=\"start\">\n                  <div className=\"space-y-3\">\n                    <h4 className=\"font-medium text-gray-900\">\n                      Filter by Status\n                    </h4>\n                    {[\n                      { value: \"all\", label: \"All Problems\" },\n                      { value: \"solved\", label: \"Solved\" },\n                      { value: \"unsolved\", label: \"Unsolved\" },\n                    ].map((option) => (\n                      <div\n                        key={option.value}\n                        className=\"flex items-center space-x-2\"\n                      >\n                        <Checkbox\n                          checked={filters.status === option.value}\n                          onCheckedChange={() =>\n                            updateFilter(\"status\", option.value)\n                          }\n                          data-testid={`checkbox-status-${option.value}`}\n                        />\n                        <label className=\"text-sm font-medium cursor-pointer\">\n                          {option.label}\n                        </label>\n                      </div>\n                    ))}\n                  </div>\n                </PopoverContent>\n              </Popover>\n            )}\n\n            {/* Clear Filters */}\n            {getActiveFilterCount() > 0 && (\n              <Button\n                variant=\"ghost\"\n                onClick={clearFilters}\n                className=\"h-10 text-gray-600 hover:text-gray-900\"\n                data-testid=\"button-clear-filters\"\n              >\n                <X className=\"w-4 h-4 mr-2\" />\n                Clear filters\n              </Button>\n            )}\n          </div>\n\n          {/* Active Filter Chips */}\n          <AnimatePresence>\n            {getActiveFilterCount() > 0 && (\n              <motion.div\n                initial={{ opacity: 0, height: 0 }}\n                animate={{ opacity: 1, height: \"auto\" }}\n                exit={{ opacity: 0, height: 0 }}\n                className=\"flex flex-wrap gap-2\"\n              >\n                {filters.difficulties.map((difficulty) => (\n                  <motion.div\n                    key={`difficulty-${difficulty}`}\n                    initial={{ opacity: 0, scale: 0.8 }}\n                    animate={{ opacity: 1, scale: 1 }}\n                    exit={{ opacity: 0, scale: 0.8 }}\n                  >\n                    <Badge\n                      variant=\"secondary\"\n                      className=\"bg-orange-100 text-orange-700 hover:bg-orange-200 cursor-pointer\"\n                      onClick={() =>\n                        toggleArrayFilter(\"difficulties\", difficulty)\n                      }\n                      data-testid={`chip-difficulty-${difficulty.toLowerCase()}`}\n                    >\n                      {difficulty}\n                      <X className=\"w-3 h-3 ml-1\" />\n                    </Badge>\n                  </motion.div>\n                ))}\n                {filters.companies.map((company) => (\n                  <motion.div\n                    key={`company-${company}`}\n                    initial={{ opacity: 0, scale: 0.8 }}\n                    animate={{ opacity: 1, scale: 1 }}\n                    exit={{ opacity: 0, scale: 0.8 }}\n                  >\n                    <Badge\n                      variant=\"secondary\"\n                      className=\"bg-blue-100 text-blue-700 hover:bg-blue-200 cursor-pointer\"\n                      onClick={() => toggleArrayFilter(\"companies\", company)}\n                      data-testid={`chip-company-${company\n                        .toLowerCase()\n                        .replace(/\\s+/g, \"-\")}`}\n                    >\n                      {company}\n                      <X className=\"w-3 h-3 ml-1\" />\n                    </Badge>\n                  </motion.div>\n                ))}\n                {filters.tags.map((tag) => (\n                  <motion.div\n                    key={`tag-${tag}`}\n                    initial={{ opacity: 0, scale: 0.8 }}\n                    animate={{ opacity: 1, scale: 1 }}\n                    exit={{ opacity: 0, scale: 0.8 }}\n                  >\n                    <Badge\n                      variant=\"secondary\"\n                      className=\"bg-purple-100 text-purple-700 hover:bg-purple-200 cursor-pointer\"\n                      onClick={() => toggleArrayFilter(\"tags\", tag)}\n                      data-testid={`chip-tag-${tag\n                        .toLowerCase()\n                        .replace(/\\s+/g, \"-\")}`}\n                    >\n                      {tag}\n                      <X className=\"w-3 h-3 ml-1\" />\n                    </Badge>\n                  </motion.div>\n                ))}\n                {filters.status !== \"all\" && (\n                  <motion.div\n                    key={`status-${filters.status}`}\n                    initial={{ opacity: 0, scale: 0.8 }}\n                    animate={{ opacity: 1, scale: 1 }}\n                    exit={{ opacity: 0, scale: 0.8 }}\n                  >\n                    <Badge\n                      variant=\"secondary\"\n                      className=\"bg-green-100 text-green-700 hover:bg-green-200 cursor-pointer\"\n                      onClick={() => updateFilter(\"status\", \"all\")}\n                      data-testid={`chip-status-${filters.status}`}\n                    >\n                      {filters.status === \"solved\" ? \"Solved\" : \"Unsolved\"}\n                      <X className=\"w-3 h-3 ml-1\" />\n                    </Badge>\n                  </motion.div>\n                )}\n              </motion.div>\n            )}\n          </AnimatePresence>\n        </div>\n\n        {/* Main Content Area - Table and Tags Side by Side */}\n        <div className=\"flex gap-8\">\n          {/* Left Side - Table and Results */}\n          <div className=\"flex-1\">\n            {/* Results Summary */}\n            <div className=\"mb-6\">\n              <p className=\"text-gray-600\">\n                Showing{\" \"}\n                <span className=\"font-semibold text-gray-900\">\n                  {filteredProblems.length}\n                </span>{\" \"}\n                of{\" \"}\n                <span className=\"font-semibold text-gray-900\">\n                  {problems?.length || 0}\n                </span>{\" \"}\n                problems\n              </p>\n            </div>\n\n            {/* Problems Table */}\n            {isLoading ? (\n              <div className=\"space-y-4\">\n                {[...Array(6)].map((_, i) => (\n                  <div key={i} className=\"animate-pulse\">\n                    <div className=\"h-16 bg-gray-200 rounded\" />\n                  </div>\n                ))}\n              </div>\n            ) : filteredProblems.length === 0 ? (\n              <motion.div\n                initial={{ opacity: 0, y: 20 }}\n                animate={{ opacity: 1, y: 0 }}\n                className=\"text-center py-16\"\n              >\n                <div className=\"w-24 h-24 bg-gray-100 rounded-full flex items-center justify-center mx-auto mb-6\">\n                  <Search className=\"w-12 h-12 text-gray-400\" />\n                </div>\n                <h3 className=\"text-2xl font-semibold text-gray-900 mb-2\">\n                  No problems found\n                </h3>\n                <p className=\"text-gray-600 mb-6\">\n                  Try changing your filters or search terms\n                </p>\n                <Button\n                  onClick={clearFilters}\n                  variant=\"outline\"\n                  data-testid=\"button-clear-all-filters\"\n                >\n                  Clear all filters\n                </Button>\n              </motion.div>\n            ) : (\n              <motion.div\n                initial={{ opacity: 0 }}\n                animate={{ opacity: 1 }}\n                className=\"border rounded-lg overflow-hidden bg-white\"\n              >\n                <Table>\n                  <TableHeader>\n                    <TableRow className=\"bg-gray-50\">\n                      <TableHead className=\"font-semibold text-gray-900\">\n                        Company\n                      </TableHead>\n                      <TableHead className=\"font-semibold text-gray-900\">\n                        Title\n                      </TableHead>\n                      <TableHead className=\"font-semibold text-gray-900\">\n                        Description\n                      </TableHead>\n                      <TableHead className=\"font-semibold text-gray-900\">\n                        Difficulty\n                      </TableHead>\n                      <TableHead className=\"font-semibold text-gray-900\">\n                        Status\n                      </TableHead>\n                      <TableHead className=\"font-semibold text-gray-900\">\n                        Submissions\n                      </TableHead>\n                    </TableRow>\n                  </TableHeader>\n                  <TableBody>\n                    {filteredProblems.map((problem, index) => (\n                      <motion.tr\n                        key={problem.id}\n                        initial={{ opacity: 0, y: 20 }}\n                        animate={{ opacity: 1, y: 0 }}\n                        transition={{ delay: index * 0.02 }}\n                        className=\"hover:bg-gray-50 transition-colors cursor-pointer\"\n                        onClick={() =>\n                          (window.location.href = `/problems/${problem.id}`)\n                        }\n                        data-testid={`row-problem-${problem.id}`}\n                      >\n                        <TableCell className=\"py-4 w-32\">\n                          <div className=\"flex flex-wrap gap-1\">\n                            <CompanyLogo\n                              companyName={problem.company}\n                              variant=\"badge\"\n                              size=\"sm\"\n                              showFallback={true}\n                              data-testid={`company-badge-${problem.id}`}\n                            />\n                          </div>\n                        </TableCell>\n\n                        <TableCell className=\"py-4 max-w-xs\">\n                          <div className=\"flex items-center gap-2\">\n                            {problem.premium && (\n                              <Lock className=\"w-4 h-4 text-amber-500 flex-shrink-0\" />\n                            )}\n                            <h3 className=\"font-medium text-gray-900 hover:text-orange-600 transition-colors truncate\">\n                              {problem.title}\n                            </h3>\n                          </div>\n                        </TableCell>\n\n                        <TableCell className=\"py-4 max-w-md\">\n                          <div className=\"text-gray-600 text-sm line-clamp-2\">\n                            <ReactMarkdown \n                              remarkPlugins={[remarkGfm]}\n                              components={{\n                                // Flatten all elements for preview - keep formatting but avoid line breaks\n                                p: ({children}) => <span className=\"inline\">{children} </span>,\n                                strong: ({children}) => <strong className=\"font-semibold text-gray-800\">{children}</strong>,\n                                em: ({children}) => <em className=\"italic\">{children}</em>,\n                                code: ({children}) => <code className=\"bg-gray-100 px-1 py-0.5 rounded text-xs font-mono text-gray-800\">{children}</code>,\n                                h1: ({children}) => <span className=\"font-bold text-gray-800\">{children} </span>,\n                                h2: ({children}) => <span className=\"font-semibold text-gray-800\">{children} </span>,\n                                h3: ({children}) => <span className=\"font-medium text-gray-800\">{children} </span>,\n                                ul: ({children}) => <span>{children}</span>,\n                                ol: ({children}) => <span>{children}</span>,\n                                li: ({children}) => <span>{children} â€¢ </span>,\n                                blockquote: ({children}) => <span className=\"italic text-blue-600\">\"{children}\" </span>,\n                                // Tables and code blocks are hidden in preview\n                                table: () => <span className=\"text-blue-600 font-medium\">[Table] </span>,\n                                pre: () => <span className=\"text-green-600 font-medium\">[Code] </span>,\n                              }}\n                            >\n                              {(() => {\n                                // Get first paragraph or first 150 chars to avoid breaking markdown syntax\n                                const desc = problem.question.description;\n                                const firstParagraph = desc.split('\\n\\n')[0];\n                                if (firstParagraph.length > 150) {\n                                  return firstParagraph.substring(0, 150) + '...';\n                                }\n                                return firstParagraph + (desc.length > firstParagraph.length ? '...' : '');\n                              })()}\n                            </ReactMarkdown>\n                          </div>\n                        </TableCell>\n\n                        <TableCell className=\"py-4\">\n                          <DifficultyBadge\n                            difficulty={problem.difficulty}\n                            variant=\"badge\"\n                            size=\"sm\"\n                            showIcon={true}\n                            data-testid={`difficulty-badge-${problem.id}`}\n                          />\n                        </TableCell>\n\n                        <TableCell className=\"py-4\">\n                          <div className=\"flex items-center justify-center\">\n                            {problem.isUserSolved ? (\n                              <div\n                                className=\"text-green-600\"\n                                data-testid={`dumbbell-solved-${problem.id}`}\n                              >\n                                <Dumbbell className=\"w-5 h-5\" />\n                              </div>\n                            ) : null}\n                          </div>\n                        </TableCell>\n\n                        <TableCell className=\"py-4\">\n                          <div className=\"flex items-center space-x-1 text-sm text-gray-500\">\n                            <Users className=\"w-4 h-4\" />\n                            <span>{problem.solvedCount}</span>\n                          </div>\n                        </TableCell>\n                      </motion.tr>\n                    ))}\n                  </TableBody>\n                </Table>\n              </motion.div>\n            )}\n\n            {/* Stats Footer */}\n            {!isLoading && filteredProblems.length > 0 && (\n              <motion.div\n                initial={{ opacity: 0, y: 20 }}\n                animate={{ opacity: 1, y: 0 }}\n                transition={{ delay: 0.3 }}\n                className=\"mt-16 bg-gray-50 rounded-2xl p-8\"\n              >\n                <div className=\"grid grid-cols-2 md:grid-cols-4 gap-8 text-center\">\n                  <div>\n                    <div className=\"text-3xl font-bold text-gray-900\">\n                      {filteredProblems.length}\n                    </div>\n                    <div className=\"text-sm text-gray-600\">Total Problems</div>\n                  </div>\n                  <div>\n                    <div className=\"text-3xl font-bold text-green-600\">\n                      {\n                        filteredProblems.filter((p) => p.difficulty?.toLowerCase() === \"easy\")\n                          .length\n                      }\n                    </div>\n                    <div className=\"text-sm text-gray-600\">Easy</div>\n                  </div>\n                  <div>\n                    <div className=\"text-3xl font-bold text-orange-600\">\n                      {\n                        filteredProblems.filter(\n                          (p) => p.difficulty?.toLowerCase() === \"medium\"\n                        ).length\n                      }\n                    </div>\n                    <div className=\"text-sm text-gray-600\">Medium</div>\n                  </div>\n                  <div>\n                    <div className=\"text-3xl font-bold text-red-600\">\n                      {\n                        filteredProblems.filter((p) => p.difficulty?.toLowerCase() === \"hard\")\n                          .length\n                      }\n                    </div>\n                    <div className=\"text-sm text-gray-600\">Hard</div>\n                  </div>\n                </div>\n              </motion.div>\n            )}\n          </div>\n\n          {/* Right Sidebar - Tags */}\n          <div className=\"w-80\">\n            {allTags.length > 0 && (\n              <div className=\"sticky top-6\">\n                <h3 className=\"text-lg font-semibold text-gray-900 mb-4\">\n                  Tags\n                </h3>\n                <div className=\"flex flex-wrap gap-1.5 max-h-96 overflow-y-auto\">\n                  {allTags.map((tag) => (\n                    <button\n                      key={tag}\n                      onClick={() => toggleArrayFilter(\"tags\", tag)}\n                      className={`\n                    px-3 py-1.5 rounded-full text-sm font-medium transition-colors duration-200\n                    ${\n                      filters.tags.includes(tag)\n                        ? \"bg-orange-500 text-white border border-orange-500\"\n                        : \"bg-white text-gray-700 border border-gray-300 hover:bg-gray-100 hover:border-gray-400\"\n                    }\n                  `}\n                    >\n                      {tag} ({getTagCount(tag)})\n                    </button>\n                  ))}\n                </div>\n              </div>\n            )}\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n","size_bytes":31903},"client/src/pages/submissions.tsx":{"content":"import { useQuery } from '@tanstack/react-query';\nimport { Clock, CheckCircle, XCircle, Code, ArrowRight, Filter } from 'lucide-react';\nimport { useState } from 'react';\nimport { Link } from 'wouter';\nimport { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';\nimport { Badge } from '@/components/ui/badge';\nimport { Button } from '@/components/ui/button';\nimport { submissionsApi, problemsApi } from '@/lib/auth';\nimport { useAuth } from '@/hooks/use-auth';\n\nexport default function Submissions() {\n  const [filter, setFilter] = useState<'all' | 'correct' | 'incorrect'>('all');\n  const { user } = useAuth();\n\n  const { data: submissions, isLoading: submissionsLoading } = useQuery({\n    queryKey: ['/api/submissions/user', user?.id],\n    queryFn: () => submissionsApi.getUserSubmissions(user!.id),\n    enabled: !!user?.id,\n  });\n\n  const { data: problems } = useQuery({\n    queryKey: ['/api/problems'],\n    queryFn: () => problemsApi.getAll(),\n  });\n\n  const filteredSubmissions = submissions?.filter(submission => {\n    if (filter === 'correct') return submission.isCorrect;\n    if (filter === 'incorrect') return !submission.isCorrect;\n    return true;\n  }) || [];\n\n  const getProblemTitle = (problemId: string) => {\n    return problems?.find(p => p.id === problemId)?.title || 'Unknown Problem';\n  };\n\n  const getProblemDifficulty = (problemId: string) => {\n    return problems?.find(p => p.id === problemId)?.difficulty || 'Unknown';\n  };\n\n  const getDifficultyColor = (difficulty: string) => {\n    switch (difficulty) {\n      case 'Easy': return 'bg-green-100 text-green-800';\n      case 'Medium': return 'bg-yellow-100 text-yellow-800';\n      case 'Hard': return 'bg-red-100 text-red-800';\n      default: return 'bg-gray-100 text-gray-800';\n    }\n  };\n\n  const formatDate = (dateString: string) => {\n    const date = new Date(dateString);\n    return date.toLocaleDateString('en-US', {\n      year: 'numeric',\n      month: 'short',\n      day: 'numeric',\n      hour: '2-digit',\n      minute: '2-digit',\n    });\n  };\n\n  const truncateQuery = (query: string, maxLength: number = 100) => {\n    if (query.length <= maxLength) return query;\n    return query.substring(0, maxLength).trim() + '...';\n  };\n\n  // Calculate stats\n  const totalSubmissions = submissions?.length || 0;\n  const correctSubmissions = submissions?.filter(s => s.isCorrect).length || 0;\n  const successRate = totalSubmissions > 0 ? Math.round((correctSubmissions / totalSubmissions) * 100) : 0;\n  const avgExecutionTime = submissions?.length ? \n    Math.round(submissions.reduce((sum, s) => sum + (s.executionTime || 0), 0) / submissions.length) : 0;\n\n  return (\n    <div className=\"min-h-screen bg-background\">\n      <div className=\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\">\n        {/* Header */}\n        <div className=\"mb-8\">\n          <h1 className=\"text-4xl font-bold text-foreground mb-4\">Your Submissions</h1>\n          <p className=\"text-xl text-muted-foreground\">Track your SQL training progress and achievements</p>\n        </div>\n\n        {/* Stats Overview */}\n        <div className=\"grid md:grid-cols-4 gap-6 mb-8\">\n          <Card>\n            <CardContent className=\"p-6 text-center\">\n              <div className=\"text-3xl font-bold text-primary mb-2\" data-testid=\"stat-total-submissions\">\n                {totalSubmissions}\n              </div>\n              <div className=\"text-sm text-muted-foreground\">Total Submissions</div>\n            </CardContent>\n          </Card>\n          \n          <Card>\n            <CardContent className=\"p-6 text-center\">\n              <div className=\"text-3xl font-bold text-green-600 mb-2\" data-testid=\"stat-correct-submissions\">\n                {correctSubmissions}\n              </div>\n              <div className=\"text-sm text-muted-foreground\">Correct Solutions</div>\n            </CardContent>\n          </Card>\n          \n          <Card>\n            <CardContent className=\"p-6 text-center\">\n              <div className=\"text-3xl font-bold text-blue-600 mb-2\" data-testid=\"stat-success-rate\">\n                {successRate}%\n              </div>\n              <div className=\"text-sm text-muted-foreground\">Success Rate</div>\n            </CardContent>\n          </Card>\n          \n          <Card>\n            <CardContent className=\"p-6 text-center\">\n              <div className=\"text-3xl font-bold text-orange-600 mb-2\" data-testid=\"stat-avg-time\">\n                {avgExecutionTime}ms\n              </div>\n              <div className=\"text-sm text-muted-foreground\">Avg Execution Time</div>\n            </CardContent>\n          </Card>\n        </div>\n\n        {/* Filters */}\n        <div className=\"flex items-center space-x-4 mb-6\">\n          <div className=\"flex items-center space-x-2\">\n            <Filter className=\"w-4 h-4 text-muted-foreground\" />\n            <span className=\"text-sm font-medium text-foreground\">Filter:</span>\n          </div>\n          <div className=\"bg-white border border-border rounded-lg p-1 inline-flex\">\n            <Button\n              variant={filter === 'all' ? 'default' : 'ghost'}\n              size=\"sm\"\n              onClick={() => setFilter('all')}\n              className={filter === 'all' ? 'bg-primary text-primary-foreground' : ''}\n              data-testid=\"button-filter-all\"\n            >\n              All ({totalSubmissions})\n            </Button>\n            <Button\n              variant={filter === 'correct' ? 'default' : 'ghost'}\n              size=\"sm\"\n              onClick={() => setFilter('correct')}\n              className={filter === 'correct' ? 'bg-primary text-primary-foreground' : ''}\n              data-testid=\"button-filter-correct\"\n            >\n              Correct ({correctSubmissions})\n            </Button>\n            <Button\n              variant={filter === 'incorrect' ? 'default' : 'ghost'}\n              size=\"sm\"\n              onClick={() => setFilter('incorrect')}\n              className={filter === 'incorrect' ? 'bg-primary text-primary-foreground' : ''}\n              data-testid=\"button-filter-incorrect\"\n            >\n              Incorrect ({totalSubmissions - correctSubmissions})\n            </Button>\n          </div>\n        </div>\n\n        {/* Submissions List */}\n        {submissionsLoading ? (\n          <div className=\"space-y-4\">\n            {[...Array(5)].map((_, i) => (\n              <Card key={i} className=\"animate-pulse\">\n                <CardContent className=\"p-6\">\n                  <div className=\"flex items-start justify-between\">\n                    <div className=\"space-y-3 flex-1\">\n                      <div className=\"h-4 bg-muted rounded w-1/3\" />\n                      <div className=\"h-3 bg-muted rounded w-1/2\" />\n                      <div className=\"h-16 bg-muted rounded\" />\n                    </div>\n                    <div className=\"ml-4 space-y-2\">\n                      <div className=\"h-6 bg-muted rounded w-20\" />\n                      <div className=\"h-4 bg-muted rounded w-16\" />\n                    </div>\n                  </div>\n                </CardContent>\n              </Card>\n            ))}\n          </div>\n        ) : filteredSubmissions.length === 0 ? (\n          <Card>\n            <CardContent className=\"p-12 text-center\">\n              <div className=\"w-16 h-16 bg-muted rounded-full flex items-center justify-center mx-auto mb-4\">\n                <Code className=\"w-8 h-8 text-muted-foreground\" />\n              </div>\n              <h3 className=\"text-lg font-semibold text-foreground mb-2\">\n                {filter === 'all' ? 'No submissions yet' : `No ${filter} submissions`}\n              </h3>\n              <p className=\"text-muted-foreground mb-6\">\n                {filter === 'all' \n                  ? 'Start solving problems to see your submission history here!'\n                  : `You haven't made any ${filter} submissions yet.`}\n              </p>\n              {filter === 'all' && (\n                <Link href=\"/problems\">\n                  <Button className=\"dumbbell-btn bg-primary text-primary-foreground hover:bg-primary/90\" data-testid=\"button-start-solving\">\n                    Start Solving Problems\n                  </Button>\n                </Link>\n              )}\n            </CardContent>\n          </Card>\n        ) : (\n          <div className=\"space-y-4\">\n            {filteredSubmissions.map((submission, index) => (\n              <Card key={submission.id} className=\"hover:shadow-md transition-shadow\" data-testid={`submission-${index}`}>\n                <CardContent className=\"p-6\">\n                  <div className=\"flex items-start justify-between\">\n                    <div className=\"flex-1\">\n                      {/* Header */}\n                      <div className=\"flex items-center space-x-3 mb-3\">\n                        <div className={`flex items-center justify-center w-8 h-8 rounded-full ${\n                          submission.isCorrect ? 'bg-green-100' : 'bg-red-100'\n                        }`}>\n                          {submission.isCorrect ? (\n                            <CheckCircle className=\"w-5 h-5 text-green-600\" />\n                          ) : (\n                            <XCircle className=\"w-5 h-5 text-red-600\" />\n                          )}\n                        </div>\n                        \n                        <div className=\"flex-1\">\n                          <Link href={`/problems/${submission.problemId}`}>\n                            <h3 className=\"font-semibold text-foreground hover:text-primary transition-colors cursor-pointer\" data-testid={`text-problem-title-${index}`}>\n                              {getProblemTitle(submission.problemId)}\n                            </h3>\n                          </Link>\n                          <div className=\"flex items-center space-x-3 mt-1\">\n                            <Badge className={getDifficultyColor(getProblemDifficulty(submission.problemId))}>\n                              {getProblemDifficulty(submission.problemId)}\n                            </Badge>\n                            <div className=\"flex items-center space-x-1 text-sm text-muted-foreground\">\n                              <Clock className=\"w-3 h-3\" />\n                              <span data-testid={`text-submission-date-${index}`}>\n                                {formatDate(submission.submittedAt)}\n                              </span>\n                            </div>\n                            {submission.executionTime && (\n                              <span className=\"text-sm text-muted-foreground\" data-testid={`text-execution-time-${index}`}>\n                                {submission.executionTime}ms\n                              </span>\n                            )}\n                          </div>\n                        </div>\n                      </div>\n\n                      {/* Query Preview */}\n                      <div className=\"bg-muted rounded-lg p-3 mb-3\">\n                        <div className=\"flex items-center justify-between mb-2\">\n                          <span className=\"text-sm font-medium text-foreground\">SQL Query</span>\n                          <Badge variant=\"outline\" className={\n                            submission.isCorrect ? 'text-green-700 border-green-300' : 'text-red-700 border-red-300'\n                          }>\n                            {submission.isCorrect ? 'Correct' : 'Incorrect'}\n                          </Badge>\n                        </div>\n                        <pre className=\"text-sm text-muted-foreground font-mono overflow-x-auto\">\n                          <code data-testid={`code-query-${index}`}>\n                            {truncateQuery(submission.query)}\n                          </code>\n                        </pre>\n                        {submission.query.length > 100 && (\n                          <Button \n                            variant=\"ghost\" \n                            size=\"sm\" \n                            className=\"mt-2 text-primary hover:bg-primary/10\"\n                            data-testid={`button-view-full-${index}`}\n                          >\n                            View Full Query\n                          </Button>\n                        )}\n                      </div>\n                    </div>\n\n                    {/* Actions */}\n                    <div className=\"ml-4 flex flex-col space-y-2\">\n                      <Link href={`/problems/${submission.problemId}`}>\n                        <Button \n                          variant=\"outline\" \n                          size=\"sm\"\n                          className=\"w-full\"\n                          data-testid={`button-view-problem-${index}`}\n                        >\n                          View Problem\n                          <ArrowRight className=\"ml-2 w-3 h-3\" />\n                        </Button>\n                      </Link>\n                      \n                      {!submission.isCorrect && (\n                        <Link href={`/problems/${submission.problemId}`}>\n                          <Button \n                            variant=\"outline\" \n                            size=\"sm\"\n                            className=\"w-full text-primary border-primary hover:bg-primary/10\"\n                            data-testid={`button-retry-${index}`}\n                          >\n                            Try Again\n                          </Button>\n                        </Link>\n                      )}\n                    </div>\n                  </div>\n                </CardContent>\n              </Card>\n            ))}\n          </div>\n        )}\n\n        {/* Performance Insights */}\n        {submissions && submissions.length > 0 && (\n          <Card className=\"mt-8\">\n            <CardHeader>\n              <CardTitle className=\"flex items-center space-x-2\">\n                <Clock className=\"w-5 h-5 text-primary\" />\n                <span>Performance Insights</span>\n              </CardTitle>\n            </CardHeader>\n            <CardContent>\n              <div className=\"grid md:grid-cols-2 gap-8\">\n                <div>\n                  <h4 className=\"font-semibold text-foreground mb-3\">Recent Progress</h4>\n                  <div className=\"space-y-2\">\n                    <div className=\"flex justify-between text-sm\">\n                      <span className=\"text-muted-foreground\">This week</span>\n                      <span className=\"font-medium\">{submissions.filter(s => {\n                        const weekAgo = new Date();\n                        weekAgo.setDate(weekAgo.getDate() - 7);\n                        return new Date(s.submittedAt) > weekAgo;\n                      }).length} submissions</span>\n                    </div>\n                    <div className=\"flex justify-between text-sm\">\n                      <span className=\"text-muted-foreground\">Best streak</span>\n                      <span className=\"font-medium\">5 correct in a row</span>\n                    </div>\n                    <div className=\"flex justify-between text-sm\">\n                      <span className=\"text-muted-foreground\">Fastest solution</span>\n                      <span className=\"font-medium\">\n                        {Math.min(...submissions.map(s => s.executionTime || Infinity))}ms\n                      </span>\n                    </div>\n                  </div>\n                </div>\n                \n                <div>\n                  <h4 className=\"font-semibold text-foreground mb-3\">Areas to Improve</h4>\n                  <div className=\"space-y-2 text-sm text-muted-foreground\">\n                    <p>â€¢ Focus on Medium difficulty problems to build confidence</p>\n                    <p>â€¢ Practice window functions and CTEs</p>\n                    <p>â€¢ Review query optimization techniques</p>\n                  </div>\n                </div>\n              </div>\n            </CardContent>\n          </Card>\n        )}\n      </div>\n    </div>\n  );\n}\n","size_bytes":15963},"client/src/components/ui/alert.tsx":{"content":"import * as React from \"react\"\nimport { cva, type VariantProps } from \"class-variance-authority\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst alertVariants = cva(\n  \"relative w-full rounded-lg border p-4 [&>svg~*]:pl-7 [&>svg+div]:translate-y-[-3px] [&>svg]:absolute [&>svg]:left-4 [&>svg]:top-4 [&>svg]:text-foreground\",\n  {\n    variants: {\n      variant: {\n        default: \"bg-background text-foreground\",\n        destructive:\n          \"border-destructive/50 text-destructive dark:border-destructive [&>svg]:text-destructive\",\n      },\n    },\n    defaultVariants: {\n      variant: \"default\",\n    },\n  }\n)\n\nconst Alert = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement> & VariantProps<typeof alertVariants>\n>(({ className, variant, ...props }, ref) => (\n  <div\n    ref={ref}\n    role=\"alert\"\n    className={cn(alertVariants({ variant }), className)}\n    {...props}\n  />\n))\nAlert.displayName = \"Alert\"\n\nconst AlertTitle = React.forwardRef<\n  HTMLParagraphElement,\n  React.HTMLAttributes<HTMLHeadingElement>\n>(({ className, ...props }, ref) => (\n  <h5\n    ref={ref}\n    className={cn(\"mb-1 font-medium leading-none tracking-tight\", className)}\n    {...props}\n  />\n))\nAlertTitle.displayName = \"AlertTitle\"\n\nconst AlertDescription = React.forwardRef<\n  HTMLParagraphElement,\n  React.HTMLAttributes<HTMLParagraphElement>\n>(({ className, ...props }, ref) => (\n  <div\n    ref={ref}\n    className={cn(\"text-sm [&_p]:leading-relaxed\", className)}\n    {...props}\n  />\n))\nAlertDescription.displayName = \"AlertDescription\"\n\nexport { Alert, AlertTitle, AlertDescription }\n","size_bytes":1584},"client/src/components/ui/avatar.tsx":{"content":"\"use client\"\n\nimport * as React from \"react\"\nimport * as AvatarPrimitive from \"@radix-ui/react-avatar\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst Avatar = React.forwardRef<\n  React.ElementRef<typeof AvatarPrimitive.Root>,\n  React.ComponentPropsWithoutRef<typeof AvatarPrimitive.Root>\n>(({ className, ...props }, ref) => (\n  <AvatarPrimitive.Root\n    ref={ref}\n    className={cn(\n      \"relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full\",\n      className\n    )}\n    {...props}\n  />\n))\nAvatar.displayName = AvatarPrimitive.Root.displayName\n\nconst AvatarImage = React.forwardRef<\n  React.ElementRef<typeof AvatarPrimitive.Image>,\n  React.ComponentPropsWithoutRef<typeof AvatarPrimitive.Image>\n>(({ className, ...props }, ref) => (\n  <AvatarPrimitive.Image\n    ref={ref}\n    className={cn(\"aspect-square h-full w-full\", className)}\n    {...props}\n  />\n))\nAvatarImage.displayName = AvatarPrimitive.Image.displayName\n\nconst AvatarFallback = React.forwardRef<\n  React.ElementRef<typeof AvatarPrimitive.Fallback>,\n  React.ComponentPropsWithoutRef<typeof AvatarPrimitive.Fallback>\n>(({ className, ...props }, ref) => (\n  <AvatarPrimitive.Fallback\n    ref={ref}\n    className={cn(\n      \"flex h-full w-full items-center justify-center rounded-full bg-muted\",\n      className\n    )}\n    {...props}\n  />\n))\nAvatarFallback.displayName = AvatarPrimitive.Fallback.displayName\n\nexport { Avatar, AvatarImage, AvatarFallback }\n","size_bytes":1419},"client/src/components/ui/badge.tsx":{"content":"import * as React from \"react\"\nimport { cva, type VariantProps } from \"class-variance-authority\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst badgeVariants = cva(\n  \"inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2\",\n  {\n    variants: {\n      variant: {\n        default:\n          \"border-transparent bg-primary text-primary-foreground hover:bg-primary/80\",\n        secondary:\n          \"border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80\",\n        destructive:\n          \"border-transparent bg-destructive text-destructive-foreground hover:bg-destructive/80\",\n        outline: \"text-foreground\",\n      },\n    },\n    defaultVariants: {\n      variant: \"default\",\n    },\n  }\n)\n\nexport interface BadgeProps\n  extends React.HTMLAttributes<HTMLDivElement>,\n    VariantProps<typeof badgeVariants> {}\n\nfunction Badge({ className, variant, ...props }: BadgeProps) {\n  return (\n    <div className={cn(badgeVariants({ variant }), className)} {...props} />\n  )\n}\n\nexport { Badge, badgeVariants }\n","size_bytes":1128},"client/src/components/ui/button.tsx":{"content":"import * as React from \"react\"\nimport { Slot } from \"@radix-ui/react-slot\"\nimport { cva, type VariantProps } from \"class-variance-authority\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst buttonVariants = cva(\n  \"inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0\",\n  {\n    variants: {\n      variant: {\n        default: \"bg-primary text-primary-foreground hover:bg-primary/90\",\n        destructive:\n          \"bg-destructive text-destructive-foreground hover:bg-destructive/90\",\n        outline:\n          \"border border-input bg-background hover:bg-accent hover:text-accent-foreground\",\n        secondary:\n          \"bg-secondary text-secondary-foreground hover:bg-secondary/80\",\n        ghost: \"hover:bg-accent hover:text-accent-foreground\",\n        link: \"text-primary underline-offset-4 hover:underline\",\n      },\n      size: {\n        default: \"h-10 px-4 py-2\",\n        sm: \"h-9 rounded-md px-3\",\n        lg: \"h-11 rounded-md px-8\",\n        icon: \"h-10 w-10\",\n      },\n    },\n    defaultVariants: {\n      variant: \"default\",\n      size: \"default\",\n    },\n  }\n)\n\nexport interface ButtonProps\n  extends React.ButtonHTMLAttributes<HTMLButtonElement>,\n    VariantProps<typeof buttonVariants> {\n  asChild?: boolean\n}\n\nconst Button = React.forwardRef<HTMLButtonElement, ButtonProps>(\n  ({ className, variant, size, asChild = false, ...props }, ref) => {\n    const Comp = asChild ? Slot : \"button\"\n    return (\n      <Comp\n        className={cn(buttonVariants({ variant, size, className }))}\n        ref={ref}\n        {...props}\n      />\n    )\n  }\n)\nButton.displayName = \"Button\"\n\nexport { Button, buttonVariants }\n","size_bytes":1901},"client/src/components/ui/card.tsx":{"content":"import * as React from \"react\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst Card = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div\n    ref={ref}\n    className={cn(\n      \"rounded-lg border bg-card text-card-foreground shadow-sm\",\n      className\n    )}\n    {...props}\n  />\n))\nCard.displayName = \"Card\"\n\nconst CardHeader = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div\n    ref={ref}\n    className={cn(\"flex flex-col space-y-1.5 p-6\", className)}\n    {...props}\n  />\n))\nCardHeader.displayName = \"CardHeader\"\n\nconst CardTitle = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div\n    ref={ref}\n    className={cn(\n      \"text-2xl font-semibold leading-none tracking-tight\",\n      className\n    )}\n    {...props}\n  />\n))\nCardTitle.displayName = \"CardTitle\"\n\nconst CardDescription = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div\n    ref={ref}\n    className={cn(\"text-sm text-muted-foreground\", className)}\n    {...props}\n  />\n))\nCardDescription.displayName = \"CardDescription\"\n\nconst CardContent = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div ref={ref} className={cn(\"p-6 pt-0\", className)} {...props} />\n))\nCardContent.displayName = \"CardContent\"\n\nconst CardFooter = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div\n    ref={ref}\n    className={cn(\"flex items-center p-6 pt-0\", className)}\n    {...props}\n  />\n))\nCardFooter.displayName = \"CardFooter\"\n\nexport { Card, CardHeader, CardFooter, CardTitle, CardDescription, CardContent }\n","size_bytes":1858},"client/src/components/ui/checkbox.tsx":{"content":"import * as React from \"react\"\nimport * as CheckboxPrimitive from \"@radix-ui/react-checkbox\"\nimport { Check } from \"lucide-react\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst Checkbox = React.forwardRef<\n  React.ElementRef<typeof CheckboxPrimitive.Root>,\n  React.ComponentPropsWithoutRef<typeof CheckboxPrimitive.Root>\n>(({ className, ...props }, ref) => (\n  <CheckboxPrimitive.Root\n    ref={ref}\n    className={cn(\n      \"peer h-4 w-4 shrink-0 rounded-sm border border-primary ring-offset-background focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50 data-[state=checked]:bg-primary data-[state=checked]:text-primary-foreground\",\n      className\n    )}\n    {...props}\n  >\n    <CheckboxPrimitive.Indicator\n      className={cn(\"flex items-center justify-center text-current\")}\n    >\n      <Check className=\"h-4 w-4\" />\n    </CheckboxPrimitive.Indicator>\n  </CheckboxPrimitive.Root>\n))\nCheckbox.displayName = CheckboxPrimitive.Root.displayName\n\nexport { Checkbox }\n","size_bytes":1056},"client/src/components/ui/dialog.tsx":{"content":"\"use client\"\n\nimport * as React from \"react\"\nimport * as DialogPrimitive from \"@radix-ui/react-dialog\"\nimport { X } from \"lucide-react\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst Dialog = DialogPrimitive.Root\n\nconst DialogTrigger = DialogPrimitive.Trigger\n\nconst DialogPortal = DialogPrimitive.Portal\n\nconst DialogClose = DialogPrimitive.Close\n\nconst DialogOverlay = React.forwardRef<\n  React.ElementRef<typeof DialogPrimitive.Overlay>,\n  React.ComponentPropsWithoutRef<typeof DialogPrimitive.Overlay>\n>(({ className, ...props }, ref) => (\n  <DialogPrimitive.Overlay\n    ref={ref}\n    className={cn(\n      \"fixed inset-0 z-50 bg-black/80 data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0\",\n      className\n    )}\n    {...props}\n  />\n))\nDialogOverlay.displayName = DialogPrimitive.Overlay.displayName\n\nconst DialogContent = React.forwardRef<\n  React.ElementRef<typeof DialogPrimitive.Content>,\n  React.ComponentPropsWithoutRef<typeof DialogPrimitive.Content>\n>(({ className, children, ...props }, ref) => (\n  <DialogPortal>\n    <DialogOverlay />\n    <DialogPrimitive.Content\n      ref={ref}\n      className={cn(\n        \"fixed left-[50%] top-[50%] z-50 grid w-full max-w-lg translate-x-[-50%] translate-y-[-50%] gap-4 border bg-background p-6 shadow-lg duration-200 data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[state=closed]:slide-out-to-left-1/2 data-[state=closed]:slide-out-to-top-[48%] data-[state=open]:slide-in-from-left-1/2 data-[state=open]:slide-in-from-top-[48%] sm:rounded-lg\",\n        className\n      )}\n      {...props}\n    >\n      {children}\n      <DialogPrimitive.Close className=\"absolute right-4 top-4 rounded-sm opacity-70 ring-offset-background transition-opacity hover:opacity-100 focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 disabled:pointer-events-none data-[state=open]:bg-accent data-[state=open]:text-muted-foreground\">\n        <X className=\"h-4 w-4\" />\n        <span className=\"sr-only\">Close</span>\n      </DialogPrimitive.Close>\n    </DialogPrimitive.Content>\n  </DialogPortal>\n))\nDialogContent.displayName = DialogPrimitive.Content.displayName\n\nconst DialogHeader = ({\n  className,\n  ...props\n}: React.HTMLAttributes<HTMLDivElement>) => (\n  <div\n    className={cn(\n      \"flex flex-col space-y-1.5 text-center sm:text-left\",\n      className\n    )}\n    {...props}\n  />\n)\nDialogHeader.displayName = \"DialogHeader\"\n\nconst DialogFooter = ({\n  className,\n  ...props\n}: React.HTMLAttributes<HTMLDivElement>) => (\n  <div\n    className={cn(\n      \"flex flex-col-reverse sm:flex-row sm:justify-end sm:space-x-2\",\n      className\n    )}\n    {...props}\n  />\n)\nDialogFooter.displayName = \"DialogFooter\"\n\nconst DialogTitle = React.forwardRef<\n  React.ElementRef<typeof DialogPrimitive.Title>,\n  React.ComponentPropsWithoutRef<typeof DialogPrimitive.Title>\n>(({ className, ...props }, ref) => (\n  <DialogPrimitive.Title\n    ref={ref}\n    className={cn(\n      \"text-lg font-semibold leading-none tracking-tight\",\n      className\n    )}\n    {...props}\n  />\n))\nDialogTitle.displayName = DialogPrimitive.Title.displayName\n\nconst DialogDescription = React.forwardRef<\n  React.ElementRef<typeof DialogPrimitive.Description>,\n  React.ComponentPropsWithoutRef<typeof DialogPrimitive.Description>\n>(({ className, ...props }, ref) => (\n  <DialogPrimitive.Description\n    ref={ref}\n    className={cn(\"text-sm text-muted-foreground\", className)}\n    {...props}\n  />\n))\nDialogDescription.displayName = DialogPrimitive.Description.displayName\n\nexport {\n  Dialog,\n  DialogPortal,\n  DialogOverlay,\n  DialogClose,\n  DialogTrigger,\n  DialogContent,\n  DialogHeader,\n  DialogFooter,\n  DialogTitle,\n  DialogDescription,\n}\n","size_bytes":3848},"client/src/components/ui/dropdown-menu.tsx":{"content":"import * as React from \"react\"\nimport * as DropdownMenuPrimitive from \"@radix-ui/react-dropdown-menu\"\nimport { Check, ChevronRight, Circle } from \"lucide-react\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst DropdownMenu = DropdownMenuPrimitive.Root\n\nconst DropdownMenuTrigger = DropdownMenuPrimitive.Trigger\n\nconst DropdownMenuGroup = DropdownMenuPrimitive.Group\n\nconst DropdownMenuPortal = DropdownMenuPrimitive.Portal\n\nconst DropdownMenuSub = DropdownMenuPrimitive.Sub\n\nconst DropdownMenuRadioGroup = DropdownMenuPrimitive.RadioGroup\n\nconst DropdownMenuSubTrigger = React.forwardRef<\n  React.ElementRef<typeof DropdownMenuPrimitive.SubTrigger>,\n  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.SubTrigger> & {\n    inset?: boolean\n  }\n>(({ className, inset, children, ...props }, ref) => (\n  <DropdownMenuPrimitive.SubTrigger\n    ref={ref}\n    className={cn(\n      \"flex cursor-default select-none items-center gap-2 rounded-sm px-2 py-1.5 text-sm outline-none focus:bg-accent data-[state=open]:bg-accent [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0\",\n      inset && \"pl-8\",\n      className\n    )}\n    {...props}\n  >\n    {children}\n    <ChevronRight className=\"ml-auto\" />\n  </DropdownMenuPrimitive.SubTrigger>\n))\nDropdownMenuSubTrigger.displayName =\n  DropdownMenuPrimitive.SubTrigger.displayName\n\nconst DropdownMenuSubContent = React.forwardRef<\n  React.ElementRef<typeof DropdownMenuPrimitive.SubContent>,\n  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.SubContent>\n>(({ className, ...props }, ref) => (\n  <DropdownMenuPrimitive.SubContent\n    ref={ref}\n    className={cn(\n      \"z-50 min-w-[8rem] overflow-hidden rounded-md border bg-popover p-1 text-popover-foreground shadow-lg data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 origin-[--radix-dropdown-menu-content-transform-origin]\",\n      className\n    )}\n    {...props}\n  />\n))\nDropdownMenuSubContent.displayName =\n  DropdownMenuPrimitive.SubContent.displayName\n\nconst DropdownMenuContent = React.forwardRef<\n  React.ElementRef<typeof DropdownMenuPrimitive.Content>,\n  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.Content>\n>(({ className, sideOffset = 4, ...props }, ref) => (\n  <DropdownMenuPrimitive.Portal>\n    <DropdownMenuPrimitive.Content\n      ref={ref}\n      sideOffset={sideOffset}\n      className={cn(\n        \"z-50 max-h-[var(--radix-dropdown-menu-content-available-height)] min-w-[8rem] overflow-y-auto overflow-x-hidden rounded-md border bg-popover p-1 text-popover-foreground shadow-md data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 origin-[--radix-dropdown-menu-content-transform-origin]\",\n        className\n      )}\n      {...props}\n    />\n  </DropdownMenuPrimitive.Portal>\n))\nDropdownMenuContent.displayName = DropdownMenuPrimitive.Content.displayName\n\nconst DropdownMenuItem = React.forwardRef<\n  React.ElementRef<typeof DropdownMenuPrimitive.Item>,\n  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.Item> & {\n    inset?: boolean\n  }\n>(({ className, inset, ...props }, ref) => (\n  <DropdownMenuPrimitive.Item\n    ref={ref}\n    className={cn(\n      \"relative flex cursor-default select-none items-center gap-2 rounded-sm px-2 py-1.5 text-sm outline-none transition-colors focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50 [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0\",\n      inset && \"pl-8\",\n      className\n    )}\n    {...props}\n  />\n))\nDropdownMenuItem.displayName = DropdownMenuPrimitive.Item.displayName\n\nconst DropdownMenuCheckboxItem = React.forwardRef<\n  React.ElementRef<typeof DropdownMenuPrimitive.CheckboxItem>,\n  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.CheckboxItem>\n>(({ className, children, checked, ...props }, ref) => (\n  <DropdownMenuPrimitive.CheckboxItem\n    ref={ref}\n    className={cn(\n      \"relative flex cursor-default select-none items-center rounded-sm py-1.5 pl-8 pr-2 text-sm outline-none transition-colors focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50\",\n      className\n    )}\n    checked={checked}\n    {...props}\n  >\n    <span className=\"absolute left-2 flex h-3.5 w-3.5 items-center justify-center\">\n      <DropdownMenuPrimitive.ItemIndicator>\n        <Check className=\"h-4 w-4\" />\n      </DropdownMenuPrimitive.ItemIndicator>\n    </span>\n    {children}\n  </DropdownMenuPrimitive.CheckboxItem>\n))\nDropdownMenuCheckboxItem.displayName =\n  DropdownMenuPrimitive.CheckboxItem.displayName\n\nconst DropdownMenuRadioItem = React.forwardRef<\n  React.ElementRef<typeof DropdownMenuPrimitive.RadioItem>,\n  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.RadioItem>\n>(({ className, children, ...props }, ref) => (\n  <DropdownMenuPrimitive.RadioItem\n    ref={ref}\n    className={cn(\n      \"relative flex cursor-default select-none items-center rounded-sm py-1.5 pl-8 pr-2 text-sm outline-none transition-colors focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50\",\n      className\n    )}\n    {...props}\n  >\n    <span className=\"absolute left-2 flex h-3.5 w-3.5 items-center justify-center\">\n      <DropdownMenuPrimitive.ItemIndicator>\n        <Circle className=\"h-2 w-2 fill-current\" />\n      </DropdownMenuPrimitive.ItemIndicator>\n    </span>\n    {children}\n  </DropdownMenuPrimitive.RadioItem>\n))\nDropdownMenuRadioItem.displayName = DropdownMenuPrimitive.RadioItem.displayName\n\nconst DropdownMenuLabel = React.forwardRef<\n  React.ElementRef<typeof DropdownMenuPrimitive.Label>,\n  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.Label> & {\n    inset?: boolean\n  }\n>(({ className, inset, ...props }, ref) => (\n  <DropdownMenuPrimitive.Label\n    ref={ref}\n    className={cn(\n      \"px-2 py-1.5 text-sm font-semibold\",\n      inset && \"pl-8\",\n      className\n    )}\n    {...props}\n  />\n))\nDropdownMenuLabel.displayName = DropdownMenuPrimitive.Label.displayName\n\nconst DropdownMenuSeparator = React.forwardRef<\n  React.ElementRef<typeof DropdownMenuPrimitive.Separator>,\n  React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.Separator>\n>(({ className, ...props }, ref) => (\n  <DropdownMenuPrimitive.Separator\n    ref={ref}\n    className={cn(\"-mx-1 my-1 h-px bg-muted\", className)}\n    {...props}\n  />\n))\nDropdownMenuSeparator.displayName = DropdownMenuPrimitive.Separator.displayName\n\nconst DropdownMenuShortcut = ({\n  className,\n  ...props\n}: React.HTMLAttributes<HTMLSpanElement>) => {\n  return (\n    <span\n      className={cn(\"ml-auto text-xs tracking-widest opacity-60\", className)}\n      {...props}\n    />\n  )\n}\nDropdownMenuShortcut.displayName = \"DropdownMenuShortcut\"\n\nexport {\n  DropdownMenu,\n  DropdownMenuTrigger,\n  DropdownMenuContent,\n  DropdownMenuItem,\n  DropdownMenuCheckboxItem,\n  DropdownMenuRadioItem,\n  DropdownMenuLabel,\n  DropdownMenuSeparator,\n  DropdownMenuShortcut,\n  DropdownMenuGroup,\n  DropdownMenuPortal,\n  DropdownMenuSub,\n  DropdownMenuSubContent,\n  DropdownMenuSubTrigger,\n  DropdownMenuRadioGroup,\n}\n","size_bytes":7609},"client/src/components/ui/form.tsx":{"content":"\"use client\"\n\nimport * as React from \"react\"\nimport * as LabelPrimitive from \"@radix-ui/react-label\"\nimport { Slot } from \"@radix-ui/react-slot\"\nimport {\n  Controller,\n  FormProvider,\n  useFormContext,\n  type ControllerProps,\n  type FieldPath,\n  type FieldValues,\n} from \"react-hook-form\"\n\nimport { cn } from \"@/lib/utils\"\nimport { Label } from \"@/components/ui/label\"\n\nconst Form = FormProvider\n\ntype FormFieldContextValue<\n  TFieldValues extends FieldValues = FieldValues,\n  TName extends FieldPath<TFieldValues> = FieldPath<TFieldValues>\n> = {\n  name: TName\n}\n\nconst FormFieldContext = React.createContext<FormFieldContextValue>(\n  {} as FormFieldContextValue\n)\n\nconst FormField = <\n  TFieldValues extends FieldValues = FieldValues,\n  TName extends FieldPath<TFieldValues> = FieldPath<TFieldValues>\n>({\n  ...props\n}: ControllerProps<TFieldValues, TName>) => {\n  return (\n    <FormFieldContext.Provider value={{ name: props.name }}>\n      <Controller {...props} />\n    </FormFieldContext.Provider>\n  )\n}\n\nconst useFormField = () => {\n  const fieldContext = React.useContext(FormFieldContext)\n  const itemContext = React.useContext(FormItemContext)\n  const { getFieldState, formState } = useFormContext()\n\n  const fieldState = getFieldState(fieldContext.name, formState)\n\n  if (!fieldContext) {\n    throw new Error(\"useFormField should be used within <FormField>\")\n  }\n\n  const { id } = itemContext\n\n  return {\n    id,\n    name: fieldContext.name,\n    formItemId: `${id}-form-item`,\n    formDescriptionId: `${id}-form-item-description`,\n    formMessageId: `${id}-form-item-message`,\n    ...fieldState,\n  }\n}\n\ntype FormItemContextValue = {\n  id: string\n}\n\nconst FormItemContext = React.createContext<FormItemContextValue>(\n  {} as FormItemContextValue\n)\n\nconst FormItem = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => {\n  const id = React.useId()\n\n  return (\n    <FormItemContext.Provider value={{ id }}>\n      <div ref={ref} className={cn(\"space-y-2\", className)} {...props} />\n    </FormItemContext.Provider>\n  )\n})\nFormItem.displayName = \"FormItem\"\n\nconst FormLabel = React.forwardRef<\n  React.ElementRef<typeof LabelPrimitive.Root>,\n  React.ComponentPropsWithoutRef<typeof LabelPrimitive.Root>\n>(({ className, ...props }, ref) => {\n  const { error, formItemId } = useFormField()\n\n  return (\n    <Label\n      ref={ref}\n      className={cn(error && \"text-destructive\", className)}\n      htmlFor={formItemId}\n      {...props}\n    />\n  )\n})\nFormLabel.displayName = \"FormLabel\"\n\nconst FormControl = React.forwardRef<\n  React.ElementRef<typeof Slot>,\n  React.ComponentPropsWithoutRef<typeof Slot>\n>(({ ...props }, ref) => {\n  const { error, formItemId, formDescriptionId, formMessageId } = useFormField()\n\n  return (\n    <Slot\n      ref={ref}\n      id={formItemId}\n      aria-describedby={\n        !error\n          ? `${formDescriptionId}`\n          : `${formDescriptionId} ${formMessageId}`\n      }\n      aria-invalid={!!error}\n      {...props}\n    />\n  )\n})\nFormControl.displayName = \"FormControl\"\n\nconst FormDescription = React.forwardRef<\n  HTMLParagraphElement,\n  React.HTMLAttributes<HTMLParagraphElement>\n>(({ className, ...props }, ref) => {\n  const { formDescriptionId } = useFormField()\n\n  return (\n    <p\n      ref={ref}\n      id={formDescriptionId}\n      className={cn(\"text-sm text-muted-foreground\", className)}\n      {...props}\n    />\n  )\n})\nFormDescription.displayName = \"FormDescription\"\n\nconst FormMessage = React.forwardRef<\n  HTMLParagraphElement,\n  React.HTMLAttributes<HTMLParagraphElement>\n>(({ className, children, ...props }, ref) => {\n  const { error, formMessageId } = useFormField()\n  const body = error ? String(error?.message ?? \"\") : children\n\n  if (!body) {\n    return null\n  }\n\n  return (\n    <p\n      ref={ref}\n      id={formMessageId}\n      className={cn(\"text-sm font-medium text-destructive\", className)}\n      {...props}\n    >\n      {body}\n    </p>\n  )\n})\nFormMessage.displayName = \"FormMessage\"\n\nexport {\n  useFormField,\n  Form,\n  FormItem,\n  FormLabel,\n  FormControl,\n  FormDescription,\n  FormMessage,\n  FormField,\n}\n","size_bytes":4120},"client/src/components/ui/input.tsx":{"content":"import * as React from \"react\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst Input = React.forwardRef<HTMLInputElement, React.ComponentProps<\"input\">>(\n  ({ className, type, ...props }, ref) => {\n    return (\n      <input\n        type={type}\n        className={cn(\n          \"flex h-10 w-full rounded-md border border-input bg-background px-3 py-2 text-base ring-offset-background file:border-0 file:bg-transparent file:text-sm file:font-medium file:text-foreground placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50 md:text-sm\",\n          className\n        )}\n        ref={ref}\n        {...props}\n      />\n    )\n  }\n)\nInput.displayName = \"Input\"\n\nexport { Input }\n","size_bytes":791},"client/src/components/ui/label.tsx":{"content":"import * as React from \"react\"\nimport * as LabelPrimitive from \"@radix-ui/react-label\"\nimport { cva, type VariantProps } from \"class-variance-authority\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst labelVariants = cva(\n  \"text-sm font-medium leading-none peer-disabled:cursor-not-allowed peer-disabled:opacity-70\"\n)\n\nconst Label = React.forwardRef<\n  React.ElementRef<typeof LabelPrimitive.Root>,\n  React.ComponentPropsWithoutRef<typeof LabelPrimitive.Root> &\n    VariantProps<typeof labelVariants>\n>(({ className, ...props }, ref) => (\n  <LabelPrimitive.Root\n    ref={ref}\n    className={cn(labelVariants(), className)}\n    {...props}\n  />\n))\nLabel.displayName = LabelPrimitive.Root.displayName\n\nexport { Label }\n","size_bytes":710},"client/src/components/ui/popover.tsx":{"content":"import * as React from \"react\"\nimport * as PopoverPrimitive from \"@radix-ui/react-popover\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst Popover = PopoverPrimitive.Root\n\nconst PopoverTrigger = PopoverPrimitive.Trigger\n\nconst PopoverContent = React.forwardRef<\n  React.ElementRef<typeof PopoverPrimitive.Content>,\n  React.ComponentPropsWithoutRef<typeof PopoverPrimitive.Content>\n>(({ className, align = \"center\", sideOffset = 4, ...props }, ref) => (\n  <PopoverPrimitive.Portal>\n    <PopoverPrimitive.Content\n      ref={ref}\n      align={align}\n      sideOffset={sideOffset}\n      className={cn(\n        \"z-50 w-72 rounded-md border bg-popover p-4 text-popover-foreground shadow-md outline-none data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 origin-[--radix-popover-content-transform-origin]\",\n        className\n      )}\n      {...props}\n    />\n  </PopoverPrimitive.Portal>\n))\nPopoverContent.displayName = PopoverPrimitive.Content.displayName\n\nexport { Popover, PopoverTrigger, PopoverContent }\n","size_bytes":1280},"client/src/components/ui/separator.tsx":{"content":"import * as React from \"react\"\nimport * as SeparatorPrimitive from \"@radix-ui/react-separator\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst Separator = React.forwardRef<\n  React.ElementRef<typeof SeparatorPrimitive.Root>,\n  React.ComponentPropsWithoutRef<typeof SeparatorPrimitive.Root>\n>(\n  (\n    { className, orientation = \"horizontal\", decorative = true, ...props },\n    ref\n  ) => (\n    <SeparatorPrimitive.Root\n      ref={ref}\n      decorative={decorative}\n      orientation={orientation}\n      className={cn(\n        \"shrink-0 bg-border\",\n        orientation === \"horizontal\" ? \"h-[1px] w-full\" : \"h-full w-[1px]\",\n        className\n      )}\n      {...props}\n    />\n  )\n)\nSeparator.displayName = SeparatorPrimitive.Root.displayName\n\nexport { Separator }\n","size_bytes":756},"client/src/components/ui/sheet.tsx":{"content":"\"use client\"\n\nimport * as React from \"react\"\nimport * as SheetPrimitive from \"@radix-ui/react-dialog\"\nimport { cva, type VariantProps } from \"class-variance-authority\"\nimport { X } from \"lucide-react\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst Sheet = SheetPrimitive.Root\n\nconst SheetTrigger = SheetPrimitive.Trigger\n\nconst SheetClose = SheetPrimitive.Close\n\nconst SheetPortal = SheetPrimitive.Portal\n\nconst SheetOverlay = React.forwardRef<\n  React.ElementRef<typeof SheetPrimitive.Overlay>,\n  React.ComponentPropsWithoutRef<typeof SheetPrimitive.Overlay>\n>(({ className, ...props }, ref) => (\n  <SheetPrimitive.Overlay\n    className={cn(\n      \"fixed inset-0 z-50 bg-black/80  data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0\",\n      className\n    )}\n    {...props}\n    ref={ref}\n  />\n))\nSheetOverlay.displayName = SheetPrimitive.Overlay.displayName\n\nconst sheetVariants = cva(\n  \"fixed z-50 gap-4 bg-background p-6 shadow-lg transition ease-in-out data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:duration-300 data-[state=open]:duration-500\",\n  {\n    variants: {\n      side: {\n        top: \"inset-x-0 top-0 border-b data-[state=closed]:slide-out-to-top data-[state=open]:slide-in-from-top\",\n        bottom:\n          \"inset-x-0 bottom-0 border-t data-[state=closed]:slide-out-to-bottom data-[state=open]:slide-in-from-bottom\",\n        left: \"inset-y-0 left-0 h-full w-3/4 border-r data-[state=closed]:slide-out-to-left data-[state=open]:slide-in-from-left sm:max-w-sm\",\n        right:\n          \"inset-y-0 right-0 h-full w-3/4  border-l data-[state=closed]:slide-out-to-right data-[state=open]:slide-in-from-right sm:max-w-sm\",\n      },\n    },\n    defaultVariants: {\n      side: \"right\",\n    },\n  }\n)\n\ninterface SheetContentProps\n  extends React.ComponentPropsWithoutRef<typeof SheetPrimitive.Content>,\n    VariantProps<typeof sheetVariants> {}\n\nconst SheetContent = React.forwardRef<\n  React.ElementRef<typeof SheetPrimitive.Content>,\n  SheetContentProps\n>(({ side = \"right\", className, children, ...props }, ref) => (\n  <SheetPortal>\n    <SheetOverlay />\n    <SheetPrimitive.Content\n      ref={ref}\n      className={cn(sheetVariants({ side }), className)}\n      {...props}\n    >\n      {children}\n      <SheetPrimitive.Close className=\"absolute right-4 top-4 rounded-sm opacity-70 ring-offset-background transition-opacity hover:opacity-100 focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 disabled:pointer-events-none data-[state=open]:bg-secondary\">\n        <X className=\"h-4 w-4\" />\n        <span className=\"sr-only\">Close</span>\n      </SheetPrimitive.Close>\n    </SheetPrimitive.Content>\n  </SheetPortal>\n))\nSheetContent.displayName = SheetPrimitive.Content.displayName\n\nconst SheetHeader = ({\n  className,\n  ...props\n}: React.HTMLAttributes<HTMLDivElement>) => (\n  <div\n    className={cn(\n      \"flex flex-col space-y-2 text-center sm:text-left\",\n      className\n    )}\n    {...props}\n  />\n)\nSheetHeader.displayName = \"SheetHeader\"\n\nconst SheetFooter = ({\n  className,\n  ...props\n}: React.HTMLAttributes<HTMLDivElement>) => (\n  <div\n    className={cn(\n      \"flex flex-col-reverse sm:flex-row sm:justify-end sm:space-x-2\",\n      className\n    )}\n    {...props}\n  />\n)\nSheetFooter.displayName = \"SheetFooter\"\n\nconst SheetTitle = React.forwardRef<\n  React.ElementRef<typeof SheetPrimitive.Title>,\n  React.ComponentPropsWithoutRef<typeof SheetPrimitive.Title>\n>(({ className, ...props }, ref) => (\n  <SheetPrimitive.Title\n    ref={ref}\n    className={cn(\"text-lg font-semibold text-foreground\", className)}\n    {...props}\n  />\n))\nSheetTitle.displayName = SheetPrimitive.Title.displayName\n\nconst SheetDescription = React.forwardRef<\n  React.ElementRef<typeof SheetPrimitive.Description>,\n  React.ComponentPropsWithoutRef<typeof SheetPrimitive.Description>\n>(({ className, ...props }, ref) => (\n  <SheetPrimitive.Description\n    ref={ref}\n    className={cn(\"text-sm text-muted-foreground\", className)}\n    {...props}\n  />\n))\nSheetDescription.displayName = SheetPrimitive.Description.displayName\n\nexport {\n  Sheet,\n  SheetPortal,\n  SheetOverlay,\n  SheetTrigger,\n  SheetClose,\n  SheetContent,\n  SheetHeader,\n  SheetFooter,\n  SheetTitle,\n  SheetDescription,\n}\n","size_bytes":4281},"client/src/components/ui/skeleton.tsx":{"content":"import { cn } from \"@/lib/utils\"\n\nfunction Skeleton({\n  className,\n  ...props\n}: React.HTMLAttributes<HTMLDivElement>) {\n  return (\n    <div\n      className={cn(\"animate-pulse rounded-md bg-muted\", className)}\n      {...props}\n    />\n  )\n}\n\nexport { Skeleton }\n","size_bytes":261},"client/src/components/ui/slider.tsx":{"content":"import * as React from \"react\"\nimport * as SliderPrimitive from \"@radix-ui/react-slider\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst Slider = React.forwardRef<\n  React.ElementRef<typeof SliderPrimitive.Root>,\n  React.ComponentPropsWithoutRef<typeof SliderPrimitive.Root>\n>(({ className, ...props }, ref) => (\n  <SliderPrimitive.Root\n    ref={ref}\n    className={cn(\n      \"relative flex w-full touch-none select-none items-center\",\n      className\n    )}\n    {...props}\n  >\n    <SliderPrimitive.Track className=\"relative h-2 w-full grow overflow-hidden rounded-full bg-secondary\">\n      <SliderPrimitive.Range className=\"absolute h-full bg-primary\" />\n    </SliderPrimitive.Track>\n    <SliderPrimitive.Thumb className=\"block h-5 w-5 rounded-full border-2 border-primary bg-background ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50\" />\n  </SliderPrimitive.Root>\n))\nSlider.displayName = SliderPrimitive.Root.displayName\n\nexport { Slider }\n","size_bytes":1077},"client/src/components/ui/switch.tsx":{"content":"import * as React from \"react\"\nimport * as SwitchPrimitives from \"@radix-ui/react-switch\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst Switch = React.forwardRef<\n  React.ElementRef<typeof SwitchPrimitives.Root>,\n  React.ComponentPropsWithoutRef<typeof SwitchPrimitives.Root>\n>(({ className, ...props }, ref) => (\n  <SwitchPrimitives.Root\n    className={cn(\n      \"peer inline-flex h-6 w-11 shrink-0 cursor-pointer items-center rounded-full border-2 border-transparent transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 focus-visible:ring-offset-background disabled:cursor-not-allowed disabled:opacity-50 data-[state=checked]:bg-primary data-[state=unchecked]:bg-input\",\n      className\n    )}\n    {...props}\n    ref={ref}\n  >\n    <SwitchPrimitives.Thumb\n      className={cn(\n        \"pointer-events-none block h-5 w-5 rounded-full bg-background shadow-lg ring-0 transition-transform data-[state=checked]:translate-x-5 data-[state=unchecked]:translate-x-0\"\n      )}\n    />\n  </SwitchPrimitives.Root>\n))\nSwitch.displayName = SwitchPrimitives.Root.displayName\n\nexport { Switch }\n","size_bytes":1139},"client/src/components/ui/table.tsx":{"content":"import * as React from \"react\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst Table = React.forwardRef<\n  HTMLTableElement,\n  React.HTMLAttributes<HTMLTableElement>\n>(({ className, ...props }, ref) => (\n  <div className=\"relative w-full overflow-auto\">\n    <table\n      ref={ref}\n      className={cn(\"w-full caption-bottom text-sm\", className)}\n      {...props}\n    />\n  </div>\n))\nTable.displayName = \"Table\"\n\nconst TableHeader = React.forwardRef<\n  HTMLTableSectionElement,\n  React.HTMLAttributes<HTMLTableSectionElement>\n>(({ className, ...props }, ref) => (\n  <thead ref={ref} className={cn(\"[&_tr]:border-b\", className)} {...props} />\n))\nTableHeader.displayName = \"TableHeader\"\n\nconst TableBody = React.forwardRef<\n  HTMLTableSectionElement,\n  React.HTMLAttributes<HTMLTableSectionElement>\n>(({ className, ...props }, ref) => (\n  <tbody\n    ref={ref}\n    className={cn(\"[&_tr:last-child]:border-0\", className)}\n    {...props}\n  />\n))\nTableBody.displayName = \"TableBody\"\n\nconst TableFooter = React.forwardRef<\n  HTMLTableSectionElement,\n  React.HTMLAttributes<HTMLTableSectionElement>\n>(({ className, ...props }, ref) => (\n  <tfoot\n    ref={ref}\n    className={cn(\n      \"border-t bg-muted/50 font-medium [&>tr]:last:border-b-0\",\n      className\n    )}\n    {...props}\n  />\n))\nTableFooter.displayName = \"TableFooter\"\n\nconst TableRow = React.forwardRef<\n  HTMLTableRowElement,\n  React.HTMLAttributes<HTMLTableRowElement>\n>(({ className, ...props }, ref) => (\n  <tr\n    ref={ref}\n    className={cn(\n      \"border-b transition-colors hover:bg-muted/50 data-[state=selected]:bg-muted\",\n      className\n    )}\n    {...props}\n  />\n))\nTableRow.displayName = \"TableRow\"\n\nconst TableHead = React.forwardRef<\n  HTMLTableCellElement,\n  React.ThHTMLAttributes<HTMLTableCellElement>\n>(({ className, ...props }, ref) => (\n  <th\n    ref={ref}\n    className={cn(\n      \"h-12 px-4 text-left align-middle font-medium text-muted-foreground [&:has([role=checkbox])]:pr-0\",\n      className\n    )}\n    {...props}\n  />\n))\nTableHead.displayName = \"TableHead\"\n\nconst TableCell = React.forwardRef<\n  HTMLTableCellElement,\n  React.TdHTMLAttributes<HTMLTableCellElement>\n>(({ className, ...props }, ref) => (\n  <td\n    ref={ref}\n    className={cn(\"p-4 align-middle [&:has([role=checkbox])]:pr-0\", className)}\n    {...props}\n  />\n))\nTableCell.displayName = \"TableCell\"\n\nconst TableCaption = React.forwardRef<\n  HTMLTableCaptionElement,\n  React.HTMLAttributes<HTMLTableCaptionElement>\n>(({ className, ...props }, ref) => (\n  <caption\n    ref={ref}\n    className={cn(\"mt-4 text-sm text-muted-foreground\", className)}\n    {...props}\n  />\n))\nTableCaption.displayName = \"TableCaption\"\n\nexport {\n  Table,\n  TableHeader,\n  TableBody,\n  TableFooter,\n  TableHead,\n  TableRow,\n  TableCell,\n  TableCaption,\n}\n","size_bytes":2765},"client/src/components/ui/tabs.tsx":{"content":"import * as React from \"react\"\nimport * as TabsPrimitive from \"@radix-ui/react-tabs\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst Tabs = TabsPrimitive.Root\n\nconst TabsList = React.forwardRef<\n  React.ElementRef<typeof TabsPrimitive.List>,\n  React.ComponentPropsWithoutRef<typeof TabsPrimitive.List>\n>(({ className, ...props }, ref) => (\n  <TabsPrimitive.List\n    ref={ref}\n    className={cn(\n      \"inline-flex h-10 items-center justify-center rounded-md bg-muted p-1 text-muted-foreground\",\n      className\n    )}\n    {...props}\n  />\n))\nTabsList.displayName = TabsPrimitive.List.displayName\n\nconst TabsTrigger = React.forwardRef<\n  React.ElementRef<typeof TabsPrimitive.Trigger>,\n  React.ComponentPropsWithoutRef<typeof TabsPrimitive.Trigger>\n>(({ className, ...props }, ref) => (\n  <TabsPrimitive.Trigger\n    ref={ref}\n    className={cn(\n      \"inline-flex items-center justify-center whitespace-nowrap rounded-sm px-3 py-1.5 text-sm font-medium ring-offset-background transition-all focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 data-[state=active]:bg-background data-[state=active]:text-foreground data-[state=active]:shadow-sm\",\n      className\n    )}\n    {...props}\n  />\n))\nTabsTrigger.displayName = TabsPrimitive.Trigger.displayName\n\nconst TabsContent = React.forwardRef<\n  React.ElementRef<typeof TabsPrimitive.Content>,\n  React.ComponentPropsWithoutRef<typeof TabsPrimitive.Content>\n>(({ className, ...props }, ref) => (\n  <TabsPrimitive.Content\n    ref={ref}\n    className={cn(\n      \"mt-2 ring-offset-background focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2\",\n      className\n    )}\n    {...props}\n  />\n))\nTabsContent.displayName = TabsPrimitive.Content.displayName\n\nexport { Tabs, TabsList, TabsTrigger, TabsContent }\n","size_bytes":1883},"client/src/components/ui/textarea.tsx":{"content":"import * as React from \"react\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst Textarea = React.forwardRef<\n  HTMLTextAreaElement,\n  React.ComponentProps<\"textarea\">\n>(({ className, ...props }, ref) => {\n  return (\n    <textarea\n      className={cn(\n        \"flex min-h-[80px] w-full rounded-md border border-input bg-background px-3 py-2 text-base ring-offset-background placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50 md:text-sm\",\n        className\n      )}\n      ref={ref}\n      {...props}\n    />\n  )\n})\nTextarea.displayName = \"Textarea\"\n\nexport { Textarea }\n","size_bytes":689},"client/src/components/ui/toast.tsx":{"content":"import * as React from \"react\"\nimport * as ToastPrimitives from \"@radix-ui/react-toast\"\nimport { cva, type VariantProps } from \"class-variance-authority\"\nimport { X } from \"lucide-react\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst ToastProvider = ToastPrimitives.Provider\n\nconst ToastViewport = React.forwardRef<\n  React.ElementRef<typeof ToastPrimitives.Viewport>,\n  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Viewport>\n>(({ className, ...props }, ref) => (\n  <ToastPrimitives.Viewport\n    ref={ref}\n    className={cn(\n      \"fixed top-0 z-[100] flex max-h-screen w-full flex-col-reverse p-4 sm:bottom-0 sm:right-0 sm:top-auto sm:flex-col md:max-w-[420px]\",\n      className\n    )}\n    {...props}\n  />\n))\nToastViewport.displayName = ToastPrimitives.Viewport.displayName\n\nconst toastVariants = cva(\n  \"group pointer-events-auto relative flex w-full items-center justify-between space-x-4 overflow-hidden rounded-md border p-6 pr-8 shadow-lg transition-all data-[swipe=cancel]:translate-x-0 data-[swipe=end]:translate-x-[var(--radix-toast-swipe-end-x)] data-[swipe=move]:translate-x-[var(--radix-toast-swipe-move-x)] data-[swipe=move]:transition-none data-[state=open]:animate-in data-[state=closed]:animate-out data-[swipe=end]:animate-out data-[state=closed]:fade-out-80 data-[state=closed]:slide-out-to-right-full data-[state=open]:slide-in-from-top-full data-[state=open]:sm:slide-in-from-bottom-full\",\n  {\n    variants: {\n      variant: {\n        default: \"border bg-background text-foreground\",\n        destructive:\n          \"destructive group border-destructive bg-destructive text-destructive-foreground\",\n      },\n    },\n    defaultVariants: {\n      variant: \"default\",\n    },\n  }\n)\n\nconst Toast = React.forwardRef<\n  React.ElementRef<typeof ToastPrimitives.Root>,\n  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Root> &\n    VariantProps<typeof toastVariants>\n>(({ className, variant, ...props }, ref) => {\n  return (\n    <ToastPrimitives.Root\n      ref={ref}\n      className={cn(toastVariants({ variant }), className)}\n      {...props}\n    />\n  )\n})\nToast.displayName = ToastPrimitives.Root.displayName\n\nconst ToastAction = React.forwardRef<\n  React.ElementRef<typeof ToastPrimitives.Action>,\n  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Action>\n>(({ className, ...props }, ref) => (\n  <ToastPrimitives.Action\n    ref={ref}\n    className={cn(\n      \"inline-flex h-8 shrink-0 items-center justify-center rounded-md border bg-transparent px-3 text-sm font-medium ring-offset-background transition-colors hover:bg-secondary focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 group-[.destructive]:border-muted/40 group-[.destructive]:hover:border-destructive/30 group-[.destructive]:hover:bg-destructive group-[.destructive]:hover:text-destructive-foreground group-[.destructive]:focus:ring-destructive\",\n      className\n    )}\n    {...props}\n  />\n))\nToastAction.displayName = ToastPrimitives.Action.displayName\n\nconst ToastClose = React.forwardRef<\n  React.ElementRef<typeof ToastPrimitives.Close>,\n  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Close>\n>(({ className, ...props }, ref) => (\n  <ToastPrimitives.Close\n    ref={ref}\n    className={cn(\n      \"absolute right-2 top-2 rounded-md p-1 text-foreground/50 opacity-0 transition-opacity hover:text-foreground focus:opacity-100 focus:outline-none focus:ring-2 group-hover:opacity-100 group-[.destructive]:text-red-300 group-[.destructive]:hover:text-red-50 group-[.destructive]:focus:ring-red-400 group-[.destructive]:focus:ring-offset-red-600\",\n      className\n    )}\n    toast-close=\"\"\n    {...props}\n  >\n    <X className=\"h-4 w-4\" />\n  </ToastPrimitives.Close>\n))\nToastClose.displayName = ToastPrimitives.Close.displayName\n\nconst ToastTitle = React.forwardRef<\n  React.ElementRef<typeof ToastPrimitives.Title>,\n  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Title>\n>(({ className, ...props }, ref) => (\n  <ToastPrimitives.Title\n    ref={ref}\n    className={cn(\"text-sm font-semibold\", className)}\n    {...props}\n  />\n))\nToastTitle.displayName = ToastPrimitives.Title.displayName\n\nconst ToastDescription = React.forwardRef<\n  React.ElementRef<typeof ToastPrimitives.Description>,\n  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Description>\n>(({ className, ...props }, ref) => (\n  <ToastPrimitives.Description\n    ref={ref}\n    className={cn(\"text-sm opacity-90\", className)}\n    {...props}\n  />\n))\nToastDescription.displayName = ToastPrimitives.Description.displayName\n\ntype ToastProps = React.ComponentPropsWithoutRef<typeof Toast>\n\ntype ToastActionElement = React.ReactElement<typeof ToastAction>\n\nexport {\n  type ToastProps,\n  type ToastActionElement,\n  ToastProvider,\n  ToastViewport,\n  Toast,\n  ToastTitle,\n  ToastDescription,\n  ToastClose,\n  ToastAction,\n}\n","size_bytes":4845},"client/src/components/ui/toaster.tsx":{"content":"import { useToast } from \"@/hooks/use-toast\"\nimport {\n  Toast,\n  ToastClose,\n  ToastDescription,\n  ToastProvider,\n  ToastTitle,\n  ToastViewport,\n} from \"@/components/ui/toast\"\n\nexport function Toaster() {\n  const { toasts } = useToast()\n\n  return (\n    <ToastProvider>\n      {toasts.map(function ({ id, title, description, action, ...props }) {\n        return (\n          <Toast key={id} {...props}>\n            <div className=\"grid gap-1\">\n              {title && <ToastTitle>{title}</ToastTitle>}\n              {description && (\n                <ToastDescription>{description}</ToastDescription>\n              )}\n            </div>\n            {action}\n            <ToastClose />\n          </Toast>\n        )\n      })}\n      <ToastViewport />\n    </ToastProvider>\n  )\n}\n","size_bytes":772},"client/src/components/ui/toggle-group.tsx":{"content":"\"use client\"\n\nimport * as React from \"react\"\nimport * as ToggleGroupPrimitive from \"@radix-ui/react-toggle-group\"\nimport { type VariantProps } from \"class-variance-authority\"\n\nimport { cn } from \"@/lib/utils\"\nimport { toggleVariants } from \"@/components/ui/toggle\"\n\nconst ToggleGroupContext = React.createContext<\n  VariantProps<typeof toggleVariants>\n>({\n  size: \"default\",\n  variant: \"default\",\n})\n\nconst ToggleGroup = React.forwardRef<\n  React.ElementRef<typeof ToggleGroupPrimitive.Root>,\n  React.ComponentPropsWithoutRef<typeof ToggleGroupPrimitive.Root> &\n    VariantProps<typeof toggleVariants>\n>(({ className, variant, size, children, ...props }, ref) => (\n  <ToggleGroupPrimitive.Root\n    ref={ref}\n    className={cn(\"flex items-center justify-center gap-1\", className)}\n    {...props}\n  >\n    <ToggleGroupContext.Provider value={{ variant, size }}>\n      {children}\n    </ToggleGroupContext.Provider>\n  </ToggleGroupPrimitive.Root>\n))\n\nToggleGroup.displayName = ToggleGroupPrimitive.Root.displayName\n\nconst ToggleGroupItem = React.forwardRef<\n  React.ElementRef<typeof ToggleGroupPrimitive.Item>,\n  React.ComponentPropsWithoutRef<typeof ToggleGroupPrimitive.Item> &\n    VariantProps<typeof toggleVariants>\n>(({ className, children, variant, size, ...props }, ref) => {\n  const context = React.useContext(ToggleGroupContext)\n\n  return (\n    <ToggleGroupPrimitive.Item\n      ref={ref}\n      className={cn(\n        toggleVariants({\n          variant: context.variant || variant,\n          size: context.size || size,\n        }),\n        className\n      )}\n      {...props}\n    >\n      {children}\n    </ToggleGroupPrimitive.Item>\n  )\n})\n\nToggleGroupItem.displayName = ToggleGroupPrimitive.Item.displayName\n\nexport { ToggleGroup, ToggleGroupItem }\n","size_bytes":1753},"client/src/components/ui/toggle.tsx":{"content":"import * as React from \"react\"\nimport * as TogglePrimitive from \"@radix-ui/react-toggle\"\nimport { cva, type VariantProps } from \"class-variance-authority\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst toggleVariants = cva(\n  \"inline-flex items-center justify-center rounded-md text-sm font-medium ring-offset-background transition-colors hover:bg-muted hover:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 data-[state=on]:bg-accent data-[state=on]:text-accent-foreground [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0 gap-2\",\n  {\n    variants: {\n      variant: {\n        default: \"bg-transparent\",\n        outline:\n          \"border border-input bg-transparent hover:bg-accent hover:text-accent-foreground\",\n      },\n      size: {\n        default: \"h-10 px-3 min-w-10\",\n        sm: \"h-9 px-2.5 min-w-9\",\n        lg: \"h-11 px-5 min-w-11\",\n      },\n    },\n    defaultVariants: {\n      variant: \"default\",\n      size: \"default\",\n    },\n  }\n)\n\nconst Toggle = React.forwardRef<\n  React.ElementRef<typeof TogglePrimitive.Root>,\n  React.ComponentPropsWithoutRef<typeof TogglePrimitive.Root> &\n    VariantProps<typeof toggleVariants>\n>(({ className, variant, size, ...props }, ref) => (\n  <TogglePrimitive.Root\n    ref={ref}\n    className={cn(toggleVariants({ variant, size, className }))}\n    {...props}\n  />\n))\n\nToggle.displayName = TogglePrimitive.Root.displayName\n\nexport { Toggle, toggleVariants }\n","size_bytes":1527},"client/src/components/ui/tooltip.tsx":{"content":"\"use client\"\n\nimport * as React from \"react\"\nimport * as TooltipPrimitive from \"@radix-ui/react-tooltip\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst TooltipProvider = TooltipPrimitive.Provider\n\nconst Tooltip = TooltipPrimitive.Root\n\nconst TooltipTrigger = TooltipPrimitive.Trigger\n\nconst TooltipContent = React.forwardRef<\n  React.ElementRef<typeof TooltipPrimitive.Content>,\n  React.ComponentPropsWithoutRef<typeof TooltipPrimitive.Content>\n>(({ className, sideOffset = 4, ...props }, ref) => (\n  <TooltipPrimitive.Content\n    ref={ref}\n    sideOffset={sideOffset}\n    className={cn(\n      \"z-50 overflow-hidden rounded-md border bg-popover px-3 py-1.5 text-sm text-popover-foreground shadow-md animate-in fade-in-0 zoom-in-95 data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=closed]:zoom-out-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 origin-[--radix-tooltip-content-transform-origin]\",\n      className\n    )}\n    {...props}\n  />\n))\nTooltipContent.displayName = TooltipPrimitive.Content.displayName\n\nexport { Tooltip, TooltipTrigger, TooltipContent, TooltipProvider }\n","size_bytes":1209},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"alembic>=1.16.5\",\n    \"asyncpg>=0.30.0\",\n    \"bcrypt>=4.3.0\",\n    \"duckdb>=1.0.0\",\n    \"email-validator>=2.3.0\",\n    \"fastapi>=0.116.1\",\n    \"fsspec>=2024.2.0\",\n    \"passlib>=1.7.4\",\n    \"psycopg2-binary>=2.9.10\",\n    \"pyarrow>=15.0.0\",\n    \"pydantic>=2.11.7\",\n    \"python-dotenv>=1.1.1\",\n    \"python-jose>=3.5.0\",\n    \"python-multipart>=0.0.20\",\n    \"sqlalchemy>=2.0.43\",\n    \"sqlparse>=0.5.3\",\n    \"uvicorn>=0.35.0\",\n]\n","size_bytes":568},"api/auth.py":{"content":"\"\"\"\nAuthentication utilities for FastAPI\n\"\"\"\nimport os\nfrom datetime import datetime, timedelta\nfrom typing import Optional\nfrom jose import JWTError, jwt\nfrom passlib.context import CryptContext\nfrom fastapi import Depends, HTTPException, status\nfrom fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\nfrom sqlalchemy.orm import Session\nfrom .database import get_db\nfrom .models import User\nfrom .schemas import TokenData\n\n# Configuration\nJWT_SECRET = os.getenv(\"JWT_SECRET\")\nif not JWT_SECRET:\n    raise ValueError(\"SECURITY ERROR: JWT_SECRET environment variable is required. Set it to a cryptographically secure random value.\")\nif JWT_SECRET in [\"your-jwt-secret-key\", \"dev-secret\", \"test-secret\", \"secret\", \"jwt-secret\"]:\n    raise ValueError(\"SECURITY ERROR: JWT_SECRET cannot use weak/default values. Generate a secure random key.\")\n\nALGORITHM = \"HS256\"\nACCESS_TOKEN_EXPIRE_HOURS = 24\n\n# Admin Configuration  \nADMIN_SECRET_KEY = os.getenv(\"ADMIN_SECRET_KEY\")\nif not ADMIN_SECRET_KEY:\n    raise ValueError(\"SECURITY ERROR: ADMIN_SECRET_KEY environment variable is required. Set it to a cryptographically secure random value.\")\nif ADMIN_SECRET_KEY in [\"admin-dev-key-123\", \"admin\", \"admin123\", \"password\", \"secret\"]:\n    raise ValueError(\"SECURITY ERROR: ADMIN_SECRET_KEY cannot use weak/default values. Generate a secure random key.\")\n\n# Password hashing\npwd_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"auto\")\n\n# OAuth2 scheme\nsecurity = HTTPBearer()\nsecurity_optional = HTTPBearer(auto_error=False)\n\ndef verify_password(plain_password: str, hashed_password: str) -> bool:\n    \"\"\"Verify a password against its hash\"\"\"\n    return pwd_context.verify(plain_password, hashed_password)\n\ndef get_password_hash(password: str) -> str:\n    \"\"\"Hash a password\"\"\"\n    return pwd_context.hash(password)\n\ndef create_access_token(data: dict, expires_delta: Optional[timedelta] = None):\n    \"\"\"Create a JWT access token\"\"\"\n    to_encode = data.copy()\n    if expires_delta:\n        expire = datetime.utcnow() + expires_delta\n    else:\n        expire = datetime.utcnow() + timedelta(hours=ACCESS_TOKEN_EXPIRE_HOURS)\n    \n    to_encode.update({\"exp\": expire})\n    encoded_jwt = jwt.encode(to_encode, JWT_SECRET, algorithm=ALGORITHM)\n    return encoded_jwt\n\ndef verify_token(token: str) -> TokenData:\n    \"\"\"Verify and decode a JWT token\"\"\"\n    try:\n        payload = jwt.decode(token, JWT_SECRET, algorithms=[ALGORITHM])\n        user_id: str = payload.get(\"userId\")\n        username: str = payload.get(\"username\")\n        is_admin: bool = payload.get(\"isAdmin\", False)\n        \n        if user_id is None:\n            raise HTTPException(\n                status_code=status.HTTP_401_UNAUTHORIZED,\n                detail=\"Invalid authentication credentials\",\n                headers={\"WWW-Authenticate\": \"Bearer\"},\n            )\n        \n        token_data = TokenData(user_id=user_id, username=username, is_admin=is_admin)\n        return token_data\n    except JWTError:\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"Invalid authentication credentials\",\n            headers={\"WWW-Authenticate\": \"Bearer\"},\n        )\n\ndef get_current_user(\n    credentials: HTTPAuthorizationCredentials = Depends(security),\n    db: Session = Depends(get_db)\n) -> User:\n    \"\"\"Get the current authenticated user\"\"\"\n    token = credentials.credentials\n    \n    # TEMPORARY: Development token bypass - only in explicit dev mode\n    if os.getenv(\"DEV_TOKEN_BYPASS\") == \"true\" and token == 'dev-token-123':\n        dev_user = db.query(User).filter(User.id == 'dev-user-1').first()\n        if dev_user:\n            return dev_user\n        else:\n            # Fallback to any admin user for development\n            dev_user = db.query(User).filter(User.username == 'admin').first()\n            if dev_user:\n                return dev_user\n    \n    # Normal JWT verification for production\n    token_data = verify_token(token)\n    \n    user = db.query(User).filter(User.id == token_data.user_id).first()\n    if user is None:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"User not found\"\n        )\n    \n    return user\n\ndef get_current_user_optional(\n    credentials: Optional[HTTPAuthorizationCredentials] = Depends(security_optional),\n    db: Session = Depends(get_db)\n) -> Optional[User]:\n    \"\"\"Get the current user if authenticated, otherwise return None\"\"\"\n    if not credentials:\n        return None\n    \n    try:\n        token = credentials.credentials\n        token_data = verify_token(token)\n        user = db.query(User).filter(User.id == token_data.user_id).first()\n        return user\n    except HTTPException:\n        return None\n\ndef verify_admin_access(\n    credentials: Optional[HTTPAuthorizationCredentials] = Depends(security_optional)\n) -> bool:\n    \"\"\"Verify admin access using the admin secret key\"\"\"\n    \n    # TEMPORARY DEV BYPASS - Only enabled with explicit flag (disabled by default)\n    if os.getenv(\"DEV_ADMIN_BYPASS\") == \"true\":\n        return True\n    \n    if not credentials:\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"Admin authentication required\",\n            headers={\"WWW-Authenticate\": \"Bearer\"},\n        )\n    \n    # Check if the token matches the admin secret key\n    if credentials.credentials != ADMIN_SECRET_KEY:\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN,\n            detail=\"Invalid admin credentials\"\n        )\n    \n    return True\n\ndef verify_admin_user_access(\n    credentials: Optional[HTTPAuthorizationCredentials] = Depends(security_optional),\n    db: Session = Depends(get_db)\n) -> User:\n    \"\"\"Verify admin access using either admin secret key or admin user token\"\"\"\n    \n    # TEMPORARY DEV BYPASS - Only enabled with explicit flag (disabled by default)\n    if os.getenv(\"DEV_ADMIN_BYPASS\") == \"true\":\n        # Create/find a temp admin user for development\n        admin_user = db.query(User).filter(User.username == \"temp_admin\").first()\n        if admin_user is None:\n            from uuid import uuid4\n            admin_user = User(\n                id=str(uuid4()),\n                username=\"temp_admin\",\n                email=\"temp_admin@example.com\",\n                is_admin=True,\n                premium=True\n            )\n            db.add(admin_user)\n            db.commit()\n            db.refresh(admin_user)\n        return admin_user\n    \n    if not credentials:\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"Admin authentication required\",\n            headers={\"WWW-Authenticate\": \"Bearer\"},\n        )\n    \n    # First, check if it's the admin secret key\n    if credentials.credentials == ADMIN_SECRET_KEY:\n        # For admin secret key, find or create an admin user\n        admin_user = db.query(User).filter(User.is_admin == True).first()\n        if admin_user is None:\n            # Create a default admin user if none exists\n            from uuid import uuid4\n            admin_user = User(\n                id=str(uuid4()),\n                username=\"admin\",\n                email=\"admin@example.com\",\n                is_admin=True,\n                premium=True\n            )\n            db.add(admin_user)\n            db.commit()\n            db.refresh(admin_user)\n        return admin_user\n    \n    # Otherwise, verify it's a JWT token from an admin user\n    try:\n        token_data = verify_token(credentials.credentials)\n        user = db.query(User).filter(User.id == token_data.user_id).first()\n        \n        if user is None:\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND,\n                detail=\"User not found\"\n            )\n        \n        # Check if user is admin\n        if not user.is_admin:\n            raise HTTPException(\n                status_code=status.HTTP_403_FORBIDDEN,\n                detail=\"Admin access required\"\n            )\n        \n        return user\n        \n    except HTTPException:\n        # If JWT verification fails, re-raise the exception\n        raise\n    except Exception:\n        # For any other error, return forbidden\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN,\n            detail=\"Invalid admin credentials\"\n        )","size_bytes":8363},"api/database.py":{"content":"\"\"\"\nDatabase configuration and connection setup\n\"\"\"\nimport os\nimport json\nfrom dotenv import load_dotenv\nfrom sqlalchemy import create_engine, text, inspect\nfrom sqlalchemy.orm import sessionmaker, Session\nfrom sqlalchemy.dialects.postgresql import JSONB\nfrom .models import Base\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Database URL from environment variable (preferred for production)\nDATABASE_URL = os.getenv(\"DATABASE_URL\")\n\n# Only fallback to .env file in development if environment variable doesn't exist\nif not DATABASE_URL and os.getenv(\"NODE_ENV\", \"development\") == \"development\":\n    from pathlib import Path\n    env_file = Path(\".env\")\n    if env_file.exists():\n        with open(env_file, 'r') as f:\n            for line in f:\n                if line.strip().startswith('DATABASE_URL=') and not line.strip().startswith('#'):\n                    DATABASE_URL = line.strip().split('=', 1)[1]\n                    break\n\nif not DATABASE_URL:\n    raise ValueError(\"DATABASE_URL environment variable is required\")\n\n# Create engine with proper SSL and connection pooling\nengine = create_engine(\n    DATABASE_URL,\n    pool_pre_ping=True,  # Verify connections before use\n    pool_recycle=300,    # Recycle connections every 5 minutes\n    pool_timeout=10,     # Timeout for getting connection from pool\n    max_overflow=0,      # No overflow connections\n    echo=False          # Set to True for SQL logging if needed\n)\n\ndef parse_tabular_data(tabular_string: str) -> list:\n    \"\"\"\n    Parse tabular string format into list of dictionaries\n    Format: 'column1 | column2\\\\nvalue1 | value2\\\\n...'\n    \"\"\"\n    if not tabular_string or tabular_string.strip() == '':\n        return []\n    \n    try:\n        lines = tabular_string.strip().split('\\\\n')\n        if len(lines) < 2:\n            return []\n        \n        # First line contains headers\n        headers = [h.strip() for h in lines[0].split('|')]\n        \n        # Remaining lines contain data\n        result = []\n        for line in lines[1:]:\n            if line.strip():\n                values = [v.strip() for v in line.split('|')]\n                if len(values) == len(headers):\n                    row = {}\n                    for i, header in enumerate(headers):\n                        value = values[i]\n                        # Try to convert to number if possible\n                        try:\n                            if '.' in value:\n                                value = float(value)\n                            else:\n                                value = int(value)\n                        except ValueError:\n                            pass  # Keep as string\n                        row[header] = value\n                    result.append(row)\n        return result\n    except Exception as e:\n        print(f\"Error parsing tabular data: {e}\")\n        return []\n\ndef run_schema_migrations():\n    \"\"\"\n    Idempotent schema migration to handle JSONB question field transition and S3 answer sources\n    \"\"\"\n    with engine.begin() as conn:\n        inspector = inspect(engine)\n        \n        # Check if problems table exists\n        if 'problems' not in inspector.get_table_names():\n            print(\"Problems table doesn't exist, will be created by create_tables()\")\n            return\n        \n        # Get current columns\n        columns = [col['name'] for col in inspector.get_columns('problems')]\n        \n        # Check if question column exists\n        if 'question' not in columns:\n            print(\"Adding question JSONB column to problems table...\")\n            \n            # Add question column\n            conn.execute(text(\"ALTER TABLE problems ADD COLUMN question JSONB NULL\"))\n            \n            # Migrate data from old columns if they exist\n            legacy_cols = ['description', 'schema', 'expected_output']\n            existing_legacy = [col for col in legacy_cols if col in columns]\n            \n            if existing_legacy:\n                print(f\"Migrating data from legacy columns: {existing_legacy}\")\n                \n                # First, get all the data that needs migration\n                result = conn.execute(text(\"SELECT id, description, schema, expected_output FROM problems WHERE question IS NULL\"))\n                problems = result.fetchall()\n                \n                for problem in problems:\n                    problem_id, description, schema, expected_output = problem\n                    \n                    # Parse expected_output from tabular format to list of dicts\n                    parsed_output = parse_tabular_data(expected_output or '')\n                    \n                    # Create the question JSONB object\n                    question_data = {\n                        'description': description or '',\n                        'tables': [],  # Schema parsing would need more complex logic\n                        'expectedOutput': parsed_output\n                    }\n                    \n                    # Update the specific row\n                    conn.execute(text(\"\"\"\n                        UPDATE problems \n                        SET question = :question_data\n                        WHERE id = :problem_id\n                    \"\"\"), {'question_data': question_data, 'problem_id': problem_id})\n                \n                # Drop old columns\n                for col in existing_legacy:\n                    print(f\"Dropping legacy column: {col}\")\n                    conn.execute(text(f\"ALTER TABLE problems DROP COLUMN IF EXISTS {col}\"))\n            \n            # Make question NOT NULL\n            conn.execute(text(\"ALTER TABLE problems ALTER COLUMN question SET NOT NULL\"))\n            print(\"Schema migration completed successfully!\")\n        \n        # Add expected_display column if it doesn't exist\n        if 'expected_display' not in columns:\n            print(\"Adding expected_display JSONB column to problems table...\")\n            conn.execute(text(\"ALTER TABLE problems ADD COLUMN expected_display JSONB NULL\"))\n            \n            # Backfill expected_display from expected_output for existing problems\n            print(\"Backfilling expected_display from expected_output for existing problems...\")\n            conn.execute(text(\"\"\"\n                UPDATE problems \n                SET expected_display = expected_output \n                WHERE expected_display IS NULL AND expected_output IS NOT NULL\n            \"\"\"))\n            print(\"expected_display column added and backfilled successfully!\")\n        \n        # Add s3_data_source column if it doesn't exist\n        if 's3_data_source' not in columns:\n            print(\"Adding s3_data_source JSONB column to problems table...\")\n            conn.execute(text(\"ALTER TABLE problems ADD COLUMN s3_data_source JSONB NULL\"))\n            print(\"S3 data source migration completed successfully!\")\n        \n        # Migrate test_cases table for S3 answer sources\n        if 'test_cases' in inspector.get_table_names():\n            test_case_columns = [col['name'] for col in inspector.get_columns('test_cases')]\n            \n            # Add S3 answer source fields if they don't exist\n            if 'expected_output_source' not in test_case_columns:\n                print(\"Adding S3 answer source fields to test_cases table...\")\n                \n                conn.execute(text(\"ALTER TABLE test_cases ADD COLUMN expected_output_source JSONB NULL\"))\n                conn.execute(text(\"ALTER TABLE test_cases ADD COLUMN preview_expected_output JSONB NULL\"))\n                conn.execute(text(\"ALTER TABLE test_cases ADD COLUMN display_limit INTEGER DEFAULT 10\"))\n                \n                print(\"S3 answer source migration completed successfully!\")\n        else:\n            # Check if we need to fix existing data with incorrect expectedOutput format\n            result = conn.execute(text(\"\"\"\n                SELECT id, question \n                FROM problems \n                WHERE jsonb_typeof(question->'expectedOutput') = 'string'\n            \"\"\"))\n            problems_to_fix = result.fetchall()\n            \n            if problems_to_fix:\n                print(f\"Fixing {len(problems_to_fix)} problems with incorrect expectedOutput format...\")\n                for problem_id, question_json in problems_to_fix:\n                    # Parse the string expectedOutput to proper list format\n                    expected_output_str = question_json.get('expectedOutput', '')\n                    parsed_output = parse_tabular_data(expected_output_str)\n                    \n                    # Update the expectedOutput field\n                    conn.execute(text(\"\"\"\n                        UPDATE problems \n                        SET question = jsonb_set(question, '$.expectedOutput', :new_output)\n                        WHERE id = :problem_id\n                    \"\"\"), {'new_output': json.dumps(parsed_output), 'problem_id': problem_id})\n                print(\"Fixed incorrect expectedOutput formats!\")\n            else:\n                print(\"Question column already exists, no migration needed\")\n        \n        # Premium feature migrations\n        print(\"Checking premium columns...\")\n        \n        # Add premium column to problems table (nullable, default null)\n        if 'premium' not in columns:\n            print(\"Adding premium column to problems table...\")\n            conn.execute(text(\"ALTER TABLE problems ADD COLUMN premium boolean\"))\n            print(\"Premium column added to problems table\")\n        \n        # Add premium column to users table (non-nullable, default false)\n        users_columns = [col['name'] for col in inspector.get_columns('users')]\n        if 'premium' not in users_columns:\n            print(\"Adding premium column to users table...\")\n            conn.execute(text(\"ALTER TABLE users ADD COLUMN premium boolean\"))\n            conn.execute(text(\"UPDATE users SET premium = false WHERE premium IS NULL\"))\n            conn.execute(text(\"ALTER TABLE users ALTER COLUMN premium SET DEFAULT false\"))\n            conn.execute(text(\"ALTER TABLE users ALTER COLUMN premium SET NOT NULL\"))\n            print(\"Premium column added to users table\")\n        \n        print(\"Premium feature migration completed!\")\n        \n        # S3 Answer Source migrations for test_cases table\n        print(\"Checking S3 answer source columns for test_cases table...\")\n        \n        # Check if test_cases table exists\n        if 'test_cases' in inspector.get_table_names():\n            test_cases_columns = [col['name'] for col in inspector.get_columns('test_cases')]\n            \n            # Add expected_output_source column for S3 configuration\n            if 'expected_output_source' not in test_cases_columns:\n                print(\"Adding expected_output_source column to test_cases table...\")\n                conn.execute(text(\"ALTER TABLE test_cases ADD COLUMN expected_output_source JSONB NULL\"))\n                print(\"expected_output_source column added to test_cases table\")\n            \n            # Add preview_expected_output column for limited frontend display\n            if 'preview_expected_output' not in test_cases_columns:\n                print(\"Adding preview_expected_output column to test_cases table...\")\n                conn.execute(text(\"ALTER TABLE test_cases ADD COLUMN preview_expected_output JSONB NULL\"))\n                print(\"preview_expected_output column added to test_cases table\")\n            \n            # Add display_limit column for preview row count\n            if 'display_limit' not in test_cases_columns:\n                print(\"Adding display_limit column to test_cases table...\")\n                conn.execute(text(\"ALTER TABLE test_cases ADD COLUMN display_limit INTEGER DEFAULT 10\"))\n                print(\"display_limit column added to test_cases table\")\n        else:\n            print(\"test_cases table doesn't exist yet, S3 columns will be created by create_tables()\")\n        \n        print(\"S3 answer source migration completed!\")\n        \n        # Master solution migration - add master_solution column for better admin UX\n        print(\"Checking master_solution column...\")\n        columns = [col['name'] for col in inspector.get_columns('problems')]  # Refresh column list\n        \n        if 'master_solution' not in columns:\n            print(\"Adding master_solution JSONB column to problems table...\")\n            conn.execute(text(\"ALTER TABLE problems ADD COLUMN master_solution JSONB NULL\"))\n            print(\"master_solution column added to problems table\")\n            \n            # Backfill existing problems: copy expectedOutput from question field to master_solution\n            print(\"Backfilling master_solution from existing question.expectedOutput data...\")\n            result = conn.execute(text(\"\"\"\n                UPDATE problems \n                SET master_solution = question->'expectedOutput'\n                WHERE master_solution IS NULL \n                  AND question->'expectedOutput' IS NOT NULL\n                  AND jsonb_typeof(question->'expectedOutput') = 'array'\n            \"\"\"))\n            updated_count = result.rowcount\n            print(f\"Backfilled master_solution for {updated_count} existing problems\")\n        \n        print(\"Master solution migration completed!\")\n\n# Create session factory\nSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n\n# Create all tables\ndef create_tables():\n    \"\"\"Create all tables including new enhanced schema tables\"\"\"\n    # First create enum types if they don't exist\n    create_enum_types()\n    \n    # Then create all tables\n    Base.metadata.create_all(bind=engine)\n    print(\"SUCCESS: All database tables created successfully\")\n    \n    # Run schema migrations (always run for idempotent migrations)\n    run_schema_migrations()\n    \n    # Initialize enhanced schema with sample data\n    initialize_enhanced_schema()\n\ndef create_enum_types():\n    \"\"\"Create PostgreSQL enum types if they don't exist\"\"\"\n    with engine.begin() as conn:\n        # Create difficultylevel enum (note: name matches model definition)\n        conn.execute(text(\"\"\"\n            DO $$ BEGIN\n                CREATE TYPE difficultylevel AS ENUM ('BEGINNER', 'EASY', 'MEDIUM', 'HARD', 'EXPERT');\n            EXCEPTION\n                WHEN duplicate_object THEN null;\n            END $$;\n        \"\"\"))\n        \n        # Create execution_status enum\n        conn.execute(text(\"\"\"\n            DO $$ BEGIN\n                CREATE TYPE execution_status AS ENUM ('SUCCESS', 'ERROR', 'TIMEOUT', 'MEMORY_LIMIT');\n            EXCEPTION\n                WHEN duplicate_object THEN null;\n            END $$;\n        \"\"\"))\n        \n        # Create sandbox_status enum\n        conn.execute(text(\"\"\"\n            DO $$ BEGIN\n                CREATE TYPE sandbox_status AS ENUM ('ACTIVE', 'EXPIRED', 'CLEANUP_PENDING');\n            EXCEPTION\n                WHEN duplicate_object THEN null;\n            END $$;\n        \"\"\"))\n        \n        print(\"SUCCESS: PostgreSQL enum types created successfully\")\n\ndef initialize_enhanced_schema():\n    \"\"\"Initialize the enhanced schema with sample data - handles topics and badges independently\"\"\"\n    from .models import Topic, Badge, DifficultyLevel\n    \n    # Create a database session\n    db = SessionLocal()\n    \n    try:\n        topics_created = 0\n        badges_created = 0\n        \n        # Initialize Topics independently\n        try:\n            if db.query(Topic).count() == 0:\n                print(\"Initializing sample topics...\")\n                \n                topics = [\n                    Topic(\n                        name=\"Joins and Relationships\",\n                        description=\"Master INNER, LEFT, RIGHT, and FULL joins\",\n                        difficulty_level=\"EASY\",\n                        order_index=1\n                    ),\n                    Topic(\n                        name=\"Aggregate Functions\",\n                        description=\"COUNT, SUM, AVG, MIN, MAX and GROUP BY clauses\",\n                        difficulty_level=\"MEDIUM\",\n                        order_index=2\n                    ),\n                    Topic(\n                        name=\"Subqueries and CTEs\",\n                        description=\"Complex nested queries and Common Table Expressions\",\n                        difficulty_level=\"HARD\",\n                        order_index=3\n                    )\n                ]\n                \n                db.add_all(topics)\n                db.commit()\n                topics_created = len(topics)\n                print(f\"SUCCESS: Created {topics_created} topics\")\n            else:\n                print(\"Topics already exist, skipping topic initialization\")\n        except Exception as e:\n            print(f\"âŒ Error initializing topics: {e}\")\n            db.rollback()\n        \n        # Initialize Badges independently\n        try:\n            if db.query(Badge).count() == 0:\n                print(\"Initializing sample badges...\")\n                \n                badges = [\n                    Badge(\n                        name=\"First Steps\",\n                        description=\"Complete your first SQL query\",\n                        criteria={\"first_successful_submission\": True},\n                        points_reward=10,\n                        rarity=\"common\"\n                    ),\n                    Badge(\n                        name=\"Problem Solver\",\n                        description=\"Solve 10 problems\",\n                        criteria={\"problems_solved\": 10},\n                        points_reward=50,\n                        rarity=\"common\"\n                    ),\n                    Badge(\n                        name=\"Speed Demon\",\n                        description=\"Execute a query in under 100ms\",\n                        criteria={\"execution_time_ms\": {\"<\": 100}},\n                        points_reward=25,\n                        rarity=\"rare\"\n                    ),\n                    Badge(\n                        name=\"Master\",\n                        description=\"Solve 5 Hard level problems\",\n                        criteria={\"hard_problems_solved\": 5},\n                        points_reward=200,\n                        rarity=\"legendary\"\n                    )\n                ]\n                \n                db.add_all(badges)\n                db.commit()\n                badges_created = len(badges)\n                print(f\"SUCCESS: Created {badges_created} badges\")\n            else:\n                print(\"Badges already exist, skipping badge initialization\")\n        except Exception as e:\n            print(f\"âŒ Error initializing badges: {e}\")\n            db.rollback()\n        \n        if topics_created == 0 and badges_created == 0:\n            print(\"Enhanced schema already fully initialized\")\n        else:\n            print(f\"Enhanced schema initialization complete: {topics_created} topics, {badges_created} badges\")\n        \n    except Exception as e:\n        print(f\"âŒ Error in enhanced schema initialization: {e}\")\n        db.rollback()\n    finally:\n        db.close()\n\n# Dependency to get database session\ndef get_db():\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()","size_bytes":19197},"api/main.py":{"content":"\"\"\"\nFastAPI application - converted from Express.js backend\n\"\"\"\nimport os\nfrom typing import List, Optional\nfrom fastapi import FastAPI, Depends, HTTPException, status, Query\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.responses import FileResponse\nfrom sqlalchemy.orm import Session, joinedload\nfrom sqlalchemy import func, case, and_, desc, Boolean, Integer\nfrom datetime import timedelta\nimport random\n\nfrom .database import get_db, create_tables\nfrom .models import (User, Problem, Submission, CommunityPost, PostLike, PostComment, Solution,\n                     ProblemInteraction, ProblemSession, Base)\nfrom .schemas import (UserCreate, UserResponse, UserLogin, LoginResponse,\n                      RegisterResponse, ProblemResponse, SubmissionCreate,\n                      SubmissionResponse, CommunityPostCreate,\n                      CommunityPostResponse, PostCommentCreate,\n                      PostCommentResponse, SolutionResponse, QuestionData)\nfrom .auth import (get_password_hash, verify_password, create_access_token,\n                   get_current_user, get_current_user_optional)\nfrom .secure_execution import secure_executor\nfrom .sandbox_routes import sandbox_router\nfrom .admin_routes import admin_router\n\n# Helper function for time tracking\ndef track_first_query(user_id: str, problem_id: str, db: Session):\n    \"\"\"Track when user first runs a query on a problem\"\"\"\n    # Check if session already exists\n    session = db.query(ProblemSession).filter(\n        ProblemSession.user_id == user_id,\n        ProblemSession.problem_id == problem_id\n    ).first()\n    \n    if not session:\n        # Create new session\n        session = ProblemSession(\n            user_id=user_id,\n            problem_id=problem_id,\n            first_query_at=func.now()\n        )\n        db.add(session)\n        db.commit()\n    elif session.first_query_at is None:\n        # Update existing session with first query time\n        session.first_query_at = func.now()\n        db.commit()\n\ndef track_successful_submission(user_id: str, problem_id: str, db: Session):\n    \"\"\"Track when user successfully submits a solution and calculate total time\"\"\"\n    session = db.query(ProblemSession).filter(\n        ProblemSession.user_id == user_id,\n        ProblemSession.problem_id == problem_id\n    ).first()\n    \n    from datetime import datetime\n    now = datetime.now()\n    \n    if not session:\n        # Create new session for direct submissions (no prior testing)\n        session = ProblemSession(\n            user_id=user_id,\n            problem_id=problem_id,\n            first_query_at=now,  # Backfill with submission time\n            completed_at=now,\n            total_time_spent_seconds=0  # Immediate submission\n        )\n        db.add(session)\n        db.commit()\n    elif session.completed_at is None:\n        # Update existing session with completion\n        session.completed_at = now\n        \n        # Calculate total time spent if first_query_at exists\n        if session.first_query_at:\n            time_diff = session.completed_at - session.first_query_at\n            session.total_time_spent_seconds = int(time_diff.total_seconds())\n        else:\n            # Backfill missing first_query_at\n            session.first_query_at = now\n            session.total_time_spent_seconds = 0\n        \n        session.updated_at = func.now()\n        db.commit()\n\n# Create FastAPI app\napp = FastAPI(title=\"SQLGym API\",\n              description=\"A gamified SQL learning platform API\",\n              version=\"1.0.0\")\n\n# Add CORS middleware - Updated for Railway + Vercel/Netlify deployment\nfrontend_origins = [\n    \"http://localhost:5000\", \n    \"http://localhost:3000\",  # Local React development\n    \"https://*.replit.dev\", \n    \"https://*.replit.app\",\n    \"https://*.replit.co\",\n    \"https://*.vercel.app\",   # Vercel deployments\n    \"https://*.netlify.app\",  # Netlify deployments\n    \"https://*.netlify.com\"   # Netlify custom domains\n]\n\n# Add production frontend domains from environment variables\nif os.getenv(\"FRONTEND_URL\"):\n    frontend_origins.append(os.getenv(\"FRONTEND_URL\"))\n\n# In production, use environment variable or specific domain\nif os.getenv(\"REPL_ID\"):\n    repl_id = os.getenv(\"REPL_ID\")\n    username = os.getenv(\"REPL_OWNER\", \"user\")\n    frontend_origins.extend([\n        f\"https://{repl_id}--{username}.replit.app\",\n        f\"https://{repl_id}.{username}.replit.dev\"\n    ])\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=frontend_origins,\n    allow_credentials=True,\n    allow_methods=[\"GET\", \"POST\", \"PUT\", \"DELETE\", \"PATCH\"],\n    allow_headers=[\"*\"],\n)\n\n# Global exception handler for UTF-8 encoding issues\nfrom fastapi.responses import JSONResponse\n@app.exception_handler(UnicodeDecodeError)\nasync def unicode_decode_error_handler(request, exc: UnicodeDecodeError):\n    \"\"\"Handle UTF-8 encoding errors by returning sanitized JSON response\"\"\"\n    from .secure_execution import sanitize_json_data\n    error_data = {\n        \"error\": \"Encoding error occurred\",\n        \"detail\": \"The response contains non-UTF-8 data that has been sanitized\",\n        \"status_code\": 500\n    }\n    return JSONResponse(\n        status_code=500,\n        content=sanitize_json_data(error_data),\n        headers={\"Content-Type\": \"application/json; charset=utf-8\"}\n    )\n\n# Include routers\napp.include_router(sandbox_router)\napp.include_router(admin_router)\n\n\ndef format_console_output(execution_result):\n    \"\"\"Create lightweight console output for errors and metadata\"\"\"\n    if not execution_result.get('success'):\n        error_msg = execution_result.get('error', 'Unknown error')\n        return f\"ERROR: {error_msg}\"\n    \n    # Extract results from query_result structure returned by secure_executor\n    query_result = execution_result.get('query_result', {})\n    results = query_result.get('result', []) if query_result else []\n    exec_time = query_result.get('execution_time_ms', 0) if query_result else 0\n    \n    if not results:\n        return f\"Query executed successfully.\\n0 rows returned.\\nExecution time: {exec_time}ms\"\n    \n    return f\"Query executed successfully.\\n{len(results)} rows returned.\\nExecution time: {exec_time}ms\"\n\n\n# Create tables on startup\n# @app.on_event(\"startup\")  \n# def startup_event():\n#     try:\n#         print(\"ðŸš€ Starting database initialization...\")\n#         create_tables()  # Just create basic tables first\n#         print(\"âœ… Database initialization completed\")\n#     except Exception as e:\n#         print(f\"âš ï¸ Database initialization failed, continuing anyway: {e}\")\n#         # Continue startup even if database fails\n\n\n# Development/fallback root endpoint\n# Health check endpoint\n@app.get(\"/api/health\")\ndef health_check():\n    return {\"status\": \"healthy\", \"service\": \"SQLGym API\", \"version\": \"1.0.0\"}\n\n\n# Root API endpoint to handle HEAD/GET requests to /api\n@app.get(\"/api\")\n@app.head(\"/api\")\ndef api_root():\n    return {\"message\": \"SQLGym API\", \"version\": \"1.0.0\", \"status\": \"running\"}\n\n\n# Database initialization endpoint (admin-only, authenticated)\n@app.post(\"/api/admin/init-db\")\ndef initialize_database(current_user: User = Depends(get_current_user)):\n    \"\"\"Initialize database tables and schema. Admin-only endpoint for safe database setup.\"\"\"\n    # Check if user is admin\n    if not current_user.is_admin:\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN,\n            detail=\"Admin access required for database initialization\"\n        )\n    \n    try:\n        print(\"ðŸš€ Starting database initialization...\")\n        \n        # Just create tables - skip complex migrations for now\n        create_tables()\n        print(\"âœ… Database tables created\")\n        \n        return {\n            \"success\": True,\n            \"message\": \"Database initialized successfully\",\n            \"operations\": [\"table_creation\"]\n        }\n    except Exception as e:\n        print(f\"âŒ Database initialization failed: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Database initialization failed: {str(e)}\"\n        )\n\n\n# Root endpoint and SPA fallback\n@app.get(\"/\")\ndef read_root():\n    if os.path.exists(\"dist/public/index.html\"):\n        return FileResponse(\"dist/public/index.html\")\n    return {\n        \"message\": \"SQLGym FastAPI Backend - Please run 'npm run build' first\"\n    }\n\n\n# SPA fallback route will be defined at the very end of the file after all API routes\n\n\n# Mount static assets for production\nif os.path.exists(\"dist/public/assets\"):\n    app.mount(\"/assets\",\n              StaticFiles(directory=\"dist/public/assets\"),\n              name=\"assets\")\n\n\n# Authentication endpoints\n@app.post(\"/api/auth/register\",\n          response_model=RegisterResponse,\n          response_model_by_alias=True)\ndef register(user_data: UserCreate, db: Session = Depends(get_db)):\n    # Check if user already exists\n    existing_user = db.query(User).filter(\n        User.email == user_data.email).first()\n    if existing_user:\n        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST,\n                            detail=\"User already exists\")\n\n    # Check if username is taken\n    existing_username = db.query(User).filter(\n        User.username == user_data.username).first()\n    if existing_username:\n        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST,\n                            detail=\"Username already taken\")\n\n    # Hash password if provided\n    password_hash = None\n    if user_data.password is not None:\n        password_hash = get_password_hash(user_data.password)\n\n    # Create user\n    user = User(username=user_data.username,\n                email=user_data.email,\n                password_hash=password_hash,\n                first_name=user_data.first_name,\n                last_name=user_data.last_name,\n                profile_image_url=user_data.profile_image_url,\n                google_id=user_data.google_id,\n                github_id=user_data.github_id,\n                auth_provider=user_data.auth_provider)\n\n    db.add(user)\n    db.commit()\n    db.refresh(user)\n\n    # Generate JWT token\n    access_token = create_access_token(data={\n        \"userId\": user.id,\n        \"username\": user.username,\n        \"isAdmin\": user.is_admin\n    })\n\n    return RegisterResponse(token=access_token,\n                            user=UserResponse.from_orm(user))\n\n\n@app.post(\"/api/auth/login\",\n          response_model=LoginResponse,\n          response_model_by_alias=True)\ndef login(login_data: UserLogin, db: Session = Depends(get_db)):\n    # Find user by email\n    user = db.query(User).filter(User.email == login_data.email).first()\n    if not user:\n        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED,\n                            detail=\"Invalid credentials\")\n\n    # Verify password\n    if not user.password_hash or not verify_password(login_data.password,\n                                                     user.password_hash):\n        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED,\n                            detail=\"Invalid credentials\")\n\n    # Generate JWT token\n    access_token = create_access_token(data={\n        \"userId\": user.id,\n        \"username\": user.username,\n        \"isAdmin\": user.is_admin\n    })\n\n    return LoginResponse(token=access_token, user=UserResponse.from_orm(user))\n\n\n@app.get(\"/api/auth/user\",\n         response_model=UserResponse,\n         response_model_by_alias=True)\ndef get_current_user_info(current_user: User = Depends(get_current_user)):\n    return UserResponse.from_orm(current_user)\n\n\n# Problem endpoints\n@app.get(\"/api/problems\",\n         response_model=List[ProblemResponse],\n         response_model_by_alias=True)\ndef get_problems(\n        difficulty: Optional[str] = Query(None),\n        company: Optional[str] = Query(None),\n        premium: Optional[str] = Query(None),\n        current_user: Optional[User] = Depends(get_current_user_optional),\n        db: Session = Depends(get_db)):\n    # Base query with solved count\n    query = db.query(\n        Problem,\n        func.coalesce(\n            func.count(\n                case((Submission.is_correct == True, Submission.user_id),\n                     else_=None).distinct()),\n            0).label(\"solved_count\")).outerjoin(Submission)\n\n    # Add user-specific solved status if authenticated\n    if current_user:\n        query = query.add_columns(\n            func.coalesce(\n                func.max(\n                    case((and_(Submission.user_id == current_user.id,\n                               Submission.is_correct == True), 1),\n                         else_=0)), 0).label(\"is_user_solved\"))\n    else:\n        query = query.add_columns(\n            func.cast(0, Integer).label(\"is_user_solved\"))\n\n    # Apply difficulty filter\n    if difficulty:\n        query = query.filter(Problem.difficulty == difficulty)\n\n    # Apply company filter\n    if company:\n        query = query.filter(Problem.company == company)\n\n    # Apply premium filter\n    if premium:\n        if premium.lower() == \"free\":\n            query = query.filter(Problem.premium.is_(None) | Problem.premium.is_(False))\n        elif premium.lower() == \"premium\":\n            query = query.filter(Problem.premium.is_(True))\n\n    # Group by problem and order by title\n    results = query.group_by(Problem.id).order_by(Problem.title).all()\n\n    # Format response\n    problems = []\n    for problem, solved_count, is_user_solved in results:\n        # Handle JSON parsing for question field if it's a string\n        import json\n        if isinstance(problem.question, str):\n            try:\n                problem.question = json.loads(problem.question)\n            except (json.JSONDecodeError, TypeError):\n                # If parsing fails, create a default QuestionData structure\n                problem.question = {\n                    \"description\": \"Error loading problem description\",\n                    \"tables\": [],\n                    \"expectedOutput\": []\n                }\n        \n        problem_data = ProblemResponse.from_orm(problem)\n        problem_data.solved_count = int(solved_count)\n        problem_data.is_user_solved = bool(\n            is_user_solved) if current_user else False\n        \n        # Add bookmark and like status for authenticated users\n        if current_user:\n            # Check if user has interactions with this problem\n            interaction = db.query(ProblemInteraction).filter(\n                ProblemInteraction.user_id == current_user.id,\n                ProblemInteraction.problem_id == problem.id\n            ).first()\n            \n            problem_data.is_bookmarked = interaction.bookmark if interaction else False\n            problem_data.is_liked = interaction.upvote if interaction else False\n        else:\n            problem_data.is_bookmarked = False\n            problem_data.is_liked = False\n        \n        # Get total likes count for this problem\n        likes_count = db.query(ProblemInteraction).filter(\n            ProblemInteraction.problem_id == problem.id,\n            ProblemInteraction.upvote == True\n        ).count()\n        problem_data.likes_count = likes_count\n        \n        # Use expected_display for user-facing expected output (separate from validation)\n        if hasattr(problem, 'expected_display') and problem.expected_display is not None:\n            problem_data.expected_output = problem.expected_display\n        elif hasattr(problem, 'expected_output') and problem.expected_output is not None:\n            # Fallback to legacy expected_output field for backward compatibility\n            problem_data.expected_output = problem.expected_output\n        else:\n            # No expected output available for display\n            problem_data.expected_output = []\n            \n        # Clear master_solution from user response - this should only be used during submission validation\n        problem_data.master_solution = None\n        \n        # For premium problems, filter content for non-premium users\n        if problem.premium is True and (not current_user or not current_user.premium):\n            # Create a limited question data for premium problems\n            limited_question = QuestionData(\n                description=\"ðŸ”’ Premium Problem - Subscribe to view full description\",\n                tables=[],\n                expectedOutput=[]\n            )\n            problem_data.question = limited_question\n        \n        problems.append(problem_data)\n\n    return problems\n\n\n# Migration endpoint (temporary - for migrating to unified interactions)\n@app.post(\"/api/admin/migrate-interactions\")\ndef migrate_to_unified_interactions(db: Session = Depends(get_db)):\n    \"\"\"Admin endpoint to migrate bookmark and like data to unified ProblemInteraction table\"\"\"\n    try:\n        # Create the new table if it doesn't exist\n        Base.metadata.create_all(bind=db.bind)\n        \n        # Get all existing bookmarks and likes (legacy tables may not exist)\n        try:\n            # Try to import old models if they still exist in database\n            from sqlalchemy import text\n            bookmarks = []\n            likes = []\n            \n            # Check if old tables still exist before querying\n            result = db.execute(text(\"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'problem_bookmarks')\"))\n            if result.scalar():\n                bookmarks = db.execute(text(\"SELECT user_id, problem_id, created_at FROM problem_bookmarks\")).fetchall()\n            \n            result = db.execute(text(\"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'problem_likes')\"))\n            if result.scalar():\n                likes = db.execute(text(\"SELECT user_id, problem_id, created_at FROM problem_likes\")).fetchall()\n                \n        except Exception as e:\n            print(f\"Legacy tables not found or error accessing them: {e}\")\n            bookmarks = []\n            likes = []\n        \n        # Create a dictionary to track user-problem combinations\n        interactions = {}\n        \n        # Process bookmarks\n        for bookmark in bookmarks:\n            key = (bookmark.user_id, bookmark.problem_id)\n            if key not in interactions:\n                interactions[key] = {\n                    'user_id': bookmark.user_id,\n                    'problem_id': bookmark.problem_id,\n                    'bookmark': True,\n                    'upvote': False,\n                    'downvote': False,\n                    'created_at': bookmark.created_at\n                }\n            else:\n                interactions[key]['bookmark'] = True\n                if bookmark.created_at < interactions[key]['created_at']:\n                    interactions[key]['created_at'] = bookmark.created_at\n        \n        # Process likes (convert to upvotes)\n        for like in likes:\n            key = (like.user_id, like.problem_id)\n            if key not in interactions:\n                interactions[key] = {\n                    'user_id': like.user_id,\n                    'problem_id': like.problem_id,\n                    'bookmark': False,\n                    'upvote': True,\n                    'downvote': False,\n                    'created_at': like.created_at\n                }\n            else:\n                interactions[key]['upvote'] = True\n                if like.created_at < interactions[key]['created_at']:\n                    interactions[key]['created_at'] = like.created_at\n        \n        # Insert into ProblemInteraction table\n        migrated_count = 0\n        for interaction_data in interactions.values():\n            # Check if this interaction already exists\n            existing = db.query(ProblemInteraction).filter(\n                ProblemInteraction.user_id == interaction_data['user_id'],\n                ProblemInteraction.problem_id == interaction_data['problem_id']\n            ).first()\n            \n            if not existing:\n                new_interaction = ProblemInteraction(\n                    user_id=interaction_data['user_id'],\n                    problem_id=interaction_data['problem_id'],\n                    bookmark=interaction_data['bookmark'],\n                    upvote=interaction_data['upvote'],\n                    downvote=interaction_data['downvote'],\n                    created_at=interaction_data['created_at']\n                )\n                db.add(new_interaction)\n                migrated_count += 1\n        \n        db.commit()\n        \n        # Verify migration\n        total_interactions = db.query(ProblemInteraction).count()\n        bookmark_count = db.query(ProblemInteraction).filter(ProblemInteraction.bookmark == True).count()\n        upvote_count = db.query(ProblemInteraction).filter(ProblemInteraction.upvote == True).count()\n        \n        return {\n            \"success\": True,\n            \"message\": f\"Successfully migrated {migrated_count} interactions\",\n            \"stats\": {\n                \"total_interactions\": total_interactions,\n                \"with_bookmarks\": bookmark_count,\n                \"with_upvotes\": upvote_count,\n                \"original_bookmarks\": len(bookmarks),\n                \"original_likes\": len(likes)\n            }\n        }\n        \n    except Exception as e:\n        db.rollback()\n        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n                          detail=f\"Migration failed: {str(e)}\")\n\n# Unified Problem Interaction endpoints (bookmark, upvote, downvote)\n@app.post(\"/api/problems/{problem_id}/bookmark\")\ndef toggle_bookmark(problem_id: str,\n                   current_user: User = Depends(get_current_user),\n                   db: Session = Depends(get_db)):\n    \"\"\"Toggle bookmark status for a problem\"\"\"\n    # Check if problem exists\n    problem = db.query(Problem).filter(Problem.id == problem_id).first()\n    if not problem:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND,\n                            detail=\"Problem not found\")\n    \n    # Get or create interaction record\n    interaction = db.query(ProblemInteraction).filter(\n        ProblemInteraction.user_id == current_user.id,\n        ProblemInteraction.problem_id == problem_id\n    ).first()\n    \n    if not interaction:\n        # Create new interaction with bookmark\n        interaction = ProblemInteraction(\n            user_id=current_user.id,\n            problem_id=problem_id,\n            bookmark=True,\n            upvote=False,\n            downvote=False\n        )\n        db.add(interaction)\n        bookmarked = True\n        message = \"Problem bookmarked\"\n    else:\n        # Toggle bookmark status\n        interaction.bookmark = not interaction.bookmark\n        bookmarked = interaction.bookmark\n        message = \"Problem bookmarked\" if bookmarked else \"Bookmark removed\"\n        \n        # If no interactions left, delete the record\n        if not interaction.bookmark and not interaction.upvote and not interaction.downvote:\n            db.delete(interaction)\n    \n    db.commit()\n    return {\"bookmarked\": bookmarked, \"message\": message}\n\n@app.post(\"/api/problems/{problem_id}/upvote\")\ndef toggle_upvote(problem_id: str,\n                 current_user: User = Depends(get_current_user),\n                 db: Session = Depends(get_db)):\n    \"\"\"Toggle upvote status for a problem\"\"\"\n    # Check if problem exists\n    problem = db.query(Problem).filter(Problem.id == problem_id).first()\n    if not problem:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND,\n                            detail=\"Problem not found\")\n    \n    # Get or create interaction record\n    interaction = db.query(ProblemInteraction).filter(\n        ProblemInteraction.user_id == current_user.id,\n        ProblemInteraction.problem_id == problem_id\n    ).first()\n    \n    if not interaction:\n        # Create new interaction with upvote\n        interaction = ProblemInteraction(\n            user_id=current_user.id,\n            problem_id=problem_id,\n            bookmark=False,\n            upvote=True,\n            downvote=False\n        )\n        db.add(interaction)\n        upvoted = True\n        message = \"Problem upvoted\"\n    else:\n        # Toggle upvote status and ensure mutual exclusion with downvote\n        if interaction.upvote:\n            # Remove upvote\n            interaction.upvote = False\n            upvoted = False\n            message = \"Upvote removed\"\n        else:\n            # Add upvote and remove downvote if present\n            interaction.upvote = True\n            interaction.downvote = False\n            upvoted = True\n            message = \"Problem upvoted\"\n        \n        # If no interactions left, delete the record\n        if not interaction.bookmark and not interaction.upvote and not interaction.downvote:\n            db.delete(interaction)\n    \n    db.commit()\n    \n    # Get current upvote count\n    upvote_count = db.query(ProblemInteraction).filter(\n        ProblemInteraction.problem_id == problem_id,\n        ProblemInteraction.upvote == True\n    ).count()\n    \n    return {\"upvoted\": upvoted, \"upvote_count\": upvote_count, \"message\": message}\n\n@app.post(\"/api/problems/{problem_id}/downvote\")\ndef toggle_downvote(problem_id: str,\n                   current_user: User = Depends(get_current_user),\n                   db: Session = Depends(get_db)):\n    \"\"\"Toggle downvote status for a problem\"\"\"\n    # Check if problem exists\n    problem = db.query(Problem).filter(Problem.id == problem_id).first()\n    if not problem:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND,\n                            detail=\"Problem not found\")\n    \n    # Get or create interaction record\n    interaction = db.query(ProblemInteraction).filter(\n        ProblemInteraction.user_id == current_user.id,\n        ProblemInteraction.problem_id == problem_id\n    ).first()\n    \n    if not interaction:\n        # Create new interaction with downvote\n        interaction = ProblemInteraction(\n            user_id=current_user.id,\n            problem_id=problem_id,\n            bookmark=False,\n            upvote=False,\n            downvote=True\n        )\n        db.add(interaction)\n        downvoted = True\n        message = \"Problem downvoted\"\n    else:\n        # Toggle downvote status and ensure mutual exclusion with upvote\n        if interaction.downvote:\n            # Remove downvote\n            interaction.downvote = False\n            downvoted = False\n            message = \"Downvote removed\"\n        else:\n            # Add downvote and remove upvote if present\n            interaction.downvote = True\n            interaction.upvote = False\n            downvoted = True\n            message = \"Problem downvoted\"\n        \n        # If no interactions left, delete the record\n        if not interaction.bookmark and not interaction.upvote and not interaction.downvote:\n            db.delete(interaction)\n    \n    db.commit()\n    return {\"downvoted\": downvoted, \"message\": message}\n\n# Legacy endpoints (maintain compatibility during transition)\n@app.post(\"/api/problems/{problem_id}/like\")\ndef toggle_like_legacy(problem_id: str,\n                      current_user: User = Depends(get_current_user),\n                      db: Session = Depends(get_db)):\n    \"\"\"Legacy like endpoint - redirects to upvote\"\"\"\n    return toggle_upvote(problem_id, current_user, db)\n\n\n@app.get(\"/api/problems/{problem_id}\",\n         response_model=ProblemResponse,\n         response_model_by_alias=True)\ndef get_problem(problem_id: str, \n                current_user: Optional[User] = Depends(get_current_user_optional),\n                db: Session = Depends(get_db)):\n    from .s3_service import s3_service\n    import logging\n    \n    logger = logging.getLogger(__name__)\n    \n    problem = db.query(Problem).filter(Problem.id == problem_id).first()\n    if not problem:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND,\n                            detail=\"Problem not found\")\n    \n    # Handle JSON parsing for question field if it's a string\n    import json\n    if isinstance(problem.question, str):\n        try:\n            problem.question = json.loads(problem.question)\n        except (json.JSONDecodeError, TypeError):\n            # If parsing fails, create a default QuestionData structure\n            problem.question = {\n                \"description\": \"Error loading problem description\",\n                \"tables\": [],\n                \"expectedOutput\": []\n            }\n    \n    # Premium access is handled at frontend level - no backend modification needed\n    \n    # Create response from ORM\n    problem_data = ProblemResponse.from_orm(problem)\n    \n    # Add interaction status for authenticated users\n    if current_user:\n        # Check user's interaction with this problem\n        interaction = db.query(ProblemInteraction).filter(\n            ProblemInteraction.user_id == current_user.id,\n            ProblemInteraction.problem_id == problem_id\n        ).first()\n        \n        if interaction:\n            problem_data.is_bookmarked = interaction.bookmark\n            problem_data.is_upvoted = interaction.upvote\n            problem_data.is_downvoted = interaction.downvote\n        else:\n            problem_data.is_bookmarked = False\n            problem_data.is_upvoted = False\n            problem_data.is_downvoted = False\n        \n        # For backward compatibility, set is_liked = is_upvoted\n        problem_data.is_liked = problem_data.is_upvoted\n    else:\n        problem_data.is_bookmarked = False\n        problem_data.is_upvoted = False\n        problem_data.is_downvoted = False\n        problem_data.is_liked = False\n    \n    # Get total upvotes count for this problem\n    upvotes_count = db.query(ProblemInteraction).filter(\n        ProblemInteraction.problem_id == problem_id,\n        ProblemInteraction.upvote == True\n    ).count()\n    problem_data.upvotes_count = upvotes_count\n    \n    # For backward compatibility, set likes_count = upvotes_count\n    problem_data.likes_count = upvotes_count\n    \n    # Use expected_display for user-facing expected output (separate from validation)\n    if hasattr(problem, 'expected_display') and problem.expected_display is not None:\n        problem_data.expected_output = problem.expected_display\n        logger.info(f\"Using expected_display with {len(problem.expected_display)} rows for user display\")\n    elif hasattr(problem, 'expected_output') and problem.expected_output is not None:\n        # Fallback to legacy expected_output field for backward compatibility\n        problem_data.expected_output = problem.expected_output\n        logger.info(f\"Using legacy expected_output field with {len(problem.expected_output)} rows\")\n    else:\n        # No expected output available for display\n        problem_data.expected_output = []\n        logger.warning(f\"No expected display output found for problem {problem_id}\")\n        \n    # Clear master_solution from user response - this should only be used during submission validation\n    problem_data.master_solution = None\n    \n    return problem_data\n\n\n# New secure execution endpoints\n@app.post(\"/api/problems/{problem_id}/submit\")\nasync def submit_solution(problem_id: str,\n                          query_data: dict,\n                          current_user: User = Depends(get_current_user),\n                          db: Session = Depends(get_db)):\n    \"\"\"Submit and execute SQL query for final evaluation\"\"\"\n    # Check if problem exists and is accessible\n    problem = db.query(Problem).filter(Problem.id == problem_id).first()\n    if not problem:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND,\n                            detail=\"Problem not found\")\n    \n    # Check if problem is premium and user doesn't have premium access\n    if problem.premium is True and not current_user.premium:\n        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN,\n                            detail=\"Premium subscription required to submit solutions for this problem\")\n    \n    query = query_data.get(\"query\", \"\").strip()\n\n    if not query:\n        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST,\n                            detail=\"Query is required\")\n\n    result = await secure_executor.submit_solution(current_user.id, problem_id,\n                                                   query, db)\n\n    if not result['success']:\n        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST,\n                            detail=result.get('feedback',\n                                              ['Submission failed'])[0])\n\n    # Track successful submission for recommendation system\n    if result['success']:\n        track_successful_submission(current_user.id, problem_id, db)\n\n    # Add console output to submission response\n    result['console_output'] = format_console_output(result)\n    \n    # Sanitize result to prevent JSON serialization errors\n    from .secure_execution import sanitize_json_data\n    return sanitize_json_data(result)\n\n\n# PostgreSQL sandbox functionality removed - using DuckDB only\n# Redirect to DuckDB sandbox endpoints in /api/sandbox/duckdb/\n\n\n@app.post(\"/api/problems/{problem_id}/test\")\nasync def test_query(problem_id: str,\n                     query_data: dict,\n                     current_user: User = Depends(get_current_user),\n                     db: Session = Depends(get_db)):\n    \"\"\"Test query without submitting (practice mode)\"\"\"\n    # Check if problem exists and is accessible\n    problem = db.query(Problem).filter(Problem.id == problem_id).first()\n    if not problem:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND,\n                            detail=\"Problem not found\")\n    \n    # Check if problem is premium and user doesn't have premium access\n    if problem.premium is True and not current_user.premium:\n        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN,\n                            detail=\"Premium subscription required to test queries for this problem\")\n    \n    query = query_data.get(\"query\", \"\").strip()\n    include_hidden = query_data.get(\"include_hidden\", False)\n\n    if not query:\n        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST,\n                            detail=\"Query is required\")\n\n    # Track first query time for recommendation system\n    track_first_query(current_user.id, problem_id, db)\n\n    result = await secure_executor.test_query(current_user.id, problem_id,\n                                              query, db, include_hidden)\n\n    # Extract results from nested query_result structure\n    query_result = result.get('query_result', {})\n    results_data = query_result.get('result', []) if query_result else []\n    execution_time = query_result.get('execution_time_ms', 0) if query_result else 0\n    \n    response_data = {\n        \"success\": result['success'],\n        \"results\": results_data,  # Raw data for table\n        \"execution_time_ms\": execution_time,\n        \"rows_affected\": len(results_data),\n        \"console_info\": format_console_output(result),  # Just metadata\n        \"feedback\": result.get('feedback', []),\n        \"test_results\": result.get('test_results', []),\n        \"error\": result.get('error')\n    }\n    \n    # Sanitize result to prevent JSON serialization errors\n    from .secure_execution import sanitize_json_data\n    return sanitize_json_data(response_data)\n\n\n@app.get(\"/api/user/progress\")\nasync def get_user_progress(current_user: User = Depends(get_current_user),\n                            db: Session = Depends(get_db)):\n    \"\"\"Get comprehensive user progress statistics\"\"\"\n    result = await secure_executor.get_user_progress(current_user.id, db)\n\n    if not result['success']:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND,\n                            detail=result.get('error',\n                                              'Progress data not found'))\n\n    # Sanitize result to prevent JSON serialization errors\n    from .secure_execution import sanitize_json_data\n    return sanitize_json_data(result)\n\n\n# Submission endpoints\n@app.post(\"/api/submissions\",\n          response_model=SubmissionResponse,\n          response_model_by_alias=True)\ndef create_submission(submission_data: SubmissionCreate,\n                      current_user: User = Depends(get_current_user),\n                      db: Session = Depends(get_db)):\n    # Simulate SQL query execution (simplified version)\n    problem = db.query(Problem).filter(\n        Problem.id == submission_data.problem_id).first()\n    if not problem:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND,\n                            detail=\"Problem not found\")\n\n    # Simple validation logic (same as Express.js version)\n    is_correct = simulate_query_execution(submission_data.query, problem)\n    execution_time = random.randint(50, 550)  # Random execution time\n\n    # Create submission\n    submission = Submission(user_id=current_user.id,\n                            problem_id=submission_data.problem_id,\n                            query=submission_data.query,\n                            is_correct=is_correct,\n                            execution_time=execution_time)\n\n    db.add(submission)\n    db.commit()\n    db.refresh(submission)\n\n    # If correct, update user progress (check for duplicates after commit)\n    if is_correct:\n        # Check if this is the first time solving this problem\n        existing_correct = db.query(Submission).filter(\n            Submission.user_id == current_user.id,\n            Submission.problem_id == submission_data.problem_id,\n            Submission.is_correct == True,\n            Submission.id != submission.id  # Exclude current submission\n        ).first()\n        \n        if not existing_correct:\n            # First time solving this problem\n            current_user.problems_solved = (current_user.problems_solved or 0) + 1\n            db.commit()\n    db.refresh(submission)\n\n    return SubmissionResponse.from_orm(submission)\n\n\n@app.get(\"/api/submissions/user/{user_id}\",\n         response_model=List[SubmissionResponse],\n         response_model_by_alias=True)\ndef get_user_submissions(user_id: str,\n                         current_user: User = Depends(get_current_user),\n                         db: Session = Depends(get_db)):\n    # Users can only view their own submissions\n    if user_id != current_user.id:\n        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN,\n                            detail=\"Access denied\")\n\n    submissions = db.query(Submission).filter(\n        Submission.user_id == user_id).order_by(desc(\n            Submission.submitted_at)).all()\n\n    return [SubmissionResponse.from_orm(sub) for sub in submissions]\n\n\n@app.get(\"/api/problems/{problem_id}/submissions\",\n         response_model=List[SubmissionResponse],\n         response_model_by_alias=True)\ndef get_problem_submissions(problem_id: str,\n                           current_user: User = Depends(get_current_user),\n                           db: Session = Depends(get_db)):\n    \"\"\"Get user's submissions for a specific problem\"\"\"\n    submissions = db.query(Submission).filter(\n        Submission.user_id == current_user.id,\n        Submission.problem_id == problem_id\n    ).order_by(desc(Submission.submitted_at)).all()\n\n    return [SubmissionResponse.from_orm(sub) for sub in submissions]\n\n\n@app.get(\"/api/problems/{problem_id}/solutions\",\n         response_model=List[SolutionResponse],\n         response_model_by_alias=True)\ndef get_problem_solutions(problem_id: str, db: Session = Depends(get_db)):\n    \"\"\"Get all official solutions for a specific problem (public access)\"\"\"\n    solutions = db.query(Solution).options(joinedload(Solution.creator)).filter(\n        Solution.problem_id == problem_id,\n        Solution.is_official == True  # Only show official solutions\n    ).order_by(Solution.created_at.desc()).all()\n    \n    return [SolutionResponse.from_orm(solution) for solution in solutions]\n\n\n@app.get(\"/api/problems/{problem_id}/official-solution\",\n         response_model=SolutionResponse,\n         response_model_by_alias=True)\ndef get_official_solution(problem_id: str, db: Session = Depends(get_db)):\n    \"\"\"Get the official solution for a specific problem - uses admin-configured source\"\"\"\n    from .s3_service import s3_service\n    import logging\n    from pathlib import Path\n    \n    logger = logging.getLogger(__name__)\n    \n    # First get the problem to check admin's solution source choice\n    problem = db.query(Problem).filter(Problem.id == problem_id).first()\n    if not problem:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Problem not found\"\n        )\n    \n    # Check if problem has solution_source attribute (legacy support)\n    solution_source = getattr(problem, 'solution_source', None)\n    s3_solution_source = getattr(problem, 's3_solution_source', None)\n    \n    logger.info(f\"Problem {problem_id} solution_source: {solution_source}\")\n    \n    # Admin-controlled hybrid logic: check the solution_source field\n    if solution_source == 's3' and s3_solution_source:\n        logger.info(f\"Using S3 solution source for problem {problem_id}\")\n        \n        try:\n            # Extract S3 solution source info configured by admin\n            s3_solution_data = s3_solution_source\n            bucket = s3_solution_data.get('bucket')\n            solution_key = s3_solution_data.get('key')\n            \n            if not bucket or not solution_key:\n                logger.warning(f\"Invalid S3 solution source configuration for problem {problem_id}\")\n                # Fall through to database solution\n            else:\n                logger.info(f\"Looking for solution at s3://{bucket}/{solution_key}\")\n                \n                # Validate and get info about the solution parquet file\n                try:\n                    validation_result = s3_service.validate_dataset_file(bucket, solution_key, 'solution')\n                    if validation_result and validation_result.get('success'):\n                        solution_row_count = validation_result.get('row_count', 0)\n                        sample_data = validation_result.get('sample_data', [])\n                        \n                        # Create a synthetic user for S3-based solutions\n                        synthetic_creator = UserResponse(\n                            id=\"system\",\n                            username=\"system\",\n                            email=\"system@platform.com\",\n                            firstName=\"System\",\n                            lastName=\"Generated\",\n                            profileImageUrl=None\n                        )\n                        \n                        # Create solution content showing the expected results\n                        content_parts = [\n                            f\"This problem uses S3-based validation against expected results with {solution_row_count} rows.\",\n                            f\"\\nSolution data source: s3://{bucket}/{solution_key}\",\n                            \"\\nExpected results structure (sample):\"\n                        ]\n                        \n                        if sample_data:\n                            for i, row in enumerate(sample_data[:3]):  # Show first 3 rows\n                                content_parts.append(f\"Row {i+1}: {row}\")\n                        \n                        content = \"\\n\".join(content_parts)\n                        \n                        solution_response = SolutionResponse(\n                            id=f\"s3_{problem_id}\",\n                            problemId=problem_id,\n                            createdBy=\"system\",\n                            title=\"Official Solution (S3 Source)\",\n                            content=content,\n                            sqlCode=\"-- This problem is validated against S3 parquet data\\n-- Write your query to match the expected results structure shown above\",\n                            isOfficial=True,\n                            createdAt=problem.created_at,\n                            updatedAt=problem.updated_at,\n                            creator=synthetic_creator\n                        )\n                        \n                        logger.info(f\"Successfully created solution response from S3 source for problem {problem_id}\")\n                        return solution_response\n                        \n                except Exception as e:\n                    logger.warning(f\"Failed to validate S3 solution source for problem {problem_id}: {e}\")\n                    # Fall through to database solution\n                    \n        except Exception as e:\n            logger.warning(f\"Failed to process S3 solution source for problem {problem_id}: {e}\")\n            # Fall through to database solution\n            \n    # Use database-based solution (either by admin choice or fallback)\n    logger.info(f\"Using database-based solution lookup for problem {problem_id}\")\n    solution = db.query(Solution).options(joinedload(Solution.creator)).filter(\n        Solution.problem_id == problem_id,\n        Solution.is_official == True\n    ).order_by(Solution.created_at.desc()).first()\n    \n    if not solution:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"No official solution found for this problem\"\n        )\n    \n    return SolutionResponse.from_orm(solution)\n\n\n# Leaderboard endpoint\n@app.get(\"/api/leaderboard\",\n         response_model=List[UserResponse],\n         response_model_by_alias=True)\ndef get_leaderboard(limit: Optional[int] = Query(50),\n                    db: Session = Depends(get_db)):\n    users = db.query(User).order_by(desc(\n        User.problems_solved)).limit(limit).all()\n\n    return [UserResponse.from_orm(user) for user in users]\n\n\n# Community endpoints\n@app.get(\"/api/community/posts\",\n         response_model=List[CommunityPostResponse],\n         response_model_by_alias=True)\ndef get_community_posts(current_user: Optional[User] = Depends(get_current_user_optional),\n                        db: Session = Depends(get_db)):\n    posts = db.query(CommunityPost).options(\n        joinedload(CommunityPost.user),\n        joinedload(CommunityPost.problem)\n    ).order_by(desc(CommunityPost.created_at)).all()\n\n    # Filter out posts related to premium problems for non-premium users\n    filtered_posts = []\n    for post in posts:\n        # If post is not related to any problem, include it\n        if not post.problem:\n            filtered_posts.append(post)\n        # If post is related to a non-premium problem, include it\n        elif not post.problem.premium:\n            filtered_posts.append(post)\n        # If post is related to a premium problem, only include it if user has premium access\n        elif current_user and current_user.premium:\n            filtered_posts.append(post)\n        # Otherwise, exclude the post\n\n    return [CommunityPostResponse.from_orm(post) for post in filtered_posts]\n\n\n@app.post(\"/api/community/posts\",\n          response_model=CommunityPostResponse,\n          response_model_by_alias=True)\ndef create_community_post(post_data: CommunityPostCreate,\n                          current_user: User = Depends(get_current_user),\n                          db: Session = Depends(get_db)):\n    # Check if user is trying to create a post about a premium problem\n    if post_data.problem_id:\n        problem = db.query(Problem).filter(Problem.id == post_data.problem_id).first()\n        if problem and problem.premium and not current_user.premium:\n            raise HTTPException(\n                status_code=status.HTTP_403_FORBIDDEN,\n                detail=\"Premium subscription required to create discussions for this problem\"\n            )\n\n    post = CommunityPost(user_id=current_user.id,\n                         content=post_data.content,\n                         code_snippet=post_data.code_snippet,\n                         problem_id=post_data.problem_id)\n\n    db.add(post)\n    db.commit()\n    db.refresh(post)\n\n    # Load user relationship\n    post = db.query(CommunityPost).options(joinedload(\n        CommunityPost.user)).filter(CommunityPost.id == post.id).first()\n\n    return CommunityPostResponse.from_orm(post)\n\n\n@app.post(\"/api/community/posts/{post_id}/like\")\ndef like_post(post_id: str,\n              current_user: User = Depends(get_current_user),\n              db: Session = Depends(get_db)):\n    # Check if post is related to a premium problem and user has access\n    post = db.query(CommunityPost).options(joinedload(CommunityPost.problem)).filter(\n        CommunityPost.id == post_id).first()\n    \n    if not post:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"Post not found\")\n    \n    # Check premium access for posts related to premium problems\n    if post.problem and post.problem.premium and not current_user.premium:\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN,\n            detail=\"Premium subscription required to interact with this discussion\"\n        )\n\n    # Check if already liked\n    existing_like = db.query(PostLike).filter(\n        and_(PostLike.user_id == current_user.id,\n             PostLike.post_id == post_id)).first()\n\n    if existing_like:\n        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST,\n                            detail=\"Post already liked\")\n\n    # Create like\n    like = PostLike(user_id=current_user.id, post_id=post_id)\n    db.add(like)\n\n    # Update post likes count (we already have the post from above)\n    post.likes = (post.likes or 0) + 1\n\n    db.commit()\n    return {\"message\": \"Post liked successfully\"}\n\n\n@app.delete(\"/api/community/posts/{post_id}/like\")\ndef unlike_post(post_id: str,\n                current_user: User = Depends(get_current_user),\n                db: Session = Depends(get_db)):\n    # Check if post is related to a premium problem and user has access\n    post = db.query(CommunityPost).options(joinedload(CommunityPost.problem)).filter(\n        CommunityPost.id == post_id).first()\n    \n    if not post:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"Post not found\")\n    \n    # Check premium access for posts related to premium problems\n    if post.problem and post.problem.premium and not current_user.premium:\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN,\n            detail=\"Premium subscription required to interact with this discussion\"\n        )\n\n    # Find and delete like\n    like = db.query(PostLike).filter(\n        and_(PostLike.user_id == current_user.id,\n             PostLike.post_id == post_id)).first()\n\n    if not like:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND,\n                            detail=\"Like not found\")\n\n    db.delete(like)\n\n    # Update post likes count (we already have the post from above)\n    post.likes = max(0, (post.likes or 0) - 1)\n\n    db.commit()\n    return {\"message\": \"Post unliked successfully\"}\n\n\n@app.get(\"/api/community/posts/{post_id}/comments\",\n         response_model=List[PostCommentResponse],\n         response_model_by_alias=True)\ndef get_post_comments(post_id: str, \n                      current_user: Optional[User] = Depends(get_current_user_optional),\n                      db: Session = Depends(get_db)):\n    # Check if post is related to a premium problem and user has access\n    post = db.query(CommunityPost).options(joinedload(CommunityPost.problem)).filter(\n        CommunityPost.id == post_id).first()\n    \n    if not post:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"Post not found\")\n    \n    # Check premium access for posts related to premium problems\n    if post.problem and post.problem.premium and (not current_user or not current_user.premium):\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN,\n            detail=\"Premium subscription required to view comments on this discussion\"\n        )\n\n    # Get all comments for the post\n    all_comments = db.query(PostComment).options(joinedload(\n        PostComment.user)).filter(PostComment.post_id == post_id).order_by(\n            PostComment.created_at).all()\n    \n    # Build nested comment structure\n    comment_map = {}\n    root_comments = []\n    \n    # First pass: create comment objects\n    for comment in all_comments:\n        comment_response = PostCommentResponse.from_orm(comment)\n        comment_map[comment.id] = comment_response\n    \n    # Second pass: build tree structure\n    for comment in all_comments:\n        comment_response = comment_map[comment.id]\n        if comment.parent_id and comment.parent_id in comment_map:\n            # This is a reply, add to parent's replies\n            comment_map[comment.parent_id].replies.append(comment_response)\n        else:\n            # This is a root comment\n            root_comments.append(comment_response)\n    \n    return root_comments\n\n\n@app.post(\"/api/community/posts/{post_id}/comments\",\n          response_model=PostCommentResponse,\n          response_model_by_alias=True)\ndef create_post_comment(post_id: str,\n                        comment_data: PostCommentCreate,\n                        current_user: User = Depends(get_current_user),\n                        db: Session = Depends(get_db)):\n    # Check if post is related to a premium problem and user has access\n    post = db.query(CommunityPost).options(joinedload(CommunityPost.problem)).filter(\n        CommunityPost.id == post_id).first()\n    \n    if not post:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"Post not found\")\n    \n    # Check premium access for posts related to premium problems\n    if post.problem and post.problem.premium and not current_user.premium:\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN,\n            detail=\"Premium subscription required to comment on this discussion\"\n        )\n\n    # Validate parent comment exists if parent_id is provided\n    if comment_data.parent_id:\n        parent_comment = db.query(PostComment).filter(\n            and_(PostComment.id == comment_data.parent_id, PostComment.post_id == post_id)\n        ).first()\n        if not parent_comment:\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND,\n                detail=\"Parent comment not found\"\n            )\n    \n    comment = PostComment(\n        user_id=current_user.id,\n        post_id=post_id,\n        parent_id=comment_data.parent_id,\n        content=comment_data.content\n    )\n\n    db.add(comment)\n\n    # Update post comments count\n    post = db.query(CommunityPost).filter(CommunityPost.id == post_id).first()\n    if post:\n        post.comments = (post.comments or 0) + 1\n\n    db.commit()\n    db.refresh(comment)\n\n    # Load user relationship\n    comment = db.query(PostComment).options(joinedload(\n        PostComment.user)).filter(PostComment.id == comment.id).first()\n\n    return PostCommentResponse.from_orm(comment)\n\n\n# Solution API routes (public viewing)\n@app.get(\"/api/problems/{problem_id}/solutions\", response_model=List[SolutionResponse])\ndef get_problem_solutions_public(\n    problem_id: str,\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get all official solutions for a problem (public view)\"\"\"\n    solutions = db.query(Solution).options(joinedload(Solution.creator)).filter(\n        and_(Solution.problem_id == problem_id, Solution.is_official == True)\n    ).order_by(Solution.created_at.desc()).all()\n    \n    return [SolutionResponse.from_orm(solution) for solution in solutions]\n\n# Enhanced discussion API routes for problem-specific discussions  \n@app.get(\"/api/problems/{problem_id}/discussions\", response_model=List[CommunityPostResponse])\ndef get_problem_discussions(\n    problem_id: str,\n    limit: int = Query(20, ge=1, le=100),\n    current_user: Optional[User] = Depends(get_current_user_optional),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get discussions for a specific problem\"\"\"\n    # First check if the problem exists and if it's premium\n    problem = db.query(Problem).filter(Problem.id == problem_id).first()\n    if not problem:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Problem not found\"\n        )\n    \n    # For premium problems with non-premium users, return empty list\n    # The frontend will handle showing the locked state UI\n    if problem.premium and (not current_user or not current_user.premium):\n        return []\n    \n    posts = db.query(CommunityPost).options(\n        joinedload(CommunityPost.user)\n    ).filter(\n        CommunityPost.problem_id == problem_id\n    ).order_by(\n        desc(CommunityPost.created_at)\n    ).limit(limit).all()\n    \n    return [CommunityPostResponse.from_orm(post) for post in posts]\n\n@app.post(\"/api/problems/{problem_id}/discussions\", response_model=CommunityPostResponse)\ndef create_problem_discussion(\n    problem_id: str,\n    post_data: CommunityPostCreate,\n    current_user: User = Depends(get_current_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Create a new discussion post for a specific problem\"\"\"\n    # Verify problem exists\n    problem = db.query(Problem).filter(Problem.id == problem_id).first()\n    if not problem:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Problem not found\"\n        )\n    \n    # Check premium access for premium problems\n    if problem.premium and not current_user.premium:\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN,\n            detail=\"Premium subscription required to create discussions for this problem\"\n        )\n    \n    # Create discussion post\n    post = CommunityPost(\n        user_id=current_user.id,\n        problem_id=problem_id,  # Link to problem\n        content=post_data.content,\n        code_snippet=post_data.code_snippet\n    )\n    \n    db.add(post)\n    db.commit()\n    db.refresh(post)\n    \n    # Load user relationship\n    post = db.query(CommunityPost).options(joinedload(CommunityPost.user)).filter(\n        CommunityPost.id == post.id\n    ).first()\n    \n    return CommunityPostResponse.from_orm(post)\n\n# Get all community posts with optional problem filtering\n@app.get(\"/api/community/posts/all\", response_model=List[CommunityPostResponse])\ndef get_all_community_posts(\n    problem_id: Optional[str] = Query(None),\n    limit: int = Query(20, ge=1, le=100),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get all community posts with optional problem filtering\"\"\"\n    query = db.query(CommunityPost).options(joinedload(CommunityPost.user))\n    \n    if problem_id:\n        query = query.filter(CommunityPost.problem_id == problem_id)\n    \n    posts = query.order_by(desc(CommunityPost.created_at)).limit(limit).all()\n    \n    return [CommunityPostResponse.from_orm(post) for post in posts]\n\n\n# Helper function for query simulation\ndef simulate_query_execution(query: str, problem: Problem) -> bool:\n    \"\"\"\n    Simplified query validation (same logic as Express.js version)\n    \"\"\"\n    normalized_query = query.lower().strip()\n\n    # Basic checks for different problem types\n    if \"sum\" in problem.title.lower():\n        return (\"select\" in normalized_query and \"from\" in normalized_query\n                and (\"sum\" in normalized_query or \"+\" in normalized_query))\n\n    if \"join\" in problem.title.lower():\n        return (\"select\" in normalized_query and \"from\" in normalized_query\n                and \"join\" in normalized_query)\n\n    # Default validation: must contain SELECT and FROM\n    return \"select\" in normalized_query and \"from\" in normalized_query\n\n\n# SPA fallback route - handle all non-API routes (must be last)\n# SPA fallback route - handle all non-API routes (must be last)\n@app.get(\"/{full_path:path}\")\ndef spa_fallback(full_path: str):\n    # Don't handle API routes\n    if full_path.startswith(\"api/\"):\n        raise HTTPException(status_code=404, detail=\"API endpoint not found\")\n\n    # Don't handle asset files\n    if full_path.startswith(\"assets/\") or \".\" in full_path.split(\"/\")[-1]:\n        raise HTTPException(status_code=404, detail=\"File not found\")\n\n    # Serve SPA for all other routes\n    index_path = \"dist/public/index.html\"\n    if os.path.exists(index_path):\n        return FileResponse(index_path)\n\n    # Fallback if no built frontend\n    raise HTTPException(status_code=404, detail=\"Frontend not built\")\n\n\nif __name__ == \"__main__\":\n    import uvicorn\n    port = int(os.getenv(\"PORT\", 8000))\n    host = \"0.0.0.0\" if os.getenv(\"REPL_ID\") else \"127.0.0.1\"\n    uvicorn.run(app, host=host, port=port)\n","size_bytes":60608},"api/models.py":{"content":"\"\"\"\nSQLAlchemy models for the PostgreSQL database schema\n\"\"\"\nfrom sqlalchemy import Column, String, Text, Integer, Boolean, DateTime, ForeignKey, Float, Enum, Index, UniqueConstraint\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import relationship\nfrom sqlalchemy.sql import func\nfrom sqlalchemy.dialects.postgresql import JSON, JSONB, ENUM\nimport uuid\nimport enum\n\nBase = declarative_base()\n\n# Named Postgres enums for better type safety and performance\n# Python enums for reference\nclass DifficultyLevel(enum.Enum):\n    EASY = \"Easy\"\n    MEDIUM = \"Medium\"\n    HARD = \"Hard\"\n\nclass ExecutionStatus(enum.Enum):\n    SUCCESS = \"SUCCESS\"\n    ERROR = \"ERROR\"\n    TIMEOUT = \"TIMEOUT\"\n    MEMORY_LIMIT = \"MEMORY_LIMIT\"\n\nclass SandboxStatus(enum.Enum):\n    ACTIVE = \"ACTIVE\"\n    EXPIRED = \"EXPIRED\"\n    CLEANUP_PENDING = \"CLEANUP_PENDING\"\n\n# Create named Postgres enums\ndifficulty_enum = ENUM(\n    'BEGINNER', 'EASY', 'MEDIUM', 'HARD', 'EXPERT',\n    name='difficultylevel',\n    create_type=False\n)\n\nexecution_status_enum = ENUM(\n    'SUCCESS', 'ERROR', 'TIMEOUT', 'MEMORY_LIMIT',\n    name='execution_status',\n    create_type=False\n)\n\nsandbox_status_enum = ENUM(\n    'ACTIVE', 'EXPIRED', 'CLEANUP_PENDING',\n    name='sandbox_status',\n    create_type=False\n)\n\nclass User(Base):\n    __tablename__ = \"users\"\n    \n    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n    username = Column(String(50), unique=True, nullable=False)\n    email = Column(String(255), unique=True, nullable=False)\n    password_hash = Column(Text, name=\"password_hash\")\n    first_name = Column(String(50), name=\"first_name\")\n    last_name = Column(String(50), name=\"last_name\")\n    profile_image_url = Column(Text, name=\"profile_image_url\")\n    google_id = Column(String(255), unique=True, name=\"google_id\")\n    github_id = Column(String(255), unique=True, name=\"github_id\")\n    auth_provider = Column(String(20), default=\"email\", nullable=False, name=\"auth_provider\")\n    problems_solved = Column(Integer, default=0, nullable=False, name=\"problems_solved\")\n    premium = Column(Boolean, nullable=False, default=False)  # False = free user, True = premium user\n    is_admin = Column(Boolean, nullable=False, default=False)  # False = regular user, True = admin user\n    created_at = Column(DateTime, default=func.now(), nullable=False, name=\"created_at\")\n    updated_at = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False, name=\"updated_at\")\n    \n    # Relationships\n    submissions = relationship(\"Submission\", back_populates=\"user\")\n    community_posts = relationship(\"CommunityPost\", back_populates=\"user\")\n    post_likes = relationship(\"PostLike\", back_populates=\"user\")\n    post_comments = relationship(\"PostComment\", back_populates=\"user\")\n    progress = relationship(\"UserProgress\", back_populates=\"user\")\n    user_badges = relationship(\"UserBadge\", back_populates=\"user\")\n\nclass Problem(Base):\n    __tablename__ = \"problems\"\n    \n    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n    title = Column(String(200), nullable=False)\n    difficulty = Column(String(20), nullable=False)  # Easy, Medium, Hard\n\n    # Match DB schema: json (not jsonb)\n    tags = Column(JSON, default=list, nullable=False)\n    company = Column(String(100), nullable=True)\n    hints = Column(JSON, default=list, nullable=False)\n\n    # Match DB schema: jsonb\n    question = Column(JSONB, nullable=False)  # description, schema, expected_output\n    s3_data_source = Column(JSONB, nullable=True)  # bucket, key, table_name, description, etag (single table - legacy)\n    s3_datasets = Column(JSONB, nullable=True)  # array of multiple dataset configs: [{'bucket': str, 'key': str, 'table_name': str, 'description': str, 'etag': str}]\n    premium = Column(Boolean, nullable=True, default=None)  # null = free, True = premium\n    \n    # Master solution field - the definitive expected output for validation\n    master_solution = Column(JSONB, nullable=True)  # Complete expected output for validation and display\n    \n    # Display field - what users see on the problem page (separate from validation)\n    expected_display = Column(JSONB, nullable=True)  # Expected output shown to users on problem page\n    \n    # Hash field for fast validation\n    expected_hash = Column(String, nullable=True)  # MD5 hash of sorted expected results for fast comparison\n\n    created_at = Column(DateTime, default=func.now(), nullable=False, name=\"created_at\")\n    updated_at = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False, name=\"updated_at\")\n    \n    topic_id = Column(String, ForeignKey(\"topics.id\", ondelete=\"SET NULL\"))\n    \n    # Relationships\n    submissions = relationship(\"Submission\", back_populates=\"problem\")\n    test_cases = relationship(\"TestCase\", back_populates=\"problem\")\n    schemas = relationship(\"ProblemSchema\", back_populates=\"problem\")\n    community_posts = relationship(\"CommunityPost\", back_populates=\"problem\")\n    solutions = relationship(\"Solution\", back_populates=\"problem\")\n    topic = relationship(\"Topic\", back_populates=\"problems\")\n    \n    # Indexes for performance\n    __table_args__ = (\n        Index('idx_problems_difficulty', 'difficulty'),\n        Index('idx_problems_company', 'company'),\n        Index('idx_problems_topic_id', 'topic_id'),\n        Index('idx_problems_created_at', 'created_at'),\n    )\n\nclass Submission(Base):\n    __tablename__ = \"submissions\"\n    \n    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n    user_id = Column(String, ForeignKey(\"users.id\", ondelete=\"CASCADE\"), nullable=False, name=\"user_id\")\n    problem_id = Column(String, ForeignKey(\"problems.id\", ondelete=\"CASCADE\"), nullable=False, name=\"problem_id\")\n    query = Column(Text, nullable=False)\n    is_correct = Column(Boolean, nullable=False, name=\"is_correct\")\n    execution_time = Column(Integer, name=\"execution_time\")  # in milliseconds\n    submitted_at = Column(DateTime, default=func.now(), nullable=False, name=\"submitted_at\")\n    \n    # Relationships\n    user = relationship(\"User\", back_populates=\"submissions\")\n    problem = relationship(\"Problem\", back_populates=\"submissions\")\n    execution_results = relationship(\"ExecutionResult\", back_populates=\"submission\")\n    \n    # Indexes for performance\n    __table_args__ = (\n        Index('idx_submissions_user_id', 'user_id'),\n        Index('idx_submissions_problem_id', 'problem_id'),\n        Index('idx_submissions_submitted_at', 'submitted_at'),\n        Index('idx_submissions_is_correct', 'is_correct'),\n    )\n\nclass CommunityPost(Base):\n    __tablename__ = \"community_posts\"\n    \n    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n    user_id = Column(String, ForeignKey(\"users.id\", ondelete=\"CASCADE\"), nullable=False, name=\"user_id\")\n    problem_id = Column(String, ForeignKey(\"problems.id\", ondelete=\"CASCADE\"), nullable=True, name=\"problem_id\")  # For problem-specific discussions\n    content = Column(Text, nullable=False)\n    code_snippet = Column(Text, name=\"code_snippet\")\n    likes = Column(Integer, default=0, nullable=False)\n    comments = Column(Integer, default=0, nullable=False)\n    created_at = Column(DateTime, default=func.now(), nullable=False, name=\"created_at\")\n    updated_at = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False, name=\"updated_at\")\n    \n    # Relationships\n    user = relationship(\"User\", back_populates=\"community_posts\")\n    problem = relationship(\"Problem\", back_populates=\"community_posts\")\n    post_likes = relationship(\"PostLike\", back_populates=\"post\")\n    post_comments = relationship(\"PostComment\", back_populates=\"post\")\n\nclass PostLike(Base):\n    __tablename__ = \"post_likes\"\n    \n    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n    user_id = Column(String, ForeignKey(\"users.id\", ondelete=\"CASCADE\"), nullable=False, name=\"user_id\")\n    post_id = Column(String, ForeignKey(\"community_posts.id\", ondelete=\"CASCADE\"), nullable=False, name=\"post_id\")\n    created_at = Column(DateTime, default=func.now(), nullable=False, name=\"created_at\")\n    \n    # Relationships\n    user = relationship(\"User\", back_populates=\"post_likes\")\n    post = relationship(\"CommunityPost\", back_populates=\"post_likes\")\n    \n    # Unique constraint: one like per user per post\n    __table_args__ = (UniqueConstraint('user_id', 'post_id', name='uq_post_likes_user_post'),)\n\nclass PostComment(Base):\n    __tablename__ = \"post_comments\"\n    \n    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n    user_id = Column(String, ForeignKey(\"users.id\", ondelete=\"CASCADE\"), nullable=False, name=\"user_id\")\n    post_id = Column(String, ForeignKey(\"community_posts.id\", ondelete=\"CASCADE\"), nullable=False, name=\"post_id\")\n    parent_id = Column(String, ForeignKey(\"post_comments.id\", ondelete=\"CASCADE\"), nullable=True, name=\"parent_id\")  # For nested replies\n    content = Column(Text, nullable=False)\n    created_at = Column(DateTime, default=func.now(), nullable=False, name=\"created_at\")\n    \n    # Relationships\n    user = relationship(\"User\", back_populates=\"post_comments\")\n    post = relationship(\"CommunityPost\", back_populates=\"post_comments\")\n    parent = relationship(\"PostComment\", remote_side=[id], backref=\"replies\")\n\n# New Tables for Enhanced SQL Learning Platform\n\nclass Topic(Base):\n    \"\"\"Topics/Categories to organize problems by SQL concepts\"\"\"\n    __tablename__ = \"topics\"\n    \n    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n    name = Column(String(100), unique=True, nullable=False)\n    description = Column(Text)\n    difficulty_level = Column(difficulty_enum, nullable=False)\n    order_index = Column(Integer, default=0)  # For ordering topics\n    parent_topic_id = Column(String, ForeignKey(\"topics.id\", ondelete=\"SET NULL\"))  # For subtopics\n    created_at = Column(DateTime, default=func.now(), nullable=False)\n    updated_at = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False)\n    \n    # Relationships\n    parent_topic = relationship(\"Topic\", remote_side=[id])\n    problems = relationship(\"Problem\", back_populates=\"topic\")\n    user_progress = relationship(\"UserProgress\", back_populates=\"topic\")\n\nclass TestCase(Base):\n    \"\"\"Test cases for problems with input data and expected outputs\"\"\"\n    __tablename__ = \"test_cases\"\n    \n    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n    problem_id = Column(String, ForeignKey(\"problems.id\", ondelete=\"CASCADE\"), nullable=False)\n    name = Column(String(200), nullable=False)\n    description = Column(Text)\n    input_data = Column(JSONB, nullable=False)  # Schema and sample data\n    expected_output = Column(JSONB, nullable=False)  # Expected query results (backward compatibility)\n    validation_rules = Column(JSONB, default=dict)  # Custom validation logic\n    is_hidden = Column(Boolean, default=False)  # Hidden test cases for evaluation\n    order_index = Column(Integer, default=0)\n    timeout_seconds = Column(Integer, default=30)\n    memory_limit_mb = Column(Integer, default=256)\n    \n    # S3 Answer Source Support\n    expected_output_source = Column(JSONB, nullable=True)  # S3 bucket, key, format, etag for full dataset\n    preview_expected_output = Column(JSONB, nullable=True)  # Limited rows for frontend display\n    display_limit = Column(Integer, default=10)  # Number of rows to show in preview\n    \n    created_at = Column(DateTime, default=func.now(), nullable=False)\n    updated_at = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False)\n    \n    # Relationships\n    problem = relationship(\"Problem\", back_populates=\"test_cases\")\n    execution_results = relationship(\"ExecutionResult\", back_populates=\"test_case\")\n    \n    # Unique constraint: unique name per problem\n    __table_args__ = (UniqueConstraint('problem_id', 'name', name='uq_test_cases_problem_name'),)\n\nclass ProblemSchema(Base):\n    \"\"\"Define table structures that problems will use\"\"\"\n    __tablename__ = \"problem_schemas\"\n    \n    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n    problem_id = Column(String, ForeignKey(\"problems.id\", ondelete=\"CASCADE\"), nullable=False)\n    table_name = Column(String(100), nullable=False)\n    schema_definition = Column(JSONB, nullable=False)  # Table structure with columns, types, constraints\n    sample_data = Column(JSONB, default=list)  # Sample rows for the table\n    indexes = Column(JSON, default=list)  # Index definitions\n    constraints = Column(JSON, default=list)  # FK, CHECK constraints etc\n    created_at = Column(DateTime, default=func.now(), nullable=False)\n    updated_at = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False)\n    \n    # Relationships\n    problem = relationship(\"Problem\", back_populates=\"schemas\")\n    \n    # Unique constraint: unique table_name per problem\n    __table_args__ = (UniqueConstraint('problem_id', 'table_name', name='uq_problem_schemas_problem_table'),)\n\nclass ExecutionResult(Base):\n    \"\"\"Track detailed query execution results\"\"\"\n    __tablename__ = \"execution_results\"\n    \n    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n    submission_id = Column(String, ForeignKey(\"submissions.id\", ondelete=\"CASCADE\"), nullable=False)\n    test_case_id = Column(String, ForeignKey(\"test_cases.id\", ondelete=\"CASCADE\"), nullable=False)\n    # user_sandbox_id removed - PostgreSQL sandbox functionality removed\n    \n    # Execution details\n    status = Column(execution_status_enum, nullable=False)\n    execution_time_ms = Column(Integer)  # Actual execution time\n    memory_used_mb = Column(Float)  # Memory consumption\n    rows_affected = Column(Integer)  # For DML queries\n    query_result = Column(JSONB)  # Actual query output\n    error_message = Column(Text)  # Error details if any\n    \n    # Performance metrics\n    cpu_time_ms = Column(Integer)\n    io_operations = Column(Integer)\n    query_plan = Column(JSONB)  # EXPLAIN output\n    \n    # Validation\n    is_correct = Column(Boolean, nullable=False)\n    validation_details = Column(JSONB)  # Detailed comparison results\n    \n    created_at = Column(DateTime, default=func.now(), nullable=False)\n    \n    # Relationships\n    submission = relationship(\"Submission\", back_populates=\"execution_results\")\n    test_case = relationship(\"TestCase\", back_populates=\"execution_results\")\n    # user_sandbox relationship removed - PostgreSQL sandbox functionality removed\n\n\nclass UserProgress(Base):\n    \"\"\"Track user statistics and problem-solving progress\"\"\"\n    __tablename__ = \"user_progress\"\n    \n    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n    user_id = Column(String, ForeignKey(\"users.id\", ondelete=\"CASCADE\"), nullable=False)\n    topic_id = Column(String, ForeignKey(\"topics.id\", ondelete=\"CASCADE\"), nullable=False)\n    \n    # Progress metrics\n    problems_attempted = Column(Integer, default=0)\n    problems_solved = Column(Integer, default=0)\n    total_submissions = Column(Integer, default=0)\n    successful_submissions = Column(Integer, default=0)\n    \n    # Performance metrics\n    average_execution_time_ms = Column(Float)\n    best_execution_time_ms = Column(Float)\n    total_time_spent_minutes = Column(Integer, default=0)\n    \n    # Difficulty progression\n    current_difficulty = Column(difficulty_enum, default=\"EASY\")\n    highest_difficulty_solved = Column(difficulty_enum, default=\"EASY\")\n    \n    # Learning metrics\n    hint_usage_count = Column(Integer, default=0)\n    average_attempts_per_problem = Column(Float, default=1.0)\n    streak_count = Column(Integer, default=0)  # Current solving streak\n    max_streak_count = Column(Integer, default=0)  # Best streak ever\n    \n    # XP and achievements\n    experience_points = Column(Integer, default=0)\n    \n    # Timestamps\n    first_attempt_at = Column(DateTime)\n    last_activity_at = Column(DateTime, default=func.now())\n    created_at = Column(DateTime, default=func.now(), nullable=False)\n    updated_at = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False)\n    \n    # Relationships\n    user = relationship(\"User\", back_populates=\"progress\")\n    topic = relationship(\"Topic\", back_populates=\"user_progress\")\n    \n    # Unique constraint: one progress record per user per topic\n    __table_args__ = (UniqueConstraint('user_id', 'topic_id', name='uq_user_progress_user_topic'),)\n\nclass Badge(Base):\n    \"\"\"Achievement badges for user motivation\"\"\"\n    __tablename__ = \"badges\"\n    \n    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n    name = Column(String(100), unique=True, nullable=False)\n    description = Column(Text, nullable=False)\n    icon_url = Column(Text)\n    criteria = Column(JSONB, nullable=False)  # Conditions to earn the badge\n    points_reward = Column(Integer, default=0)\n    rarity = Column(String(20), default=\"common\")  # common, rare, epic, legendary\n    created_at = Column(DateTime, default=func.now(), nullable=False)\n    \n    # Relationships\n    user_badges = relationship(\"UserBadge\", back_populates=\"badge\")\n\nclass UserBadge(Base):\n    \"\"\"Junction table for user-earned badges\"\"\"\n    __tablename__ = \"user_badges\"\n    \n    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n    user_id = Column(String, ForeignKey(\"users.id\", ondelete=\"CASCADE\"), nullable=False)\n    badge_id = Column(String, ForeignKey(\"badges.id\", ondelete=\"CASCADE\"), nullable=False)\n    earned_at = Column(DateTime, default=func.now(), nullable=False)\n    \n    # Relationships\n    user = relationship(\"User\", back_populates=\"user_badges\")\n    badge = relationship(\"Badge\", back_populates=\"user_badges\")\n    \n    # Unique constraint: one badge per user (prevent duplicate awards)\n    __table_args__ = (UniqueConstraint('user_id', 'badge_id', name='uq_user_badges_user_badge'),)\n\nclass ProblemInteraction(Base):\n    \"\"\"Unified user interactions for problems (bookmark, upvote, downvote)\"\"\"\n    __tablename__ = \"problem_interactions\"\n    \n    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n    user_id = Column(String, ForeignKey(\"users.id\", ondelete=\"CASCADE\"), nullable=False)\n    problem_id = Column(String, ForeignKey(\"problems.id\", ondelete=\"CASCADE\"), nullable=False)\n    \n    # Interaction flags - all optional\n    bookmark = Column(Boolean, default=False, nullable=False)\n    upvote = Column(Boolean, default=False, nullable=False)\n    downvote = Column(Boolean, default=False, nullable=False)\n    \n    created_at = Column(DateTime, default=func.now(), nullable=False)\n    updated_at = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False)\n    \n    # Relationships\n    user = relationship(\"User\", backref=\"problem_interactions\")\n    problem = relationship(\"Problem\", backref=\"interactions\")\n    \n    # Unique constraint: one interaction record per user per problem\n    __table_args__ = (UniqueConstraint('user_id', 'problem_id', name='uq_problem_interactions_user_problem'),)\n\n# Migration completed - old ProblemBookmark and ProblemLike models removed\n\nclass ProblemSession(Base):\n    \"\"\"Track user engagement timing for problems\"\"\"\n    __tablename__ = \"problem_sessions\"\n    \n    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n    user_id = Column(String, ForeignKey(\"users.id\", ondelete=\"CASCADE\"), nullable=False)\n    problem_id = Column(String, ForeignKey(\"problems.id\", ondelete=\"CASCADE\"), nullable=False)\n    first_query_at = Column(DateTime, nullable=True)  # When user first runs a query\n    completed_at = Column(DateTime, nullable=True)    # When user successfully submits\n    total_time_spent_seconds = Column(Integer, nullable=True)  # Calculated time difference\n    created_at = Column(DateTime, default=func.now(), nullable=False)\n    updated_at = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False)\n    \n    # Relationships\n    user = relationship(\"User\", backref=\"problem_sessions\")\n    problem = relationship(\"Problem\", backref=\"sessions\")\n    \n    # Index for performance\n    __table_args__ = (\n        Index('idx_problem_sessions_user_problem', 'user_id', 'problem_id'),\n        Index('idx_problem_sessions_completed_at', 'completed_at'),\n    )\n\nclass Solution(Base):\n    \"\"\"Official solutions for problems posted by admins\"\"\"\n    __tablename__ = \"solutions\"\n    \n    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n    problem_id = Column(String, ForeignKey(\"problems.id\", ondelete=\"CASCADE\"), nullable=False, name=\"problem_id\")\n    created_by = Column(String, ForeignKey(\"users.id\", ondelete=\"CASCADE\"), nullable=False, name=\"created_by\")\n    title = Column(String(200), nullable=False)\n    content = Column(Text, nullable=False)  # Solution explanation\n    sql_code = Column(Text, nullable=False, name=\"sql_code\")  # The actual SQL solution\n    is_official = Column(Boolean, default=True, nullable=False, name=\"is_official\")  # Mark as official solution\n    created_at = Column(DateTime, default=func.now(), nullable=False, name=\"created_at\")\n    updated_at = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False, name=\"updated_at\")\n    \n    # Relationships\n    problem = relationship(\"Problem\", back_populates=\"solutions\")\n    creator = relationship(\"User\", foreign_keys=[created_by])\n    \n    # Indexes for performance\n    __table_args__ = (\n        Index('idx_solutions_problem_id', 'problem_id'),\n        Index('idx_solutions_created_by', 'created_by'),\n        Index('idx_solutions_created_at', 'created_at'),\n    )\n","size_bytes":21615},"api/schemas.py":{"content":"\"\"\"\nPydantic schemas for request/response validation\n\"\"\"\nfrom pydantic import BaseModel, EmailStr, ConfigDict, Field\nfrom pydantic.alias_generators import to_camel\nfrom typing import Optional, List, Dict, Any\nfrom datetime import datetime\nfrom enum import Enum\n\n# Enums matching the SQLAlchemy enums\nclass DifficultyLevel(str, Enum):\n    BEGINNER = \"BEGINNER\"\n    EASY = \"EASY\"\n    MEDIUM = \"MEDIUM\"\n    HARD = \"HARD\"\n    EXPERT = \"EXPERT\"\n\nclass ExecutionStatus(str, Enum):\n    SUCCESS = \"SUCCESS\"\n    ERROR = \"ERROR\"\n    TIMEOUT = \"TIMEOUT\"\n    MEMORY_LIMIT = \"MEMORY_LIMIT\"\n\nclass SandboxStatus(str, Enum):\n    ACTIVE = \"ACTIVE\"\n    EXPIRED = \"EXPIRED\"\n    CLEANUP_PENDING = \"CLEANUP_PENDING\"\n\n# Base model for camelCase aliasing\nclass CamelCaseModel(BaseModel):\n    model_config = ConfigDict(\n        alias_generator=to_camel,\n        populate_by_name=True,\n        from_attributes=True\n    )\n\n# S3 Answer Source schemas\nclass S3AnswerSource(BaseModel):\n    \"\"\"Schema for S3 answer source configuration\"\"\"\n    bucket: str\n    key: str  # S3 object key (file path)\n    format: str  # csv, json, parquet\n    etag: Optional[str] = None  # For cache validation\n    last_modified: Optional[datetime] = None\n    description: Optional[str] = None\n    \n    model_config = ConfigDict(\n        populate_by_name=True,\n        from_attributes=True\n    )\n\n# S3 Dataset Source schemas (for problem datasets)\nclass S3DatasetSource(BaseModel):\n    \"\"\"Schema for S3 dataset source configuration\"\"\"\n    bucket: str\n    key: str  # S3 object key (file path) - must be .parquet\n    table_name: str  # Table name for DuckDB\n    description: Optional[str] = None\n    etag: Optional[str] = None  # For cache validation\n    \n    model_config = ConfigDict(\n        populate_by_name=True,\n        from_attributes=True\n    )\n\nclass MultiTableS3Source(BaseModel):\n    \"\"\"Schema for multiple S3 dataset sources in a single question\"\"\"\n    datasets: List[S3DatasetSource]  # List of S3 dataset configurations\n    description: Optional[str] = None  # Overall description of the multi-table setup\n    \n    model_config = ConfigDict(\n        populate_by_name=True,\n        from_attributes=True\n    )\n\n# User schemas\nclass UserBase(CamelCaseModel):\n    username: str\n    email: EmailStr\n    first_name: Optional[str] = None\n    last_name: Optional[str] = None\n    profile_image_url: Optional[str] = None\n\nclass UserCreate(UserBase):\n    password: Optional[str] = None\n    google_id: Optional[str] = None\n    github_id: Optional[str] = None\n    auth_provider: str = \"email\"\n\nclass UserResponse(UserBase):\n    id: str\n    problems_solved: int\n    premium: bool\n    created_at: datetime\n\nclass UserLogin(CamelCaseModel):\n    email: EmailStr\n    password: str\n\n# Table column definition for structured display\nclass TableColumn(BaseModel):\n    name: str\n    type: str\n\n# Table data with columns and sample data\nclass TableData(BaseModel):\n    name: str\n    columns: List[TableColumn]\n    sample_data: List[dict] = Field(..., alias=\"sampleData\")\n    \n    model_config = ConfigDict(\n        populate_by_name=True,\n        from_attributes=True\n    )\n\n# Problem question structure for JSONB field - structured format\nclass QuestionData(BaseModel):\n    description: str\n    tables: List[TableData] = []\n    # Note: expected_output moved to top-level ProblemBase for better data architecture\n    \n    model_config = ConfigDict(\n        populate_by_name=True,\n        from_attributes=True\n    )\n\n# Problem schemas\nclass ProblemBase(CamelCaseModel):\n    title: str\n    question: QuestionData  # JSONB field containing description, schema\n    difficulty: str\n    tags: List[str] = []\n    company: Optional[str] = None\n    hints: List[str] = []\n    premium: Optional[bool] = None  # null = free, True = premium\n    master_solution: Optional[List[dict]] = Field(default=None, alias=\"masterSolution\")  # Complete expected output for validation (admin only)\n    expected_display: Optional[List[dict]] = Field(default=None, alias=\"expectedDisplay\")  # Expected output for user display\n    expected_output: Optional[List[dict]] = Field(default=None, alias=\"expectedOutput\")  # Legacy field - use master_solution instead\n    parquet_data_source: Optional[Dict[str, Any]] = None  # JSONB field for DuckDB parquet data (legacy)\n    s3_data_source: Optional[S3DatasetSource] = None  # S3 dataset source configuration (legacy)\n    s3_datasets: Optional[List[S3DatasetSource]] = None  # Multiple S3 dataset sources configuration\n\nclass ProblemCreate(ProblemBase):\n    pass\n\nclass ProblemResponse(ProblemBase):\n    id: str\n    created_at: datetime\n    solved_count: Optional[int] = 0\n    is_user_solved: Optional[bool] = False\n    is_bookmarked: Optional[bool] = False\n    is_liked: Optional[bool] = False  # For backward compatibility\n    is_upvoted: Optional[bool] = False\n    is_downvoted: Optional[bool] = False\n    likes_count: Optional[int] = 0  # For backward compatibility\n    upvotes_count: Optional[int] = 0\n\n# Submission schemas\nclass SubmissionBase(CamelCaseModel):\n    problem_id: str\n    query: str\n\nclass SubmissionCreate(SubmissionBase):\n    pass\n\nclass SubmissionResponse(SubmissionBase):\n    id: str\n    user_id: str\n    is_correct: bool\n    execution_time: Optional[int] = None\n    submitted_at: datetime\n\n# Community post schemas\nclass CommunityPostBase(CamelCaseModel):\n    content: str\n    code_snippet: Optional[str] = None\n    problem_id: Optional[str] = None  # For problem-specific discussions\n\nclass CommunityPostCreate(CommunityPostBase):\n    pass\n\n# Simple problem schema for community posts\nclass CommunityProblemResponse(CamelCaseModel):\n    id: str\n    title: str\n    company: Optional[str] = None\n    difficulty: str\n\nclass CommunityPostResponse(CommunityPostBase):\n    id: str\n    user_id: str\n    likes: int\n    comments: int\n    created_at: datetime\n    user: UserResponse\n    problem: Optional[CommunityProblemResponse] = None\n\n# Post comment schemas\nclass PostCommentBase(CamelCaseModel):\n    content: str\n    parent_id: Optional[str] = None  # For nested replies\n\nclass PostCommentCreate(PostCommentBase):\n    pass\n\nclass PostCommentResponse(PostCommentBase):\n    id: str\n    user_id: str\n    post_id: str\n    parent_id: Optional[str] = None\n    created_at: datetime\n    user: UserResponse\n    replies: List['PostCommentResponse'] = []  # Nested replies\n\n# Update forward references for recursive type\nPostCommentResponse.model_rebuild()\n\n# Authentication schemas\nclass Token(CamelCaseModel):\n    access_token: str\n    token_type: str = \"bearer\"\n\nclass TokenData(CamelCaseModel):\n    user_id: Optional[str] = None\n    username: Optional[str] = None\n    is_admin: Optional[bool] = None\n\nclass LoginResponse(CamelCaseModel):\n    token: str\n    user: UserResponse\n    message: str = \"Login successful\"\n\nclass RegisterResponse(CamelCaseModel):\n    token: str\n    user: UserResponse\n    message: str = \"User created successfully\"\n\n# Enhanced schemas for new database models\n\n# Topic schemas\nclass TopicBase(CamelCaseModel):\n    name: str\n    description: Optional[str] = None\n    difficulty_level: DifficultyLevel\n    order_index: int = 0\n    parent_topic_id: Optional[str] = None\n\nclass TopicCreate(TopicBase):\n    pass\n\nclass TopicResponse(TopicBase):\n    id: str\n    created_at: datetime\n    updated_at: datetime\n\n# Test case schemas\nclass TestCaseBase(CamelCaseModel):\n    problem_id: str\n    name: str\n    description: Optional[str] = None\n    input_data: Dict[str, Any]\n    expected_output: List[Dict[str, Any]]  # Backward compatibility - full dataset or fallback\n    validation_rules: Dict[str, Any] = {}\n    is_hidden: bool = False\n    order_index: int = 0\n    timeout_seconds: int = 30\n    memory_limit_mb: int = 256\n    \n    # S3 Answer Source Support\n    expected_output_source: Optional[S3AnswerSource] = None  # S3 source for full dataset\n    preview_expected_output: Optional[List[Dict[str, Any]]] = None  # Limited rows for frontend\n    display_limit: int = 10  # Number of rows to show in preview\n\nclass TestCaseCreate(TestCaseBase):\n    pass\n\nclass TestCaseResponse(TestCaseBase):\n    id: str\n    created_at: datetime\n    updated_at: datetime\n\n# Problem schema schemas\nclass ProblemSchemaBase(CamelCaseModel):\n    problem_id: str\n    table_name: str\n    schema_definition: Dict[str, Any]\n    sample_data: List[Dict[str, Any]] = []\n    indexes: List[Dict[str, Any]] = []\n    constraints: List[Dict[str, Any]] = []\n\nclass ProblemSchemaCreate(ProblemSchemaBase):\n    pass\n\nclass ProblemSchemaResponse(ProblemSchemaBase):\n    id: str\n    created_at: datetime\n    updated_at: datetime\n\n# Execution result schemas\nclass ExecutionResultBase(CamelCaseModel):\n    submission_id: str\n    test_case_id: str\n    # user_sandbox_id removed - PostgreSQL sandbox functionality removed\n    status: ExecutionStatus\n    execution_time_ms: Optional[int] = None\n    memory_used_mb: Optional[float] = None\n    rows_affected: Optional[int] = None\n    query_result: Optional[Dict[str, Any]] = None\n    error_message: Optional[str] = None\n    cpu_time_ms: Optional[int] = None\n    io_operations: Optional[int] = None\n    query_plan: Optional[Dict[str, Any]] = None\n    is_correct: bool\n    validation_details: Optional[Dict[str, Any]] = None\n\nclass ExecutionResultCreate(ExecutionResultBase):\n    pass\n\nclass ExecutionResultResponse(ExecutionResultBase):\n    id: str\n    created_at: datetime\n\n# User sandbox schemas removed - PostgreSQL sandbox functionality removed\n\n# User progress schemas\nclass UserProgressBase(CamelCaseModel):\n    user_id: str\n    topic_id: str\n    problems_attempted: int = 0\n    problems_solved: int = 0\n    total_submissions: int = 0\n    successful_submissions: int = 0\n    average_execution_time_ms: Optional[float] = None\n    best_execution_time_ms: Optional[float] = None\n    total_time_spent_minutes: int = 0\n    current_difficulty: DifficultyLevel = DifficultyLevel.EASY\n    highest_difficulty_solved: DifficultyLevel = DifficultyLevel.EASY\n    hint_usage_count: int = 0\n    average_attempts_per_problem: float = 1.0\n    streak_count: int = 0\n    max_streak_count: int = 0\n    experience_points: int = 0\n    first_attempt_at: Optional[datetime] = None\n    last_activity_at: Optional[datetime] = None\n\nclass UserProgressCreate(UserProgressBase):\n    pass\n\nclass UserProgressResponse(UserProgressBase):\n    id: str\n    created_at: datetime\n    updated_at: datetime\n\n# Badge schemas\nclass BadgeBase(CamelCaseModel):\n    name: str\n    description: str\n    icon_url: Optional[str] = None\n    criteria: Dict[str, Any]\n    points_reward: int = 0\n    rarity: str = \"common\"\n\nclass BadgeCreate(BadgeBase):\n    pass\n\nclass BadgeResponse(BadgeBase):\n    id: str\n    created_at: datetime\n\nclass UserBadgeResponse(CamelCaseModel):\n    id: str\n    user_id: str\n    badge_id: str\n    earned_at: datetime\n    badge: BadgeResponse\n\n# Enhanced existing schemas\nclass EnhancedUserResponse(UserResponse):\n    \"\"\"Enhanced user response with progress data\"\"\"\n    progress: Optional[List[UserProgressResponse]] = []\n    badges: Optional[List[UserBadgeResponse]] = []\n    current_level: Optional[str] = None\n    total_xp: Optional[int] = 0\n\nclass EnhancedProblemResponse(ProblemResponse):\n    \"\"\"Enhanced problem response with test cases and schema\"\"\"\n    test_cases: Optional[List[TestCaseResponse]] = []\n    schemas: Optional[List[ProblemSchemaResponse]] = []\n    topic: Optional[TopicResponse] = None\n\nclass DetailedSubmissionResponse(SubmissionResponse):\n    \"\"\"Detailed submission with execution results\"\"\"\n    execution_results: Optional[List[ExecutionResultResponse]] = []\n    overall_score: Optional[float] = None\n    passed_test_cases: Optional[int] = 0\n    total_test_cases: Optional[int] = 0\n\n# Solution schemas\nclass SolutionBase(CamelCaseModel):\n    title: str\n    content: str\n    sql_code: str\n    is_official: bool = True  # Always true since there's only one solution per problem\n\nclass SolutionCreate(SolutionBase):\n    pass\n\nclass SolutionResponse(SolutionBase):\n    id: str\n    problem_id: str\n    created_by: str\n    created_at: datetime\n    updated_at: datetime\n    creator: UserResponse","size_bytes":12086},"client/src/pages/crud.py":{"content":"from sqlalchemy.orm import Session\nimport models, schemas\nfrom sqlalchemy import func, case, literal_column\n\ndef get_user(db: Session, user_id: str):\n    return db.query(models.User).filter(models.User.id == user_id).first()\n\ndef upsert_user(db: Session, user: schemas.UserUpsert):\n    db_user = db.query(models.User).filter(models.User.id == user.id).first()\n    if db_user:\n        db_user.email = user.email\n        db_user.first_name = user.first_name\n        db_user.last_name = user.last_name\n        db_user.profile_image_url = user.profile_image_url\n    else:\n        db_user = models.User(**user.dict())\n        db.add(db_user)\n    db.commit()\n    db.refresh(db_user)\n    return db_user\n\ndef get_problems(db: Session, user_id: str | None):\n    # Subquery for total correct submissions count per problem\n    solved_count_sq = db.query(\n        models.Submission.problem_id,\n        func.count(models.Submission.user_id.distinct()).label(\"solved_count\")\n    ).filter(models.Submission.is_correct == True).group_by(models.Submission.problem_id).subquery()\n\n    # Subquery to check if the current user has solved the problem\n    user_solved_sq = None\n    if user_id:\n        user_solved_sq = db.query(\n            models.Submission.problem_id,\n            literal_column(\"1\").label(\"is_user_solved\")\n        ).filter(\n            models.Submission.user_id == user_id,\n            models.Submission.is_correct == True\n        ).distinct().subquery()\n\n    # Main query\n    query = db.query(\n        models.Problem,\n        func.coalesce(solved_count_sq.c.solved_count, 0).label(\"solvedCount\")\n    ).outerjoin(\n        solved_count_sq, models.Problem.id == solved_count_sq.c.problem_id\n    )\n\n    if user_solved_sq is not None:\n        query = query.add_columns(\n            case(\n                (user_solved_sq.c.is_user_solved != None, True),\n                else_=False\n            ).label(\"isUserSolved\")\n        ).outerjoin(\n            user_solved_sq, models.Problem.id == user_solved_sq.c.problem_id\n        )\n    else:\n        # If no user, isUserSolved is always false\n        query = query.add_columns(literal_column(\"false\").label(\"isUserSolved\"))\n    \n    problems_with_stats = query.all()\n\n    # Manually construct the output to match the Pydantic schema\n    results = []\n    for problem, solved_count, is_user_solved in problems_with_stats:\n        results.append(schemas.ProblemOut(\n            id=problem.id,\n            title=problem.title,\n            description=problem.description,\n            difficulty=problem.difficulty,\n            starter_code=problem.starter_code,\n            tags=problem.tags or [],\n            companies=problem.companies or [],\n            solvedCount=solved_count,\n            isUserSolved=is_user_solved\n        ))\n    return results\n\ndef get_problem(db: Session, problem_id: int):\n    return db.query(models.Problem).filter(models.Problem.id == problem_id).first()\n\ndef create_submission(db: Session, submission: schemas.SubmissionCreate, user_id: str):\n    # Mocking correctness check. In a real app, this would execute the SQL.\n    is_correct = \"select\" in submission.user_code.lower() and \"from\" in submission.user_code.lower()\n    db_sub = models.Submission(\n        problem_id=submission.problem_id,\n        user_id=user_id,\n        user_code=submission.user_code,\n        is_correct=is_correct\n    )\n    db.add(db_sub)\n    db.commit()\n    db.refresh(db_sub)\n    return db_sub\n\ndef get_user_submissions(db: Session, user_id: str):\n    return db.query(models.Submission).filter(models.Submission.user_id == user_id).all()\n","size_bytes":3581},"client/src/pages/main.py":{"content":"from fastapi import FastAPI, Depends, HTTPException\nfrom sqlalchemy.orm import Session\nfrom pydantic import BaseModel\nfrom typing import Optional\nimport models, schemas, crud\nfrom database import engine, Base, get_db\n\n# Create tables\nBase.metadata.create_all(bind=engine)\n\napp = FastAPI()\n\n# Mock auth dependency, similar to the one in server/routes.ts\nclass MockUserClaims(BaseModel):\n    sub: str\n    email: str\n    first_name: Optional[str]\n    last_name: Optional[str]\n    profile_image_url: Optional[str]\n\nclass MockAuth(BaseModel):\n    claims: MockUserClaims\n\ndef mock_auth_user() -> MockAuth:\n    # Mock user for development\n    return MockAuth(claims=MockUserClaims(\n      sub=\"mock-user-1\",\n      email=\"jane@techcorp.com\",\n      first_name=\"Jane\",\n      last_name=\"Smith\",\n      profile_image_url=None,\n    ))\n\n# ---------------- AUTH ----------------\n@app.get(\"/api/auth/user\", response_model=schemas.User)\ndef get_current_user(user: MockAuth = Depends(mock_auth_user), db: Session = Depends(get_db)):\n    db_user = crud.get_user(db, user_id=user.claims.sub)\n    if not db_user:\n        claims = user.claims\n        user_data = schemas.UserUpsert(\n            id=claims.sub,\n            email=claims.email,\n            first_name=claims.first_name,\n            last_name=claims.last_name,\n            profile_image_url=claims.profile_image_url,\n        )\n        db_user = crud.upsert_user(db, user=user_data)\n    return db_user\n\n# ---------------- PROBLEMS ----------------\n@app.get(\"/api/problems\", response_model=list[schemas.ProblemOut])\ndef list_problems(user: MockAuth = Depends(mock_auth_user), db: Session = Depends(get_db)):\n    user_id = user.claims.sub\n    return crud.get_problems(db, user_id=user_id)\n\n@app.get(\"/api/problems/{problem_id}\", response_model=schemas.ProblemBase)\ndef get_problem(problem_id: int, db: Session = Depends(get_db)):\n    problem = crud.get_problem(db, problem_id)\n    if not problem:\n        raise HTTPException(status_code=404, detail=\"Problem not found\")\n    return problem\n\n# ---------------- SUBMISSIONS ----------------\n@app.post(\"/api/submissions\", response_model=schemas.SubmissionOut)\ndef submit(sub: schemas.SubmissionCreate, user: MockAuth = Depends(mock_auth_user), db: Session = Depends(get_db)):\n    user_id = user.claims.sub\n    return crud.create_submission(db, sub, user_id=user_id)\n\n@app.get(\"/api/user/submissions\", response_model=list[schemas.SubmissionOut])\ndef get_user_submissions(user: MockAuth = Depends(mock_auth_user), db: Session = Depends(get_db)):\n    submissions = crud.get_user_submissions(db, user_id=user.claims.sub)\n    return submissions\n","size_bytes":2622},"client/src/pages/models.py":{"content":"from sqlalchemy import Column, Integer, String, Text, ForeignKey, Boolean, JSON\nfrom sqlalchemy.orm import relationship\nfrom database import Base\n\nclass User(Base):\n    __tablename__ = \"users\"\n\n    id = Column(String, primary_key=True, index=True)\n    email = Column(String, unique=True, index=True, nullable=False)\n    first_name = Column(String, nullable=True)\n    last_name = Column(String, nullable=True)\n    profile_image_url = Column(String, nullable=True)\n\n    submissions = relationship(\"Submission\", back_populates=\"user\")\n\nclass Problem(Base):\n    __tablename__ = \"problems\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    title = Column(String)\n    description = Column(Text)\n    difficulty = Column(String)\n    starter_code = Column(Text)\n    tags = Column(JSON, default=[], nullable=False)\n    companies = Column(JSON, default=[], nullable=False)\n\n    submissions = relationship(\"Submission\", back_populates=\"problem\")\n\nclass Submission(Base):\n    __tablename__ = \"submissions\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    problem_id = Column(Integer, ForeignKey(\"problems.id\"))\n    user_id = Column(String, ForeignKey(\"users.id\"))\n    user_code = Column(Text)\n    is_correct = Column(Boolean, default=False, nullable=False)\n\n    user = relationship(\"User\", back_populates=\"submissions\")\n    problem = relationship(\"Problem\", back_populates=\"submissions\")\n","size_bytes":1396},"client/src/pages/schemas.py":{"content":"from pydantic import BaseModel\nfrom typing import Optional, List\n\nclass User(BaseModel):\n    id: str\n    email: str\n    first_name: Optional[str] = None\n    last_name: Optional[str] = None\n    profile_image_url: Optional[str] = None\n\n    class Config:\n        orm_mode = True\n\nclass UserUpsert(User):\n    pass\n\nclass ProblemBase(BaseModel):\n    id: int\n    title: str\n    description: str\n    difficulty: str\n    starter_code: str\n    tags: List[str]\n    companies: List[str]\n\nclass ProblemOut(ProblemBase):\n    solvedCount: int\n    isUserSolved: bool\n\n    class Config:\n        orm_mode = True\n\nclass SubmissionCreate(BaseModel):\n    problem_id: int\n    user_code: str\n\nclass SubmissionOut(BaseModel):\n    id: int\n    problem_id: int\n    user_id: str\n    is_correct: bool\n\n    class Config:\n        orm_mode = True\n","size_bytes":816},"api/seed.py":{"content":"import os\nimport sys\nimport json\nimport argparse\nfrom sqlalchemy.orm import Session\n\n# Add the project root to the Python path to allow for absolute imports\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\n\nfrom api.database import SessionLocal, engine\nfrom api.models import Base, Problem\n\ndef seed_data(env: str):\n    \"\"\"\n    Populates the database with initial data from a JSON file\n    based on the provided environment.\n    \"\"\"\n    # This ensures tables are created before trying to seed them\n    Base.metadata.create_all(bind=engine)\n    \n    db: Session = SessionLocal()\n    \n    try:\n        # Check if problems already exist\n        if db.query(Problem).count() > 0:\n            print(\"Database already contains problems. Skipping seeding.\")\n            return\n\n        # Determine which data file to use\n        file_path = os.path.join(os.path.dirname(__file__), 'data', f'{env}_problems.json')\n        \n        if not os.path.exists(file_path):\n            print(f\"Error: Data file not found at {file_path}\")\n            print(\"Please specify a valid environment: 'demo' or 'production'.\")\n            return\n            \n        print(f\"Seeding database with data from {file_path}...\")\n\n        with open(file_path, 'r') as f:\n            problems_data = json.load(f)\n\n        # Create Problem objects from the loaded data\n        problems_to_add = [Problem(**p) for p in problems_data]\n\n        db.add_all(problems_to_add)\n        db.commit()\n        \n        print(f\"Successfully seeded {len(problems_to_add)} problems from '{env}' environment.\")\n\n    finally:\n        db.close()\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Seed the database with a specific problem set.\")\n    parser.add_argument(\n        \"env\", \n        choices=[\"demo\", \"production\"], \n        help=\"The environment to seed (e.g., 'demo' or 'production').\"\n    )\n    args = parser.parse_args()\n    \n    seed_data(args.env)\n","size_bytes":1975},"client/src/components/table-display.tsx":{"content":"import { Table, TableBody, TableCell, TableHead, TableHeader, TableRow } from '@/components/ui/table';\n\ninterface Column {\n  name: string;\n  type: string;\n}\n\ninterface TableData {\n  name: string;\n  columns: Column[];\n  sampleData: Record<string, any>[];\n}\n\ninterface TableDisplayProps {\n  tables: TableData[];\n  expectedOutput?: Record<string, any>[];\n}\n\nexport default function TableDisplay({ tables, expectedOutput }: TableDisplayProps) {\n  const renderDataTable = (data: Record<string, any>[], title: string) => {\n    if (!data || data.length === 0) return null;\n\n    const headers = Object.keys(data[0]);\n    \n    return (\n      <div className=\"mb-6\">\n        <h4 className=\"font-semibold text-sm text-foreground mb-3\">{title}</h4>\n        <div className=\"border rounded-lg overflow-hidden\">\n          <Table>\n            <TableHeader>\n              <TableRow className=\"bg-muted/50\">\n                {headers.map((header) => (\n                  <TableHead key={header} className=\"font-semibold text-foreground\">\n                    {header}\n                  </TableHead>\n                ))}\n              </TableRow>\n            </TableHeader>\n            <TableBody>\n              {data.map((row, index) => (\n                <TableRow key={index}>\n                  {headers.map((header) => (\n                    <TableCell key={header} className=\"py-2\">\n                      {row[header]}\n                    </TableCell>\n                  ))}\n                </TableRow>\n              ))}\n            </TableBody>\n          </Table>\n        </div>\n      </div>\n    );\n  };\n\n  return (\n    <div className=\"space-y-6\">\n      {tables.map((table) => (\n        <div key={table.name} className=\"space-y-4\">\n          {/* Table Schema */}\n          <div>\n            <h4 className=\"font-semibold text-sm text-foreground mb-3\">\n              <span className=\"font-bold\">{table.name}</span> Table:\n            </h4>\n            <div className=\"border rounded-lg overflow-hidden\">\n              <Table>\n                <TableHeader>\n                  <TableRow className=\"bg-muted/50\">\n                    <TableHead className=\"font-semibold text-foreground\">Column Name</TableHead>\n                    <TableHead className=\"font-semibold text-foreground\">Type</TableHead>\n                  </TableRow>\n                </TableHeader>\n                <TableBody>\n                  {table.columns.map((column) => (\n                    <TableRow key={column.name}>\n                      <TableCell className=\"py-2 font-mono text-sm\">{column.name}</TableCell>\n                      <TableCell className=\"py-2\">{column.type}</TableCell>\n                    </TableRow>\n                  ))}\n                </TableBody>\n              </Table>\n            </div>\n          </div>\n\n          {/* Sample Data */}\n          {table.sampleData && table.sampleData.length > 0 && \n            renderDataTable(table.sampleData, `${table.name} Example Input:`)\n          }\n        </div>\n      ))}\n\n      {/* Expected Output */}\n      {expectedOutput && expectedOutput.length > 0 && \n        renderDataTable(expectedOutput, \"Expected Output:\")\n      }\n    </div>\n  );\n}","size_bytes":3154},"client/src/components/resizable-splitter.tsx":{"content":"import { useState, useRef, useCallback, useEffect } from 'react';\n\ninterface ResizableSplitterProps {\n  leftPanel: React.ReactNode;\n  rightPanel: React.ReactNode;\n  defaultLeftWidth?: number;\n  minLeftWidth?: number;\n  minRightWidth?: number;\n  className?: string;\n}\n\nexport default function ResizableSplitter({\n  leftPanel,\n  rightPanel,\n  defaultLeftWidth = 50,\n  minLeftWidth = 20,\n  minRightWidth = 20,\n  className = ''\n}: ResizableSplitterProps) {\n  const [leftWidth, setLeftWidth] = useState(defaultLeftWidth);\n  const [isDragging, setIsDragging] = useState(false);\n  const containerRef = useRef<HTMLDivElement>(null);\n\n  const handleMouseDown = useCallback((e: React.MouseEvent) => {\n    setIsDragging(true);\n    e.preventDefault();\n  }, []);\n\n  const handleMouseMove = useCallback((e: MouseEvent) => {\n    if (!isDragging || !containerRef.current) return;\n\n    const containerRect = containerRef.current.getBoundingClientRect();\n    const newLeftWidth = ((e.clientX - containerRect.left) / containerRect.width) * 100;\n    \n    // Apply constraints\n    const constrainedWidth = Math.max(\n      minLeftWidth,\n      Math.min(100 - minRightWidth, newLeftWidth)\n    );\n    \n    setLeftWidth(constrainedWidth);\n  }, [isDragging, minLeftWidth, minRightWidth]);\n\n  const handleMouseUp = useCallback(() => {\n    setIsDragging(false);\n  }, []);\n\n  // Add event listeners when dragging\n  useEffect(() => {\n    if (isDragging) {\n      document.addEventListener('mousemove', handleMouseMove);\n      document.addEventListener('mouseup', handleMouseUp);\n      document.body.style.cursor = 'col-resize';\n      document.body.style.userSelect = 'none';\n      \n      return () => {\n        document.removeEventListener('mousemove', handleMouseMove);\n        document.removeEventListener('mouseup', handleMouseUp);\n        document.body.style.cursor = '';\n        document.body.style.userSelect = '';\n      };\n    }\n  }, [isDragging, handleMouseMove, handleMouseUp]);\n\n  return (\n    <div \n      ref={containerRef}\n      className={`flex h-full w-full ${className}`}\n    >\n      {/* Left Panel */}\n      <div \n        style={{ width: `${leftWidth}%` }}\n        className=\"flex-shrink-0 overflow-hidden\"\n      >\n        {leftPanel}\n      </div>\n      \n      {/* Resizer */}\n      <div\n        className=\"w-1 bg-border hover:bg-primary/50 cursor-col-resize flex-shrink-0 transition-colors relative group\"\n        onMouseDown={handleMouseDown}\n      >\n        <div className=\"absolute inset-y-0 -left-1 -right-1 group-hover:bg-primary/20\" />\n      </div>\n      \n      {/* Right Panel */}\n      <div \n        style={{ width: `${100 - leftWidth}%` }}\n        className=\"flex-1 overflow-hidden\"\n      >\n        {rightPanel}\n      </div>\n    </div>\n  );\n}","size_bytes":2736},"client/src/components/vertical-resizable-splitter.tsx":{"content":"import { useState, useRef, useCallback, useEffect } from 'react';\n\ninterface VerticalResizableSplitterProps {\n  topPanel: React.ReactNode;\n  bottomPanel: React.ReactNode;\n  defaultTopHeight?: number;\n  minTopHeight?: number;\n  minBottomHeight?: number;\n  className?: string;\n}\n\nexport default function VerticalResizableSplitter({\n  topPanel,\n  bottomPanel,\n  defaultTopHeight = 70,\n  minTopHeight = 30,\n  minBottomHeight = 20,\n  className = ''\n}: VerticalResizableSplitterProps) {\n  const [topHeight, setTopHeight] = useState(defaultTopHeight);\n  const [isDragging, setIsDragging] = useState(false);\n  const containerRef = useRef<HTMLDivElement>(null);\n\n  const handleMouseDown = useCallback((e: React.MouseEvent) => {\n    setIsDragging(true);\n    e.preventDefault();\n  }, []);\n\n  const handleMouseMove = useCallback((e: MouseEvent) => {\n    if (!isDragging || !containerRef.current) return;\n\n    const containerRect = containerRef.current.getBoundingClientRect();\n    const newTopHeight = ((e.clientY - containerRect.top) / containerRect.height) * 100;\n    \n    // Apply constraints\n    const constrainedHeight = Math.max(\n      minTopHeight,\n      Math.min(100 - minBottomHeight, newTopHeight)\n    );\n    \n    setTopHeight(constrainedHeight);\n  }, [isDragging, minTopHeight, minBottomHeight]);\n\n  const handleMouseUp = useCallback(() => {\n    setIsDragging(false);\n  }, []);\n\n  // Add event listeners when dragging\n  useEffect(() => {\n    if (isDragging) {\n      document.addEventListener('mousemove', handleMouseMove);\n      document.addEventListener('mouseup', handleMouseUp);\n      document.body.style.cursor = 'row-resize';\n      document.body.style.userSelect = 'none';\n      \n      return () => {\n        document.removeEventListener('mousemove', handleMouseMove);\n        document.removeEventListener('mouseup', handleMouseUp);\n        document.body.style.cursor = '';\n        document.body.style.userSelect = '';\n      };\n    }\n  }, [isDragging, handleMouseMove, handleMouseUp]);\n\n  return (\n    <div \n      ref={containerRef}\n      className={`flex flex-col h-full w-full ${className}`}\n    >\n      {/* Top Panel */}\n      <div \n        style={{ height: `${topHeight}%` }}\n        className=\"flex-shrink-0 overflow-hidden\"\n      >\n        {topPanel}\n      </div>\n      \n      {/* Resizer */}\n      <div\n        className=\"h-1 bg-border hover:bg-primary/50 cursor-row-resize flex-shrink-0 transition-colors relative group\"\n        onMouseDown={handleMouseDown}\n      >\n        <div className=\"absolute inset-x-0 -top-1 -bottom-1 group-hover:bg-primary/20\" />\n      </div>\n      \n      {/* Bottom Panel */}\n      <div \n        style={{ height: `${100 - topHeight}%` }}\n        className=\"flex-1 overflow-hidden\"\n      >\n        {bottomPanel}\n      </div>\n    </div>\n  );\n}","size_bytes":2781},"REPLIT_SETUP.md":{"content":"ðŸš€ Replit Auto-Setup Instructions\nThis file ensures zero-analysis setup for future GitHub imports and reduces agent utilization by 80%+.\n\nðŸŽ¯ Quick Start (Recommended)\nbash scripts/replit-setup.sh && npm run dev\nðŸ“‹ What's Pre-Configured\nâœ… Full-stack setup: React frontend + FastAPI backend\nâœ… Database: PostgreSQL with SQLAlchemy ORM\nâœ… Dependencies: Node.js + Python packages\nâœ… Deployment: Ready for autoscale deployment\nâœ… Workflows: Frontend (Vite) on port 5000, backend (FastAPI) on 8000\nâœ… Environment: All configs optimized for Replit\nðŸ”§ Project Structure\nSQLGym/\nâ”œâ”€â”€ client/ # React + TypeScript frontend\nâ”œâ”€â”€ api/ # FastAPI Python backend  \nâ”œâ”€â”€ scripts/ # Auto-setup scripts\nâ”œâ”€â”€ .replit # Complete Replit configuration\nâ””â”€â”€ replit.md # Comprehensive project documentation\nðŸ’¡ Agent Optimization Features\nExpert mode enabled in .replit\nPre-configured modules: nodejs-20, python-3.11, postgresql-16\nAuto-workflows: Development and production ready\nIntegration ready: Database and auth integrations included\nZero manual config: Everything automated\nðŸš¨ For Future Imports\nInstead of asking agent to \"set up the project\", simply say:\n\n\"Run the setup script in REPLIT_SETUP.md\"\n\nThis will complete the entire setup in under 2 minutes with minimal agent utilization.\n\nThis automation setup saves ~80% of typical import analysis time\n\n## Python Package Management on Replit\n\n**Important**: This project uses **Python 3.11** and **pip exclusively** on Replit due to compatibility requirements. The setup includes fixes for common Replit environment issues:\n\n- **Python version**: Fixed to use `python3.11` consistently to avoid pydantic compatibility issues\n- **Package installation**: Uses `--break-system-packages` flag to work with NixOS externally-managed environment\n- **Primary dependency file**: `requirements.txt` (pinned with cryptographic hashes)\n- **Development script**: `scripts/dev_backend.cjs` handles Python setup and backend startup\n\n### Environment Fixes Applied\n\nâœ… **Pydantic Compatibility**: Fixed ModuleNotFoundError by using consistent Python 3.11 version  \nâœ… **NixOS Compatibility**: Added `--break-system-packages` flag for pip installations  \nâœ… **Port Configuration**: Frontend on 5000 (proxy-ready), backend on 8000  \nâœ… **Database Setup**: PostgreSQL initialization with proper schema migration  \nâœ… **Deployment Ready**: Production start script uses python3.11 on correct ports\n\n### Updating Dependencies\n\nTo update Python dependencies:\n1. Modify `pyproject.toml` as needed\n2. Run `uv export --format requirements-txt > requirements.txt` locally (if using uv)\n3. Or manually update `requirements.txt` with pinned versions\n4. Commit the updated `requirements.txt`\n\n### Development vs Production\n\n- **Development**: Backend on port 8000, frontend dev server on 5000 with API proxy\n- **Production**: Build frontend assets, serve backend on appropriate port using `python3.11`\n","size_bytes":2954},"scripts/migrate_database.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nDatabase Migration Script - SQLGym\n==================================\nThis script migrates data from your current Neon database to a local PostgreSQL database.\n\nUsage:\n    python scripts/migrate_database.py\n\nPrerequisites:\n1. Set up local PostgreSQL server\n2. Create a local database\n3. Set LOCAL_DATABASE_URL environment variable or update the script\n\nMigration Order (respects foreign key dependencies):\n1. Users\n2. Problems  \n3. Submissions\n4. CommunityPosts\n5. PostLikes\n6. PostComments\n\"\"\"\n\nimport os\nimport sys\nfrom typing import List, Dict, Any\nfrom datetime import datetime\nfrom dotenv import load_dotenv\nfrom sqlalchemy import create_engine, text\nfrom sqlalchemy.orm import sessionmaker\nfrom sqlalchemy.exc import SQLAlchemyError\n\n# Add the parent directory to sys.path to import from api\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom api.models import Base, User, Problem, Submission, CommunityPost, PostLike, PostComment\nfrom api.database import DATABASE_URL as SOURCE_DATABASE_URL\n\n# Load environment variables\nload_dotenv()\n\n# Configuration\nLOCAL_DATABASE_URL = os.getenv(\"LOCAL_DATABASE_URL\", \"postgresql://username:password@localhost:5432/sqlgym\")\nBATCH_SIZE = 100  # Process records in batches for memory efficiency\n\nclass DatabaseMigrator:\n    def __init__(self, source_url: str, destination_url: str):\n        \"\"\"Initialize migrator with source and destination database connections.\"\"\"\n        self.source_url = source_url\n        self.destination_url = destination_url\n        \n        # Create engines\n        self.source_engine = create_engine(source_url, echo=False)\n        self.destination_engine = create_engine(destination_url, echo=False)\n        \n        # Create session factories\n        self.SourceSession = sessionmaker(bind=self.source_engine)\n        self.DestinationSession = sessionmaker(bind=self.destination_engine)\n        \n    def test_connections(self) -> bool:\n        \"\"\"Test both database connections.\"\"\"\n        try:\n            print(\"Testing source database connection...\")\n            with self.source_engine.connect() as conn:\n                conn.execute(text(\"SELECT 1\"))\n            print(\"SUCCESS: Source database connection successful\")\n            \n            print(\"Testing destination database connection...\")\n            with self.destination_engine.connect() as conn:\n                conn.execute(text(\"SELECT 1\"))\n            print(\"SUCCESS: Destination database connection successful\")\n            \n            return True\n        except Exception as e:\n            print(f\"âŒ Connection test failed: {e}\")\n            return False\n    \n    def setup_destination_schema(self) -> bool:\n        \"\"\"Create tables in destination database.\"\"\"\n        try:\n            print(\"Creating destination database schema...\")\n            Base.metadata.create_all(bind=self.destination_engine)\n            print(\"SUCCESS: Schema created successfully\")\n            return True\n        except Exception as e:\n            print(f\"âŒ Schema creation failed: {e}\")\n            return False\n    \n    def get_record_counts(self) -> Dict[str, int]:\n        \"\"\"Get record counts from source database.\"\"\"\n        counts = {}\n        tables = [\n            ('users', User),\n            ('problems', Problem),\n            ('submissions', Submission),\n            ('community_posts', CommunityPost),\n            ('post_likes', PostLike),\n            ('post_comments', PostComment)\n        ]\n        \n        with self.SourceSession() as session:\n            for table_name, model_class in tables:\n                try:\n                    count = session.query(model_class).count()\n                    counts[table_name] = count\n                    print(f\"ðŸ“Š {table_name}: {count} records\")\n                except Exception as e:\n                    print(f\"âš ï¸ Could not count {table_name}: {e}\")\n                    counts[table_name] = 0\n        \n        return counts\n    \n    def migrate_users(self) -> bool:\n        \"\"\"Migrate users table.\"\"\"\n        try:\n            print(\"\\nðŸš€ Migrating users...\")\n            \n            with self.SourceSession() as source_session:\n                with self.DestinationSession() as dest_session:\n                    # Get total count for progress tracking\n                    total_users = source_session.query(User).count()\n                    \n                    if total_users == 0:\n                        print(\"â„¹ï¸ No users to migrate\")\n                        return True\n                    \n                    # Process in batches\n                    offset = 0\n                    migrated = 0\n                    \n                    while offset < total_users:\n                        users = source_session.query(User).offset(offset).limit(BATCH_SIZE).all()\n                        \n                        if not users:\n                            break\n                        \n                        # Create new user objects for destination\n                        for user in users:\n                            new_user = User(\n                                id=user.id,\n                                username=user.username,\n                                email=user.email,\n                                password_hash=user.password_hash,\n                                first_name=user.first_name,\n                                last_name=user.last_name,\n                                profile_image_url=user.profile_image_url,\n                                google_id=user.google_id,\n                                github_id=user.github_id,\n                                auth_provider=user.auth_provider,\n                                problems_solved=user.problems_solved,\n                                created_at=user.created_at,\n                                updated_at=user.updated_at\n                            )\n                            dest_session.add(new_user)\n                        \n                        dest_session.commit()\n                        migrated += len(users)\n                        offset += BATCH_SIZE\n                        \n                        print(f\"  SUCCESS: Migrated {migrated}/{total_users} users\")\n                    \n                    print(f\"SUCCESS: Users migration completed: {migrated} records\")\n                    return True\n                    \n        except Exception as e:\n            print(f\"âŒ Users migration failed: {e}\")\n            return False\n    \n    def migrate_problems(self) -> bool:\n        \"\"\"Migrate problems table.\"\"\"\n        try:\n            print(\"\\nðŸš€ Migrating problems...\")\n            \n            with self.SourceSession() as source_session:\n                with self.DestinationSession() as dest_session:\n                    total_problems = source_session.query(Problem).count()\n                    \n                    if total_problems == 0:\n                        print(\"â„¹ï¸ No problems to migrate\")\n                        return True\n                    \n                    offset = 0\n                    migrated = 0\n                    \n                    while offset < total_problems:\n                        problems = source_session.query(Problem).offset(offset).limit(BATCH_SIZE).all()\n                        \n                        if not problems:\n                            break\n                        \n                        for problem in problems:\n                            new_problem = Problem(\n                                id=problem.id,\n                                title=problem.title,\n                                difficulty=problem.difficulty,\n                                tags=problem.tags,\n                                company=problem.company,  # Single company field\n                                hints=problem.hints,\n                                question=problem.question,\n                                created_at=problem.created_at,\n                                updated_at=problem.updated_at\n                            )\n                            dest_session.add(new_problem)\n                        \n                        dest_session.commit()\n                        migrated += len(problems)\n                        offset += BATCH_SIZE\n                        \n                        print(f\"  SUCCESS: Migrated {migrated}/{total_problems} problems\")\n                    \n                    print(f\"SUCCESS: Problems migration completed: {migrated} records\")\n                    return True\n                    \n        except Exception as e:\n            print(f\"âŒ Problems migration failed: {e}\")\n            return False\n    \n    def migrate_submissions(self) -> bool:\n        \"\"\"Migrate submissions table.\"\"\"\n        try:\n            print(\"\\nðŸš€ Migrating submissions...\")\n            \n            with self.SourceSession() as source_session:\n                with self.DestinationSession() as dest_session:\n                    total_submissions = source_session.query(Submission).count()\n                    \n                    if total_submissions == 0:\n                        print(\"â„¹ï¸ No submissions to migrate\")\n                        return True\n                    \n                    offset = 0\n                    migrated = 0\n                    \n                    while offset < total_submissions:\n                        submissions = source_session.query(Submission).offset(offset).limit(BATCH_SIZE).all()\n                        \n                        if not submissions:\n                            break\n                        \n                        for submission in submissions:\n                            new_submission = Submission(\n                                id=submission.id,\n                                user_id=submission.user_id,\n                                problem_id=submission.problem_id,\n                                query=submission.query,\n                                is_correct=submission.is_correct,\n                                execution_time=submission.execution_time,\n                                submitted_at=submission.submitted_at\n                            )\n                            dest_session.add(new_submission)\n                        \n                        dest_session.commit()\n                        migrated += len(submissions)\n                        offset += BATCH_SIZE\n                        \n                        print(f\"  SUCCESS: Migrated {migrated}/{total_submissions} submissions\")\n                    \n                    print(f\"SUCCESS: Submissions migration completed: {migrated} records\")\n                    return True\n                    \n        except Exception as e:\n            print(f\"âŒ Submissions migration failed: {e}\")\n            return False\n    \n    def migrate_community_posts(self) -> bool:\n        \"\"\"Migrate community posts table.\"\"\"\n        try:\n            print(\"\\nðŸš€ Migrating community posts...\")\n            \n            with self.SourceSession() as source_session:\n                with self.DestinationSession() as dest_session:\n                    total_posts = source_session.query(CommunityPost).count()\n                    \n                    if total_posts == 0:\n                        print(\"â„¹ï¸ No community posts to migrate\")\n                        return True\n                    \n                    offset = 0\n                    migrated = 0\n                    \n                    while offset < total_posts:\n                        posts = source_session.query(CommunityPost).offset(offset).limit(BATCH_SIZE).all()\n                        \n                        if not posts:\n                            break\n                        \n                        for post in posts:\n                            new_post = CommunityPost(\n                                id=post.id,\n                                user_id=post.user_id,\n                                content=post.content,\n                                code_snippet=post.code_snippet,\n                                likes=post.likes,\n                                comments=post.comments,\n                                created_at=post.created_at,\n                                updated_at=post.updated_at\n                            )\n                            dest_session.add(new_post)\n                        \n                        dest_session.commit()\n                        migrated += len(posts)\n                        offset += BATCH_SIZE\n                        \n                        print(f\"  SUCCESS: Migrated {migrated}/{total_posts} community posts\")\n                    \n                    print(f\"SUCCESS: Community posts migration completed: {migrated} records\")\n                    return True\n                    \n        except Exception as e:\n            print(f\"âŒ Community posts migration failed: {e}\")\n            return False\n    \n    def migrate_post_likes(self) -> bool:\n        \"\"\"Migrate post likes table.\"\"\"\n        try:\n            print(\"\\nðŸš€ Migrating post likes...\")\n            \n            with self.SourceSession() as source_session:\n                with self.DestinationSession() as dest_session:\n                    total_likes = source_session.query(PostLike).count()\n                    \n                    if total_likes == 0:\n                        print(\"â„¹ï¸ No post likes to migrate\")\n                        return True\n                    \n                    offset = 0\n                    migrated = 0\n                    \n                    while offset < total_likes:\n                        likes = source_session.query(PostLike).offset(offset).limit(BATCH_SIZE).all()\n                        \n                        if not likes:\n                            break\n                        \n                        for like in likes:\n                            new_like = PostLike(\n                                id=like.id,\n                                user_id=like.user_id,\n                                post_id=like.post_id,\n                                created_at=like.created_at\n                            )\n                            dest_session.add(new_like)\n                        \n                        dest_session.commit()\n                        migrated += len(likes)\n                        offset += BATCH_SIZE\n                        \n                        print(f\"  SUCCESS: Migrated {migrated}/{total_likes} post likes\")\n                    \n                    print(f\"SUCCESS: Post likes migration completed: {migrated} records\")\n                    return True\n                    \n        except Exception as e:\n            print(f\"âŒ Post likes migration failed: {e}\")\n            return False\n    \n    def migrate_post_comments(self) -> bool:\n        \"\"\"Migrate post comments table.\"\"\"\n        try:\n            print(\"\\nðŸš€ Migrating post comments...\")\n            \n            with self.SourceSession() as source_session:\n                with self.DestinationSession() as dest_session:\n                    total_comments = source_session.query(PostComment).count()\n                    \n                    if total_comments == 0:\n                        print(\"â„¹ï¸ No post comments to migrate\")\n                        return True\n                    \n                    offset = 0\n                    migrated = 0\n                    \n                    while offset < total_comments:\n                        comments = source_session.query(PostComment).offset(offset).limit(BATCH_SIZE).all()\n                        \n                        if not comments:\n                            break\n                        \n                        for comment in comments:\n                            new_comment = PostComment(\n                                id=comment.id,\n                                user_id=comment.user_id,\n                                post_id=comment.post_id,\n                                content=comment.content,\n                                created_at=comment.created_at\n                            )\n                            dest_session.add(new_comment)\n                        \n                        dest_session.commit()\n                        migrated += len(comments)\n                        offset += BATCH_SIZE\n                        \n                        print(f\"  SUCCESS: Migrated {migrated}/{total_comments} post comments\")\n                    \n                    print(f\"SUCCESS: Post comments migration completed: {migrated} records\")\n                    return True\n                    \n        except Exception as e:\n            print(f\"âŒ Post comments migration failed: {e}\")\n            return False\n    \n    def verify_migration(self) -> bool:\n        \"\"\"Verify migration by comparing record counts.\"\"\"\n        print(\"\\nðŸ” Verifying migration...\")\n        \n        try:\n            source_counts = {}\n            dest_counts = {}\n            \n            tables = [\n                ('users', User),\n                ('problems', Problem),\n                ('submissions', Submission),\n                ('community_posts', CommunityPost),\n                ('post_likes', PostLike),\n                ('post_comments', PostComment)\n            ]\n            \n            # Get source counts\n            with self.SourceSession() as session:\n                for table_name, model_class in tables:\n                    source_counts[table_name] = session.query(model_class).count()\n            \n            # Get destination counts\n            with self.DestinationSession() as session:\n                for table_name, model_class in tables:\n                    dest_counts[table_name] = session.query(model_class).count()\n            \n            # Compare counts\n            all_match = True\n            print(\"\\nðŸ“Š Migration Verification:\")\n            print(\"=\" * 50)\n            print(f\"{'Table':<20} {'Source':<10} {'Dest':<10} {'Status':<10}\")\n            print(\"-\" * 50)\n            \n            for table_name in source_counts:\n                source_count = source_counts[table_name]\n                dest_count = dest_counts[table_name]\n                status = \"OK\" if source_count == dest_count else \"MISMATCH\"\n                \n                if source_count != dest_count:\n                    all_match = False\n                \n                print(f\"{table_name:<20} {source_count:<10} {dest_count:<10} {status:<10}\")\n            \n            print(\"-\" * 50)\n            \n            if all_match:\n                print(\"SUCCESS: Migration verification successful! All record counts match.\")\n                return True\n            else:\n                print(\"âŒ Migration verification failed! Some record counts don't match.\")\n                return False\n                \n        except Exception as e:\n            print(f\"âŒ Migration verification failed: {e}\")\n            return False\n    \n    def run_migration(self) -> bool:\n        \"\"\"Run the complete migration process.\"\"\"\n        print(\"ðŸš€ SQLGym Database Migration\")\n        print(\"=\" * 50)\n        print(f\"Source: {self.source_url[:50]}...\")\n        print(f\"Destination: {self.destination_url[:50]}...\")\n        print()\n        \n        # Test connections\n        if not self.test_connections():\n            return False\n        \n        # Setup destination schema\n        if not self.setup_destination_schema():\n            return False\n        \n        # Show record counts\n        print(\"\\nðŸ“Š Source database record counts:\")\n        self.get_record_counts()\n        \n        # Migrate in dependency order\n        migration_steps = [\n            self.migrate_users,\n            self.migrate_problems,\n            self.migrate_submissions,\n            self.migrate_community_posts,\n            self.migrate_post_likes,\n            self.migrate_post_comments\n        ]\n        \n        for step in migration_steps:\n            if not step():\n                print(f\"\\nâŒ Migration failed at step: {step.__name__}\")\n                return False\n        \n        # Verify migration\n        if not self.verify_migration():\n            return False\n        \n        print(\"\\nðŸŽ‰ Database migration completed successfully!\")\n        print(\"\\nNext steps:\")\n        print(\"1. Update your DATABASE_URL environment variable to point to the local database\")\n        print(\"2. Restart your application\")\n        print(\"3. Test your application thoroughly\")\n        \n        return True\n\n\ndef main():\n    \"\"\"Main function to run the migration.\"\"\"\n    if not SOURCE_DATABASE_URL:\n        print(\"âŒ SOURCE_DATABASE_URL not found. Make sure DATABASE_URL is set in your environment.\")\n        return False\n    \n    if LOCAL_DATABASE_URL == \"postgresql://username:password@localhost:5432/sqlgym\":\n        print(\"âš ï¸ Using default LOCAL_DATABASE_URL. Please set LOCAL_DATABASE_URL environment variable\")\n        print(\"   or update the LOCAL_DATABASE_URL in this script.\")\n        \n        response = input(\"Continue with default URL? (y/N): \")\n        if response.lower() != 'y':\n            print(\"Migration cancelled.\")\n            return False\n    \n    # Run migration\n    migrator = DatabaseMigrator(SOURCE_DATABASE_URL, LOCAL_DATABASE_URL)\n    return migrator.run_migration()\n\n\nif __name__ == \"__main__\":\n    success = main()\n    sys.exit(0 if success else 1)","size_bytes":21426},"client/src/components/AnimatedFields.css":{"content":"/* ===== CSS ANIMATIONS & STYLES ===== */\n\n/* Base animations and keyframes */\n@keyframes fadeInUp {\n  from {\n    opacity: 0;\n    transform: translateY(10px);\n  }\n  to {\n    opacity: 1;\n    transform: translateY(0);\n  }\n}\n\n@keyframes pulse {\n  0%,\n  100% {\n    transform: scale(1);\n    opacity: 0.8;\n  }\n  50% {\n    transform: scale(1.2);\n    opacity: 1;\n  }\n}\n\n@keyframes bounce {\n  0%,\n  100% {\n    transform: translateY(0);\n  }\n  50% {\n    transform: translateY(-2px);\n  }\n}\n\n@keyframes skillBarGrow {\n  from {\n    transform: scaleY(0);\n  }\n  to {\n    transform: scaleY(1);\n  }\n}\n\n@keyframes shimmer {\n  0% {\n    background-position: -200px 0;\n  }\n  100% {\n    background-position: 200px 0;\n  }\n}\n\n/* ===== COMPANY FIELD STYLES ===== */\n.company-field {\n  display: inline-flex;\n  align-items: center;\n  gap: 6px;\n  padding: 6px 10px;\n  font-size: 12px;\n  font-weight: 500;\n  border-radius: 6px;\n  background: white;\n  color: #374151;\n  border: none;\n  cursor: pointer;\n  transition: all 0.2s cubic-bezier(0.4, 0, 0.2, 1);\n  position: relative;\n  overflow: hidden;\n  animation: fadeInUp 0.3s ease-out;\n}\n\n/* Dark mode */\n@media (prefers-color-scheme: dark) {\n  .company-field {\n    background: #1f2937;\n    color: #d1d5db;\n  }\n}\n\n/* Hover effects */\n.company-field:hover {\n  transform: translateY(-1px);\n  background: #f3f4f6;\n  box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);\n}\n\n@media (prefers-color-scheme: dark) {\n  .company-field:hover {\n    background: #374151;\n  }\n}\n\n/* Selected state */\n.company-field.selected {\n  background: #dbeafe;\n  color: #1d4ed8;\n  box-shadow: 0 1px 3px rgba(59, 130, 246, 0.2);\n}\n\n@media (prefers-color-scheme: dark) {\n  .company-field.selected {\n    background: rgba(59, 130, 246, 0.2);\n    color: #93c5fd;\n  }\n}\n\n/* Hover on selected */\n.company-field.selected:hover {\n  background: #bfdbfe;\n  transform: translateY(-1px) scale(1.02);\n  box-shadow: 0 4px 12px rgba(59, 130, 246, 0.25);\n}\n\n@media (prefers-color-scheme: dark) {\n  .company-field.selected:hover {\n    background: rgba(59, 130, 246, 0.3);\n  }\n}\n\n/* Active/pressed state */\n.company-field:active {\n  transform: translateY(0) scale(0.98);\n}\n\n/* Focus state */\n.company-field:focus {\n  outline: none;\n  box-shadow: 0 0 0 2px #3b82f6;\n}\n\n/* Disabled state */\n.company-field.disabled {\n  opacity: 0.5;\n  cursor: not-allowed;\n  pointer-events: none;\n}\n\n/* Company icon */\n.company-icon {\n  display: flex;\n  align-items: center;\n  justify-content: center;\n  transition: transform 0.3s ease;\n}\n\n.company-field:hover .company-icon {\n  transform: rotate(180deg);\n  animation: bounce 0.6s ease-in-out;\n}\n\n.company-logo {\n  width: 14px;\n  height: 14px;\n  border-radius: 2px;\n  object-fit: contain;\n}\n\n/* Company name */\n.company-name {\n  white-space: nowrap;\n  transition: color 0.2s ease;\n}\n\n/* Selected dot indicator */\n.selected-dot {\n  width: 4px;\n  height: 4px;\n  border-radius: 50%;\n  background: #3b82f6;\n  opacity: 0;\n  transform: scale(0);\n  transition: all 0.2s ease;\n}\n\n.selected-dot.visible {\n  opacity: 1;\n  transform: scale(1);\n  animation: pulse 1.5s ease-in-out infinite;\n}\n\n/* ===== DIFFICULTY FIELD STYLES ===== */\n.difficulty-field {\n  display: inline-flex;\n  align-items: center;\n  gap: 6px;\n  padding: 6px 10px;\n  font-size: 12px;\n  font-weight: 500;\n  border-radius: 6px;\n  background: white;\n  color: #374151;\n  border: none;\n  cursor: pointer;\n  transition: all 0.2s cubic-bezier(0.4, 0, 0.2, 1);\n  position: relative;\n  animation: fadeInUp 0.3s ease-out;\n}\n\n@media (prefers-color-scheme: dark) {\n  .difficulty-field {\n    background: #1f2937;\n    color: #d1d5db;\n  }\n}\n\n/* Difficulty-specific colors */\n.difficulty-field.easy.selected {\n  background: #f0fdf4;\n  color: #15803d;\n}\n\n.difficulty-field.medium.selected {\n  background: #fffbeb;\n  color: #d97706;\n}\n\n.difficulty-field.hard.selected {\n  background: #fef2f2;\n  color: #dc2626;\n}\n\n@media (prefers-color-scheme: dark) {\n  .difficulty-field.easy.selected {\n    background: rgba(34, 197, 94, 0.2);\n    color: #86efac;\n  }\n\n  .difficulty-field.medium.selected {\n    background: rgba(245, 158, 11, 0.2);\n    color: #fbbf24;\n  }\n\n  .difficulty-field.hard.selected {\n    background: rgba(239, 68, 68, 0.2);\n    color: #fca5a5;\n  }\n}\n\n/* Hover effects */\n.difficulty-field:hover {\n  transform: translateY(-1px) rotateY(2deg);\n  background: #f3f4f6;\n  box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);\n}\n\n@media (prefers-color-scheme: dark) {\n  .difficulty-field:hover {\n    background: #374151;\n  }\n}\n\n/* Selected hover effects */\n.difficulty-field.easy.selected:hover {\n  background: #dcfce7;\n  box-shadow: 0 4px 12px rgba(34, 197, 94, 0.2);\n}\n\n.difficulty-field.medium.selected:hover {\n  background: #fef3c7;\n  box-shadow: 0 4px 12px rgba(245, 158, 11, 0.2);\n}\n\n.difficulty-field.hard.selected:hover {\n  background: #fee2e2;\n  box-shadow: 0 4px 12px rgba(239, 68, 68, 0.2);\n}\n\n/* Active state */\n.difficulty-field:active {\n  transform: translateY(0) scale(0.98);\n}\n\n/* Focus state */\n.difficulty-field:focus {\n  outline: none;\n  box-shadow: 0 0 0 2px currentColor;\n}\n\n/* Difficulty icon */\n.difficulty-icon {\n  display: flex;\n  align-items: center;\n  justify-content: center;\n  transition: transform 0.3s ease;\n}\n\n.difficulty-field:hover .difficulty-icon {\n  transform: translateY(-2px) rotate(5deg);\n  animation: bounce 0.5s ease-in-out;\n}\n\n/* Difficulty name */\n.difficulty-name {\n  white-space: nowrap;\n  transition: color 0.2s ease;\n}\n\n/* Skill bars */\n.skill-bars {\n  display: flex;\n  align-items: end;\n  gap: 2px;\n}\n\n.skill-bar {\n  width: 2px;\n  height: 8px;\n  background: #d1d5db;\n  border-radius: 1px;\n  transition: all 0.3s ease;\n  transform-origin: bottom;\n  animation: skillBarGrow 0.3s ease-out;\n}\n\n@media (prefers-color-scheme: dark) {\n  .skill-bar {\n    background: #6b7280;\n  }\n}\n\n/* Skill bar colors when selected */\n.difficulty-field.easy.selected .skill-bar {\n  background: #22c55e;\n}\n\n.difficulty-field.medium.selected .skill-bar {\n  background: #f59e0b;\n}\n\n.difficulty-field.hard.selected .skill-bar {\n  background: #ef4444;\n}\n\n/* Hover effect on skill bars */\n.difficulty-field:hover .skill-bar {\n  height: 10px;\n  transform: scaleY(1.2);\n}\n\n/* Staggered animation for skill bars */\n.skill-bar:nth-child(1) {\n  animation-delay: 0.1s;\n}\n\n.skill-bar:nth-child(2) {\n  animation-delay: 0.2s;\n}\n\n.skill-bar:nth-child(3) {\n  animation-delay: 0.3s;\n}\n\n/* ===== LAYOUT STYLES ===== */\n.filter-demo {\n  padding: 16px;\n  min-height: 100vh;\n  background: #f9fafb;\n}\n\n@media (prefers-color-scheme: dark) {\n  .filter-demo {\n    background: #111827;\n  }\n}\n\n.demo-container {\n  max-width: 1024px;\n  margin: 0 auto;\n  animation: fadeInUp 0.5s ease-out;\n}\n\n.demo-header {\n  text-align: center;\n  margin-bottom: 24px;\n}\n\n.demo-title {\n  font-size: 20px;\n  font-weight: bold;\n  color: #111827;\n  margin-bottom: 4px;\n}\n\n@media (prefers-color-scheme: dark) {\n  .demo-title {\n    color: white;\n  }\n}\n\n.demo-subtitle {\n  font-size: 14px;\n  color: #6b7280;\n}\n\n@media (prefers-color-scheme: dark) {\n  .demo-subtitle {\n    color: #9ca3af;\n  }\n}\n\n.filters-container {\n  display: flex;\n  flex-direction: column;\n  gap: 16px;\n}\n\n.filter-section {\n  display: flex;\n  flex-direction: column;\n  gap: 12px;\n}\n\n.filter-title {\n  font-size: 14px;\n  font-weight: 500;\n  color: #111827;\n}\n\n@media (prefers-color-scheme: dark) {\n  .filter-title {\n    color: white;\n  }\n}\n\n.filter-grid {\n  display: flex;\n  flex-wrap: wrap;\n  gap: 8px;\n}\n\n.active-filters {\n  padding: 8px 0;\n  animation: fadeInUp 0.3s ease-out;\n}\n\n.active-filters-text {\n  font-size: 14px;\n  color: #1e40af;\n}\n\n@media (prefers-color-scheme: dark) {\n  .active-filters-text {\n    color: #93c5fd;\n  }\n}\n\n.results-section {\n  margin-top: 24px;\n  display: flex;\n  flex-direction: column;\n  gap: 8px;\n}\n\n.result-card {\n  background: white;\n  border-radius: 8px;\n  padding: 16px;\n  transition: transform 0.2s ease, box-shadow 0.2s ease;\n  animation: fadeInUp 0.4s ease-out;\n}\n\n@media (prefers-color-scheme: dark) {\n  .result-card {\n    background: #1f2937;\n  }\n}\n\n.result-card:hover {\n  transform: translateY(-1px);\n  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);\n}\n\n.result-header {\n  display: flex;\n  align-items: center;\n  justify-content: space-between;\n  margin-bottom: 4px;\n}\n\n.result-title {\n  font-weight: 500;\n  color: #111827;\n}\n\n@media (prefers-color-scheme: dark) {\n  .result-title {\n    color: white;\n  }\n}\n\n.result-meta {\n  font-size: 12px;\n  color: #6b7280;\n}\n\n@media (prefers-color-scheme: dark) {\n  .result-meta {\n    color: #9ca3af;\n  }\n}\n\n.result-description {\n  font-size: 14px;\n  color: #6b7280;\n}\n\n@media (prefers-color-scheme: dark) {\n  .result-description {\n    color: #9ca3af;\n  }\n}\n\n/* ===== RESPONSIVE DESIGN ===== */\n@media (max-width: 768px) {\n  .filter-demo {\n    padding: 12px;\n  }\n\n  .demo-title {\n    font-size: 18px;\n  }\n\n  .filter-grid {\n    gap: 6px;\n  }\n\n  .company-field,\n  .difficulty-field {\n    font-size: 11px;\n    padding: 5px 8px;\n  }\n}\n\n/* ===== ACCESSIBILITY ===== */\n@media (prefers-reduced-motion: reduce) {\n  * {\n    animation-duration: 0.01ms !important;\n    animation-iteration-count: 1 !important;\n    transition-duration: 0.01ms !important;\n  }\n}\n\n/* High contrast mode support */\n@media (prefers-contrast: high) {\n  .company-field,\n  .difficulty-field {\n    border: 1px solid currentColor;\n  }\n\n  .company-field:focus,\n  .difficulty-field:focus {\n    outline: 2px solid currentColor;\n    outline-offset: 2px;\n  }\n}\n","size_bytes":9360},"client/src/components/CompanyLogo.tsx":{"content":"import { useEffect, useState } from \"react\";\nimport { Building2 } from \"lucide-react\";\nimport { Badge } from \"@/components/ui/badge\";\nimport { getCompanyInfo, CompanyInfo } from \"@/data/companyLogos\";\n\ninterface CompanyLogoProps {\n  companyName: string | null | undefined;\n  variant?: \"badge\" | \"icon\" | \"full\" | \"minimal\";\n  size?: \"sm\" | \"md\" | \"lg\";\n  showFallback?: boolean;\n  className?: string;\n  onClick?: () => void;\n  \"data-testid\"?: string;\n}\n\n/**\n * CompanyLogo component that displays SVG logos based on company names\n * with fallback support and multiple display variants\n */\nexport function CompanyLogo({\n  companyName,\n  variant = \"badge\",\n  size = \"md\",\n  showFallback = true,\n  className = \"\",\n  onClick,\n  \"data-testid\": testId,\n}: CompanyLogoProps) {\n  const [companyInfo, setCompanyInfo] = useState<CompanyInfo | null>(null);\n  const [logoSrc, setLogoSrc] = useState<string | null>(null);\n  const [logoError, setLogoError] = useState(false);\n  const [isLoading, setIsLoading] = useState(false);\n\n  useEffect(() => {\n    if (!companyName) {\n      setCompanyInfo(null);\n      setLogoSrc(null);\n      setLogoError(false);\n      setIsLoading(false);\n      return;\n    }\n\n    setIsLoading(true);\n    setLogoError(false);\n    \n    try {\n      const info = getCompanyInfo(companyName);\n      setCompanyInfo(info);\n\n      if (info) {\n        setLogoSrc(info.logoPath);\n      } else {\n        setLogoSrc(null);\n      }\n    } catch (error) {\n      console.error('Error loading company info:', error);\n      setCompanyInfo(null);\n      setLogoSrc(null);\n      setLogoError(true);\n    } finally {\n      setIsLoading(false);\n    }\n  }, [companyName]);\n\n  // Size configurations\n  const sizeConfig = {\n    sm: {\n      logo: \"w-3 h-3\",\n      badge: \"text-xs px-2 py-1\",\n      icon: \"w-4 h-4\",\n      text: \"text-xs\",\n    },\n    md: {\n      logo: \"w-4 h-4\",\n      badge: \"text-xs px-2 py-1\",\n      icon: \"w-5 h-5\",\n      text: \"text-sm\",\n    },\n    lg: {\n      logo: \"w-6 h-6\",\n      badge: \"text-sm px-3 py-1.5\",\n      icon: \"w-6 h-6\",\n      text: \"text-base\",\n    },\n  };\n\n  const config = sizeConfig[size];\n\n  // Handle logo loading error\n  const handleLogoError = () => {\n    setLogoError(true);\n  };\n\n  // If no company name and no fallback, return null\n  if (!companyName && !showFallback) {\n    return null;\n  }\n\n  // If no company name but fallback is enabled\n  if (!companyName && showFallback) {\n    return (\n      <span className={`text-gray-400 ${config.text} ${className}`} data-testid={testId}>\n        -\n      </span>\n    );\n  }\n\n  // Render based on variant\n  switch (variant) {\n    case \"icon\":\n      return (\n        <div \n          className={`flex items-center justify-center ${config.icon} ${className}`}\n          onClick={onClick}\n          data-testid={testId}\n          style={{ \n            color: companyInfo?.primaryColor || \"#6B7280\",\n            cursor: onClick ? \"pointer\" : \"default\"\n          }}\n        >\n          {logoSrc && !logoError ? (\n            <img\n              src={logoSrc}\n              alt={`${companyName} logo`}\n              className={`${config.logo} object-contain`}\n              onError={handleLogoError}\n              style={{ \n                filter: companyInfo ? 'none' : 'grayscale(100%)',\n              }}\n            />\n          ) : (\n            <Building2 className={config.icon} />\n          )}\n        </div>\n      );\n\n    case \"minimal\":\n      return (\n        <div \n          className={`inline-flex items-center gap-1.5 ${className}`}\n          onClick={onClick}\n          data-testid={testId}\n          style={{ cursor: onClick ? \"pointer\" : \"default\" }}\n        >\n          {logoSrc && !logoError ? (\n            <img\n              src={logoSrc}\n              alt={`${companyName} logo`}\n              className={`${config.logo} object-contain`}\n              onError={handleLogoError}\n            />\n          ) : (\n            <Building2 className={config.logo} style={{ color: companyInfo?.primaryColor || \"#6B7280\" }} />\n          )}\n          <span className={`${config.text} font-medium`} style={{ color: companyInfo?.primaryColor || \"#374151\" }}>\n            {companyName}\n          </span>\n        </div>\n      );\n\n    case \"full\":\n      return (\n        <div\n          className={`company-field ${companyInfo ? \"selected\" : \"\"} ${className}`}\n          onClick={onClick}\n          data-testid={testId}\n          style={{\n            backgroundColor: companyInfo?.primaryColor ? `${companyInfo.primaryColor}10` : undefined,\n            borderColor: companyInfo?.primaryColor ? `${companyInfo.primaryColor}30` : undefined,\n          }}\n        >\n          <span className=\"company-icon\">\n            {logoSrc && !logoError ? (\n              <img\n                src={logoSrc}\n                alt={`${companyName} logo`}\n                className=\"company-logo\"\n                onError={handleLogoError}\n              />\n            ) : (\n              <Building2 className=\"w-3.5 h-3.5\" style={{ color: companyInfo?.primaryColor || \"#6B7280\" }} />\n            )}\n          </span>\n          <span className=\"company-name\" style={{ color: companyInfo?.primaryColor || \"#374151\" }}>\n            {companyInfo?.displayName || companyName}\n          </span>\n          <span className={`selected-dot ${companyInfo ? \"visible\" : \"\"}`} />\n        </div>\n      );\n\n    case \"badge\":\n    default:\n      return (\n        <Badge\n          variant=\"outline\"\n          className={`bg-blue-50 text-blue-700 border-blue-200 ${config.badge} flex items-center gap-1.5 ${className}`}\n          onClick={onClick}\n          data-testid={testId}\n          style={{\n            backgroundColor: companyInfo?.primaryColor ? `${companyInfo.primaryColor}15` : undefined,\n            borderColor: companyInfo?.primaryColor ? `${companyInfo.primaryColor}40` : undefined,\n            color: companyInfo?.primaryColor || \"#1D4ED8\",\n            cursor: onClick ? \"pointer\" : \"default\"\n          }}\n        >\n          {logoSrc && !logoError ? (\n            <img\n              src={logoSrc}\n              alt={`${companyName} logo`}\n              className={`${config.logo} object-contain`}\n              onError={handleLogoError}\n            />\n          ) : (\n            <Building2 className={config.logo} />\n          )}\n          {companyInfo?.displayName || companyName}\n        </Badge>\n      );\n  }\n}\n\n/**\n * Simplified component for backward compatibility\n */\nexport function CompanyBadge({ companyName, className, ...props }: Omit<CompanyLogoProps, \"variant\">) {\n  return (\n    <CompanyLogo\n      companyName={companyName}\n      variant=\"badge\"\n      className={className}\n      {...props}\n    />\n  );\n}\n\nexport default CompanyLogo;","size_bytes":6693},"client/src/components/DifficultyBadge.tsx":{"content":"import { Badge } from \"@/components/ui/badge\";\nimport { Target, Zap, Flame, Award } from \"lucide-react\";\n\ninterface DifficultyBadgeProps {\n  difficulty: string;\n  variant?: \"badge\" | \"full\" | \"minimal\" | \"skill\";\n  size?: \"sm\" | \"md\" | \"lg\";\n  showIcon?: boolean;\n  showBars?: boolean;\n  className?: string;\n  onClick?: () => void;\n  \"data-testid\"?: string;\n}\n\ntype DifficultyLevel = \"Easy\" | \"Medium\" | \"Hard\" | \"Expert\" | (string & {});\n\ninterface DifficultyConfig {\n  level: DifficultyLevel;\n  colors: {\n    bg: string;\n    text: string;\n    border: string;\n    primary: string;\n    secondary: string;\n  };\n  icon: typeof Target;\n  bars: number;\n  label: string;\n  description: string;\n}\n\nconst DIFFICULTY_CONFIG: Record<string, DifficultyConfig> = {\n  easy: {\n    level: \"Easy\",\n    colors: {\n      bg: \"bg-green-50\",\n      text: \"text-green-700\",\n      border: \"border-green-200\", \n      primary: \"#15803d\",\n      secondary: \"#22c55e\",\n    },\n    icon: Target,\n    bars: 1,\n    label: \"Easy\",\n    description: \"Perfect for beginners\",\n  },\n  medium: {\n    level: \"Medium\",\n    colors: {\n      bg: \"bg-orange-50\",\n      text: \"text-orange-700\",\n      border: \"border-orange-200\",\n      primary: \"#ea580c\",\n      secondary: \"#f97316\",\n    },\n    icon: Zap,\n    bars: 2,\n    label: \"Medium\",\n    description: \"Requires some experience\",\n  },\n  hard: {\n    level: \"Hard\",\n    colors: {\n      bg: \"bg-red-50\",\n      text: \"text-red-700\",\n      border: \"border-red-200\",\n      primary: \"#dc2626\",\n      secondary: \"#ef4444\",\n    },\n    icon: Flame,\n    bars: 3,\n    label: \"Hard\",\n    description: \"For experienced developers\",\n  },\n  expert: {\n    level: \"Expert\",\n    colors: {\n      bg: \"bg-purple-50\",\n      text: \"text-purple-700\",\n      border: \"border-purple-200\",\n      primary: \"#7c3aed\",\n      secondary: \"#8b5cf6\",\n    },\n    icon: Award,\n    bars: 4,\n    label: \"Expert\",\n    description: \"Challenge for experts\",\n  },\n};\n\n/**\n * Generate dynamic difficulty configuration for unknown difficulty levels\n * Creates appropriate colors and styling based on difficulty name\n */\nfunction generateDynamicDifficultyConfig(difficulty: string): DifficultyConfig {\n  const normalizedDifficulty = difficulty.trim();\n  const hash = normalizedDifficulty.split('').reduce((a, b) => {\n    a = ((a << 5) - a) + b.charCodeAt(0);\n    return a & a;\n  }, 0);\n  \n  // Generate colors based on hash for consistency\n  const hue = Math.abs(hash) % 360;\n  const saturation = 70;\n  const lightness = 60;\n  \n  const primaryColor = `hsl(${hue}, ${saturation}%, ${lightness}%)`;\n  const secondaryColor = `hsl(${hue}, ${saturation - 10}%, ${lightness + 10}%)`;\n  const bgColor = `hsl(${hue}, ${saturation - 50}%, 97%)`;\n  const textColor = `hsl(${hue}, ${saturation}%, 30%)`;\n  const borderColor = `hsl(${hue}, ${saturation - 30}%, 85%)`;\n  \n  // Determine bars based on common difficulty patterns\n  let bars = 2; // default\n  const lowerDifficulty = normalizedDifficulty.toLowerCase();\n  if (lowerDifficulty.includes('easy') || lowerDifficulty.includes('beginner') || lowerDifficulty.includes('basic')) {\n    bars = 1;\n  } else if (lowerDifficulty.includes('expert') || lowerDifficulty.includes('master') || lowerDifficulty.includes('advanced')) {\n    bars = 4;\n  } else if (lowerDifficulty.includes('hard') || lowerDifficulty.includes('difficult') || lowerDifficulty.includes('complex')) {\n    bars = 3;\n  }\n  \n  return {\n    level: normalizedDifficulty,\n    colors: {\n      bg: `bg-gray-50`, // Use neutral background for better control\n      text: `text-gray-700`, // Use neutral text for better control  \n      border: `border-gray-200`, // Use neutral border for better control\n      primary: primaryColor,\n      secondary: secondaryColor,\n    },\n    icon: Target, // Default icon for unknown difficulties\n    bars,\n    label: normalizedDifficulty,\n    description: `${normalizedDifficulty} level challenge`,\n  };\n}\n\n/**\n * Enhanced difficulty badge component with multiple variants and improved styling\n * Now supports dynamic difficulty levels from the database with automatic color generation\n */\nexport function DifficultyBadge({\n  difficulty,\n  variant = \"badge\",\n  size = \"md\",\n  showIcon = true,\n  showBars = false,\n  className = \"\",\n  onClick,\n  \"data-testid\": testId,\n}: DifficultyBadgeProps) {\n  const difficultyKey = difficulty?.toLowerCase() || \"easy\";\n  \n  // Get config from predefined list or generate dynamic config for unknown difficulties\n  const config = DIFFICULTY_CONFIG[difficultyKey] || generateDynamicDifficultyConfig(difficulty || \"easy\");\n  const IconComponent = config.icon;\n\n  // Size configurations\n  const sizeConfig = {\n    sm: {\n      badge: \"text-xs px-2 py-0.5\",\n      icon: \"w-3 h-3\",\n      text: \"text-xs\",\n      bar: \"w-1 h-2\",\n      gap: \"gap-1\",\n    },\n    md: {\n      badge: \"text-xs px-2 py-1\",\n      icon: \"w-3.5 h-3.5\",\n      text: \"text-sm\",\n      bar: \"w-1.5 h-3\",\n      gap: \"gap-1.5\",\n    },\n    lg: {\n      badge: \"text-sm px-3 py-1.5\",\n      icon: \"w-4 h-4\",\n      text: \"text-base\",\n      bar: \"w-2 h-4\",\n      gap: \"gap-2\",\n    },\n  };\n\n  const sizeConf = sizeConfig[size];\n\n  // Skill bars component\n  const SkillBars = ({ count }: { count: number }) => (\n    <div className={`flex items-end ${sizeConf.gap}`}>\n      {Array.from({ length: 4 }, (_, i) => (\n        <div\n          key={i}\n          className={`${sizeConf.bar} rounded-sm transition-all duration-300 ease-out`}\n          style={{\n            backgroundColor: i < count ? config.colors.primary : \"#d1d5db\",\n            animationDelay: `${i * 100}ms`,\n          }}\n        />\n      ))}\n    </div>\n  );\n\n  // Render based on variant\n  switch (variant) {\n    case \"minimal\":\n      return (\n        <span\n          className={`inline-flex items-center ${sizeConf.gap} ${sizeConf.text} font-medium ${className}`}\n          onClick={onClick}\n          data-testid={testId}\n          style={{ \n            color: config.colors.primary,\n            cursor: onClick ? \"pointer\" : \"default\"\n          }}\n        >\n          {showIcon && <IconComponent className={sizeConf.icon} />}\n          {config.label}\n        </span>\n      );\n\n    case \"skill\":\n      return (\n        <div\n          className={`inline-flex items-center ${sizeConf.gap} ${className}`}\n          onClick={onClick}\n          data-testid={testId}\n          style={{ cursor: onClick ? \"pointer\" : \"default\" }}\n        >\n          {showIcon && (\n            <IconComponent \n              className={sizeConf.icon} \n              style={{ color: config.colors.primary }}\n            />\n          )}\n          <span \n            className={`${sizeConf.text} font-medium`}\n            style={{ color: config.colors.primary }}\n          >\n            {config.label}\n          </span>\n          <SkillBars count={config.bars} />\n        </div>\n      );\n\n    case \"full\":\n      // Check if this is a custom (dynamic) configuration\n      const isCustomConfigFull = !DIFFICULTY_CONFIG[difficultyKey];\n      \n      return (\n        <div\n          className={`difficulty-field ${difficultyKey} selected ${className}`}\n          onClick={onClick}\n          data-testid={testId}\n          style={{\n            ...(isCustomConfigFull && {\n              backgroundColor: config.colors.primary + '15', // 15% opacity\n              borderColor: config.colors.primary + '40', // 40% opacity\n            })\n          }}\n        >\n          <span className=\"difficulty-icon\">\n            {showIcon ? (\n              <IconComponent className=\"w-3.5 h-3.5\" style={{ color: config.colors.primary }} />\n            ) : (\n              \"ðŸŽ¯\"\n            )}\n          </span>\n          <span \n            className=\"difficulty-name\"\n            style={{\n              ...(isCustomConfigFull && {\n                color: config.colors.primary\n              })\n            }}\n          >\n            {config.label}\n          </span>\n          {showBars && (\n            <div className=\"skill-bars\">\n              {Array.from({ length: 3 }, (_, i) => (\n                <div\n                  key={i}\n                  className=\"skill-bar\"\n                  style={{\n                    background: i < config.bars ? config.colors.secondary : \"#d1d5db\",\n                  }}\n                />\n              ))}\n            </div>\n          )}\n        </div>\n      );\n\n    case \"badge\":\n    default:\n      // Check if this is a custom (dynamic) configuration\n      const isCustomConfig = !DIFFICULTY_CONFIG[difficultyKey];\n      \n      return (\n        <Badge\n          className={`${config.colors.bg} ${config.colors.text} ${config.colors.border} border font-medium inline-flex items-center ${sizeConf.gap} ${sizeConf.badge} ${className}`}\n          onClick={onClick}\n          data-testid={testId}\n          style={{ \n            cursor: onClick ? \"pointer\" : \"default\",\n            // Apply custom colors for dynamic configurations\n            ...(isCustomConfig && {\n              backgroundColor: config.colors.primary + '20', // 20% opacity\n              borderColor: config.colors.primary + '50', // 50% opacity\n              color: config.colors.primary,\n            })\n          }}\n        >\n          {showIcon && <IconComponent className={sizeConf.icon} />}\n          {config.label}\n          {showBars && (\n            <div className={`flex items-end ${sizeConf.gap} ml-1`}>\n              {Array.from({ length: 3 }, (_, i) => (\n                <div\n                  key={i}\n                  className={`${sizeConf.bar} rounded-sm`}\n                  style={{\n                    backgroundColor: i < config.bars ? config.colors.primary : \"#d1d5db\",\n                  }}\n                />\n              ))}\n            </div>\n          )}\n        </Badge>\n      );\n  }\n}\n\n/**\n * Get difficulty color classes for legacy compatibility\n * Now supports dynamic difficulties with custom colors\n */\nexport function getDifficultyColor(difficulty: string): string {\n  const difficultyKey = difficulty?.toLowerCase() || \"easy\";\n  const config = DIFFICULTY_CONFIG[difficultyKey] || generateDynamicDifficultyConfig(difficulty || \"easy\");\n  \n  // For custom configurations, return inline styles via CSS classes\n  const isCustomConfig = !DIFFICULTY_CONFIG[difficultyKey];\n  if (isCustomConfig) {\n    return `text-gray-700 bg-gray-50 border-gray-200`; // Neutral classes for custom colors\n  }\n  \n  return `${config.colors.text} ${config.colors.bg} ${config.colors.border}`;\n}\n\n/**\n * Get difficulty configuration\n * Now supports dynamic difficulties\n */\nexport function getDifficultyConfig(difficulty: string): DifficultyConfig {\n  const difficultyKey = difficulty?.toLowerCase() || \"easy\";\n  return DIFFICULTY_CONFIG[difficultyKey] || generateDynamicDifficultyConfig(difficulty || \"easy\");\n}\n\n/**\n * Simplified component for backward compatibility\n */\nexport function DifficultyTag({ difficulty, className, ...props }: Omit<DifficultyBadgeProps, \"variant\">) {\n  return (\n    <DifficultyBadge\n      difficulty={difficulty}\n      variant=\"badge\"\n      className={className}\n      {...props}\n    />\n  );\n}\n\nexport default DifficultyBadge;","size_bytes":11066},"client/src/data/companyLogos.ts":{"content":"/**\n * AUTO-GENERATED FILE - DO NOT EDIT MANUALLY\n * Generated by scripts/generate-logos.js\n * Run 'npm run generate:logos' to regenerate\n */\n\nimport airbnbLogo from '@assets/logos/airbnb.svg';\nimport amazonLogo from '@assets/logos/amazon.svg';\nimport appleLogo from '@assets/logos/apple.svg';\nimport googleLogo from '@assets/logos/google.svg';\nimport mcdonaldLogo from '@assets/logos/mcdonald.svg';\nimport metaLogo from '@assets/logos/meta.svg';\nimport microsoftLogo from '@assets/logos/microsoft.svg';\nimport netflixLogo from '@assets/logos/netflix.svg';\nimport snapchatLogo from '@assets/logos/snapchat.svg';\nimport stripeLogo from '@assets/logos/stripe.svg';\n\nexport interface CompanyInfo {\n  id: string;\n  name: string;\n  displayName: string;\n  logoPath: string;\n  primaryColor: string;\n  secondaryColor?: string;\n}\n\n// Auto-generated logo registry\nconst LOGO_REGISTRY: Record<string, string> = {\n  airbnb: airbnbLogo,\n  amazon: amazonLogo,\n  apple: appleLogo,\n  google: googleLogo,\n  mcdonald: mcdonaldLogo,\n  meta: metaLogo,\n  microsoft: microsoftLogo,\n  netflix: netflixLogo,\n  snapchat: snapchatLogo,\n  stripe: stripeLogo,\n};\n\n// Default color configurations for known companies\nconst COMPANY_COLORS: Record<string, Pick<CompanyInfo, 'primaryColor' | 'secondaryColor'>> = {\n  microsoft: {\n    primaryColor: '#00BCF2',\n    secondaryColor: '#0078D4',\n  },\n  google: {\n    primaryColor: '#4285F4',\n    secondaryColor: '#DB4437',\n  },\n  apple: {\n    primaryColor: '#000000',\n    secondaryColor: '#A8A8A8',\n  },\n  amazon: {\n    primaryColor: '#FF9900',\n    secondaryColor: '#232F3E',\n  },\n  meta: {\n    primaryColor: '#1877F2',\n    secondaryColor: '#42B883',\n  },\n  netflix: {\n    primaryColor: '#E50914',\n    secondaryColor: '#221F1F',\n  },\n  stripe: {\n    primaryColor: '#635BFF',\n    secondaryColor: '#0A2540',\n  },\n  airbnb: {\n    primaryColor: '#FF5A5F',\n    secondaryColor: '#FF385C',\n  },\n  tesla: {\n    primaryColor: '#CC0000',\n    secondaryColor: '#000000',\n  },\n  uber: {\n    primaryColor: '#000000',\n    secondaryColor: '#1FBAD6',\n  },\n  shopify: {\n    primaryColor: '#7AB55C',\n    secondaryColor: '#95BF47',\n  },\n  discord: {\n    primaryColor: '#5865F2',\n    secondaryColor: '#7289DA',\n  },\n  slack: {\n    primaryColor: '#4A154B',\n    secondaryColor: '#36C5F0',\n  },\n};\n\n/**\n * Normalizes company name to match expected filename format\n */\nfunction normalizeCompanyName(companyName: string): string {\n  return companyName.toLowerCase()\n    .trim()\n    .replace(/\\s+/g, '')\n    .replace(/[^a-z0-9]/g, '');\n}\n\n/**\n * Gets company info by name using auto-generated logo registry\n */\nexport function getCompanyInfo(companyName: string): CompanyInfo | null {\n  if (!companyName) return null;\n  \n  const normalizedName = normalizeCompanyName(companyName);\n  const logoPath = LOGO_REGISTRY[normalizedName];\n  \n  // If no logo found, return null\n  if (!logoPath) return null;\n  \n  // Get colors from config or use defaults\n  const colors = COMPANY_COLORS[normalizedName] || {\n    primaryColor: '#6366F1', // Default indigo\n    secondaryColor: '#4F46E5',\n  };\n  \n  // Create display name (capitalize first letter of each word)\n  const displayName = companyName\n    .toLowerCase()\n    .split(/\\s+/)\n    .map(word => word.charAt(0).toUpperCase() + word.slice(1))\n    .join(' ');\n  \n  return {\n    id: normalizedName,\n    name: displayName,\n    displayName: displayName,\n    logoPath: logoPath,\n    primaryColor: colors.primaryColor,\n    secondaryColor: colors.secondaryColor,\n  };\n}\n\n/**\n * Gets company info by ID\n */\nexport function getCompanyById(id: string): CompanyInfo | null {\n  return getCompanyInfo(id);\n}\n\n/**\n * Generates a company ID from a company name\n */\nexport function generateCompanyId(companyName: string): string {\n  return normalizeCompanyName(companyName);\n}\n\n/**\n * Gets all available companies (those in the logo registry)\n */\nexport function getAllCompanies(): CompanyInfo[] {\n  const companies: CompanyInfo[] = [];\n  \n  for (const [normalizedName, logoPath] of Object.entries(LOGO_REGISTRY)) {\n    const colors = COMPANY_COLORS[normalizedName] || {\n      primaryColor: '#6366F1',\n      secondaryColor: '#4F46E5',\n    };\n    \n    const displayName = normalizedName.charAt(0).toUpperCase() + normalizedName.slice(1);\n    \n    companies.push({\n      id: normalizedName,\n      name: displayName,\n      displayName: displayName,\n      logoPath: logoPath,\n      primaryColor: colors.primaryColor,\n      secondaryColor: colors.secondaryColor,\n    });\n  }\n  \n  return companies;\n}\n\n/**\n * Checks if a company logo exists\n */\nexport function hasCompanyLogo(companyName: string): boolean {\n  const info = getCompanyInfo(companyName);\n  return info !== null;\n}\n","size_bytes":4681},"scripts/generate-logos.js":{"content":"#!/usr/bin/env node\n/**\n * Auto-generates companyLogos.ts based on SVG files in attached_assets/logos/\n * Run this script before building or in CI/CD pipeline\n */\n\nimport fs from 'fs';\nimport path from 'path';\nimport { fileURLToPath } from 'url';\n\nconst __filename = fileURLToPath(import.meta.url);\nconst __dirname = path.dirname(__filename);\n\nconst LOGOS_DIR = path.join(__dirname, '..', 'attached_assets', 'logos');\nconst OUTPUT_FILE = path.join(__dirname, '..', 'client', 'src', 'data', 'companyLogos.ts');\n\n// Default colors for companies\nconst COMPANY_COLORS = {\n  microsoft: { primaryColor: '#00BCF2', secondaryColor: '#0078D4' },\n  google: { primaryColor: '#4285F4', secondaryColor: '#DB4437' },\n  apple: { primaryColor: '#000000', secondaryColor: '#A8A8A8' },\n  amazon: { primaryColor: '#FF9900', secondaryColor: '#232F3E' },\n  meta: { primaryColor: '#1877F2', secondaryColor: '#42B883' },\n  netflix: { primaryColor: '#E50914', secondaryColor: '#221F1F' },\n  stripe: { primaryColor: '#635BFF', secondaryColor: '#0A2540' },\n  airbnb: { primaryColor: '#FF5A5F', secondaryColor: '#FF385C' },\n  tesla: { primaryColor: '#CC0000', secondaryColor: '#000000' },\n  uber: { primaryColor: '#000000', secondaryColor: '#1FBAD6' },\n  shopify: { primaryColor: '#7AB55C', secondaryColor: '#95BF47' },\n  discord: { primaryColor: '#5865F2', secondaryColor: '#7289DA' },\n  slack: { primaryColor: '#4A154B', secondaryColor: '#36C5F0' },\n};\n\nfunction normalizeCompanyName(filename) {\n  return path.basename(filename, '.svg').toLowerCase().replace(/[^a-z0-9]/g, '');\n}\n\nfunction generateCompanyLogos() {\n  console.log('ðŸš€ Generating company logos...');\n  \n  if (!fs.existsSync(LOGOS_DIR)) {\n    console.error(`âŒ Logos directory not found: ${LOGOS_DIR}`);\n    process.exit(1);\n  }\n\n  // Get all SVG files\n  const svgFiles = fs.readdirSync(LOGOS_DIR)\n    .filter(file => file.endsWith('.svg'))\n    .sort();\n\n  if (svgFiles.length === 0) {\n    console.warn('âš ï¸ No SVG files found in logos directory');\n    return;\n  }\n\n  console.log(`ðŸ“ Found ${svgFiles.length} logo files:`, svgFiles.map(f => f.replace('.svg', '')).join(', '));\n\n  // Generate imports\n  const imports = svgFiles.map(file => {\n    const normalizedName = normalizeCompanyName(file);\n    const varName = `${normalizedName}Logo`;\n    return `import ${varName} from '@assets/logos/${file}';`;\n  }).join('\\n');\n\n  // Generate registry\n  const registryEntries = svgFiles.map(file => {\n    const normalizedName = normalizeCompanyName(file);\n    const varName = `${normalizedName}Logo`;\n    return `  ${normalizedName}: ${varName},`;\n  }).join('\\n');\n\n  // Generate colors object\n  const colorsEntries = Object.entries(COMPANY_COLORS)\n    .map(([company, colors]) => \n      `  ${company}: {\\n    primaryColor: '${colors.primaryColor}',\\n    secondaryColor: '${colors.secondaryColor}',\\n  },`\n    ).join('\\n');\n\n  const fileContent = `/**\n * AUTO-GENERATED FILE - DO NOT EDIT MANUALLY\n * Generated by scripts/generate-logos.js\n * Run 'npm run generate:logos' to regenerate\n */\n\n${imports}\n\nexport interface CompanyInfo {\n  id: string;\n  name: string;\n  displayName: string;\n  logoPath: string;\n  primaryColor: string;\n  secondaryColor?: string;\n}\n\n// Auto-generated logo registry\nconst LOGO_REGISTRY: Record<string, string> = {\n${registryEntries}\n};\n\n// Default color configurations for known companies\nconst COMPANY_COLORS: Record<string, Pick<CompanyInfo, 'primaryColor' | 'secondaryColor'>> = {\n${colorsEntries}\n};\n\n/**\n * Normalizes company name to match expected filename format\n */\nfunction normalizeCompanyName(companyName: string): string {\n  return companyName.toLowerCase()\n    .trim()\n    .replace(/\\\\s+/g, '')\n    .replace(/[^a-z0-9]/g, '');\n}\n\n/**\n * Gets company info by name using auto-generated logo registry\n */\nexport function getCompanyInfo(companyName: string): CompanyInfo | null {\n  if (!companyName) return null;\n  \n  const normalizedName = normalizeCompanyName(companyName);\n  const logoPath = LOGO_REGISTRY[normalizedName];\n  \n  // If no logo found, return null\n  if (!logoPath) return null;\n  \n  // Get colors from config or use defaults\n  const colors = COMPANY_COLORS[normalizedName] || {\n    primaryColor: '#6366F1', // Default indigo\n    secondaryColor: '#4F46E5',\n  };\n  \n  // Create display name (capitalize first letter of each word)\n  const displayName = companyName\n    .toLowerCase()\n    .split(/\\\\s+/)\n    .map(word => word.charAt(0).toUpperCase() + word.slice(1))\n    .join(' ');\n  \n  return {\n    id: normalizedName,\n    name: displayName,\n    displayName: displayName,\n    logoPath: logoPath,\n    primaryColor: colors.primaryColor,\n    secondaryColor: colors.secondaryColor,\n  };\n}\n\n/**\n * Gets company info by ID\n */\nexport function getCompanyById(id: string): CompanyInfo | null {\n  return getCompanyInfo(id);\n}\n\n/**\n * Generates a company ID from a company name\n */\nexport function generateCompanyId(companyName: string): string {\n  return normalizeCompanyName(companyName);\n}\n\n/**\n * Gets all available companies (those in the logo registry)\n */\nexport function getAllCompanies(): CompanyInfo[] {\n  const companies: CompanyInfo[] = [];\n  \n  for (const [normalizedName, logoPath] of Object.entries(LOGO_REGISTRY)) {\n    const colors = COMPANY_COLORS[normalizedName] || {\n      primaryColor: '#6366F1',\n      secondaryColor: '#4F46E5',\n    };\n    \n    const displayName = normalizedName.charAt(0).toUpperCase() + normalizedName.slice(1);\n    \n    companies.push({\n      id: normalizedName,\n      name: displayName,\n      displayName: displayName,\n      logoPath: logoPath,\n      primaryColor: colors.primaryColor,\n      secondaryColor: colors.secondaryColor,\n    });\n  }\n  \n  return companies;\n}\n\n/**\n * Checks if a company logo exists\n */\nexport function hasCompanyLogo(companyName: string): boolean {\n  const info = getCompanyInfo(companyName);\n  return info !== null;\n}\n`;\n\n  fs.writeFileSync(OUTPUT_FILE, fileContent);\n  console.log(`Generated ${OUTPUT_FILE} with ${svgFiles.length} company logos`);\n}\n\n// Run if called directly\nif (import.meta.url === `file://${process.argv[1]}`) {\n  generateCompanyLogos();\n}\n\nexport { generateCompanyLogos };","size_bytes":6142},"client/src/components/CodeEditor.tsx":{"content":"import { memo, useState, useCallback, useEffect } from 'react';\nimport { Play, Save } from 'lucide-react';\nimport CodeMirror from '@uiw/react-codemirror';\nimport { Card, CardContent } from '@/components/ui/card';\nimport { Button } from '@/components/ui/button';\nimport { useTheme } from '@/hooks/use-theme';\nimport { useCodeMirrorConfig } from '@/hooks/use-codemirror-config';\n\ninterface Problem {\n  question?: {\n    starterQuery?: string;\n    tables?: Array<{ name: string }>;\n  };\n}\n\ninterface CodeEditorProps {\n  problem?: Problem;\n  problemId?: string;\n  onRunQuery: (query: string) => Promise<any>;\n  onSubmitSolution: (query: string) => Promise<any>;\n  isRunning?: boolean;\n  isSubmitting?: boolean;\n  className?: string;\n}\n\nconst CodeEditor = memo(function CodeEditor({\n  problem,\n  problemId,\n  onRunQuery,\n  onSubmitSolution,\n  isRunning = false,\n  isSubmitting = false,\n  className,\n}: CodeEditorProps) {\n  const [query, setQuery] = useState('');\n  const isDarkMode = useTheme();\n\n  // Get storage key for this problem\n  const storageKey = problemId ? `sqlgym_query_${problemId}` : null;\n\n  // Initialize query with priority: saved query > starter query > default table query\n  useEffect(() => {\n    if (!problem || !problemId) return;\n\n    // Try to restore saved query first\n    let initialQuery = '';\n    if (storageKey) {\n      const savedQuery = localStorage.getItem(storageKey);\n      if (savedQuery) {\n        initialQuery = savedQuery;\n      }\n    }\n\n    // Fall back to starter query or default if no saved query\n    if (!initialQuery) {\n      if (problem?.question?.starterQuery) {\n        initialQuery = problem.question.starterQuery;\n      } else if (problem?.question?.tables && problem.question.tables.length > 0) {\n        const firstTable = problem.question.tables[0];\n        const tableName = firstTable.name;\n        initialQuery = `SELECT * FROM \"${tableName}\";`;\n      }\n    }\n\n    if (initialQuery) {\n      setQuery(initialQuery);\n    }\n  }, [problem, problemId, storageKey]);\n\n  // Handle query changes and persist to localStorage\n  const handleQueryChange = useCallback((value: string) => {\n    setQuery(value);\n    \n    // Save to localStorage immediately to survive remounts\n    if (storageKey) {\n      localStorage.setItem(storageKey, value);\n    }\n  }, [storageKey]);\n\n  // Memoized handlers to prevent recreation\n  const handleRun = useCallback(async () => {\n    if (!query.trim()) return;\n    await onRunQuery(query);\n  }, [query, onRunQuery]);\n\n  const handleSubmit = useCallback(async () => {\n    if (!query.trim()) return;\n    await onSubmitSolution(query);\n    localStorage.setItem(\"sqlgym_last_query\", query);\n  }, [query, onSubmitSolution]);\n\n  // Get optimized CodeMirror configuration\n  const { extensions, theme } = useCodeMirrorConfig({\n    problem,\n    isDarkMode,\n    onRunQuery: handleRun,\n  });\n\n  return (\n    <div className={`h-full flex flex-col ${className || ''}`}>\n      <div className=\"flex-1 flex flex-col min-h-0\">\n        <Card className=\"flex-1 flex flex-col overflow-hidden rounded-none border-0\">\n          <CardContent className=\"p-0 flex-1 min-h-0 overflow-hidden\">\n            <CodeMirror\n              value={query}\n              onChange={handleQueryChange}\n              height=\"calc(100vh - 200px)\"\n              theme={theme}\n              extensions={extensions}\n              basicSetup={{\n                lineNumbers: true,\n                foldGutter: true,\n                dropCursor: false,\n                allowMultipleSelections: false,\n                indentOnInput: true,\n                bracketMatching: true,\n                closeBrackets: true,\n                autocompletion: false,\n                highlightSelectionMatches: false,\n                searchKeymap: true,\n                tabSize: 2,\n              }}\n              data-testid=\"editor-sql\"\n              className=\"sqlgym-editor\"\n            />\n          </CardContent>\n        </Card>\n      </div>\n\n      {/* Action Buttons */}\n      <div className=\"flex-shrink-0 p-2 bg-muted/30\">\n        <div className=\"flex justify-end gap-3\">\n          <Button\n            onClick={handleRun}\n            disabled={isRunning || !query.trim()}\n            className=\"bg-primary text-primary-foreground hover:bg-primary/90 font-semibold h-8\"\n            data-testid=\"button-run-query\"\n          >\n            <Play className=\"mr-2 h-4 w-4\" />\n            {isRunning ? \"Running...\" : \"Run Code\"}\n          </Button>\n\n          <Button\n            onClick={handleSubmit}\n            disabled={isSubmitting || !query.trim()}\n            className=\"bg-green-600 hover:bg-green-700 text-white font-semibold h-8\"\n            data-testid=\"button-submit\"\n          >\n            <Save className=\"mr-2 h-4 w-4\" />\n            {isSubmitting ? \"Submitting...\" : \"Check Solution\"}\n          </Button>\n        </div>\n      </div>\n    </div>\n  );\n});\n\nexport default CodeEditor;","size_bytes":4902},"client/src/components/DatabaseSelector.tsx":{"content":"import { memo, useState, useEffect } from 'react';\nimport { ChevronDown } from 'lucide-react';\nimport { Button } from '@/components/ui/button';\nimport {\n  DropdownMenu,\n  DropdownMenuContent,\n  DropdownMenuItem,\n  DropdownMenuTrigger,\n} from '@/components/ui/dropdown-menu';\n\ninterface DatabaseSelectorProps {\n  className?: string;\n  problem?: any;\n}\n\nconst DatabaseSelector = memo(function DatabaseSelector({ className, problem }: DatabaseSelectorProps) {\n  // Always use DuckDB to prevent access to main database\n  const [selectedDatabase, setSelectedDatabase] = useState(\"DuckDB\");\n\n  // Always keep DuckDB selected regardless of problem data\n  useEffect(() => {\n    setSelectedDatabase(\"DuckDB\");\n  }, [problem]);\n\n  const databases = [\n    \"DuckDB\"\n  ];\n\n  return (\n    <DropdownMenu>\n      <DropdownMenuTrigger asChild>\n        <Button\n          variant=\"ghost\"\n          size=\"sm\"\n          className={`h-7 px-2 text-xs text-muted-foreground hover:text-foreground border border-border bg-muted ${className || ''}`}\n          data-testid=\"button-db-selector\"\n        >\n          <span>{selectedDatabase}</span>\n          <ChevronDown className=\"h-3 w-3 ml-1\" />\n        </Button>\n      </DropdownMenuTrigger>\n      <DropdownMenuContent align=\"end\" className=\"w-48\">\n        {databases.map((db) => (\n          <DropdownMenuItem\n            key={db}\n            onClick={() => setSelectedDatabase(db)}\n            className={selectedDatabase === db ? \"bg-accent\" : \"\"}\n          >\n            {db}\n          </DropdownMenuItem>\n        ))}\n      </DropdownMenuContent>\n    </DropdownMenu>\n  );\n});\n\nexport default DatabaseSelector;","size_bytes":1635},"client/src/components/EditorHeader.tsx":{"content":"import { memo } from 'react';\nimport { CardHeader } from '@/components/ui/card';\nimport { CompanyLogo } from '@/components/CompanyLogo';\nimport { DifficultyBadge } from '@/components/DifficultyBadge';\nimport TimerControls from '@/components/TimerControls';\nimport DatabaseSelector from '@/components/DatabaseSelector';\n\ninterface EditorHeaderProps {\n  company: string;\n  difficulty: string;\n  onCompanyClick: (company: string) => void;\n  onDifficultyClick: (difficulty: string) => void;\n  className?: string;\n  problem?: any;\n}\n\nconst EditorHeader = memo(function EditorHeader({\n  company,\n  difficulty,\n  onCompanyClick,\n  onDifficultyClick,\n  className,\n  problem,\n}: EditorHeaderProps) {\n  return (\n    <CardHeader className={`bg-muted/50 px-4 py-2 flex-shrink-0 ${className || ''}`}>\n      <div className=\"flex items-center justify-between\">\n        <div className=\"flex items-center space-x-3\">\n          {/* Company field */}\n          <CompanyLogo\n            companyName={company}\n            variant=\"full\"\n            size=\"md\"\n            onClick={() => onCompanyClick(company)}\n            data-testid=\"company-selector\"\n          />\n\n          {/* Difficulty field */}\n          <DifficultyBadge\n            difficulty={difficulty}\n            variant=\"full\"\n            size=\"md\"\n            showIcon={true}\n            showBars={true}\n            onClick={() => onDifficultyClick(difficulty)}\n            data-testid=\"difficulty-selector\"\n          />\n        </div>\n\n        <div className=\"flex items-center space-x-3\">\n          {/* Timer Controls */}\n          <TimerControls />\n\n          {/* Database Selector */}\n          <DatabaseSelector problem={problem} />\n        </div>\n      </div>\n    </CardHeader>\n  );\n});\n\nexport default EditorHeader;","size_bytes":1768},"client/src/components/OptimizedEditorOutputSplit.tsx":{"content":"import { memo, useState, useCallback } from \"react\";\nimport EditorHeader from \"@/components/EditorHeader\";\nimport CodeEditor from \"@/components/CodeEditor\";\nimport OutputPanel from \"@/components/OutputPanel\";\nimport SubmissionResultPanel from \"@/components/SubmissionResultPanel\";\nimport VerticalResizableSplitter from \"@/components/vertical-resizable-splitter\";\n\ninterface Problem {\n  company?: string;\n  difficulty?: string;\n  premium?: boolean | null;\n  question?: {\n    starterQuery?: string;\n    tables?: Array<{ name: string }>;\n  };\n}\n\ninterface QueryResult {\n  success: boolean;\n  results?: any[];\n  execution_time_ms?: number;\n  rows_affected?: number;\n  console_info?: string;\n  error?: string;\n  feedback?: string[];\n  test_results?: any[];\n}\n\ninterface OptimizedEditorOutputSplitProps {\n  problem?: Problem;\n  problemId?: string;\n  handleRunQuery: (query: string) => Promise<any>;\n  handleSubmitSolution: (query: string) => Promise<any>;\n  onDifficultyClick: (difficulty: string) => void;\n  onCompanyClick: (company: string) => void;\n  className?: string;\n}\n\nconst OptimizedEditorOutputSplit = memo(function OptimizedEditorOutputSplit({\n  problem,\n  problemId,\n  handleRunQuery,\n  handleSubmitSolution,\n  onDifficultyClick,\n  onCompanyClick,\n  className,\n}: OptimizedEditorOutputSplitProps) {\n  const [result, setResult] = useState<QueryResult | null>(null);\n  const [submissionResult, setSubmissionResult] = useState<any | null>(null);\n  const [isRunning, setIsRunning] = useState(false);\n  const [isSubmitting, setIsSubmitting] = useState(false);\n  const [showOutput, setShowOutput] = useState(false);\n  const [isSubmissionMode, setIsSubmissionMode] = useState(false);\n\n  const selectedCompany = problem?.company || \"NY Times\";\n  const selectedDifficulty = problem?.difficulty || \"Medium\";\n\n  // Optimized run query handler\n  const optimizedRunQuery = useCallback(\n    async (query: string) => {\n      setIsRunning(true);\n      setShowOutput(true);\n      setIsSubmissionMode(false); // Switch to query mode\n      try {\n        const runResult = await handleRunQuery(query);\n        setResult(runResult);\n        return runResult;\n      } catch (error) {\n        const errorResult = {\n          success: false,\n          error:\n            error instanceof Error ? error.message : \"Query execution failed\",\n        };\n        setResult(errorResult);\n        return errorResult;\n      } finally {\n        setIsRunning(false);\n      }\n    },\n    [handleRunQuery],\n  );\n\n  // Optimized submit solution handler\n  const optimizedSubmitSolution = useCallback(\n    async (query: string) => {\n      setIsSubmitting(true);\n      setShowOutput(true);\n      setIsSubmissionMode(true); // Switch to submission mode\n      try {\n        const submitResult = await handleSubmitSolution(query);\n        setSubmissionResult(submitResult);\n        return submitResult;\n      } catch (error) {\n        const errorResult = {\n          success: false,\n          error: error instanceof Error ? error.message : \"Submission failed\",\n        };\n        setSubmissionResult(errorResult);\n        return errorResult;\n      } finally {\n        setIsSubmitting(false);\n      }\n    },\n    [handleSubmitSolution],\n  );\n\n  // Editor panel with header\n  const editorPanel = (\n    <div className=\"h-full flex flex-col\">\n      <EditorHeader\n        company={selectedCompany}\n        difficulty={selectedDifficulty}\n        onCompanyClick={onCompanyClick}\n        onDifficultyClick={onDifficultyClick}\n        problem={problem}\n      />\n      <div className=\"flex-1 min-h-0\">\n        <CodeEditor\n          problem={problem}\n          problemId={problemId}\n          onRunQuery={optimizedRunQuery}\n          onSubmitSolution={optimizedSubmitSolution}\n          isRunning={isRunning}\n          isSubmitting={isSubmitting}\n        />\n      </div>\n    </div>\n  );\n\n  // Output panel - show different component based on mode\n  const outputPanel = isSubmissionMode ? (\n    <SubmissionResultPanel \n      result={submissionResult} \n      isLoading={isSubmitting}\n      problemId={problemId || \"\"} \n    />\n  ) : (\n    <OutputPanel result={result} isLoading={isRunning} />\n  );\n\n  // Show resizable layout when output is visible, otherwise show just the editor\n  if (showOutput) {\n    return (\n      <VerticalResizableSplitter\n        topPanel={editorPanel}\n        bottomPanel={outputPanel}\n        defaultTopHeight={60}\n        minTopHeight={35}\n        minBottomHeight={25}\n        className={`h-full ${className || \"\"}`}\n      />\n    );\n  }\n\n  // Show just the editor when no output\n  return <div className={`h-full ${className || \"\"}`}>{editorPanel}</div>;\n});\n\nexport default OptimizedEditorOutputSplit;\n","size_bytes":4678},"client/src/components/OutputPanel.tsx":{"content":"import React, { useMemo } from 'react';\n\ninterface OutputPanelProps {\n  result: {\n    success: boolean;\n    results?: any[];\n    execution_time_ms?: number;\n    rows_affected?: number;\n    console_info?: string;\n    error?: string;\n    feedback?: string[];\n    test_results?: any[];\n  } | null;\n  isLoading: boolean;\n}\n\nconst OptimizedTable = ({ data }: { data: any[] }) => {\n  const { headers, rows } = useMemo(() => {\n    if (!data || data.length === 0) return { headers: [], rows: [] };\n    \n    const headers = Object.keys(data[0]);\n    const rows = data.map(row => headers.map(header => row[header]));\n    \n    return { headers, rows };\n  }, [data]);\n\n  if (headers.length === 0) {\n    return <div className=\"text-gray-500 italic p-4\">No data to display</div>;\n  }\n\n  return (\n    <div className=\"bg-white border border-gray-200 rounded-lg overflow-hidden max-h-full\">\n      <div className=\"overflow-auto max-h-96\">\n        <table className=\"w-full\">\n          <thead className=\"sticky top-0 bg-gray-50\">\n            <tr className=\"border-b border-gray-200\">\n              {headers.map((header, i) => (\n                <th \n                  key={i} \n                  className=\"px-4 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider\"\n                >\n                  {header}\n                </th>\n              ))}\n            </tr>\n          </thead>\n          <tbody className=\"bg-white divide-y divide-gray-200\">\n            {rows.map((row, i) => (\n              <tr key={i} className=\"hover:bg-gray-50\">\n                {row.map((cell, j) => (\n                  <td key={j} className=\"px-4 py-3 text-sm text-gray-900\">\n                    {String(cell ?? '')}\n                  </td>\n                ))}\n              </tr>\n            ))}\n          </tbody>\n        </table>\n      </div>\n    </div>\n  );\n};\n\nexport default function OutputPanel({ result, isLoading }: OutputPanelProps) {\n  if (isLoading) {\n    return (\n      <div className=\"h-full bg-gray-50 flex items-center justify-center\">\n        <div className=\"text-gray-600\">Executing query...</div>\n      </div>\n    );\n  }\n\n  if (!result) {\n    return (\n      <div className=\"h-full bg-gray-50 flex items-center justify-center\">\n        <div className=\"text-gray-500\">Ready to execute queries...</div>\n      </div>\n    );\n  }\n\n  const executionTimeSeconds = result.execution_time_ms ? (result.execution_time_ms / 1000).toFixed(5) : '0.00000';\n\n  // Add this handler for the \"View in new tab\" functionality\n  const handleViewInNewTab = () => {\n    if (!result?.results || result.results.length === 0) return;\n    \n    const htmlContent = `\n      <!DOCTYPE html>\n      <html>\n      <head>\n        <title>Query Results</title>\n        <style>\n          body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; margin: 20px; }\n          table { width: 100%; border-collapse: collapse; border: 1px solid #e5e5e5; }\n          th { background: #f9f9f9; padding: 12px; text-align: left; border-bottom: 1px solid #e5e5e5; font-weight: 600; }\n          td { padding: 12px; border-bottom: 1px solid #f0f0f0; }\n          tr:hover { background: #f9f9f9; }\n        </style>\n      </head>\n      <body>\n        <h2>Query Results</h2>\n        <p>Execution time: ${executionTimeSeconds} seconds | ${result.results.length} rows</p>\n        <table>\n          <thead>\n            <tr>\n              ${Object.keys(result.results[0]).map(header => `<th>${header}</th>`).join('')}\n            </tr>\n          </thead>\n          <tbody>\n            ${result.results.map(row => \n              `<tr>${Object.values(row).map(cell => `<td>${String(cell ?? '')}</td>`).join('')}</tr>`\n            ).join('')}\n          </tbody>\n        </table>\n      </body>\n      </html>\n    `;\n    \n    const blob = new Blob([htmlContent], { type: 'text/html' });\n    const url = URL.createObjectURL(blob);\n    window.open(url, '_blank');\n    \n    // Clean up the URL object after a delay\n    setTimeout(() => URL.revokeObjectURL(url), 1000);\n  };\n\n  return (\n    <div className=\"h-full bg-gray-50 flex flex-col\">\n      {/* Header with execution info */}\n      <div className=\"flex-shrink-0 px-4 py-3 bg-white border-b border-gray-200 flex items-center justify-between\">\n        <div className=\"flex items-center space-x-4\">\n          <span className=\"text-sm text-gray-700\">\n            Execution time: {executionTimeSeconds} seconds\n          </span>\n          {result.rows_affected !== undefined && (\n            <span className=\"text-sm text-gray-500\">\n              {result.rows_affected} rows\n            </span>\n          )}\n        </div>\n        <button \n          onClick={handleViewInNewTab}\n          className=\"px-3 py-1 text-sm text-blue-600 border border-blue-300 rounded hover:bg-blue-50\"\n          disabled={!result?.results || result.results.length === 0}\n          data-testid=\"button-view-new-tab\"\n        >\n          View the output in a new tab\n        </button>\n      </div>\n\n      {/* Results area */}\n      <div className=\"flex-1 p-4 overflow-auto\">\n        {result.success && result.results && result.results.length > 0 ? (\n          <OptimizedTable data={result.results} />\n        ) : !result.success ? (\n          <div className=\"bg-red-50 border border-red-200 rounded-lg p-4\">\n            <div className=\"text-red-800 font-medium\">Query Error</div>\n            <div className=\"text-red-700 mt-1 whitespace-pre-wrap\">\n              {result.error || 'Query failed'}\n            </div>\n          </div>\n        ) : (\n          <div className=\"text-center text-gray-500 py-8\">\n            Query executed successfully - no rows returned\n          </div>\n        )}\n      </div>\n\n      {/* Test results section */}\n      {result.test_results && result.test_results.length > 0 && (\n        <div className=\"flex-shrink-0 border-t border-gray-200 p-4 bg-white\">\n          <h3 className=\"text-gray-900 font-medium mb-2\">Test Results:</h3>\n          <div className=\"space-y-1\">\n            {result.test_results.map((test, index) => (\n              <div key={index} className={`text-sm flex items-center space-x-2`}>\n                <span className={test.passed ? 'text-green-600' : 'text-red-600'}>\n                  {test.passed ? 'âœ“' : 'âœ—'}\n                </span>\n                <span className=\"text-gray-700\">{test.name}</span>\n              </div>\n            ))}\n          </div>\n        </div>\n      )}\n    </div>\n  );\n}","size_bytes":6430},"client/src/components/ProblemDescriptionTab.tsx":{"content":"import { memo, useState, useCallback, useEffect } from \"react\";\nimport { Lightbulb } from \"lucide-react\";\nimport ReactMarkdown from \"react-markdown\";\nimport remarkGfm from \"remark-gfm\";\nimport { Button } from \"@/components/ui/button\";\nimport { Badge } from \"@/components/ui/badge\";\nimport TableDisplay from \"@/components/table-display\";\nimport { queryClient } from \"@/lib/queryClient\";\n\ninterface Problem {\n  question?: {\n    description?: string;\n    tables?: any[];\n    expectedOutput?: any[];\n  };\n  hints?: string[];\n  tags?: string[];\n}\n\ninterface ProblemDescriptionTabProps {\n  problem?: Problem;\n  className?: string;\n  problemId?: string;\n}\n\nconst ProblemDescriptionTab = memo(function ProblemDescriptionTab({\n  problem,\n  className,\n  problemId,\n}: ProblemDescriptionTabProps) {\n  const [showHint, setShowHint] = useState(false);\n  const [hintIndex, setHintIndex] = useState(0);\n\n  // Force cache invalidation on mount to ensure fresh data\n  useEffect(() => {\n    if (problemId) {\n      queryClient.invalidateQueries({ queryKey: [\"/api/problems\", problemId] });\n    }\n  }, [problemId]);\n\n  const handleHintClick = useCallback(() => {\n    if (!showHint) {\n      setShowHint(true);\n    } else if (hintIndex < (problem?.hints?.length || 0) - 1) {\n      setHintIndex((prev) => prev + 1);\n    }\n  }, [showHint, hintIndex, problem?.hints?.length]);\n\n  // Parse hint content and extract code blocks\n  const parseHintContent = useCallback((content: string) => {\n    const parts = content.split(/(\\*\\/\\*[\\s\\S]*?\\*\\/\\*)/);\n    return parts.map((part, partIndex) => {\n      if (part.startsWith(\"*/*\") && part.endsWith(\"*/*\")) {\n        const codeContent = part.slice(3, -3);\n        return (\n          <code\n            key={partIndex}\n            className=\"block bg-gray-100 dark:bg-gray-800 p-3 rounded-md text-sm font-mono my-2 whitespace-pre-wrap\"\n          >\n            {codeContent}\n          </code>\n        );\n      } else {\n        return part;\n      }\n    });\n  }, []);\n\n  return (\n    <div className={`space-y-6 ${className || \"\"}`}>\n      {/* Problem Description */}\n      <div className=\"space-y-4\">\n        <div className=\"text-foreground prose prose-sm max-w-none dark:prose-invert\">\n          <ReactMarkdown\n            remarkPlugins={[remarkGfm]}\n            components={{\n              p: ({ children }) => (\n                <p className=\"mb-3 text-foreground leading-relaxed\">\n                  {children}\n                </p>\n              ),\n              h1: ({ children }) => (\n                <h1 className=\"text-xl font-bold mb-4 text-foreground\">\n                  {children}\n                </h1>\n              ),\n              h2: ({ children }) => (\n                <h2 className=\"text-lg font-semibold mb-3 text-foreground\">\n                  {children}\n                </h2>\n              ),\n              h3: ({ children }) => (\n                <h3 className=\"text-base font-semibold mb-2 text-foreground\">\n                  {children}\n                </h3>\n              ),\n              ul: ({ children }) => (\n                <ul className=\"list-disc list-inside mb-3 space-y-1 text-foreground\">\n                  {children}\n                </ul>\n              ),\n              ol: ({ children }) => (\n                <ol className=\"list-decimal list-inside mb-3 space-y-1 text-foreground\">\n                  {children}\n                </ol>\n              ),\n              li: ({ children }) => (\n                <li className=\"text-foreground\">{children}</li>\n              ),\n              strong: ({ children }) => (\n                <strong className=\"font-semibold text-foreground\">\n                  {children}\n                </strong>\n              ),\n              em: ({ children }) => (\n                <em className=\"italic text-foreground\">{children}</em>\n              ),\n              code: ({ children }) => (\n                <code className=\"bg-muted px-1.5 py-0.5 rounded text-sm font-mono text-foreground\">\n                  {children}\n                </code>\n              ),\n              pre: ({ children }) => (\n                <pre className=\"bg-muted p-4 rounded-lg overflow-x-auto text-sm font-mono text-foreground mb-4\">\n                  {children}\n                </pre>\n              ),\n              blockquote: ({ children }) => (\n                <blockquote className=\"border-l-4 border-primary pl-4 italic text-muted-foreground mb-4\">\n                  {children}\n                </blockquote>\n              ),\n              table: ({ children }) => (\n                <div className=\"overflow-x-auto mb-4\">\n                  <table className=\"min-w-full border border-muted rounded-lg\">\n                    {children}\n                  </table>\n                </div>\n              ),\n              thead: ({ children }) => (\n                <thead className=\"bg-muted/50\">{children}</thead>\n              ),\n              tbody: ({ children }) => <tbody>{children}</tbody>,\n              tr: ({ children }) => (\n                <tr className=\"border-b border-muted\">{children}</tr>\n              ),\n              th: ({ children }) => (\n                <th className=\"border border-muted px-3 py-2 text-left font-semibold\">\n                  {children}\n                </th>\n              ),\n              td: ({ children }) => (\n                <td className=\"border border-muted px-3 py-2\">{children}</td>\n              ),\n            }}\n          >\n            {problem?.question?.description || \"\"}\n          </ReactMarkdown>\n        </div>\n      </div>\n\n      {/* Structured Table Display */}\n      <TableDisplay\n        tables={problem?.question?.tables || []}\n        expectedOutput={problem?.expectedDisplay || problem?.question?.expectedOutput || []}\n      />\n\n      {/* Hints Section */}\n      {problem?.hints && problem.hints.length > 0 && (\n        <div className=\"space-y-3\">\n          {!showHint ? (\n            <Button\n              onClick={handleHintClick}\n              variant=\"outline\"\n              className=\"w-full text-primary hover:bg-primary/10\"\n              data-testid=\"button-hint\"\n            >\n              <Lightbulb className=\"mr-2 h-4 w-4\" />\n              HINT\n            </Button>\n          ) : (\n            <>\n              <div className=\"space-y-4\">\n                {problem.hints\n                  .slice(0, hintIndex + 1)\n                  .map((hint: string, index: number) => (\n                    <div key={index} className=\"text-foreground\">\n                      <h3 className=\"text-center font-bold text-lg mb-2 text-foreground\">\n                        HINT {index + 1}\n                      </h3>\n                      <p className=\"text-foreground leading-relaxed\">\n                        {parseHintContent(hint)}\n                      </p>\n                    </div>\n                  ))}\n              </div>\n\n              {hintIndex < (problem?.hints?.length || 0) - 1 && (\n                <Button\n                  onClick={handleHintClick}\n                  variant=\"outline\"\n                  className=\"w-full text-primary hover:bg-primary/10 mt-3\"\n                  data-testid=\"button-hint\"\n                >\n                  <Lightbulb className=\"mr-2 h-4 w-4\" />\n                  HINT\n                </Button>\n              )}\n            </>\n          )}\n        </div>\n      )}\n\n      {/* Tags */}\n      {problem?.tags && problem.tags.length > 0 && (\n        <div>\n          <h4 className=\"text-sm font-medium text-foreground mb-2\">Tags</h4>\n          <div className=\"flex flex-wrap gap-2\">\n            {problem.tags.map((tag: string, index: number) => (\n              <Badge key={index} variant=\"outline\" data-testid={`tag-${tag}`}>\n                {tag}\n              </Badge>\n            ))}\n          </div>\n        </div>\n      )}\n    </div>\n  );\n});\n\n\nexport default ProblemDescriptionTab;\n","size_bytes":7837},"client/src/components/ProblemNavigation.tsx":{"content":"import { memo, useCallback } from 'react';\nimport { ArrowLeft, ChevronLeft, ChevronRight, Users, Star, Lock, Bookmark, ThumbsUp, ThumbsDown } from 'lucide-react';\nimport { Link } from 'wouter';\nimport { Button } from '@/components/ui/button';\nimport { Badge } from '@/components/ui/badge';\nimport { useMutation, useQueryClient } from '@tanstack/react-query';\nimport { problemsApi } from '@/lib/auth';\nimport { useAuth } from '@/hooks/use-auth';\nimport { useToast } from '@/hooks/use-toast';\n\ninterface Problem {\n  id?: string;\n  title?: string;\n  likes?: number; // For backward compatibility\n  upvotesCount?: number;\n  company?: string;\n  difficulty?: string;\n  premium?: boolean | null;\n  isBookmarked?: boolean;\n  isLiked?: boolean; // For backward compatibility\n  isUpvoted?: boolean;\n  isDownvoted?: boolean;\n}\n\ninterface ProblemNavigationProps {\n  problem?: Problem;\n  userSubmissions?: any[];\n  onPrevious?: () => void;\n  onNext?: () => void;\n  hasPrevious?: boolean;\n  hasNext?: boolean;\n  className?: string;\n}\n\nconst ProblemNavigation = memo(function ProblemNavigation({\n  problem,\n  userSubmissions = [],\n  onPrevious,\n  onNext,\n  hasPrevious = false,\n  hasNext = false,\n  className,\n}: ProblemNavigationProps) {\n  const { user } = useAuth();\n  const { toast } = useToast();\n  const queryClient = useQueryClient();\n\n  // Memoized calculation for solved status\n  const isSolved = useCallback(() => {\n    return userSubmissions?.some((sub) => sub.isCorrect) || false;\n  }, [userSubmissions]);\n\n  // Bookmark mutation\n  const bookmarkMutation = useMutation({\n    mutationFn: async () => {\n      if (!problem?.id) throw new Error(\"No problem ID\");\n      return problemsApi.toggleBookmark(problem.id);\n    },\n    onSuccess: () => {\n      // Invalidate and refetch problem data to get updated bookmark status\n      queryClient.invalidateQueries({\n        queryKey: [\"/api/problems\", problem?.id],\n      });\n      toast({\n        title: problem?.isBookmarked ? \"Bookmark removed\" : \"Problem bookmarked\",\n        description: problem?.isBookmarked \n          ? \"Problem removed from your bookmarks\" \n          : \"Problem added to your bookmarks\",\n      });\n    },\n    onError: (error) => {\n      toast({\n        title: \"Failed to update bookmark\",\n        description: error instanceof Error ? error.message : \"Unknown error\",\n        variant: \"destructive\",\n      });\n    },\n  });\n\n  // Upvote mutation\n  const upvoteMutation = useMutation({\n    mutationFn: async () => {\n      if (!problem?.id) throw new Error(\"No problem ID\");\n      return problemsApi.toggleUpvote(problem.id);\n    },\n    onSuccess: () => {\n      // Invalidate and refetch problem data to get updated vote status\n      queryClient.invalidateQueries({\n        queryKey: [\"/api/problems\", problem?.id],\n      });\n      toast({\n        title: problem?.isUpvoted ? \"Upvote removed\" : \"Problem upvoted\",\n        description: problem?.isUpvoted \n          ? \"You removed your upvote from this problem\" \n          : \"You upvoted this problem\",\n      });\n    },\n    onError: (error) => {\n      toast({\n        title: \"Failed to update upvote\",\n        description: error instanceof Error ? error.message : \"Unknown error\",\n        variant: \"destructive\",\n      });\n    },\n  });\n\n  // Downvote mutation\n  const downvoteMutation = useMutation({\n    mutationFn: async () => {\n      if (!problem?.id) throw new Error(\"No problem ID\");\n      return problemsApi.toggleDownvote(problem.id);\n    },\n    onSuccess: () => {\n      // Invalidate and refetch problem data to get updated vote status\n      queryClient.invalidateQueries({\n        queryKey: [\"/api/problems\", problem?.id],\n      });\n      toast({\n        title: problem?.isDownvoted ? \"Downvote removed\" : \"Problem downvoted\",\n        description: problem?.isDownvoted \n          ? \"You removed your downvote from this problem\" \n          : \"You downvoted this problem\",\n      });\n    },\n    onError: (error) => {\n      toast({\n        title: \"Failed to update downvote\",\n        description: error instanceof Error ? error.message : \"Unknown error\",\n        variant: \"destructive\",\n      });\n    },\n  });\n\n  const handlePrevious = useCallback(() => {\n    if (hasPrevious && onPrevious) {\n      onPrevious();\n    }\n  }, [hasPrevious, onPrevious]);\n\n  const handleNext = useCallback(() => {\n    if (hasNext && onNext) {\n      onNext();\n    }\n  }, [hasNext, onNext]);\n\n  return (\n    <div className={`flex items-center justify-between py-4 px-6 border-b ${className || ''}`}>\n      {/* Left: Back to Problems + Title */}\n      <div className=\"flex items-center space-x-4\">\n        <Link to=\"/problems\">\n          <Button\n            variant=\"ghost\"\n            size=\"sm\"\n            className=\"text-muted-foreground hover:text-foreground\"\n            data-testid=\"button-back-to-problems\"\n          >\n            <ArrowLeft className=\"h-4 w-4 mr-2\" />\n            Problems\n          </Button>\n        </Link>\n\n        {problem && (\n          <>\n            <div className=\"h-4 w-px bg-border\"></div>\n            <div className=\"flex items-center space-x-3\">\n              <div className=\"flex items-center gap-2\">\n                {problem.premium && (\n                  <Lock className=\"w-4 h-4 text-amber-500\" />\n                )}\n                <h1 className=\"text-lg font-semibold\" data-testid=\"text-problem-title\">\n                  {problem.title || 'Untitled Problem'}\n                </h1>\n              </div>\n              {isSolved() && (\n                <Badge variant=\"secondary\" className=\"bg-green-100 text-green-800 dark:bg-green-900 dark:text-green-200\">\n                  âœ“ Solved\n                </Badge>\n              )}\n            </div>\n          </>\n        )}\n      </div>\n\n      {/* Right: Problem Stats + Bookmark/Like Actions + Navigation */}\n      <div className=\"flex items-center space-x-4\">\n        {problem && user && (\n          <>\n            {/* Bookmark, Upvote and Downvote Buttons */}\n            <div className=\"flex items-center space-x-2\">\n              <Button\n                onClick={() => bookmarkMutation.mutate()}\n                disabled={bookmarkMutation.isPending}\n                variant=\"ghost\"\n                size=\"sm\"\n                className={`h-8 w-8 p-0 ${problem.isBookmarked ? 'text-green-700 dark:text-green-400' : 'text-muted-foreground'}`}\n                data-testid=\"button-bookmark\"\n              >\n                <Bookmark className={`h-4 w-4 ${problem.isBookmarked ? 'fill-current' : ''}`} />\n              </Button>\n              \n              <div className=\"flex items-center space-x-1\">\n                <Button\n                  onClick={() => upvoteMutation.mutate()}\n                  disabled={upvoteMutation.isPending}\n                  variant=\"ghost\"\n                  size=\"sm\"\n                  className={`h-8 w-8 p-0 ${problem.isUpvoted ? 'text-green-600 dark:text-green-400' : 'text-muted-foreground'}`}\n                  data-testid=\"button-upvote\"\n                >\n                  <ThumbsUp className={`h-4 w-4 ${problem.isUpvoted ? 'fill-current' : ''}`} />\n                </Button>\n                \n                {/* Show upvote count */}\n                {(problem.upvotesCount && problem.upvotesCount > 0) && (\n                  <span className=\"text-sm text-muted-foreground min-w-[1rem]\">\n                    {problem.upvotesCount}\n                  </span>\n                )}\n                \n                <Button\n                  onClick={() => downvoteMutation.mutate()}\n                  disabled={downvoteMutation.isPending}\n                  variant=\"ghost\"\n                  size=\"sm\"\n                  className={`h-8 w-8 p-0 ${problem.isDownvoted ? 'text-red-600 dark:text-red-400' : 'text-muted-foreground'}`}\n                  data-testid=\"button-downvote\"\n                >\n                  <ThumbsDown className={`h-4 w-4 ${problem.isDownvoted ? 'fill-current' : ''}`} />\n                </Button>\n              </div>\n            </div>\n            \n            {/* Problem Stats */}\n            <div className=\"flex items-center space-x-3 text-sm text-muted-foreground\">\n              <div className=\"flex items-center space-x-1\">\n                <Users className=\"h-3 w-3\" />\n                <span>2.1k</span>\n              </div>\n              <div className=\"flex items-center space-x-1\">\n                <ThumbsUp className=\"h-3 w-3\" />\n                <span>{problem.upvotesCount || problem.likes || 0}</span>\n              </div>\n            </div>\n\n            <div className=\"h-4 w-px bg-border\"></div>\n          </>\n        )}\n        \n        {problem && !user && (\n          <>\n            {/* Problem Stats for non-logged in users */}\n            <div className=\"flex items-center space-x-3 text-sm text-muted-foreground\">\n              <div className=\"flex items-center space-x-1\">\n                <Users className=\"h-3 w-3\" />\n                <span>2.1k</span>\n              </div>\n              <div className=\"flex items-center space-x-1\">\n                <ThumbsUp className=\"h-3 w-3\" />\n                <span>{problem.upvotesCount || problem.likes || 0}</span>\n              </div>\n            </div>\n\n            <div className=\"h-4 w-px bg-border\"></div>\n          </>\n        )}\n\n        {/* Navigation Controls */}\n        <div className=\"flex items-center space-x-2\">\n          <Button\n            onClick={handlePrevious}\n            disabled={!hasPrevious}\n            variant=\"outline\"\n            size=\"sm\"\n            className=\"h-8 w-8 p-0\"\n            data-testid=\"button-previous-problem\"\n          >\n            <ChevronLeft className=\"h-4 w-4\" />\n          </Button>\n          <Button\n            onClick={handleNext}\n            disabled={!hasNext}\n            variant=\"outline\"\n            size=\"sm\"\n            className=\"h-8 w-8 p-0\"\n            data-testid=\"button-next-problem\"\n          >\n            <ChevronRight className=\"h-4 w-4\" />\n          </Button>\n        </div>\n      </div>\n    </div>\n  );\n});\n\nexport default ProblemNavigation;","size_bytes":10018},"client/src/components/ProblemTabsContent.tsx":{"content":"import { memo, useState } from 'react';\nimport { Code2, MessageSquare, CheckCircle, BookOpen, Heart, Reply, Send, ChevronUp, ChevronDown, Lock } from 'lucide-react';\nimport { useQuery, useMutation } from \"@tanstack/react-query\";\nimport { Tabs, TabsContent, TabsList, TabsTrigger } from '@/components/ui/tabs';\nimport { Button } from '@/components/ui/button';\nimport { Card, CardContent } from '@/components/ui/card';\nimport { Badge } from '@/components/ui/badge';\nimport { Alert, AlertDescription } from '@/components/ui/alert';\nimport { Textarea } from '@/components/ui/textarea';\nimport { Avatar, AvatarFallback, AvatarImage } from '@/components/ui/avatar';\nimport { Dialog, DialogContent, DialogHeader, DialogTitle, DialogTrigger } from '@/components/ui/dialog';\nimport { useToast } from '@/hooks/use-toast';\nimport { useAuth } from '@/hooks/use-auth';\nimport { apiRequest, queryClient } from '@/lib/queryClient';\nimport ProblemDescriptionTab from '@/components/ProblemDescriptionTab';\nimport AnswersScreen from '@/components/AnswersScreen';\n\ninterface Problem {\n  id?: string;\n  question?: {\n    description?: string;\n    tables?: any[];\n    expectedOutput?: any[];\n  };\n  hints?: string[];\n  tags?: string[];\n  premium?: boolean | null;\n}\n\ninterface Solution {\n  id: string;\n  problem_id: string;\n  title: string;\n  explanation: string;\n  code: string;\n  approach: string;\n  time_complexity: string;\n  space_complexity: string;\n  tags: string[];\n  created_at: string;\n}\n\ninterface Submission {\n  id: string;\n  isCorrect: boolean;\n  submittedAt: string;\n  executionTime?: number;\n}\n\ninterface TestResult {\n  test_case_id: string;\n  test_case_name: string;\n  is_hidden: boolean;\n  is_correct: boolean;\n  score: number;\n  feedback: string[];\n  execution_time_ms: number;\n  execution_status: string;\n  validation_details: any;\n  user_output: any[];\n  expected_output: any[];\n  output_matches: boolean;\n}\n\ninterface SubmissionResult {\n  success: boolean;\n  is_correct: boolean;\n  score: number;\n  feedback: string[];\n  test_results: TestResult[];\n  submission_id: string;\n  execution_stats: {\n    avg_time_ms: number;\n    max_time_ms: number;\n    memory_used_mb: number;\n  };\n}\n\ninterface ProblemTabsContentProps {\n  problem?: Problem;\n  userSubmissions?: Submission[];\n  latestSubmissionResult?: SubmissionResult | null;\n  className?: string;\n  activeTab?: string;\n  onTabChange?: (value: string) => void;\n  problemId?: string;\n}\n\ninterface User {\n  id: string;\n  username: string;\n  profileImageUrl?: string;\n}\n\ninterface Discussion {\n  id: string;\n  userId: string;\n  problemId: string;\n  content: string;\n  codeSnippet?: string;\n  likes: number;\n  comments: number;\n  createdAt: string;\n  user: User;\n  isLiked?: boolean;\n}\n\ninterface Comment {\n  id: string;\n  postId: string;\n  userId: string;\n  parentId?: string;\n  content: string;\n  createdAt: string;\n  user: User;\n  replies?: Comment[];\n}\n\nconst NestedComment = memo(function NestedComment({\n  comment,\n  discussionId,\n  onReply,\n  depth = 0\n}: {\n  comment: Comment;\n  discussionId: string;\n  onReply: (content: string, parentId?: string) => void;\n  depth: number;\n}) {\n  const [showReplyBox, setShowReplyBox] = useState(false);\n  const [replyContent, setReplyContent] = useState('');\n  const { toast } = useToast();\n\n  const replyMutation = useMutation({\n    mutationFn: async (data: { content: string; parentId?: string }) => {\n      return apiRequest('POST', `/api/community/posts/${discussionId}/comments`, { \n          content: data.content,\n          parent_id: data.parentId \n        });\n    },\n    onSuccess: () => {\n      queryClient.invalidateQueries({ queryKey: [`/api/community/posts/${discussionId}/comments`] });\n      setReplyContent('');\n      setShowReplyBox(false);\n      toast({ title: \"Reply posted successfully!\" });\n    },\n    onError: () => {\n      toast({ title: \"Failed to post reply\", variant: \"destructive\" });\n    },\n  });\n\n  const handleSubmitReply = () => {\n    if (!replyContent.trim()) return;\n    replyMutation.mutate({ content: replyContent, parentId: comment.id });\n  };\n\n  const maxDepth = 3; // Limit nesting depth to avoid infinite nesting\n  const isMaxDepth = depth >= maxDepth;\n\n  return (\n    <div className={`${depth > 0 ? 'ml-6 mt-3' : ''}`} data-testid={`comment-${comment.id}`}>\n      <div className=\"flex items-start space-x-3\">\n        <Avatar className={`${depth > 0 ? 'w-6 h-6' : 'w-8 h-8'}`}>\n          <AvatarImage src={comment.user.profileImageUrl} alt={comment.user.username} />\n          <AvatarFallback>\n            {comment.user.username?.charAt(0).toUpperCase() || 'U'}\n          </AvatarFallback>\n        </Avatar>\n        \n        <div className=\"flex-1\">\n          <div className=\"flex items-center space-x-2 mb-1\">\n            <span className={`font-medium text-foreground ${depth > 0 ? 'text-sm' : 'text-sm'}`}>\n              {comment.user.username}\n            </span>\n            <span className=\"text-xs text-muted-foreground\">\n              {new Date(comment.createdAt).toLocaleDateString()}\n            </span>\n          </div>\n          \n          <p className={`text-foreground whitespace-pre-wrap ${depth > 0 ? 'text-sm' : 'text-sm'}`}>\n            {comment.content}\n          </p>\n          \n          {/* Reply button */}\n          {!isMaxDepth && (\n            <div className=\"mt-2\">\n              <Button\n                variant=\"ghost\"\n                size=\"sm\"\n                onClick={() => setShowReplyBox(!showReplyBox)}\n                className=\"text-xs text-muted-foreground hover:text-blue-500 h-6 px-2\"\n                data-testid={`button-reply-${comment.id}`}\n              >\n                <Reply className=\"w-3 h-3 mr-1\" />\n                Reply\n              </Button>\n            </div>\n          )}\n          \n          {/* Reply input box */}\n          {showReplyBox && (\n            <div className=\"mt-3 space-y-2\">\n              <Textarea\n                placeholder={`Reply to ${comment.user.username}...`}\n                value={replyContent}\n                onChange={(e) => setReplyContent(e.target.value)}\n                rows={2}\n                className=\"resize-none text-sm\"\n                data-testid={`textarea-nested-reply-${comment.id}`}\n              />\n              <div className=\"flex justify-end space-x-2\">\n                <Button\n                  variant=\"outline\"\n                  size=\"sm\"\n                  onClick={() => {\n                    setShowReplyBox(false);\n                    setReplyContent('');\n                  }}\n                  className=\"h-8 text-xs\"\n                  data-testid={`button-cancel-reply-${comment.id}`}\n                >\n                  Cancel\n                </Button>\n                <Button\n                  size=\"sm\"\n                  onClick={handleSubmitReply}\n                  disabled={!replyContent.trim() || replyMutation.isPending}\n                  className=\"h-8 text-xs\"\n                  data-testid={`button-submit-reply-${comment.id}`}\n                >\n                  {replyMutation.isPending ? \"Posting...\" : \"Reply\"}\n                </Button>\n              </div>\n            </div>\n          )}\n          \n          {/* Nested replies */}\n          {comment.replies && comment.replies.length > 0 && (\n            <div className=\"mt-3 space-y-3\">\n              {comment.replies.map((reply) => (\n                <NestedComment\n                  key={reply.id}\n                  comment={reply}\n                  discussionId={discussionId}\n                  onReply={onReply}\n                  depth={depth + 1}\n                />\n              ))}\n            </div>\n          )}\n        </div>\n      </div>\n    </div>\n  );\n});\n\nconst OutputTable = ({ data, title }: { data: any[]; title: string }) => {\n  if (!data || data.length === 0) {\n    return (\n      <div className=\"bg-gray-50 border border-gray-200 rounded-lg p-4\">\n        <h3 className=\"text-sm font-medium text-gray-700 mb-2\">{title}</h3>\n        <div className=\"text-gray-500 italic text-sm\">No data to display</div>\n      </div>\n    );\n  }\n\n  const headers = Object.keys(data[0]);\n\n  return (\n    <div className=\"bg-white border border-gray-200 rounded-lg overflow-hidden\">\n      <div className=\"bg-gray-50 px-4 py-2 border-b border-gray-200\">\n        <h3 className=\"text-sm font-medium text-gray-700\">{title}</h3>\n      </div>\n      <div className=\"overflow-auto max-h-80 min-h-32\">\n        <table className=\"w-full\">\n          <thead className=\"sticky top-0 bg-gray-50 z-10\">\n            <tr className=\"border-b border-gray-200\">\n              {headers.map((header, i) => (\n                <th \n                  key={i} \n                  className=\"px-4 py-2 text-left text-xs font-medium text-gray-500 uppercase tracking-wider\"\n                >\n                  {header}\n                </th>\n              ))}\n            </tr>\n          </thead>\n          <tbody className=\"bg-white divide-y divide-gray-200\">\n            {data.map((row, i) => (\n              <tr key={i} className=\"hover:bg-gray-50\">\n                {headers.map((header, j) => (\n                  <td key={j} className=\"px-4 py-2 text-sm text-gray-900\">\n                    {String(row[header] ?? '')}\n                  </td>\n                ))}\n              </tr>\n            ))}\n          </tbody>\n        </table>\n      </div>\n    </div>\n  );\n};\n\nconst DiscussionCard = memo(function DiscussionCard({ \n  discussion, \n  onLike, \n  onComment \n}: { \n  discussion: Discussion;\n  onLike: (id: string, isLiked: boolean) => void;\n  onComment: (id: string) => void;\n}) {\n  const [showComments, setShowComments] = useState(false);\n  const [replyContent, setReplyContent] = useState('');\n  const { toast } = useToast();\n\n  const { data: comments = [] } = useQuery({\n    queryKey: [`/api/community/posts/${discussion.id}/comments`, discussion.id],\n    enabled: showComments,\n  });\n\n  const replyMutation = useMutation({\n    mutationFn: async (content: string) => {\n      return apiRequest('POST', `/api/community/posts/${discussion.id}/comments`, { content });\n    },\n    onSuccess: () => {\n      queryClient.invalidateQueries({ queryKey: [`/api/community/posts/${discussion.id}/comments`] });\n      queryClient.invalidateQueries({ queryKey: [`/api/problems/${discussion.problemId}/discussions`] });\n      setReplyContent('');\n      toast({ title: \"Reply posted successfully!\" });\n    },\n    onError: () => {\n      toast({ title: \"Failed to post reply\", variant: \"destructive\" });\n    },\n  });\n\n  const handleReply = () => {\n    if (!replyContent.trim()) return;\n    replyMutation.mutate(replyContent);\n  };\n\n  return (\n    <Card className=\"mb-4\" data-testid={`discussion-${discussion.id}`}>\n      <CardContent className=\"p-6\">\n        <div className=\"flex items-start space-x-4\">\n          <Avatar className=\"w-10 h-10\">\n            <AvatarImage src={discussion.user.profileImageUrl} alt={discussion.user.username} />\n            <AvatarFallback>\n              {discussion.user.username?.charAt(0).toUpperCase() || 'U'}\n            </AvatarFallback>\n          </Avatar>\n          \n          <div className=\"flex-1\">\n            <div className=\"flex items-center space-x-2 mb-2\">\n              <span className=\"font-semibold text-foreground\" data-testid={`text-username-${discussion.id}`}>\n                {discussion.user.username}\n              </span>\n              <span className=\"text-sm text-muted-foreground\">\n                {new Date(discussion.createdAt).toLocaleDateString()}\n              </span>\n            </div>\n            \n            <p className=\"text-foreground mb-3 whitespace-pre-wrap\" data-testid={`text-content-${discussion.id}`}>\n              {discussion.content}\n            </p>\n            \n            {discussion.codeSnippet && (\n              <div className=\"bg-muted/50 rounded-lg p-3 mb-3\">\n                <pre className=\"text-sm font-mono whitespace-pre-wrap\" data-testid={`code-snippet-${discussion.id}`}>\n                  {discussion.codeSnippet}\n                </pre>\n              </div>\n            )}\n            \n            <div className=\"flex items-center space-x-4\">\n              <Button\n                variant=\"ghost\"\n                size=\"sm\"\n                onClick={() => onLike(discussion.id, !!discussion.isLiked)}\n                className=\"text-muted-foreground hover:text-red-500\"\n                data-testid={`button-like-${discussion.id}`}\n              >\n                <Heart className={`w-4 h-4 mr-1 ${discussion.isLiked ? 'fill-current text-red-500' : ''}`} />\n                {discussion.likes}\n              </Button>\n              \n              <Button\n                variant=\"ghost\"\n                size=\"sm\"\n                onClick={() => setShowComments(!showComments)}\n                className=\"text-muted-foreground hover:text-blue-500\"\n                data-testid={`button-comments-${discussion.id}`}\n              >\n                <MessageSquare className=\"w-4 h-4 mr-1\" />\n                {discussion.comments}\n              </Button>\n            </div>\n            \n            {showComments && (\n              <div className=\"mt-4 space-y-4\">\n                {/* Reply Input */}\n                <div className=\"flex items-start space-x-3\">\n                  <Textarea\n                    placeholder=\"Write a reply...\"\n                    value={replyContent}\n                    onChange={(e) => setReplyContent(e.target.value)}\n                    rows={2}\n                    className=\"resize-none\"\n                    data-testid={`textarea-reply-${discussion.id}`}\n                  />\n                  <Button \n                    size=\"sm\" \n                    onClick={handleReply}\n                    disabled={!replyContent.trim() || replyMutation.isPending}\n                    data-testid={`button-send-reply-${discussion.id}`}\n                  >\n                    <Send className=\"w-4 h-4\" />\n                  </Button>\n                </div>\n                \n                {/* Comments */}\n                <div className=\"space-y-3 pl-4 border-l-2 border-muted\">\n                  {comments.map((comment: Comment) => (\n                    <NestedComment \n                      key={comment.id} \n                      comment={comment} \n                      discussionId={discussion.id}\n                      onReply={() => {}} // Handled internally by NestedComment\n                      depth={0}\n                    />\n                  ))}\n                </div>\n              </div>\n            )}\n          </div>\n        </div>\n      </CardContent>\n    </Card>\n  );\n});\n\nconst CreateDiscussionDialog = memo(function CreateDiscussionDialog({ \n  problemId, \n  onClose \n}: { \n  problemId: string;\n  onClose: () => void;\n}) {\n  const [content, setContent] = useState('');\n  const [codeSnippet, setCodeSnippet] = useState('');\n  const { toast } = useToast();\n\n  const createMutation = useMutation({\n    mutationFn: async (data: { content: string; codeSnippet?: string }) => {\n      return apiRequest('POST', `/api/problems/${problemId}/discussions`, {\n          content: data.content,\n          codeSnippet: data.codeSnippet || undefined,\n        });\n    },\n    onSuccess: () => {\n      queryClient.invalidateQueries({ queryKey: [`/api/problems/${problemId}/discussions`] });\n      setContent('');\n      setCodeSnippet('');\n      onClose();\n      toast({ title: \"Discussion posted successfully!\" });\n    },\n    onError: () => {\n      toast({ title: \"Failed to create discussion\", variant: \"destructive\" });\n    },\n  });\n\n  const handleSubmit = () => {\n    if (!content.trim()) return;\n    createMutation.mutate({ content, codeSnippet });\n  };\n\n  return (\n    <DialogContent className=\"max-w-2xl\" data-testid=\"dialog-create-discussion\">\n      <DialogHeader>\n        <DialogTitle>Start a New Discussion</DialogTitle>\n      </DialogHeader>\n      <div className=\"space-y-4\">\n        <div>\n          <Textarea\n            placeholder=\"What would you like to discuss about this problem?\"\n            value={content}\n            onChange={(e) => setContent(e.target.value)}\n            rows={4}\n            className=\"resize-none\"\n            data-testid=\"textarea-discussion-content\"\n          />\n        </div>\n        <details>\n          <summary className=\"cursor-pointer text-sm text-muted-foreground hover:text-foreground mb-2\">\n            Add code snippet (optional)\n          </summary>\n          <Textarea\n            placeholder=\"-- Your SQL code here\nSELECT column1, column2\nFROM table_name\nWHERE condition;\"\n            value={codeSnippet}\n            onChange={(e) => setCodeSnippet(e.target.value)}\n            rows={4}\n            className=\"font-mono text-sm resize-none\"\n            data-testid=\"textarea-discussion-code\"\n          />\n        </details>\n        <div className=\"flex justify-end space-x-2\">\n          <Button variant=\"outline\" onClick={onClose} data-testid=\"button-cancel-discussion\">\n            Cancel\n          </Button>\n          <Button \n            onClick={handleSubmit}\n            disabled={!content.trim() || createMutation.isPending}\n            data-testid=\"button-submit-discussion\"\n          >\n            {createMutation.isPending ? \"Posting...\" : \"Post Discussion\"}\n          </Button>\n        </div>\n      </div>\n    </DialogContent>\n  );\n});\n\nconst ProblemTabsContent = memo(function ProblemTabsContent({\n  problem,\n  userSubmissions = [],\n  latestSubmissionResult = null,\n  className,\n  activeTab = \"problem\",\n  onTabChange,\n  problemId,\n}: ProblemTabsContentProps) {\n  const [showCreateDiscussion, setShowCreateDiscussion] = useState(false);\n  const { toast } = useToast();\n  const { user } = useAuth();\n\n  // Removed premium access restrictions for discussions\n\n\n  // Fetch discussions for this problem\n  const { data: discussions = [], isLoading: discussionsLoading } = useQuery({\n    queryKey: [`/api/problems/${problemId}/discussions`],\n    enabled: !!problemId,\n  });\n\n  // Like/unlike discussion mutation\n  const likeMutation = useMutation({\n    mutationFn: async ({ postId, isLiked }: { postId: string; isLiked: boolean }) => {\n      const method = isLiked ? 'DELETE' : 'POST';\n      return apiRequest(method, `/api/community/posts/${postId}/like`);\n    },\n    onSuccess: () => {\n      queryClient.invalidateQueries({ queryKey: [`/api/problems/${problemId}/discussions`] });\n    },\n    onError: () => {\n      toast({ title: \"Failed to update like\", variant: \"destructive\" });\n    },\n  });\n\n  const handleLike = (postId: string, isLiked: boolean) => {\n    likeMutation.mutate({ postId, isLiked });\n  };\n\n  const handleComment = (postId: string) => {\n    // This is handled by the DiscussionCard component\n  };\n\n  return (\n    <div className={`h-full flex flex-col ${className || ''}`}>\n      <Tabs value={activeTab} onValueChange={onTabChange} className=\"flex flex-col h-full\">\n        <TabsList className=\"w-full justify-start border-b bg-transparent p-0 h-auto rounded-none\">\n          <TabsTrigger\n            value=\"problem\"\n            className=\"data-[state=active]:bg-transparent data-[state=active]:border-b-2 data-[state=active]:border-primary rounded-none\"\n            data-testid=\"tab-problem\"\n          >\n            Problem\n          </TabsTrigger>\n          <TabsTrigger\n            value=\"solution\"\n            className=\"data-[state=active]:bg-transparent data-[state=active]:border-b-2 data-[state=active]:border-primary rounded-none\"\n            data-testid=\"tab-solution\"\n          >\n            Answers\n          </TabsTrigger>\n          <TabsTrigger\n            value=\"discussion\"\n            className=\"data-[state=active]:bg-transparent data-[state=active]:border-b-2 data-[state=active]:border-primary rounded-none\"\n            data-testid=\"tab-discussion\"\n          >\n            Discussion\n          </TabsTrigger>\n          <TabsTrigger\n            value=\"submission\"\n            className=\"data-[state=active]:bg-transparent data-[state=active]:border-b-2 data-[state=active]:border-primary rounded-none\"\n            data-testid=\"tab-submission\"\n          >\n            Submissions\n          </TabsTrigger>\n        </TabsList>\n\n        <TabsContent\n          value=\"problem\"\n          className=\"flex-1 overflow-auto p-6 pt-0 mt-0\"\n          data-testid=\"content-problem\"\n        >\n          <ProblemDescriptionTab problem={problem} problemId={problemId} />\n        </TabsContent>\n\n        <TabsContent\n          value=\"solution\"\n          className=\"flex-1 overflow-auto p-6 pt-0 mt-0\"\n          data-testid=\"content-solution\"\n        >\n          {problemId && (\n            <AnswersScreen \n              problemId={problemId}\n            />\n          )}\n        </TabsContent>\n\n        <TabsContent\n          value=\"discussion\"\n          className=\"flex-1 overflow-auto p-6 pt-0 mt-0\"\n          data-testid=\"content-discussion\"\n        >\n          <div className=\"space-y-6\">\n            <div className=\"flex items-center justify-between\">\n              <h3 className=\"text-lg font-semibold text-foreground\">\n                Discussion\n              </h3>\n              <Dialog open={showCreateDiscussion} onOpenChange={setShowCreateDiscussion}>\n                <DialogTrigger asChild>\n                  <Button\n                    variant=\"outline\"\n                    size=\"sm\"\n                    data-testid=\"button-new-discussion\"\n                  >\n                    <MessageSquare className=\"h-4 w-4 mr-2\" />\n                    New Discussion\n                  </Button>\n                </DialogTrigger>\n                  {problemId && (\n                    <CreateDiscussionDialog \n                      problemId={problemId} \n                      onClose={() => setShowCreateDiscussion(false)} \n                    />\n                  )}\n                </Dialog>\n            </div>\n\n            {/* Premium lock removed - discussions now always available */}\n            {false ? (\n              <div className=\"flex flex-col items-center justify-center py-12 space-y-4\">\n                <div className=\"flex items-center justify-center w-16 h-16 bg-amber-100 dark:bg-amber-900/20 rounded-full\">\n                  <Lock className=\"w-8 h-8 text-amber-600 dark:text-amber-500\" />\n                </div>\n                <div className=\"text-center space-y-2\">\n                  <h4 className=\"text-lg font-semibold text-foreground\">\n                    Premium Content Locked\n                  </h4>\n                  <p className=\"text-muted-foreground max-w-md\">\n                    ðŸ”’ Premium subscription required to view and participate in discussions for this problem!\n                  </p>\n                  <div className=\"pt-4\">\n                    <Button variant=\"default\" className=\"bg-amber-600 hover:bg-amber-700\">\n                      <Lock className=\"w-4 h-4 mr-2\" />\n                      Upgrade to Premium\n                    </Button>\n                  </div>\n                </div>\n              </div>\n            ) : (\n              <div className=\"space-y-4\">\n                {discussionsLoading && (\n                  <div className=\"text-center py-8\">\n                    <div className=\"animate-spin rounded-full h-8 w-8 border-b-2 border-primary mx-auto mb-4\"></div>\n                    <p className=\"text-muted-foreground\">Loading discussions...</p>\n                  </div>\n                )}\n\n                {!discussionsLoading && discussions.length === 0 && (\n                  <div className=\"text-center py-8\">\n                    <MessageSquare className=\"h-12 w-12 text-muted-foreground mx-auto mb-4\" />\n                    <h4 className=\"text-base font-semibold text-foreground mb-2\">\n                      No discussions yet\n                    </h4>\n                    <p className=\"text-muted-foreground mb-4\">\n                      Be the first to start a discussion about this problem!\n                    </p>\n                  </div>\n                )}\n\n                {!discussionsLoading && discussions.length > 0 && (\n                  <div className=\"space-y-4\" data-testid=\"discussions-list\">\n                    {discussions.map((discussion: Discussion) => (\n                      <DiscussionCard\n                        key={discussion.id}\n                        discussion={discussion}\n                        onLike={handleLike}\n                        onComment={handleComment}\n                      />\n                    ))}\n                  </div>\n                )}\n              </div>\n            )}\n          </div>\n        </TabsContent>\n\n        <TabsContent\n          value=\"submission\"\n          className=\"flex-1 overflow-auto p-6 pt-0 mt-0\"\n          data-testid=\"content-submission\"\n        >\n          <div className=\"space-y-6\">\n            <div className=\"flex items-center justify-between\">\n              <h3 className=\"text-lg font-semibold text-foreground\">\n                My Submissions\n              </h3>\n              <div className=\"text-sm text-muted-foreground\">\n                {userSubmissions.length} submissions\n              </div>\n            </div>\n\n            {/* Latest Submission Result */}\n            {latestSubmissionResult && (\n              <div className=\"space-y-4\">\n                {/* Result Status Banner */}\n                {latestSubmissionResult.is_correct ? (\n                  <div className=\"bg-green-50 border border-green-200 rounded-lg p-3\" data-testid=\"banner-success\">\n                    <div className=\"flex items-center space-x-2\">\n                      <div className=\"w-2 h-2 bg-green-500 rounded-full\"></div>\n                      <span className=\"text-green-800 font-medium text-sm\">Success!</span>\n                    </div>\n                    <p className=\"text-green-700 text-sm mt-1\">\n                      Your solution is correct! Well done!\n                    </p>\n                  </div>\n                ) : (\n                  <div className=\"bg-red-50 border border-red-200 rounded-lg p-3\" data-testid=\"banner-mismatch\">\n                    <div className=\"flex items-center space-x-2\">\n                      <div className=\"w-2 h-2 bg-red-500 rounded-full\"></div>\n                      <span className=\"text-red-800 font-medium text-sm\">Mismatched</span>\n                    </div>\n                    <p className=\"text-red-700 text-sm mt-1\">\n                      Your query's output doesn't match with the solution's output!\n                    </p>\n                  </div>\n                )}\n\n                {/* Output and Expected Tables */}\n                {latestSubmissionResult.test_results && latestSubmissionResult.test_results.length > 0 && (\n                  <div className=\"space-y-4\">\n                    {(() => {\n                      const mainTestResult = latestSubmissionResult.test_results.find(test => !test.is_hidden) || latestSubmissionResult.test_results[0];\n                      return mainTestResult ? (\n                        <>\n                          <OutputTable \n                            data={mainTestResult.user_output} \n                            title=\"Your Output\" \n                          />\n                          <OutputTable \n                            data={mainTestResult.expected_output} \n                            title=\"Expected Output\" \n                          />\n                        </>\n                      ) : null;\n                    })()}\n                  </div>\n                )}\n              </div>\n            )}\n\n            {/* Submission History */}\n            {userSubmissions.length > 0 ? (\n              <div className=\"space-y-3\">\n                <h4 className=\"text-md font-semibold text-foreground border-t pt-4\">\n                  Submission History\n                </h4>\n                {userSubmissions.map((submission, index) => (\n                  <Card key={submission.id} className=\"p-4\">\n                    <div className=\"flex items-center justify-between\">\n                      <div className=\"flex items-center space-x-3\">\n                        <div\n                          className={`w-3 h-3 rounded-full ${\n                            submission.isCorrect ? \"bg-green-500\" : \"bg-red-500\"\n                          }`}\n                        />\n                        <span className=\"text-sm font-mono\">\n                          Submission {index + 1}\n                        </span>\n                        {submission.isCorrect && (\n                          <Badge className=\"bg-green-100 text-green-800 text-xs\">\n                            âœ“ Accepted\n                          </Badge>\n                        )}\n                      </div>\n                      <div className=\"text-xs text-muted-foreground\">\n                        {new Date(submission.submittedAt).toLocaleDateString()}\n                      </div>\n                    </div>\n                    <div className=\"mt-3 text-sm text-muted-foreground\">\n                      Runtime: {submission.executionTime || \"N/A\"}ms\n                    </div>\n                  </Card>\n                ))}\n              </div>\n            ) : !latestSubmissionResult && (\n              <div className=\"text-center py-8\">\n                <CheckCircle className=\"h-12 w-12 text-muted-foreground mx-auto mb-4\" />\n                <h4 className=\"text-base font-semibold text-foreground mb-2\">\n                  No submissions yet\n                </h4>\n                <p className=\"text-muted-foreground mb-4\">\n                  Submit your first solution to see it here!\n                </p>\n              </div>\n            )}\n          </div>\n        </TabsContent>\n      </Tabs>\n    </div>\n  );\n});\n\nexport default ProblemTabsContent;","size_bytes":29648},"client/src/components/TimerControls.tsx":{"content":"import { memo } from 'react';\nimport { Timer, Play, Pause, Square } from 'lucide-react';\nimport { Button } from '@/components/ui/button';\nimport { useTimer } from '@/hooks/use-timer';\n\ninterface TimerControlsProps {\n  className?: string;\n}\n\nconst TimerControls = memo(function TimerControls({ className }: TimerControlsProps) {\n  const { formattedTime, isRunning, start, pause, reset } = useTimer();\n\n  return (\n    <div className={`flex items-center space-x-1 px-2 py-1 rounded border bg-muted text-muted-foreground border-border ${className || ''}`}>\n      {/* Play/Pause Toggle button */}\n      <Button\n        onClick={isRunning ? pause : start}\n        variant=\"ghost\"\n        size=\"sm\"\n        className={`h-5 w-5 p-0 hover:bg-transparent ${\n          isRunning\n            ? \"text-orange-600 dark:text-orange-400\"\n            : \"text-muted-foreground\"\n        }`}\n        data-testid={\n          isRunning\n            ? \"button-pause-timer\"\n            : \"button-start-timer\"\n        }\n        aria-label={isRunning ? \"Pause timer\" : \"Start timer\"}\n      >\n        {isRunning ? (\n          <Pause className=\"h-3 w-3\" />\n        ) : (\n          <Play className=\"h-3 w-3\" />\n        )}\n      </Button>\n\n      {/* Timer Display */}\n      <div className=\"flex items-center space-x-1\">\n        <Timer\n          className={`h-3 w-3 ${\n            isRunning\n              ? \"text-orange-600 dark:text-orange-400\"\n              : \"text-muted-foreground\"\n          }`}\n        />\n        <span\n          className={`font-mono text-xs ${\n            isRunning\n              ? \"text-orange-600 dark:text-orange-400 font-medium\"\n              : \"text-muted-foreground\"\n          }`}\n          data-testid=\"text-timer\"\n        >\n          {formattedTime}\n        </span>\n      </div>\n\n      {/* Reset button */}\n      <Button\n        onClick={reset}\n        variant=\"ghost\"\n        size=\"sm\"\n        className={`h-5 w-5 p-0 hover:bg-transparent ${\n          isRunning\n            ? \"text-orange-600 dark:text-orange-400\"\n            : \"text-muted-foreground\"\n        }`}\n        data-testid=\"button-reset-timer\"\n        aria-label=\"Reset timer\"\n      >\n        <Square className=\"h-3 w-3\" />\n      </Button>\n    </div>\n  );\n});\n\nexport default TimerControls;","size_bytes":2252},"client/src/hooks/use-codemirror-config.tsx":{"content":"import { useMemo } from 'react';\nimport { sql, PostgreSQL } from '@codemirror/lang-sql';\nimport { autocompletion } from '@codemirror/autocomplete';\nimport { EditorView, keymap, placeholder } from '@codemirror/view';\nimport { defaultKeymap, indentWithTab } from '@codemirror/commands';\nimport { oneDark } from '@codemirror/theme-one-dark';\n\ninterface Problem {\n  question?: {\n    tables?: Array<{ name: string }>;\n  };\n}\n\ninterface UseCodeMirrorConfigOptions {\n  problem?: Problem;\n  isDarkMode: boolean;\n  onRunQuery: () => void;\n}\n\nexport function useCodeMirrorConfig({ problem, isDarkMode, onRunQuery }: UseCodeMirrorConfigOptions) {\n  // Generate dynamic placeholder based on first table in problem\n  const placeholderText = useMemo(() => {\n    if (problem?.question?.tables && problem.question.tables.length > 0) {\n      const firstTable = problem.question.tables[0];\n      const tableName = firstTable.name;\n      return `-- Write your SQL query here\\nSELECT * FROM \"${tableName}\";`;\n    }\n    return \"-- Write your SQL query here\\nSELECT \\n    column1,\\n    column2\\nFROM table_name\\nWHERE condition;\";\n  }, [problem?.question?.tables]);\n\n  // Memoize extensions to prevent recreation on every render\n  const extensions = useMemo(() => [\n    sql({\n      dialect: PostgreSQL,\n      upperCaseKeywords: true,\n      schema: {\n        customers: [\"id\", \"name\", \"email\"],\n        employees: [\"id\", \"name\", \"department\"],\n        orders: [\"id\", \"customer_id\", \"total\"],\n        order_items: [\"id\", \"order_id\", \"price\", \"quantity\"],\n      },\n    }),\n    autocompletion(),\n    EditorView.lineWrapping,\n    placeholder(placeholderText),\n    keymap.of([\n      ...defaultKeymap,\n      indentWithTab,\n      {\n        key: \"Mod-Enter\",\n        run: () => {\n          onRunQuery();\n          return true;\n        },\n      },\n    ]),\n  ], [placeholderText, onRunQuery]);\n\n  // Memoize theme configuration\n  const theme = useMemo(() => {\n    if (isDarkMode) {\n      return [oneDark];\n    }\n    return [\n      EditorView.theme({\n        \"&\": {\n          color: \"hsl(var(--foreground))\",\n          backgroundColor: \"hsl(var(--background))\",\n        },\n        \".cm-content\": {\n          padding: \"16px\",\n          fontSize: \"14px\",\n          fontFamily: \"var(--font-mono)\",\n          minHeight: \"200px\",\n        },\n        \".cm-focused\": {\n          outline: \"none\",\n        },\n        \".cm-editor\": {\n          borderRadius: \"0\",\n        },\n        \".cm-scroller\": {\n          fontFamily: \"var(--font-mono)\",\n        },\n        \".cm-line\": {\n          lineHeight: \"1.5\",\n        },\n        \"&.cm-focused .cm-cursor\": {\n          borderLeftColor: \"hsl(var(--primary))\",\n        },\n        \"&.cm-focused .cm-selectionBackground, .cm-selectionBackground\": {\n          backgroundColor: \"hsl(var(--primary) / 0.2)\",\n        },\n      }),\n    ];\n  }, [isDarkMode]);\n\n  return {\n    extensions,\n    theme,\n    placeholderText,\n  };\n}","size_bytes":2913},"client/src/hooks/use-theme.tsx":{"content":"import { useState, useEffect } from 'react';\n\nexport function useTheme() {\n  // Initialize state only once\n  const [isDarkMode, setIsDarkMode] = useState(() => {\n    if (typeof window !== 'undefined') {\n      return document.documentElement.classList.contains('dark');\n    }\n    return false;\n  });\n\n  useEffect(() => {\n    // Optimized observer with throttling to prevent excessive re-renders\n    let timeoutId: number | null = null;\n    \n    const observer = new MutationObserver(() => {\n      // Throttle updates to prevent rapid re-renders\n      if (timeoutId) {\n        window.clearTimeout(timeoutId);\n      }\n      \n      timeoutId = window.setTimeout(() => {\n        const newIsDarkMode = document.documentElement.classList.contains('dark');\n        setIsDarkMode((prevMode) => {\n          // Only update if the value has actually changed\n          return prevMode !== newIsDarkMode ? newIsDarkMode : prevMode;\n        });\n      }, 50); // Small delay to batch multiple changes\n    });\n\n    observer.observe(document.documentElement, {\n      attributes: true,\n      attributeFilter: ['class'],\n    });\n\n    return () => {\n      observer.disconnect();\n      if (timeoutId) {\n        window.clearTimeout(timeoutId);\n      }\n    };\n  }, []);\n\n  return isDarkMode;\n}","size_bytes":1269},"client/src/hooks/use-timer.tsx":{"content":"import { useState, useRef, useEffect, useCallback } from 'react';\n\nexport interface UseTimerReturn {\n  seconds: number;\n  isRunning: boolean;\n  formattedTime: string;\n  start: () => void;\n  pause: () => void;\n  reset: () => void;\n  toggle: () => void;\n}\n\nexport function useTimer(): UseTimerReturn {\n  const [seconds, setSeconds] = useState(0);\n  const [isRunning, setIsRunning] = useState(false);\n  const timerRef = useRef<number | null>(null);\n\n  // Timer effect - optimized to only run when isRunning changes\n  useEffect(() => {\n    if (isRunning) {\n      timerRef.current = window.setInterval(() => {\n        setSeconds((prev) => prev + 1);\n      }, 1000);\n    } else {\n      if (timerRef.current) {\n        window.clearInterval(timerRef.current);\n        timerRef.current = null;\n      }\n    }\n\n    return () => {\n      if (timerRef.current) {\n        window.clearInterval(timerRef.current);\n      }\n    };\n  }, [isRunning]);\n\n  // Memoized format function\n  const formattedTime = useCallback(() => {\n    const minutes = Math.floor(seconds / 60);\n    const remainingSeconds = seconds % 60;\n    return `${minutes.toString().padStart(2, \"0\")}:${remainingSeconds\n      .toString()\n      .padStart(2, \"0\")}`;\n  }, [seconds])();\n\n  // Timer controls - memoized to prevent recreation\n  const start = useCallback(() => {\n    setIsRunning(true);\n  }, []);\n\n  const pause = useCallback(() => {\n    setIsRunning(false);\n  }, []);\n\n  const reset = useCallback(() => {\n    setIsRunning(false);\n    setSeconds(0);\n  }, []);\n\n  const toggle = useCallback(() => {\n    setIsRunning((prev) => !prev);\n  }, []);\n\n  return {\n    seconds,\n    isRunning,\n    formattedTime,\n    start,\n    pause,\n    reset,\n    toggle,\n  };\n}","size_bytes":1709},"test_sandbox.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nTest script for sandbox database functionality\n\"\"\"\nimport asyncio\nimport sys\nimport os\n\n# Add the current directory to Python path to import api modules\nsys.path.append(os.getcwd())\n\nfrom api.sandbox_manager import sandbox_manager, create_user_sandbox, execute_sandbox_query\nfrom api.database import SessionLocal\n\nasync def test_sandbox_functionality():\n    \"\"\"Test the sandbox database creation and query execution\"\"\"\n    \n    # Test data\n    user_id = \"880be3c3-e093-4274-9294-d20c5f08c583\"  # demo12s user\n    problem_id = \"28640a47-e0c3-4330-86bb-98f21cb6950f\"  # Select All Customers problem\n    \n    print(\"ðŸ§ª Testing Sandbox Database System\")\n    print(\"=\" * 50)\n    \n    try:\n        # Step 1: Create a sandbox\n        print(\"1ï¸âƒ£  Creating sandbox database...\")\n        sandbox = await create_user_sandbox(user_id, problem_id)\n        print(f\"SUCCESS: Sandbox created successfully!\")\n        \n        # Capture attributes before session closes\n        database_name = sandbox.database_name\n        sandbox_id = sandbox.id\n        status = sandbox.status\n        expires_at = sandbox.expires_at\n        \n        print(f\"   - Database Name: {database_name}\")\n        print(f\"   - Status: {status}\")\n        print(f\"   - Expires At: {expires_at}\")\n        \n        # Step 2: Test basic query execution\n        print(\"\\n2ï¸âƒ£  Testing query execution...\")\n        test_query = \"SELECT * FROM customers\"\n        \n        result, status = await execute_sandbox_query(\n            sandbox_id, \n            test_query, \n            timeout_seconds=10\n        )\n        \n        print(f\"SUCCESS: Query executed successfully!\")\n        print(f\"   - Status: {status}\")\n        print(f\"   - Execution Time: {result.get('execution_time_ms', 0)}ms\")\n        print(f\"   - Rows Returned: {result.get('rows_affected', 0)}\")\n        \n        if result.get('result'):\n            print(f\"   - Sample Data: {result['result'][:2]}...\")  # Show first 2 rows\n        \n        # Step 3: Test a more complex query\n        print(\"\\n3ï¸âƒ£  Testing complex query...\")\n        complex_query = \"SELECT name, city FROM customers WHERE city = 'New York'\"\n        \n        result2, status2 = await execute_sandbox_query(\n            sandbox_id, \n            complex_query, \n            timeout_seconds=10\n        )\n        \n        print(f\"SUCCESS: Complex query executed successfully!\")\n        print(f\"   - Status: {status2}\")\n        print(f\"   - Execution Time: {result2.get('execution_time_ms', 0)}ms\")\n        print(f\"   - Filtered Results: {result2.get('result', [])}\")\n        \n        # Step 4: Test query validation\n        print(\"\\n4ï¸âƒ£  Testing query validation...\")\n        validation_query = \"SELECT * FROM customers ORDER BY id\"\n        \n        # This would typically be done through the validation endpoint\n        result3, status3 = await execute_sandbox_query(\n            sandbox_id, \n            validation_query, \n            timeout_seconds=10\n        )\n        \n        print(f\"SUCCESS: Validation query executed successfully!\")\n        print(f\"   - Status: {status3}\")\n        print(f\"   - Data matches expected format: {len(result3.get('result', [])) == 3}\")\n        \n        print(f\"\\nðŸŽ‰ All sandbox tests passed successfully!\")\n        print(f\"ðŸ“Š Summary:\")\n        print(f\"   - Sandbox Database: {database_name}\")\n        print(f\"   - Total Queries Executed: 3\")\n        print(f\"   - All Tests: PASSED\")\n        \n        return True\n        \n    except Exception as e:\n        print(f\"âŒ Error during sandbox testing: {e}\")\n        import traceback\n        traceback.print_exc()\n        return False\n\nif __name__ == \"__main__\":\n    success = asyncio.run(test_sandbox_functionality())\n    if success:\n        print(\"\\nSUCCESS: Sandbox system is working correctly!\")\n        sys.exit(0)\n    else:\n        print(\"\\nâŒ Sandbox system has issues!\")\n        sys.exit(1)","size_bytes":3913},"api/sandbox_manager.py":{"content":"\"\"\"\nSandbox Database System for SQL Learning Platform\n================================================\nThis module provides dynamic database creation, data population,\nresource management, and cleanup for user sandbox environments.\n\"\"\"\n\nimport os\nimport asyncio\nimport uuid\nimport time\nimport logging\nfrom datetime import datetime, timedelta\nfrom typing import Optional, Dict, List, Any, Tuple\nfrom contextlib import asynccontextmanager\nimport psycopg2\nfrom psycopg2 import sql\nimport asyncpg\nfrom sqlalchemy import create_engine, text\nfrom sqlalchemy.orm import sessionmaker\nfrom sqlalchemy.pool import QueuePool\nfrom sqlalchemy.engine.url import make_url\n\nfrom .database import DATABASE_URL, SessionLocal\nfrom .models import UserSandbox, TestCase, ProblemSchema, SandboxStatus, ExecutionStatus\nfrom .schemas import UserSandboxCreate, ExecutionResultCreate\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nclass SandboxConnectionPool:\n    \"\"\"Manages database connections for sandbox environments\"\"\"\n\n    def __init__(self, max_connections: int = 50):\n        self.max_connections = max_connections\n        self.connection_pools: Dict[str, asyncpg.Pool] = {}\n        self._cleanup_lock = asyncio.Lock()\n\n    async def get_pool(self, connection_string: str) -> asyncpg.Pool:\n        \"\"\"Get or create a connection pool for a sandbox database\"\"\"\n        if connection_string not in self.connection_pools:\n            try:\n                pool = await asyncpg.create_pool(\n                    connection_string,\n                    min_size=1,\n                    max_size=5,\n                    command_timeout=30,\n                    server_settings={\n                        'statement_timeout': '30000',  # 30 seconds\n                        'lock_timeout': '10000',  # 10 seconds\n                        'idle_in_transaction_session_timeout':\n                        '30000'  # 30 seconds\n                    })\n                self.connection_pools[connection_string] = pool\n                logger.info(f\"Created connection pool for sandbox database\")\n            except Exception as e:\n                logger.error(f\"Failed to create connection pool: {e}\")\n                raise\n\n        return self.connection_pools[connection_string]\n\n    async def close_pool(self, connection_string: str):\n        \"\"\"Close and remove a connection pool\"\"\"\n        if connection_string in self.connection_pools:\n            pool = self.connection_pools.pop(connection_string)\n            await pool.close()\n            logger.info(f\"Closed connection pool for sandbox database\")\n\n    async def cleanup_all(self):\n        \"\"\"Close all connection pools\"\"\"\n        async with self._cleanup_lock:\n            for connection_string, pool in self.connection_pools.items():\n                await pool.close()\n            self.connection_pools.clear()\n            logger.info(\"Closed all sandbox connection pools\")\n\n\n# Global connection pool manager\nsandbox_pool_manager = SandboxConnectionPool()\n\n\nclass SandboxManager:\n    \"\"\"Manages sandbox database lifecycle and operations\"\"\"\n\n    def __init__(self):\n        self.base_db_url = DATABASE_URL\n        self._parse_database_url()\n\n    def _parse_database_url(self):\n        \"\"\"Parse the main database URL to extract connection details using sqlalchemy\"\"\"\n        try:\n            url = make_url(self.base_db_url)\n            self.db_user = url.username or 'postgres'\n            self.db_password = url.password or ''\n            self.db_host = url.host or 'localhost'\n            self.db_port = url.port or 5432\n            self.db_name = url.database or 'postgres'\n        except Exception as e:\n            logger.error(f\"Failed to parse DATABASE_URL: {e}\")\n            # Fallback to defaults\n            self.db_user = 'postgres'\n            self.db_password = ''\n            self.db_host = 'localhost'\n            self.db_port = 5432\n            self.db_name = 'postgres'\n\n    def _generate_sandbox_name(self, user_id: str, problem_id: str) -> str:\n        \"\"\"Generate a unique sandbox database name\"\"\"\n        # Create a safe database name with timestamp\n        timestamp = int(time.time())\n        short_user_id = user_id[:8]\n        short_problem_id = problem_id[:8]\n        return f\"sandbox_{short_user_id}_{short_problem_id}_{timestamp}\"\n\n    def _build_connection_string(self, database_name: str) -> str:\n        \"\"\"Build connection string for a sandbox database\"\"\"\n        return f\"postgresql://{self.db_user}:{self.db_password}@{self.db_host}:{self.db_port}/{database_name}\"\n\n    async def create_sandbox(self,\n                             user_id: str,\n                             problem_id: str,\n                             expires_in_hours: int = 2) -> UserSandbox:\n        \"\"\"Create a new sandbox database for a user and problem\"\"\"\n        db = SessionLocal()\n\n        try:\n            # Check if user already has an active sandbox for this problem\n            existing_sandbox = db.query(UserSandbox).filter(\n                UserSandbox.user_id == user_id,\n                UserSandbox.problem_id == problem_id,\n                UserSandbox.status == SandboxStatus.ACTIVE.value).first()\n\n            if existing_sandbox:\n                # Extend expiry of existing sandbox\n                existing_sandbox.expires_at = datetime.utcnow() + timedelta(\n                    hours=expires_in_hours)\n                existing_sandbox.last_accessed_at = datetime.utcnow()\n                db.commit()\n                return existing_sandbox\n\n            # Generate unique database name\n            sandbox_db_name = self._generate_sandbox_name(user_id, problem_id)\n            connection_string = self._build_connection_string(sandbox_db_name)\n\n            # Create the sandbox database\n            await self._create_database(sandbox_db_name)\n\n            # Create UserSandbox record\n            sandbox = UserSandbox(user_id=user_id,\n                                  problem_id=problem_id,\n                                  database_name=sandbox_db_name,\n                                  status=SandboxStatus.ACTIVE.value,\n                                  expires_at=datetime.utcnow() +\n                                  timedelta(hours=expires_in_hours),\n                                  last_accessed_at=datetime.utcnow())\n\n            db.add(sandbox)\n            db.commit()\n            db.refresh(sandbox)\n\n            # Populate sandbox with test data\n            await self._populate_sandbox_data(sandbox_db_name, problem_id, db)\n\n            logger.info(\n                f\"Created sandbox {sandbox_db_name} for user {user_id}, problem {problem_id}\"\n            )\n            return sandbox\n\n        except Exception as e:\n            db.rollback()\n            logger.error(f\"Failed to create sandbox: {e}\")\n            raise\n        finally:\n            db.close()\n\n    async def _create_database(self, database_name: str):\n        \"\"\"Create a new PostgreSQL database\"\"\"\n        # Connect to the main database to create new one\n        admin_connection_string = f\"postgresql://{self.db_user}:{self.db_password}@{self.db_host}:{self.db_port}/postgres\"\n\n        try:\n            conn = await asyncpg.connect(admin_connection_string)\n\n            # Create the database\n            await conn.execute(f'CREATE DATABASE \"{database_name}\"')\n\n            await conn.close()\n\n            logger.info(f\"Created database: {database_name}\")\n\n        except asyncpg.DuplicateDatabaseError:\n            logger.warning(f\"Database {database_name} already exists\")\n        except Exception as e:\n            logger.error(f\"Failed to create database {database_name}: {e}\")\n            raise\n\n    async def _populate_sandbox_data(self, sandbox_db_name: str,\n                                     problem_id: str, db):\n        \"\"\"Populate sandbox database with problem schema and test data\"\"\"\n        connection_string = self._build_connection_string(sandbox_db_name)\n\n        try:\n            # Get problem schemas and test cases\n            problem_schemas = db.query(ProblemSchema).filter(\n                ProblemSchema.problem_id == problem_id).all()\n\n            test_cases = db.query(TestCase).filter(\n                TestCase.problem_id == problem_id).all()\n\n            pool = await sandbox_pool_manager.get_pool(connection_string)\n\n            async with pool.acquire() as conn:\n                # Create tables from problem schemas\n                for schema in problem_schemas:\n                    await self._create_table_from_schema(\n                        conn, schema.table_name, schema.schema_definition)\n\n                    # Insert sample data\n                    if schema.sample_data:\n                        await self._insert_sample_data(conn, schema.table_name,\n                                                       schema.sample_data)\n\n                # Create indexes and constraints\n                for schema in problem_schemas:\n                    if schema.indexes:\n                        await self._create_indexes(conn, schema.table_name,\n                                                   schema.indexes)\n\n                    if schema.constraints:\n                        await self._create_constraints(conn, schema.table_name,\n                                                       schema.constraints)\n\n            logger.info(\n                f\"Populated sandbox {sandbox_db_name} with {len(problem_schemas)} tables\"\n            )\n\n        except Exception as e:\n            logger.error(f\"Failed to populate sandbox {sandbox_db_name}: {e}\")\n            raise\n\n    async def _create_table_from_schema(self, conn: asyncpg.Connection,\n                                        table_name: str,\n                                        schema_definition: Dict[str, Any]):\n        \"\"\"Create a table from schema definition\"\"\"\n        try:\n            # Build CREATE TABLE statement\n            columns = []\n            for col_name, col_def in schema_definition.get('columns',\n                                                           {}).items():\n                col_type = col_def.get('type', 'TEXT')\n                nullable = 'NULL' if col_def.get('nullable',\n                                                 True) else 'NOT NULL'\n                default = f\"DEFAULT {col_def['default']}\" if 'default' in col_def else ''\n                primary_key = 'PRIMARY KEY' if col_def.get(\n                    'primary_key', False) else ''\n\n                column_def = f'\"{col_name}\" {col_type} {nullable} {default} {primary_key}'.strip(\n                )\n                columns.append(column_def)\n\n            if columns:\n                create_table_sql = f'CREATE TABLE \"{table_name}\" ({\", \".join(columns)})'\n                await conn.execute(create_table_sql)\n                logger.info(f\"Created table: {table_name}\")\n\n        except Exception as e:\n            logger.error(f\"Failed to create table {table_name}: {e}\")\n            raise\n\n    async def _insert_sample_data(self, conn: asyncpg.Connection,\n                                  table_name: str,\n                                  sample_data: List[Dict[str, Any]]):\n        \"\"\"Insert sample data into a table\"\"\"\n        if not sample_data:\n            return\n\n        try:\n            for row in sample_data:\n                if row:  # Skip empty rows\n                    columns = list(row.keys())\n                    values = list(row.values())\n                    placeholders = [f'${i+1}' for i in range(len(values))]\n\n                    quoted_columns = [f'\"{col}\"' for col in columns]\n                    insert_sql = f'INSERT INTO \"{table_name}\" ({\", \".join(quoted_columns)}) VALUES ({\", \".join(placeholders)})'\n                    await conn.execute(insert_sql, *values)\n\n            logger.info(f\"Inserted {len(sample_data)} rows into {table_name}\")\n\n        except Exception as e:\n            logger.error(\n                f\"Failed to insert sample data into {table_name}: {e}\")\n            raise\n\n    async def _create_indexes(self, conn: asyncpg.Connection, table_name: str,\n                              indexes: List[Dict[str, Any]]):\n        \"\"\"Create indexes for a table\"\"\"\n        for index in indexes:\n            try:\n                index_name = index.get(\n                    'name', f\"idx_{table_name}_{index['columns'][0]}\")\n                columns = index.get('columns', [])\n                unique = 'UNIQUE' if index.get('unique', False) else ''\n\n                if columns:\n                    quoted_columns = [f'\"{col}\"' for col in columns]\n                    create_index_sql = f'CREATE {unique} INDEX \"{index_name}\" ON \"{table_name}\" ({\", \".join(quoted_columns)})'\n                    await conn.execute(create_index_sql)\n                    logger.info(f\"Created index: {index_name}\")\n\n            except Exception as e:\n                logger.error(f\"Failed to create index on {table_name}: {e}\")\n\n    async def _create_constraints(self, conn: asyncpg.Connection,\n                                  table_name: str,\n                                  constraints: List[Dict[str, Any]]):\n        \"\"\"Create constraints for a table\"\"\"\n        for constraint in constraints:\n            try:\n                constraint_type = constraint.get('type')\n                constraint_name = constraint.get(\n                    'name', f\"con_{table_name}_{constraint_type}\")\n\n                if constraint_type == 'foreign_key':\n                    column = constraint['column']\n                    ref_table = constraint['references']['table']\n                    ref_column = constraint['references']['column']\n\n                    alter_sql = f'ALTER TABLE \"{table_name}\" ADD CONSTRAINT \"{constraint_name}\" FOREIGN KEY (\"{column}\") REFERENCES \"{ref_table}\" (\"{ref_column}\")'\n                    await conn.execute(alter_sql)\n                    logger.info(\n                        f\"Created foreign key constraint: {constraint_name}\")\n\n                elif constraint_type == 'check':\n                    check_condition = constraint['condition']\n                    alter_sql = f'ALTER TABLE \"{table_name}\" ADD CONSTRAINT \"{constraint_name}\" CHECK ({check_condition})'\n                    await conn.execute(alter_sql)\n                    logger.info(f\"Created check constraint: {constraint_name}\")\n\n            except Exception as e:\n                logger.error(\n                    f\"Failed to create constraint on {table_name}: {e}\")\n\n    async def execute_query(self,\n                            sandbox_id: str,\n                            query: str,\n                            timeout_seconds: int = 30\n                            ) -> Tuple[Dict[str, Any], ExecutionStatus]:\n        \"\"\"Execute a SQL query in a sandbox environment with resource limits\"\"\"\n        db = SessionLocal()\n\n        try:\n            # Get sandbox details\n            sandbox = db.query(UserSandbox).filter(\n                UserSandbox.id == sandbox_id).first()\n            if not sandbox:\n                raise ValueError(f\"Sandbox {sandbox_id} not found\")\n\n            if sandbox.status != SandboxStatus.ACTIVE.value:\n                raise ValueError(f\"Sandbox {sandbox_id} is not active\")\n\n            # Update last accessed time\n            sandbox.last_accessed_at = datetime.utcnow()\n            db.commit()\n\n            connection_string = self._build_connection_string(\n                sandbox.database_name)\n            pool = await sandbox_pool_manager.get_pool(connection_string)\n\n            start_time = time.time()\n\n            async with pool.acquire() as conn:\n                # Set resource limits with proper None handling\n                timeout_value = timeout_seconds if timeout_seconds is not None else 30\n                await conn.execute(\n                    f\"SET statement_timeout = '{timeout_value}s'\")\n                await conn.execute(\"SET lock_timeout = '10s'\")\n\n                try:\n                    # Execute the query\n                    result = await conn.fetch(query)\n\n                    execution_time_ms = int((time.time() - start_time) * 1000)\n\n                    # Convert result to JSON-serializable format\n                    result_data = []\n                    if result:\n                        columns = list(result[0].keys())\n                        for row in result:\n                            row_dict = {}\n                            for col in columns:\n                                value = row[col]\n                                # Handle non-serializable types\n                                if hasattr(value,\n                                           'isoformat'):  # datetime objects\n                                    value = value.isoformat()\n                                elif isinstance(value, (bytes, bytearray)):\n                                    value = str(value)\n                                row_dict[col] = value\n                            result_data.append(row_dict)\n\n                    return {\n                        'status': ExecutionStatus.SUCCESS,\n                        'execution_time_ms': execution_time_ms,\n                        'result': result_data,\n                        'rows_affected': len(result_data),\n                        'columns': list(result[0].keys()) if result else []\n                    }, ExecutionStatus.SUCCESS\n\n                except asyncpg.QueryCanceledError:\n                    return {\n                        'status': ExecutionStatus.TIMEOUT,\n                        'error':\n                        f'Query execution timed out after {timeout_seconds} seconds',\n                        'execution_time_ms': timeout_seconds * 1000\n                    }, ExecutionStatus.TIMEOUT\n\n                except asyncpg.PostgresError as e:\n                    return {\n                        'status': ExecutionStatus.ERROR,\n                        'error': str(e),\n                        'error_code': e.sqlstate,\n                        'execution_time_ms': int(\n                            (time.time() - start_time) * 1000)\n                    }, ExecutionStatus.ERROR\n\n        except Exception as e:\n            logger.error(\n                f\"Failed to execute query in sandbox {sandbox_id}: {e}\")\n            return {\n                'status': ExecutionStatus.ERROR,\n                'error': str(e),\n                'execution_time_ms': 0\n            }, ExecutionStatus.ERROR\n\n        finally:\n            db.close()\n\n    async def cleanup_expired_sandboxes(self):\n        \"\"\"Clean up expired sandbox databases\"\"\"\n        db = SessionLocal()\n\n        try:\n            # Find expired sandboxes\n            expired_sandboxes = db.query(UserSandbox).filter(\n                UserSandbox.status == SandboxStatus.ACTIVE.value,\n                UserSandbox.expires_at < datetime.utcnow()).all()\n\n            logger.info(\n                f\"Found {len(expired_sandboxes)} expired sandboxes to cleanup\")\n\n            for sandbox in expired_sandboxes:\n                try:\n                    # Mark as cleanup pending\n                    sandbox.status = SandboxStatus.CLEANUP_PENDING.value\n                    sandbox.cleanup_scheduled_at = datetime.utcnow()\n                    db.commit()\n\n                    # Close connection pool\n                    connection_string = self._build_connection_string(\n                        sandbox.database_name)\n                    await sandbox_pool_manager.close_pool(connection_string)\n\n                    # Drop the database\n                    await self._drop_database(sandbox.database_name)\n\n                    # Mark as expired\n                    sandbox.status = SandboxStatus.EXPIRED.value\n                    db.commit()\n\n                    logger.info(f\"Cleaned up sandbox: {sandbox.database_name}\")\n\n                except Exception as e:\n                    logger.error(\n                        f\"Failed to cleanup sandbox {sandbox.database_name}: {e}\"\n                    )\n                    # Continue with other sandboxes\n                    continue\n\n        except Exception as e:\n            logger.error(f\"Failed to cleanup expired sandboxes: {e}\")\n\n        finally:\n            db.close()\n\n    async def _drop_database(self, database_name: str):\n        \"\"\"Drop a sandbox database\"\"\"\n        admin_connection_string = f\"postgresql://{self.db_user}:{self.db_password}@{self.db_host}:{self.db_port}/postgres\"\n\n        try:\n            conn = await asyncpg.connect(admin_connection_string)\n\n            # Terminate active connections to the database\n            await conn.execute(f\"\"\"\n                SELECT pg_terminate_backend(pid)\n                FROM pg_stat_activity\n                WHERE datname = '{database_name}' AND pid <> pg_backend_pid()\n            \"\"\")\n\n            # Drop the database\n            await conn.execute(f'DROP DATABASE IF EXISTS \"{database_name}\"')\n\n            await conn.close()\n\n            logger.info(f\"Dropped database: {database_name}\")\n\n        except Exception as e:\n            logger.error(f\"Failed to drop database {database_name}: {e}\")\n            raise\n\n\n# Global sandbox manager instance\nsandbox_manager = SandboxManager()\n\n\n# Background cleanup task\nasync def start_cleanup_scheduler():\n    \"\"\"Start the background cleanup scheduler\"\"\"\n    while True:\n        try:\n            await sandbox_manager.cleanup_expired_sandboxes()\n            # Run cleanup every 30 minutes\n            await asyncio.sleep(30 * 60)\n        except Exception as e:\n            logger.error(f\"Cleanup scheduler error: {e}\")\n            # Wait 5 minutes before retrying on error\n            await asyncio.sleep(5 * 60)\n\n\n# Utility functions for API integration\nasync def create_user_sandbox(user_id: str, problem_id: str) -> UserSandbox:\n    \"\"\"Create a sandbox for a user and problem\"\"\"\n    return await sandbox_manager.create_sandbox(user_id, problem_id)\n\n\nasync def execute_sandbox_query(\n        sandbox_id: str,\n        query: str,\n        timeout_seconds: int = 30) -> Tuple[Dict[str, Any], ExecutionStatus]:\n    \"\"\"Execute a query in a sandbox\"\"\"\n    return await sandbox_manager.execute_query(sandbox_id, query,\n                                               timeout_seconds)\n\n\nasync def cleanup_sandbox_resources():\n    \"\"\"Cleanup all sandbox resources (for shutdown)\"\"\"\n    await sandbox_pool_manager.cleanup_all()\n","size_bytes":22327},"api/sandbox_routes.py":{"content":"\"\"\"\nDuckDB Sandbox API Routes for SQL Learning Platform\n=================================================\nProvides endpoints for managing DuckDB sandbox environments only.\nPostgreSQL sandboxes have been removed.\n\"\"\"\n\nimport asyncio\nfrom typing import Dict, Any\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom sqlalchemy.orm import Session\n\nfrom .database import get_db\nfrom .auth import get_current_user\nfrom .models import User, TestCase, ExecutionResult, ExecutionStatus\nfrom .schemas import (\n    ExecutionResultCreate, \n    ExecutionResultResponse,\n    TestCaseResponse\n)\nfrom .duckdb_sandbox import DuckDBSandbox, sandbox_manager as duckdb_sandbox_manager\n\n# Create router\nsandbox_router = APIRouter(prefix=\"/api/sandbox\", tags=[\"sandbox\"])\n\n# ============================================================================\n# DUCKDB-BASED SANDBOX ENDPOINTS\n# ============================================================================\n\n@sandbox_router.post(\"/duckdb/{problem_id}/create\", response_model=Dict[str, Any])\nasync def create_duckdb_sandbox(\n    problem_id: str,\n    current_user: User = Depends(get_current_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Create a new DuckDB sandbox for a problem with S3 data\"\"\"\n    try:\n        # Verify problem exists\n        from .models import Problem\n        problem = db.query(Problem).filter(Problem.id == problem_id).first()\n        if not problem:\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND,\n                detail=\"Problem not found\"\n            )\n        \n        # Create DuckDB sandbox\n        sandbox = await duckdb_sandbox_manager.create_sandbox(current_user.id, problem_id)\n        \n        # Setup problem data using S3 datasets only\n        s3_datasets = problem.s3_datasets if hasattr(problem, 's3_datasets') and problem.s3_datasets else None\n        \n        setup_result = await sandbox.setup_problem_data(problem_id, s3_datasets)\n        \n        if not setup_result[\"success\"]:\n            sandbox.cleanup()\n            raise HTTPException(\n                status_code=status.HTTP_400_BAD_REQUEST,\n                detail=setup_result[\"error\"]\n            )\n        \n        # Get table info for user\n        table_info = sandbox.get_table_info()\n        \n        response_data = {\n            \"success\": True,\n            \"problem_id\": problem_id,\n            \"sandbox_type\": \"duckdb\",\n            \"data_source\": setup_result.get(\"data_source\"),\n            \"data_info\": {\n                \"row_count\": setup_result.get(\"row_count\", 0),\n                \"schema\": setup_result.get(\"schema\", []),\n                \"tables\": table_info.get(\"tables\", [])\n            },\n            \"message\": \"DuckDB sandbox created successfully\"\n        }\n        \n        # Sanitize result to prevent JSON serialization errors\n        from .secure_execution import sanitize_json_data\n        return sanitize_json_data(response_data)\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Failed to create DuckDB sandbox: {str(e)}\"\n        )\n\n@sandbox_router.post(\"/duckdb/{problem_id}/execute\", response_model=Dict[str, Any])\nasync def execute_duckdb_query(\n    problem_id: str,\n    query_data: Dict[str, str],\n    current_user: User = Depends(get_current_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Execute SQL query in DuckDB sandbox against S3 data\"\"\"\n    try:\n        # Verify problem exists\n        from .models import Problem\n        problem = db.query(Problem).filter(Problem.id == problem_id).first()\n        if not problem:\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND,\n                detail=\"Problem not found\"\n            )\n        \n        # Get or create sandbox\n        sandbox = duckdb_sandbox_manager.get_sandbox(current_user.id, problem_id)\n        if not sandbox:\n            sandbox = await duckdb_sandbox_manager.create_sandbox(current_user.id, problem_id)\n            # Get S3 datasets for the problem\n            s3_datasets = problem.s3_datasets if hasattr(problem, 's3_datasets') and problem.s3_datasets else None\n            \n            setup_result = await sandbox.setup_problem_data(problem_id, s3_datasets)\n            if not setup_result[\"success\"]:\n                sandbox.cleanup()\n                raise HTTPException(\n                    status_code=status.HTTP_400_BAD_REQUEST,\n                    detail=setup_result[\"error\"]\n                )\n        \n        # Execute query\n        query = query_data.get(\"query\", \"\").strip()\n        if not query:\n            raise HTTPException(\n                status_code=status.HTTP_400_BAD_REQUEST,\n                detail=\"Query is required\"\n            )\n        \n        result = sandbox.execute_query(query)\n        \n        response_data = {\n            \"problem_id\": problem_id,\n            \"query\": query,\n            \"sandbox_type\": \"duckdb\",\n            **result\n        }\n        \n        # Sanitize result to prevent JSON serialization errors\n        from .secure_execution import sanitize_json_data\n        return sanitize_json_data(response_data)\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Failed to execute DuckDB query: {str(e)}\"\n        )\n\n@sandbox_router.get(\"/duckdb/{problem_id}/schema\", response_model=Dict[str, Any])\nasync def get_duckdb_schema(\n    problem_id: str,\n    current_user: User = Depends(get_current_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get schema information for DuckDB sandbox\"\"\"\n    try:\n        # Get existing sandbox\n        sandbox = duckdb_sandbox_manager.get_sandbox(current_user.id, problem_id)\n        if not sandbox:\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND,\n                detail=\"Sandbox not found. Create a sandbox first.\"\n            )\n        \n        # Get table information\n        table_info = sandbox.get_table_info()\n        \n        response_data = {\n            \"problem_id\": problem_id,\n            \"sandbox_type\": \"duckdb\",\n            **table_info\n        }\n        \n        # Sanitize result to prevent JSON serialization errors\n        from .secure_execution import sanitize_json_data\n        return sanitize_json_data(response_data)\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Failed to get DuckDB schema: {str(e)}\"\n        )\n\n@sandbox_router.delete(\"/duckdb/{problem_id}/cleanup\")\nasync def cleanup_duckdb_sandbox(\n    problem_id: str,\n    current_user: User = Depends(get_current_user)\n):\n    \"\"\"Clean up DuckDB sandbox for a specific problem\"\"\"\n    try:\n        duckdb_sandbox_manager.cleanup_sandbox(current_user.id, problem_id)\n        \n        response_data = {\n            \"message\": f\"DuckDB sandbox for problem {problem_id} cleaned up successfully\",\n            \"problem_id\": problem_id,\n            \"sandbox_type\": \"duckdb\"\n        }\n        \n        # Sanitize result to prevent JSON serialization errors\n        from .secure_execution import sanitize_json_data\n        return sanitize_json_data(response_data)\n        \n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Failed to cleanup DuckDB sandbox: {str(e)}\"\n        )\n\n@sandbox_router.get(\"/duckdb/{problem_id}/capabilities\", response_model=Dict[str, Any])\nasync def get_duckdb_capabilities(\n    problem_id: str,\n    current_user: User = Depends(get_current_user)\n):\n    \"\"\"Get DuckDB sandbox capabilities information\"\"\"\n    try:\n        # Create temporary sandbox to get capabilities\n        with DuckDBSandbox() as temp_sandbox:\n            capabilities = temp_sandbox.get_sandbox_capabilities()\n            return {\n                \"success\": True,\n                \"problem_id\": problem_id,\n                \"sandbox_type\": \"duckdb\",\n                **capabilities\n            }\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Failed to get DuckDB capabilities: {str(e)}\"\n        )\n\n@sandbox_router.post(\"/duckdb/{problem_id}/test\", response_model=Dict[str, Any])\nasync def test_duckdb_connection(\n    problem_id: str,\n    current_user: User = Depends(get_current_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Test DuckDB connection and S3 data accessibility\"\"\"\n    try:\n        # Verify problem exists\n        from .models import Problem\n        problem = db.query(Problem).filter(Problem.id == problem_id).first()\n        if not problem:\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND,\n                detail=\"Problem not found\"\n            )\n        \n        # Create temporary sandbox to test connection\n        with DuckDBSandbox() as test_sandbox:\n            # Get S3 datasets for testing\n            s3_datasets = problem.s3_datasets if hasattr(problem, 's3_datasets') and problem.s3_datasets else None\n            \n            if not s3_datasets:\n                return {\n                    \"success\": False,\n                    \"message\": \"No S3 datasets configured for this problem\",\n                    \"problem_id\": problem_id,\n                    \"sandbox_type\": \"duckdb\"\n                }\n            \n            # Test data setup\n            test_result = await test_sandbox.setup_problem_data(problem_id, s3_datasets)\n            \n            return {\n                \"success\": test_result[\"success\"],\n                \"message\": test_result.get(\"message\", \"Connection test completed\"),\n                \"problem_id\": problem_id,\n                \"sandbox_type\": \"duckdb\",\n                \"data_source\": test_result.get(\"data_source\"),\n                \"error\": test_result.get(\"error\") if not test_result[\"success\"] else None\n            }\n            \n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Failed to test DuckDB connection: {str(e)}\"\n        )\n\n","size_bytes":10392},"scripts/init_enhanced_schema.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nInitialize Enhanced Database Schema\n==================================\nCreates the new database tables for the enhanced SQL learning platform.\n\"\"\"\n\nimport os\nimport sys\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom api.database import create_tables, engine\nfrom api.models import Base\n\ndef main():\n    \"\"\"Initialize the enhanced database schema\"\"\"\n    print(\"ðŸš€ Initializing Enhanced Database Schema...\")\n    \n    try:\n        # Create all tables\n        create_tables()\n        print(\"SUCCESS: Enhanced database schema initialized successfully!\")\n        \n        # List all tables\n        from sqlalchemy import inspect\n        inspector = inspect(engine)\n        tables = inspector.get_table_names()\n        \n        print(f\"\\nðŸ“Š Database now contains {len(tables)} tables:\")\n        for table in sorted(tables):\n            print(f\"  â€¢ {table}\")\n            \n        return True\n        \n    except Exception as e:\n        print(f\"âŒ Error initializing schema: {e}\")\n        return False\n\nif __name__ == \"__main__\":\n    success = main()\n    sys.exit(0 if success else 1)","size_bytes":1145},"test_security_fixes.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nTest script to verify SQL query validator security fixes\n\"\"\"\n\nimport sys\nimport os\nsys.path.append('/home/runner/workspace')\n\nfrom api.query_validator import query_validator, QueryValidationError\n\ndef test_security_fixes():\n    \"\"\"Comprehensive test of security fixes\"\"\"\n    \n    print(\"ðŸ”’ Testing SQL Query Validator Security Fixes\")\n    print(\"=\" * 50)\n    \n    # Test 1: Single statement enforcement\n    print(\"\\n1. Testing single statement enforcement...\")\n    \n    # Should pass: Single SELECT\n    result = query_validator.validate_query(\"SELECT * FROM users\")\n    assert result['is_valid'] == True, \"Single SELECT should be valid\"\n    print(\"SUCCESS: Single SELECT statement allowed\")\n    \n    # Should fail: Multiple statements\n    result = query_validator.validate_query(\"SELECT * FROM users; DROP TABLE users;\")\n    assert result['is_valid'] == False, \"Multiple statements should be blocked\"\n    assert any(\"Multiple statements\" in error for error in result['errors']), \"Should detect multiple statements\"\n    print(\"SUCCESS: Multiple statements blocked\")\n    \n    # Test 2: DML/DDL blocking\n    print(\"\\n2. Testing DML/DDL operation blocking...\")\n    \n    # Should fail: INSERT\n    result = query_validator.validate_query(\"INSERT INTO users (name) VALUES ('test')\")\n    assert result['is_valid'] == False, \"INSERT should be blocked\"\n    print(\"SUCCESS: INSERT operations blocked\")\n    \n    # Should fail: UPDATE\n    result = query_validator.validate_query(\"UPDATE users SET name = 'test' WHERE id = 1\")\n    assert result['is_valid'] == False, \"UPDATE should be blocked\"\n    print(\"SUCCESS: UPDATE operations blocked\")\n    \n    # Should fail: DELETE\n    result = query_validator.validate_query(\"DELETE FROM users WHERE id = 1\")\n    assert result['is_valid'] == False, \"DELETE should be blocked\"\n    print(\"SUCCESS: DELETE operations blocked\")\n    \n    # Should fail: CREATE\n    result = query_validator.validate_query(\"CREATE TABLE test (id INT)\")\n    assert result['is_valid'] == False, \"CREATE should be blocked\"\n    print(\"SUCCESS: CREATE operations blocked\")\n    \n    # Should fail: DROP\n    result = query_validator.validate_query(\"DROP TABLE users\")\n    assert result['is_valid'] == False, \"DROP should be blocked\"\n    print(\"SUCCESS: DROP operations blocked\")\n    \n    # Test 3: UNION operations (should be allowed)\n    print(\"\\n3. Testing UNION operations (should be allowed)...\")\n    \n    result = query_validator.validate_query(\"\"\"\n        SELECT name FROM users \n        UNION \n        SELECT name FROM customers\n    \"\"\")\n    assert result['is_valid'] == True, \"UNION should be allowed\"\n    print(\"SUCCESS: UNION operations allowed\")\n    \n    result = query_validator.validate_query(\"\"\"\n        SELECT id, name FROM users \n        UNION ALL \n        SELECT id, name FROM customers\n    \"\"\")\n    assert result['is_valid'] == True, \"UNION ALL should be allowed\"\n    print(\"SUCCESS: UNION ALL operations allowed\")\n    \n    # Test 4: INTERSECT/EXCEPT operations\n    print(\"\\n4. Testing INTERSECT/EXCEPT operations...\")\n    \n    result = query_validator.validate_query(\"\"\"\n        SELECT name FROM users \n        INTERSECT \n        SELECT name FROM customers\n    \"\"\")\n    assert result['is_valid'] == True, \"INTERSECT should be allowed\"\n    print(\"SUCCESS: INTERSECT operations allowed\")\n    \n    result = query_validator.validate_query(\"\"\"\n        SELECT name FROM users \n        EXCEPT \n        SELECT name FROM customers\n    \"\"\")\n    assert result['is_valid'] == True, \"EXCEPT should be allowed\"\n    print(\"SUCCESS: EXCEPT operations allowed\")\n    \n    # Test 5: Comments (should be allowed)\n    print(\"\\n5. Testing SQL comments...\")\n    \n    result = query_validator.validate_query(\"\"\"\n        -- This is a comment\n        SELECT * FROM users -- Another comment\n        WHERE id > 10\n    \"\"\")\n    assert result['is_valid'] == True, \"Comments should be allowed\"\n    print(\"SUCCESS: SQL comments allowed\")\n    \n    result = query_validator.validate_query(\"\"\"\n        /* Multi-line comment */\n        SELECT * FROM users \n        /* Another comment */\n    \"\"\")\n    assert result['is_valid'] == True, \"Multi-line comments should be allowed\"\n    print(\"SUCCESS: Multi-line comments allowed\")\n    \n    # Test 6: Dangerous functions (should be blocked)\n    print(\"\\n6. Testing dangerous function blocking...\")\n    \n    # Should fail: File operations\n    result = query_validator.validate_query(\"SELECT LOAD_FILE('/etc/passwd')\")\n    assert result['is_valid'] == False, \"LOAD_FILE should be blocked\"\n    print(\"SUCCESS: LOAD_FILE operations blocked\")\n    \n    result = query_validator.validate_query(\"SELECT * FROM users INTO OUTFILE '/tmp/test.txt'\")\n    assert result['is_valid'] == False, \"INTO OUTFILE should be blocked\"\n    print(\"SUCCESS: INTO OUTFILE operations blocked\")\n    \n    # Test 7: Complex valid queries\n    print(\"\\n7. Testing complex valid queries...\")\n    \n    result = query_validator.validate_query(\"\"\"\n        WITH user_stats AS (\n            SELECT \n                department,\n                COUNT(*) as user_count,\n                AVG(salary) as avg_salary\n            FROM users u\n            JOIN departments d ON u.dept_id = d.id\n            WHERE u.active = true\n            GROUP BY department\n        )\n        SELECT \n            department,\n            user_count,\n            avg_salary,\n            CASE \n                WHEN avg_salary > 50000 THEN 'High'\n                WHEN avg_salary > 30000 THEN 'Medium'\n                ELSE 'Low'\n            END as salary_bracket\n        FROM user_stats\n        ORDER BY avg_salary DESC\n        LIMIT 10\n    \"\"\")\n    assert result['is_valid'] == True, \"Complex valid query should be allowed\"\n    print(\"SUCCESS: Complex valid queries allowed\")\n    \n    # Test 8: Injection attempts (should be blocked)\n    print(\"\\n8. Testing injection attempt blocking...\")\n    \n    result = query_validator.validate_query(\"SELECT * FROM users WHERE name = '' OR '1'='1'\")\n    assert result['is_valid'] == False, \"SQL injection should be blocked\"\n    print(\"SUCCESS: SQL injection attempts blocked\")\n    \n    print(\"\\n\" + \"=\" * 50)\n    print(\"ðŸŽ‰ ALL SECURITY TESTS PASSED!\")\n    print(\"SUCCESS: Single statement enforcement working\")\n    print(\"SUCCESS: Complete DML/DDL blocking working\") \n    print(\"SUCCESS: UNION/INTERSECT/EXCEPT operations allowed\")\n    print(\"SUCCESS: SQL comments allowed\")\n    print(\"SUCCESS: Dangerous functions blocked\")\n    print(\"SUCCESS: Complex valid queries supported\")\n    print(\"SUCCESS: Injection attempts blocked\")\n    print(\"\\nðŸ”’ SQL Query Validator is now SECURE! ðŸ”’\")\n\nif __name__ == \"__main__\":\n    try:\n        test_security_fixes()\n    except Exception as e:\n        print(f\"\\nâŒ SECURITY TEST FAILED: {e}\")\n        import traceback\n        traceback.print_exc()\n        sys.exit(1)","size_bytes":6832},"api/query_validator.py":{"content":"\"\"\"\nSecure SQL Query Validation System\n=================================\nProvides comprehensive validation for SQL queries including:\n- Syntax validation\n- Dangerous operation detection  \n- Query analysis and security filtering\n- Complete token tree walking for security\n- Execution limits enforcement\n\"\"\"\n\nimport re\nimport logging\nfrom typing import Dict, List, Tuple, Optional, Any, Set\nfrom enum import Enum\nfrom sqlparse import parse, tokens, sql\nfrom sqlparse.engine import FilterStack\nfrom sqlparse.filters import StripWhitespaceFilter\n\nlogger = logging.getLogger(__name__)\n\n\nclass QueryRisk(Enum):\n    \"\"\"Risk levels for SQL queries\"\"\"\n    SAFE = \"safe\"\n    LOW = \"low\"\n    MEDIUM = \"medium\"\n    HIGH = \"high\"\n    CRITICAL = \"critical\"\n\n\nclass QueryValidationError(Exception):\n    \"\"\"Raised when query validation fails\"\"\"\n    pass\n\n\nclass QueryExecutionRequest:\n    \"\"\"Query execution request configuration\"\"\"\n\n    def __init__(self,\n                 query: str,\n                 timeout_seconds: int = 30,\n                 max_rows: int = 1000):\n        if not query.strip():\n            raise ValueError('Query cannot be empty')\n        if len(query) > 10000:\n            raise ValueError('Query too long (max 10000 characters)')\n        if timeout_seconds < 1 or timeout_seconds > 60:\n            raise ValueError('Timeout must be between 1 and 60 seconds')\n        if max_rows < 1 or max_rows > 10000:\n            raise ValueError('Max rows must be between 1 and 10000')\n\n        self.query = query.strip()\n        self.timeout_seconds = timeout_seconds\n        self.max_rows = max_rows\n\n\nclass ExecutionLimits:\n    \"\"\"Execution limits configuration\"\"\"\n\n    def __init__(self,\n                 max_execution_time_seconds: int = 30,\n                 max_memory_mb: int = 256,\n                 max_result_rows: int = 1000,\n                 max_query_length: int = 10000):\n        self.max_execution_time_seconds = max_execution_time_seconds\n        self.max_memory_mb = max_memory_mb\n        self.max_result_rows = max_result_rows\n        self.max_query_length = max_query_length\n\n\nclass SecureSQLValidator:\n    \"\"\"Comprehensive SQL query validator with security checks\"\"\"\n\n    def __init__(self, allowed_tables=None, max_subqueries=2, max_joins=3):\n        # Execution limits\n        self.execution_limits = ExecutionLimits()\n        \n        # Configurable validation limits\n        self.allowed_tables = allowed_tables or set()\n        self.max_subqueries = max_subqueries\n        self.max_joins = max_joins\n\n        # Strictly blocked DML/DDL keywords (anywhere in query)\n        self.blocked_keywords = {\n            # All DML operations that modify data\n            'INSERT',\n            'UPDATE',\n            'DELETE',\n            'MERGE',\n            'UPSERT',\n\n            # All DDL operations that modify structure\n            'CREATE',\n            'ALTER',\n            'DROP',\n            'TRUNCATE',\n            'RENAME',\n\n            # Administrative and control statements\n            'GRANT',\n            'REVOKE',\n            'COMMIT',\n            'ROLLBACK',\n            'SAVEPOINT',\n            'SET',\n            'RESET',\n            'SHOW',\n            'DESCRIBE',\n            'DESC',\n            'EXPLAIN',\n\n            # Database/schema level operations\n            'USE',\n            'ATTACH',\n            'DETACH'\n        }\n\n        # Dangerous system functions and commands\n        self.dangerous_patterns = {\n            # System access functions\n            'system_functions': [\n                r'\\b(?:xp_cmdshell|sp_configure|openrowset|opendatasource)\\b',\n                r'\\b(?:pg_read_file|pg_write_file|copy\\s+.*?\\bfrom\\s+program)\\b',\n                r'\\b(?:load_file|into\\s+outfile|into\\s+dumpfile)\\b',\n                r'\\b(?:exec|execute|eval)\\s*\\(',\n                r'\\b(?:sleep|waitfor|benchmark)\\s*\\(',\n            ],\n\n            # File and OS operations\n            'file_operations': [\n                r'\\binto\\s+(?:outfile|dumpfile)\\b',\n                r'\\bload\\s+data\\s+infile\\b',\n                r'\\bselect\\s+.*?\\binto\\s+(?:outfile|dumpfile)\\b'\n            ],\n\n            # Multi-statement injection attempts\n            'injection_attempts': [\n                r';\\s*(?:DROP|DELETE|UPDATE|INSERT|ALTER|CREATE|TRUNCATE)',\n                r\"'\\s*OR\\s*'[^']*'\\s*=\\s*'[^']*'\",  # Classic SQL injection\n                r'\\bunion\\s+(?:all\\s+)?select\\s+.*?\\bfrom\\s+(?:information_schema|pg_|sys)'\n            ]\n        }\n\n        # Allowed statement types for learning platform (read-only)\n        self.allowed_statements = {\n            'SELECT',\n            'WITH'  # Only read operations allowed\n        }\n\n        # Allowed read-only operations and functions\n        self.allowed_keywords = {\n            'SELECT', 'FROM', 'WHERE', 'GROUP', 'HAVING', 'ORDER', 'LIMIT',\n            'OFFSET', 'JOIN', 'INNER', 'LEFT', 'RIGHT', 'FULL', 'CROSS', 'ON',\n            'USING', 'UNION', 'INTERSECT', 'EXCEPT', 'ALL', 'DISTINCT', 'AS',\n            'CASE', 'WHEN', 'THEN', 'ELSE', 'END', 'AND', 'OR', 'NOT', 'IN',\n            'EXISTS', 'BETWEEN', 'LIKE', 'IS', 'NULL', 'WITH', 'RECURSIVE'\n        }\n\n    def validate_query_with_hardcode_detection(self, query: str,\n                       loaded_tables: Optional[Set[str]] = None) -> Dict[str, Any]:\n        \"\"\"\n        Enhanced validation with comprehensive anti-hardcode detection\n        \n        Args:\n            query: SQL query string to validate\n            loaded_tables: Set of table names available in the sandbox\n            \n        Returns:\n            Dict with validation results including hardcode detection\n        \"\"\"\n        result = self.validate_query(query, loaded_tables)\n        \n        # Add hardcode detection if basic validation passes\n        if result.get('is_valid', False):\n            query_info = result.get('query_info', {})\n            \n            # Layer 1: Static Analysis - Detect hardcoded queries\n            hardcode_result = self.detect_hardcoded_query(query, query_info)\n            \n            # Merge hardcode detection results\n            if hardcode_result['is_hardcoded']:\n                result['is_valid'] = False\n                result['errors'].extend(hardcode_result['errors'])\n                result['warnings'].extend(hardcode_result['warnings'])\n                \n            result['hardcode_detection'] = hardcode_result\n            \n            # Enhanced semantic validation for loaded tables\n            if loaded_tables:\n                enhanced_semantic = self._enhanced_semantic_validation(query, query_info, loaded_tables)\n                if enhanced_semantic['errors']:\n                    result['is_valid'] = False\n                    result['errors'].extend(enhanced_semantic['errors'])\n                result['warnings'].extend(enhanced_semantic['warnings'])\n        \n        return result\n    \n    def _enhanced_semantic_validation(self, query: str, query_info: Dict[str, Any], \n                                    loaded_tables: Set[str]) -> Dict[str, Any]:\n        \"\"\"\n        Enhanced semantic validation specifically for anti-hardcode detection\n        \"\"\"\n        result = {'errors': [], 'warnings': []}\n        \n        query_tables = query_info.get('tables', [])\n        query_upper = query.upper().strip()\n        \n        # Rule 1: Must reference at least one loaded table\n        if not any(table.lower() in {t.lower() for t in loaded_tables} for table in query_tables):\n            if 'FROM' in query_upper or 'JOIN' in query_upper:\n                result['errors'].append(\n                    \"Query must reference tables from the loaded dataset. \"\n                    f\"Available tables: {', '.join(sorted(loaded_tables))}\"\n                )\n            else:\n                result['errors'].append(\n                    \"Query must include FROM clause with dataset tables. \"\n                    \"Constant-only queries are not permitted for data analysis problems.\"\n                )\n        \n        # Rule 2: Must have meaningful column references for data analysis\n        column_refs = self._count_column_references(query)\n        if query_tables and column_refs == 0:\n            # Exception for COUNT(*) which is legitimate\n            if not ('COUNT(*)' in query_upper or 'COUNT( * )' in query_upper):\n                result['errors'].append(\n                    \"Query must reference actual table columns for data analysis. \"\n                    \"Queries that only access table structure without column data are not permitted.\"\n                )\n        \n        # Rule 3: Aggregation queries must have column dependencies\n        agg_functions = ['SUM(', 'AVG(', 'MAX(', 'MIN(']\n        has_agg = any(func in query_upper for func in agg_functions)\n        if has_agg:\n            # Check that aggregation functions contain column references, not just literals\n            agg_has_columns = False\n            for func in agg_functions:\n                if func in query_upper:\n                    # Find the function call and check its contents\n                    start = query_upper.find(func)\n                    if start != -1:\n                        # Simple check: ensure there's a word character after the function\n                        remaining = query_upper[start + len(func):]\n                        if re.search(r'[a-zA-Z_]\\w*', remaining.split(')')[0]):\n                            agg_has_columns = True\n                            break\n            \n            if not agg_has_columns:\n                result['errors'].append(\n                    \"Aggregation functions must operate on actual table columns, not constant values. \"\n                    \"Use column names in SUM(), AVG(), MAX(), MIN() functions.\"\n                )\n        \n        return result\n\n    def validate_query(\n            self,\n            query: str,\n            loaded_tables: Optional[Set[str]] = None) -> Dict[str, Any]:\n        \"\"\"\n        Comprehensive query validation\n        \n        Args:\n            query: SQL query string to validate\n            loaded_tables: Set of table names that are loaded in the sandbox (optional)\n        \n        Returns:\n            Dict with validation results including:\n            - is_valid: bool\n            - risk_level: QueryRisk\n            - errors: List[str]\n            - warnings: List[str]\n            - parsed_query: Dict\n        \"\"\"\n        result = {\n            'is_valid': False,\n            'risk_level': QueryRisk.SAFE,\n            'errors': [],\n            'warnings': [],\n            'parsed_query': {},\n            'allowed_operations': [],\n            'blocked_operations': []\n        }\n\n        try:\n            # Basic sanitization\n            cleaned_query = self._sanitize_query(query)\n\n            # Syntax validation\n            syntax_result = self._validate_syntax(cleaned_query)\n            if not syntax_result['valid']:\n                result['errors'].extend(syntax_result['errors'])\n                result['risk_level'] = QueryRisk.HIGH\n                return result\n\n            # Parse the query\n            parsed = parse(cleaned_query)[0] if parse(cleaned_query) else None\n            if not parsed:\n                result['errors'].append(\"Failed to parse SQL query\")\n                result['risk_level'] = QueryRisk.HIGH\n                return result\n\n            # Extract query information\n            query_info = self._extract_query_info(parsed)\n            result['parsed_query'] = query_info\n\n            # Security validation\n            security_result = self._validate_security(cleaned_query,\n                                                      query_info)\n            result['errors'].extend(security_result['errors'])\n            result['warnings'].extend(security_result['warnings'])\n            result['blocked_operations'] = security_result[\n                'blocked_operations']\n            result['allowed_operations'] = security_result[\n                'allowed_operations']\n\n            # Semantic validation (if loaded tables are provided)\n            if loaded_tables is not None:\n                semantic_result = self._validate_semantics(\n                    query_info, loaded_tables)\n                result['errors'].extend(semantic_result['errors'])\n                result['warnings'].extend(semantic_result['warnings'])\n\n            # Determine final risk level\n            if result['errors']:\n                result['risk_level'] = QueryRisk.CRITICAL\n                result['is_valid'] = False\n            elif result['warnings']:\n                result['risk_level'] = QueryRisk.MEDIUM\n                result['is_valid'] = True\n            else:\n                result['risk_level'] = QueryRisk.SAFE\n                result['is_valid'] = True\n\n        except Exception as e:\n            logger.error(f\"Query validation failed: {e}\")\n            result['errors'].append(f\"Validation error: {str(e)}\")\n            result['risk_level'] = QueryRisk.CRITICAL\n\n        return result\n\n    def _sanitize_query(self, query: str) -> str:\n        \"\"\"Basic query sanitization with enhanced security\"\"\"\n        if not query or not query.strip():\n            raise QueryValidationError(\"Empty query provided\")\n\n        # Remove leading/trailing whitespace\n        cleaned = query.strip()\n\n        # Enhanced length check\n        if len(cleaned) > self.execution_limits.max_query_length:\n            raise QueryValidationError(\n                f\"Query too long (max {self.execution_limits.max_query_length} characters)\"\n            )\n\n        # Remove null bytes and other control characters\n        cleaned = ''.join(char for char in cleaned\n                          if ord(char) >= 32 or char in '\\t\\n\\r')\n\n        return cleaned\n\n    def _validate_syntax(self, query: str) -> Dict[str, Any]:\n        \"\"\"Validate SQL syntax with enhanced security checks\"\"\"\n        result = {'valid': False, 'errors': []}\n\n        try:\n            parsed = parse(query)\n            if not parsed:\n                result['errors'].append(\"Invalid SQL syntax\")\n                return result\n\n            # CRITICAL: Enforce single statement only\n            if len(parsed) > 1:\n                result['errors'].append(\n                    \"Multiple statements not allowed. Only single SELECT or WITH statements permitted.\"\n                )\n                return result\n\n            # Walk the complete token tree to find ALL keywords\n            all_keywords = set()\n            blocked_found = set()\n\n            self._walk_token_tree(parsed[0], all_keywords, blocked_found)\n\n            # Check if any blocked keywords were found\n            if blocked_found:\n                result['errors'].append(\n                    f\"Blocked operations detected: {', '.join(sorted(blocked_found))}\"\n                )\n                return result\n\n            # Validate that first meaningful keyword is allowed\n            first_token = None\n            # Use flattened tokens to ensure we get the very first keyword in order\n            for token in parsed[0].flatten():\n                # Check for any keyword type (including DML, DDL, etc.)\n                if (token.ttype is tokens.Keyword\n                        or token.ttype is tokens.Keyword.DML\n                        or token.ttype is tokens.Keyword.DDL):\n                    potential_token = token.value.upper()\n                    if potential_token in self.allowed_statements:\n                        first_token = potential_token\n                        break\n\n            if not first_token:\n                result['errors'].append(\"No valid SQL statement found\")\n                return result\n\n            if first_token not in self.allowed_statements:\n                result['errors'].append(\n                    f\"Statement type '{first_token}' not allowed. Only SELECT and WITH statements permitted.\"\n                )\n                return result\n\n            result['valid'] = True\n\n        except Exception as e:\n            result['errors'].append(f\"Syntax validation error: {str(e)}\")\n\n        return result\n\n    def _walk_token_tree(self, token, all_keywords: Set[str],\n                         blocked_found: Set[str]):\n        \"\"\"Recursively walk the complete SQL token tree to find all keywords\"\"\"\n        if hasattr(token, 'tokens'):\n            for sub_token in token.tokens:\n                self._walk_token_tree(sub_token, all_keywords, blocked_found)\n        else:\n            # Check for all types of keywords including DML and DDL\n            if (token.ttype is tokens.Keyword\n                    or token.ttype is tokens.Keyword.DML\n                    or token.ttype is tokens.Keyword.DDL):\n                keyword = token.value.upper()\n                all_keywords.add(keyword)\n\n                # Check if this keyword is blocked\n                if keyword in self.blocked_keywords:\n                    blocked_found.add(keyword)\n\n    def _extract_query_info(self, parsed_query) -> Dict[str, Any]:\n        \"\"\"Extract information from parsed query\"\"\"\n        info = {\n            'statement_type': None,\n            'tables': [],\n            'columns': [],\n            'functions': [],\n            'joins': [],\n            'where_clauses': [],\n            'subqueries': 0,\n            'complexity_score': 0\n        }\n\n        try:\n            # Get statement type\n            for token in parsed_query.flatten():\n                if token.ttype is tokens.Keyword:\n                    info['statement_type'] = token.value.upper()\n                    break\n\n            # Extract table names, functions, etc. using improved method\n            extracted_info = self._extract_query_elements(parsed_query)\n            # Merge the extracted info with the existing info structure\n            info.update(extracted_info)\n\n            # Calculate complexity score\n            info['complexity_score'] = self._calculate_complexity(info)\n\n        except Exception as e:\n            logger.warning(f\"Failed to extract query info: {e}\")\n\n        return info\n\n    def _extract_query_elements(self, stmt):\n        \"\"\"\n        Use sqlparse AST to extract tables, functions, joins, subqueries\n        This replaces the old hardcoded approach with proper AST parsing\n        \"\"\"\n        from sqlparse.sql import Identifier, IdentifierList, Function\n        from sqlparse.tokens import Keyword, DML\n        \n        tables = set()\n        functions = set()\n        joins = 0\n        subqueries = 0\n\n        def extract_tokens(token_list):\n            nonlocal joins, subqueries\n\n            for token in token_list:\n                # Handle nested statements\n                if token.is_group:\n                    if hasattr(token, 'tokens'):\n                        # Count subqueries by looking for nested SELECT statements\n                        token_str = str(token).strip().upper()\n                        if token_str.startswith('(') and 'SELECT' in token_str:\n                            subqueries += 1\n                        extract_tokens(token.tokens)\n\n                # Handle functions\n                if isinstance(token, Function):\n                    func_name = token.get_name()\n                    if func_name:\n                        functions.add(func_name.lower())\n\n                # Handle identifiers (tables/columns)\n                elif isinstance(token, Identifier):\n                    name = token.get_real_name()\n                    if name and self._is_likely_table_name(token, token_list):\n                        tables.add(name.lower())\n\n                elif isinstance(token, IdentifierList):\n                    for identifier in token.get_identifiers():\n                        if isinstance(identifier, Identifier):\n                            name = identifier.get_real_name()\n                            if name and self._is_likely_table_name(identifier, token_list):\n                                tables.add(name.lower())\n\n                # Count JOINs\n                elif hasattr(token, 'ttype') and token.ttype is Keyword and \"JOIN\" in token.value.upper():\n                    joins += 1\n\n        extract_tokens(stmt.tokens)\n\n        return {\n            \"tables\": list(tables),\n            \"functions\": list(functions),\n            \"subqueries\": subqueries,\n            \"joins\": joins,\n        }\n\n    def _is_likely_table_name(self, identifier, parent_tokens):\n        \"\"\"\n        Determine if an identifier is likely a table name based on context\n        \"\"\"\n        # Get the identifier as string\n        identifier_str = str(identifier).strip()\n        \n        # Skip if it contains dots (likely column references like o.id)\n        if '.' in identifier_str:\n            return False\n            \n        # Look at the immediate context around this identifier\n        context_tokens = []\n        for token in parent_tokens:\n            if hasattr(token, 'tokens'):\n                for sub_token in token.tokens:\n                    if hasattr(sub_token, 'value'):\n                        context_tokens.append(sub_token.value.upper())\n        \n        context_str = ' '.join(context_tokens[-10:])  # Last 10 tokens for context\n        \n        # Look for keywords that typically precede table names\n        table_indicators = ['FROM', 'JOIN', 'UPDATE', 'INTO']\n        \n        # Check if any table indicator appears right before this identifier\n        for indicator in table_indicators:\n            if indicator in context_str:\n                # Find position of indicator\n                indicator_pos = context_str.rfind(indicator)\n                # Check if our identifier appears after the indicator\n                remaining_context = context_str[indicator_pos + len(indicator):].strip()\n                if remaining_context.startswith(identifier_str.upper()):\n                    return True\n                \n        return False\n\n    def _calculate_complexity(self, info: Dict[str, Any]) -> int:\n        \"\"\"Calculate query complexity score using improved scoring\"\"\"\n        score = 0\n        score += len(info.get('tables', [])) * 2\n        score += info.get('joins', 0) * 3\n        score += len(info.get('functions', [])) * 1\n        score += info.get('subqueries', 0) * 2\n        score += len(info.get('where_clauses', []))\n        return score\n\n    def _validate_security(self, query: str,\n                           query_info: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Perform enhanced security validation checks\"\"\"\n        result = {\n            'errors': [],\n            'warnings': [],\n            'blocked_operations': [],\n            'allowed_operations': []\n        }\n\n        query_upper = query.upper()\n\n        # Check for dangerous system functions and operations\n        for category, patterns in self.dangerous_patterns.items():\n            for pattern in patterns:\n                if re.search(pattern, query_upper, re.IGNORECASE):\n                    result['errors'].append(\n                        f\"Dangerous operation detected: {category}\")\n                    result['blocked_operations'].append(category)\n\n        # Check for allowed operations\n        if query_info.get('statement_type') in self.allowed_statements:\n            result['allowed_operations'].append(query_info['statement_type'])\n\n        # NEW: Configurable table validation\n        for table in query_info.get('tables', []):\n            if self.allowed_tables and table not in self.allowed_tables:\n                result['errors'].append(f\"Table '{table}' is not part of dataset\")\n\n        # NEW: Subquery limit validation\n        subquery_count = query_info.get('subqueries', 0)\n        if subquery_count > self.max_subqueries:\n            result['errors'].append(\n                f\"Too many subqueries ({subquery_count}). Maximum allowed: {self.max_subqueries}\"\n            )\n\n        # NEW: JOIN limit validation\n        join_count = query_info.get('joins', 0)\n        if join_count > self.max_joins:\n            result['errors'].append(\n                f\"Too many joins ({join_count}). Maximum allowed: {self.max_joins}\"\n            )\n\n        # Enhanced complexity warnings\n        complexity_score = query_info.get('complexity_score', 0)\n        if complexity_score > 25:\n            result['warnings'].append(\"Very high query complexity detected\")\n        elif complexity_score > 15:\n            result['warnings'].append(\"High query complexity detected\")\n\n        # Check for too many tables (potential for cartesian product)\n        tables = query_info.get('tables', [])\n        table_count = len(tables) if isinstance(tables, list) else 0\n        if table_count > 6:\n            result['warnings'].append(\n                f\"Query accesses {table_count} tables - ensure proper JOIN conditions to avoid cartesian products\"\n            )\n        elif table_count > 3:\n            result['warnings'].append(\n                \"Query accesses multiple tables - verify JOIN conditions\")\n\n        # Check for potential performance issues\n        if 'LIKE' in query_upper and '%' in query and query.index(\n                '%') == query.index('LIKE') + 5:\n            result['warnings'].append(\n                \"Leading wildcard in LIKE pattern may cause slow performance\")\n\n        # NEW: SELECT * warning\n        if \"select *\" in query.lower():\n            result[\"warnings\"].append(\"Avoid using SELECT * - specify columns explicitly\")\n\n        return result\n\n    def _validate_semantics(self, query_info: Dict[str, Any],\n                            loaded_tables: Set[str]) -> Dict[str, Any]:\n        \"\"\"\n        Validate semantic correctness of query against loaded dataset\n        Enhanced with anti-hardcode detection\n        \n        Args:\n            query_info: Extracted query information\n            loaded_tables: Set of table names loaded in the sandbox\n            \n        Returns:\n            Dict with semantic validation results\n        \"\"\"\n        result = {'errors': [], 'warnings': []}\n\n        query_tables = query_info.get('tables', [])\n\n        # Check if query has no tables (likely a constant-only query)\n        if not query_tables:\n            if query_info.get('statement_type') == 'SELECT':\n                result['errors'].append(\n                    \"Query must reference at least one table from the loaded dataset. Constant-only queries are not allowed for dataset problems.\"\n                )\n            return result\n\n        # Check if all referenced tables are in the loaded dataset\n        missing_tables = []\n        for table in query_tables:\n            # Convert to lowercase for case-insensitive comparison\n            if table.lower() not in {t.lower() for t in loaded_tables}:\n                missing_tables.append(table)\n\n        if missing_tables:\n            available_tables = ', '.join(sorted(loaded_tables))\n            result['errors'].append(\n                f\"Query references unknown table(s): {', '.join(missing_tables)}. \"\n                f\"Available tables: {available_tables}\")\n\n        # Warning for queries that don't use all available tables (optional enhancement)\n        unused_tables = set(loaded_tables) - {t.lower() for t in query_tables}\n        if len(unused_tables) > 0 and len(loaded_tables) > 1:\n            result['warnings'].append(\n                f\"Query doesn't use all available tables. Unused: {', '.join(sorted(unused_tables))}\"\n            )\n\n        return result\n\n    def detect_hardcoded_query(self, query: str, query_info: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Layer 1: Static Analysis - Detect hardcoded queries that don't properly analyze data\n        \n        Returns:\n            Dict with detection results including errors and confidence score\n        \"\"\"\n        result = {\n            'is_hardcoded': False,\n            'confidence': 0.0,\n            'errors': [],\n            'warnings': [],\n            'reasons': []\n        }\n        \n        query_upper = query.upper().strip()\n        query_tables = query_info.get('tables', [])\n        \n        # Pattern 1: Pure constant queries (SELECT 355, SELECT 'hello', etc.)\n        if re.match(r'^\\s*SELECT\\s+[\\d\\'\\\"\\w\\s,\\(\\)\\.]+(\\s+AS\\s+[\\w\\\"\\'\\`]+)?\\s*;?\\s*$', query_upper):\n            # Check if it contains any table references\n            if not query_tables and 'FROM' not in query_upper:\n                result['is_hardcoded'] = True\n                result['confidence'] = 1.0\n                result['errors'].append(\"Pure constant query detected - must analyze actual data\")\n                result['reasons'].append(\"No table references, only literal values\")\n                return result\n        \n        # Pattern 2: SELECT literals FROM table LIMIT 1 (common cheat pattern)\n        if 'LIMIT 1' in query_upper or 'LIMIT\\s+1' in query_upper:\n            # Check if SELECT clause contains only literals/constants\n            select_match = re.search(r'SELECT\\s+(.*?)\\s+FROM', query_upper)\n            if select_match:\n                select_clause = select_match.group(1).strip()\n                # Check if select clause is primarily numeric literals\n                if re.match(r'^[\\d\\s,\\(\\)\\.]+$', select_clause.replace(' AS ', ' ').replace('\"', '').replace(\"'\", '')):\n                    result['is_hardcoded'] = True\n                    result['confidence'] = 0.9\n                    result['errors'].append(\"Suspected hardcoded query: literal values with LIMIT 1\")\n                    result['reasons'].append(\"Selecting literal values with artificial LIMIT\")\n                    return result\n        \n        # Pattern 3: Check for minimal column references\n        column_refs = self._count_column_references(query)\n        if query_tables and column_refs == 0:\n            result['is_hardcoded'] = True\n            result['confidence'] = 0.8\n            result['errors'].append(\"Query references tables but no actual columns - likely hardcoded\")\n            result['reasons'].append(\"Table referenced but no column access detected\")\n            return result\n        \n        # Pattern 4: Aggregation functions with no column references\n        agg_functions = ['SUM', 'COUNT', 'AVG', 'MAX', 'MIN']\n        has_agg = any(func in query_upper for func in agg_functions)\n        if has_agg and column_refs == 0 and query_tables:\n            # Exception: COUNT(*) is legitimate\n            if not ('COUNT(*)' in query_upper or 'COUNT( * )' in query_upper):\n                result['warnings'].append(\"Aggregation function found but no column references - verify legitimacy\")\n                result['confidence'] = 0.6\n                result['reasons'].append(\"Aggregation without clear column access\")\n        \n        # Pattern 5: VALUES clause usage (often used for hardcoding)\n        if 'VALUES' in query_upper and query_tables:\n            result['warnings'].append(\"VALUES clause detected - ensure it's for legitimate purpose\")\n            result['confidence'] = 0.4\n            result['reasons'].append(\"VALUES clause present\")\n        \n        return result\n    \n    def _count_column_references(self, query: str) -> int:\n        \"\"\"\n        Count probable column references in a query\n        This is a heuristic approach - not perfect but catches most cases\n        \"\"\"\n        # Remove string literals to avoid false positives\n        query_clean = re.sub(r\"'[^']*'\", \"\", query)\n        query_clean = re.sub(r'\"[^\"]*\"', \"\", query_clean)\n        \n        # Look for patterns that suggest column access\n        column_patterns = [\n            r'\\b\\w+\\.\\w+\\b',  # table.column\n            r'\\bSUM\\s*\\(\\s*\\w+\\s*\\)',  # SUM(column)\n            r'\\bCOUNT\\s*\\(\\s*\\w+\\s*\\)',  # COUNT(column)\n            r'\\bAVG\\s*\\(\\s*\\w+\\s*\\)',  # AVG(column)\n            r'\\bMAX\\s*\\(\\s*\\w+\\s*\\)',  # MAX(column)\n            r'\\bMIN\\s*\\(\\s*\\w+\\s*\\)',  # MIN(column)\n            r'\\bWHERE\\s+\\w+',  # WHERE column\n            r'\\bGROUP\\s+BY\\s+\\w+',  # GROUP BY column\n            r'\\bORDER\\s+BY\\s+\\w+',  # ORDER BY column\n        ]\n        \n        count = 0\n        for pattern in column_patterns:\n            matches = re.findall(pattern, query_clean, re.IGNORECASE)\n            count += len(matches)\n        \n        return count\n\n    def get_safe_query_suggestions(self, query: str) -> List[str]:\n        \"\"\"Provide suggestions for making query safer\"\"\"\n        suggestions = []\n\n        query_upper = query.upper()\n\n        # Check for missing WHERE clauses\n        if 'DELETE FROM' in query_upper and 'WHERE' not in query_upper:\n            suggestions.append(\n                \"Add WHERE clause to DELETE statement for safety\")\n\n        if 'UPDATE' in query_upper and 'SET' in query_upper and 'WHERE' not in query_upper:\n            suggestions.append(\n                \"Add WHERE clause to UPDATE statement for safety\")\n\n        # Check for SELECT *\n        if 'SELECT *' in query_upper:\n            suggestions.append(\n                \"Consider specifying column names instead of using SELECT *\")\n\n        # Check for potential inefficiencies\n        if 'LIKE' in query_upper and '%' in query:\n            suggestions.append(\n                \"LIKE with leading wildcards can be slow - consider alternatives\"\n            )\n\n        return suggestions\n\n\nclass QuerySanitizer:\n    \"\"\"Enhanced query sanitization utilities\"\"\"\n\n    @staticmethod\n    def normalize_whitespace(query: str) -> str:\n        \"\"\"Normalize whitespace in query\"\"\"\n        return re.sub(r'\\s+', ' ', query.strip())\n\n    @staticmethod\n    def add_execution_limits(query: str, limits: ExecutionLimits) -> str:\n        \"\"\"Add execution limits to query if not present\"\"\"\n        query = query.rstrip(';').strip()\n\n        # Add LIMIT clause if not present for SELECT statements\n        if 'SELECT' in query.upper() and 'LIMIT' not in query.upper():\n            query += f' LIMIT {limits.max_result_rows}'\n\n        return query\n\n    @staticmethod\n    def validate_execution_request(\n            request_data: dict) -> QueryExecutionRequest:\n        \"\"\"Validate execution request using Pydantic\"\"\"\n        try:\n            return QueryExecutionRequest(**request_data)\n        except Exception as e:\n            raise QueryValidationError(f\"Invalid request format: {str(e)}\")\n\n\nclass ExecutionLimitEnforcer:\n    \"\"\"Enforces execution limits during query execution\"\"\"\n\n    def __init__(self, limits: ExecutionLimits):\n        self.limits = limits\n\n    def prepare_query_with_limits(self, query: str) -> str:\n        \"\"\"Prepare query with enforced limits\"\"\"\n        # Add row limit if not present\n        if 'LIMIT' not in query.upper() and 'SELECT' in query.upper():\n            query = query.rstrip(';')\n            query += f' LIMIT {self.limits.max_result_rows}'\n\n        return query\n\n    def validate_execution_time(self, start_time: float,\n                                current_time: float) -> bool:\n        \"\"\"Check if execution time exceeds limits\"\"\"\n        return (current_time -\n                start_time) <= self.limits.max_execution_time_seconds\n\n\n# Global validator instance\nquery_validator = SecureSQLValidator()\n","size_bytes":34940},"api/secure_execution.py":{"content":"\"\"\"\nSecure Query Execution System - High Performance\n===============================================\nUltra-optimized version focused on submission speed while maintaining API compatibility.\n\"\"\"\n\nimport asyncio\nimport logging\nimport json\nimport math\nimport hashlib\nimport time\nfrom typing import Dict, List, Any, Optional, Tuple, Set\nfrom datetime import datetime, timedelta\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy import text, create_engine\nfrom contextlib import asynccontextmanager\nfrom functools import lru_cache\nfrom concurrent.futures import ThreadPoolExecutor\nimport threading\nimport re\n\nfrom .query_validator import query_validator, QueryValidationError, QueryRisk\nfrom .test_validator import optimized_test_validator, ComparisonMode\nfrom .duckdb_sandbox import DuckDBSandboxManager, DuckDBSandbox\nfrom .models import (User, Problem, TestCase, Submission, ExecutionResult,\n                     ExecutionStatus)\nfrom .schemas import (ExecutionResultCreate, DetailedSubmissionResponse,\n                      TestCaseResponse)\n\nlogger = logging.getLogger(__name__)\n\n\ndef sanitize_json_data(data: Any, seen: set = None) -> Any:\n    \"\"\"Comprehensive JSON sanitization for FastAPI responses with UTF-8 safety\"\"\"\n    if seen is None:\n        seen = set()\n\n    # Cycle detection for nested structures\n    data_id = id(data)\n    if data_id in seen:\n        return None\n\n    # Handle None first\n    if data is None:\n        return None\n\n    # Handle basic JSON-safe types\n    if isinstance(data, (bool, int)):\n        return data\n    elif isinstance(data, str):\n        # Ensure string is UTF-8 safe\n        try:\n            data.encode('utf-8')\n            return data\n        except UnicodeEncodeError:\n            return data.encode('utf-8', errors='replace').decode('utf-8')\n\n    # Add to seen set for complex types\n    seen.add(data_id)\n\n    try:\n        # Handle float with NaN/Infinity\n        if isinstance(data, float):\n            if math.isnan(data):\n                return None\n            elif math.isinf(data):\n                return \"Infinity\" if data > 0 else \"-Infinity\"\n            else:\n                return data\n\n        # Handle bytes/bytearray/memoryview - convert to UTF-8 string or base64\n        elif isinstance(data, (bytes, bytearray, memoryview)):\n            if isinstance(data, memoryview):\n                data = data.tobytes()\n            elif isinstance(data, bytearray):\n                data = bytes(data)\n\n            # Try multiple encodings\n            for encoding in ['utf-8', 'latin-1', 'cp1252', 'ascii']:\n                try:\n                    return data.decode(encoding)\n                except UnicodeDecodeError:\n                    continue\n\n            # Final fallback: base64 encoding for binary data\n            import base64\n            return f\"base64:{base64.b64encode(data).decode('ascii')}\"\n\n        # Handle dict - sanitize keys and values\n        elif isinstance(data, dict):\n            return {\n                str(k): sanitize_json_data(v, seen)\n                for k, v in data.items()\n            }\n\n        # Handle list/tuple/set - convert to list with sanitized elements\n        elif isinstance(data, (list, tuple, set)):\n            return [sanitize_json_data(item, seen) for item in data]\n\n        # Handle datetime objects\n        elif hasattr(data, 'isoformat'):  # datetime, date, time\n            try:\n                return data.isoformat()\n            except:\n                return str(data)\n\n        # Handle Decimal\n        elif hasattr(data,\n                     '__class__') and data.__class__.__name__ == 'Decimal':\n            try:\n                if data.is_finite():\n                    return float(data)\n                else:\n                    return str(data)\n            except:\n                return str(data)\n\n        # Handle UUID\n        elif hasattr(data, '__class__') and data.__class__.__name__ == 'UUID':\n            return str(data)\n\n        # Handle numpy types if available\n        elif hasattr(data, '__module__'\n                     ) and data.__module__ and 'numpy' in data.__module__:\n            try:\n                # Handle numpy scalars\n                if hasattr(data, 'item'):\n                    return sanitize_json_data(data.item(), seen)\n                # Handle numpy arrays\n                elif hasattr(data, 'tolist'):\n                    return sanitize_json_data(data.tolist(), seen)\n                else:\n                    return str(data)\n            except:\n                return str(data)\n\n        # Handle pandas types if available\n        elif hasattr(data, '__module__'\n                     ) and data.__module__ and 'pandas' in data.__module__:\n            try:\n                # Handle DataFrame\n                if hasattr(data, 'to_dict'):\n                    return sanitize_json_data(data.to_dict('records'), seen)\n                # Handle Series\n                elif hasattr(data, 'tolist'):\n                    return sanitize_json_data(data.tolist(), seen)\n                # Handle Timestamp/NaT\n                elif hasattr(data, 'isoformat'):\n                    return data.isoformat()\n                else:\n                    return str(data)\n            except:\n                return str(data)\n\n        # Handle Path-like objects\n        elif hasattr(data, '__fspath__'):\n            return str(data)\n\n        # Handle Exception objects\n        elif isinstance(data, Exception):\n            return str(data)\n\n        # Default fallback - convert to string\n        else:\n            return str(data)\n\n    finally:\n        # Remove from seen set when done processing\n        seen.discard(data_id)\n\n\nclass _FastSecurityChecker:\n    \"\"\"Minimal security checker optimized for speed\"\"\"\n\n    def __init__(self):\n        # Only essential security checks for maximum speed\n        self.forbidden_keywords = {\n            'DROP', 'DELETE', 'INSERT', 'UPDATE', 'CREATE', 'ALTER', 'TRUNCATE'\n        }\n\n    def is_safe(self, query: str) -> Tuple[bool, List[str]]:\n        \"\"\"Ultra-fast security check\"\"\"\n        query_upper = query.upper().strip()\n\n        # Fast whitelist check\n        if not query_upper.startswith(('SELECT', 'WITH')):\n            first_word = query_upper.split()[0] if query_upper else 'UNKNOWN'\n            return False, [\n                f\"Only SELECT and WITH statements allowed, found: {first_word}\"\n            ]\n\n        # Fast keyword check\n        query_words = set(query_upper.split())\n        forbidden_found = query_words & self.forbidden_keywords\n        if forbidden_found:\n            return False, [\n                f\"Forbidden operations detected: {', '.join(forbidden_found)}\"\n            ]\n\n        return True, []\n\n\nclass _MinimalCache:\n    \"\"\"Minimal cache implementation for maximum speed\"\"\"\n\n    def __init__(self, max_size: int = 500):\n        self.data = {}\n        self.max_size = max_size\n        self._lock = threading.Lock()\n\n    def get(self, key: str) -> Optional[Any]:\n        with self._lock:\n            return self.data.get(key)\n\n    def set(self, key: str, value: Any):\n        with self._lock:\n            if len(self.data) >= self.max_size:\n                # Remove oldest (simple FIFO)\n                oldest_key = next(iter(self.data))\n                del self.data[oldest_key]\n            self.data[key] = value\n\n    def make_key(self, query: str, problem_id: str) -> str:\n        return f\"{problem_id}:{hashlib.md5(query.encode()).hexdigest()[:16]}\"\n\n\nclass SecureQueryExecutor:\n    \"\"\"Ultra-fast secure query executor optimized for submission speed\"\"\"\n\n    def __init__(self):\n        self.max_execution_time = 30\n        self.max_memory_mb = 256\n        self.max_result_rows = 10000\n        self.sandbox_manager = DuckDBSandboxManager()\n\n        # Minimal components for maximum speed\n        self._security_checker = _FastSecurityChecker()\n        self._cache = _MinimalCache()\n        self._thread_pool = ThreadPoolExecutor(\n            max_workers=2)  # Reduced for lower overhead\n\n    async def submit_solution(self, user_id: str, problem_id: str, query: str,\n                              db: Session) -> Dict[str, Any]:\n        \"\"\"Ultra-optimized submission with minimal overhead\"\"\"\n        start_time = time.time()\n\n        try:\n            # STEP 1: Ultra-fast security check (no external calls)\n            is_safe, security_errors = self._security_checker.is_safe(query)\n            if not is_safe:\n                return self._create_error_response(security_errors[0])\n\n            # STEP 2: Fast cache check (skip for now to avoid complexity)\n            cache_key = self._cache.make_key(query, problem_id)\n            cached = self._cache.get(cache_key)\n            if cached and cached.get('is_correct'):\n                # Fast submission creation from cache\n                submission = self._create_submission_fast(\n                    user_id, problem_id, query, cached, db)\n                cached['submission_id'] = submission.id\n                return cached\n\n            # STEP 3: Get sandbox (reuse existing if possible)\n            sandbox = await self._get_sandbox_fast(user_id, problem_id, db)\n            if not sandbox:\n                return self._create_error_response(\n                    'Failed to create execution sandbox')\n\n            # STEP 4: Execute query with minimal validation\n            test_results = await self._execute_minimal_validation(\n                sandbox, problem_id, query, db)\n\n            # STEP 5: Fast scoring\n            final_score = self._calculate_score_fast(test_results)\n            is_correct = final_score['overall_score'] >= 95.0\n\n            # STEP 6: Create submission (minimal data)\n            submission = Submission(\n                user_id=user_id,\n                problem_id=problem_id,\n                query=query,\n                is_correct=is_correct,\n                execution_time=final_score['avg_execution_time'])\n\n            db.add(submission)\n            db.commit()\n            db.refresh(submission)\n\n            # STEP 7: Build minimal response\n            result = {\n                'success': True,\n                'submission_id': submission.id,\n                'is_correct': is_correct,\n                'score': final_score['overall_score'],\n                'feedback': final_score['feedback'],\n                'test_results': test_results,\n                'passed_tests': final_score['passed_count'],\n                'total_tests': final_score['total_count'],\n                'execution_stats': {\n                    'avg_time_ms': final_score['avg_execution_time'],\n                    'max_time_ms': final_score['max_execution_time'],\n                    'total_time_ms': int((time.time() - start_time) * 1000)\n                },\n                'security_warnings': []\n            }\n\n            # STEP 8: Cache successful results\n            if is_correct:\n                self._cache.set(cache_key, result)\n\n            # STEP 9: Async user progress update (fire and forget)\n            if is_correct:\n                self._update_user_progress_background(user_id, problem_id, db)\n\n            return result\n\n        except Exception as e:\n            logger.error(f\"Fast submission failed: {e}\")\n            return self._create_error_response(f'Execution error: {str(e)}')\n\n    async def test_query(self,\n                         user_id: str,\n                         problem_id: str,\n                         query: str,\n                         db: Session,\n                         include_hidden_tests: bool = False) -> Dict[str, Any]:\n        \"\"\"Ultra-fast query testing\"\"\"\n        try:\n            # Fast security check\n            is_safe, security_errors = self._security_checker.is_safe(query)\n            if not is_safe:\n                return {\n                    'success': False,\n                    'feedback': security_errors,\n                    'security_violations': security_errors,\n                    'test_results': []\n                }\n\n            # Get sandbox fast\n            sandbox = await self._get_sandbox_fast(user_id, problem_id, db)\n            if not sandbox:\n                return {\n                    'success': False,\n                    'feedback': ['Failed to create execution sandbox'],\n                    'test_results': []\n                }\n\n            # Execute with minimal validation\n            query_result = await self._execute_query_fast(sandbox, query)\n\n            if not query_result.get('success'):\n                return {\n                    'success':\n                    False,\n                    'feedback':\n                    [query_result.get('error', 'Query execution failed')],\n                    'test_results': []\n                }\n\n            # Minimal test validation\n            test_results = await self._validate_minimal(\n                sandbox, problem_id, query, query_result.get('results', []),\n                db)\n\n            return {\n                'success': True,\n                'feedback': self._generate_feedback_fast(test_results),\n                'test_results': test_results,\n                'security_warnings': [],\n                'query_result': {\n                    'rows_returned': len(query_result.get('results', [])),\n                    'execution_time_ms':\n                    query_result.get('execution_time_ms', 0)\n                },\n                'execution_status': 'SUCCESS'\n            }\n\n        except Exception as e:\n            logger.error(f\"Fast test failed: {e}\")\n            return {\n                'success': False,\n                'feedback': [f'Test execution error: {str(e)}'],\n                'test_results': []\n            }\n\n    async def _get_sandbox_fast(self, user_id: str, problem_id: str,\n                                db: Session) -> Optional[DuckDBSandbox]:\n        \"\"\"Ultra-fast sandbox retrieval with proper S3 data loading\"\"\"\n        try:\n            # Try existing sandbox first\n            sandbox = self.sandbox_manager.get_sandbox(user_id, problem_id)\n            if sandbox:\n                # Check if sandbox needs data reloading (from original logic)\n                problem = db.query(Problem).filter(\n                    Problem.id == problem_id).first()\n                if problem and hasattr(problem, 's3_datasets') and problem.s3_datasets:\n                    # Verify if any tables exist\n                    table_info = sandbox.get_table_info()\n                    existing_tables = [table.get('name') for table in table_info.get('tables', [])]\n\n                    # Check if we need to reload data\n                    needs_reload = len(existing_tables) == 0\n                    if not needs_reload and isinstance(problem.s3_datasets, list):\n                        # Check if all expected tables exist\n                        expected_tables = [dataset.get('table_name') for dataset in problem.s3_datasets if dataset.get('table_name')]\n                        needs_reload = not all(table in existing_tables for table in expected_tables)\n\n                    if needs_reload:\n                        logger.info(\n                            f\"Reloading S3 data for existing sandbox - missing tables\"\n                        )\n                        # Properly await async operation\n                        setup_result = await sandbox.setup_problem_data(\n                            problem_id, problem.s3_datasets)\n                        if not setup_result.get('success', False):\n                            logger.error(\n                                f\"Failed to reload problem data: {setup_result.get('error')}\"\n                            )\n\n                return sandbox\n\n            # Get problem info for new sandbox\n            problem = db.query(Problem).filter(\n                Problem.id == problem_id).first()\n            if not problem:\n                logger.error(f\"Problem {problem_id} not found\")\n                return None\n\n            # Create sandbox properly with await\n            sandbox = await self.sandbox_manager.create_sandbox(\n                user_id, problem_id)\n\n            # Load S3 data if needed\n            if hasattr(problem, 's3_datasets') and problem.s3_datasets:\n                logger.info(f\"Loading S3 data for problem {problem_id}\")\n                setup_result = await sandbox.setup_problem_data(\n                    problem_id, problem.s3_datasets)\n\n                if not setup_result.get('success', False):\n                    logger.error(\n                        f\"Failed to load problem data: {setup_result.get('error')}\"\n                    )\n\n            return sandbox\n\n        except Exception as e:\n            logger.error(f\"Fast sandbox creation failed: {e}\")\n            return None\n\n    async def _execute_query_fast(self, sandbox: DuckDBSandbox,\n                                  query: str) -> Dict[str, Any]:\n        \"\"\"Execute query with minimal overhead\"\"\"\n        try:\n            # Direct execution without complex timeout handling\n            result = sandbox.execute_query(query)\n            return result\n        except Exception as e:\n            return {'success': False, 'error': str(e), 'execution_time_ms': 0}\n\n    async def _execute_minimal_validation(self, sandbox: DuckDBSandbox,\n                                          problem_id: str, query: str,\n                                          db: Session) -> List[Dict[str, Any]]:\n        \"\"\"Optimized validation that properly handles all test case types\"\"\"\n        try:\n            # Get problem with all needed fields for validation\n            problem = db.query(Problem).filter(\n                Problem.id == problem_id).first()\n\n            if not problem:\n                return [\n                    self._build_validation_result(\n                        test_case_id='error',\n                        test_case_name='Problem Not Found',\n                        is_correct=False,\n                        feedback=['Problem not found in database'],\n                        validation_details={\n                            'row_comparisons': [],\n                            'matching_row_count':\n                            0,\n                            'total_row_count':\n                            0,\n                            'comparison_differences':\n                            ['Problem not found in database']\n                        })\n                ]\n\n            # Check if this is an enhanced S3-based question with hash validation (fastest path)\n            if hasattr(problem, 'expected_hash') and problem.expected_hash and problem.s3_data_source:\n                logger.info(\n                    f\"Using S3 hash validation for problem {problem_id}\")\n                return await self._hash_validation_fast(\n                    problem, sandbox, query)\n\n            # Check for traditional test cases\n            test_cases = db.query(TestCase).filter(\n                TestCase.problem_id == problem_id).order_by(\n                    TestCase.order_index).all()\n\n            if test_cases:\n                # Execute against test cases (optimized)\n                return await self._execute_test_cases_fast(\n                    sandbox, query, test_cases)\n\n            # Check if problem has solution validation requirements (use Neon database instead of S3)\n            if hasattr(problem,\n                       'solution_source') and problem.solution_source in [\n                           'neon', 's3'\n                       ]:\n                # Execute query and verify with Neon database solution\n                result = await self._execute_query_fast(sandbox, query)\n\n                if result.get('success'):\n                    user_results = result.get('results', [])\n                    neon_verification = await self._verify_with_neon_solution(\n                        sandbox, problem, query, user_results, db)\n                    return neon_verification\n                else:\n                    return [\n                        self._build_validation_result(\n                            test_case_id='neon_verification',\n                            test_case_name='Neon Solution Verification',\n                            is_correct=False,\n                            feedback=[\n                                result.get('error', 'Query execution failed')\n                            ],\n                            validation_details={\n                                'row_comparisons': [],\n                                'matching_row_count':\n                                0,\n                                'total_row_count':\n                                0,\n                                'comparison_differences': [\n                                    result.get('error',\n                                               'Query execution failed')\n                                ]\n                            })\n                    ]\n\n            # Check for expected output - prioritize master_solution, then fallback to legacy fields\n            expected_output = None\n\n            # First priority: master_solution field (new admin system)\n            if hasattr(problem, 'master_solution') and problem.master_solution:\n                expected_output = problem.master_solution\n\n            # Second priority: legacy expected_output column\n            elif hasattr(problem,\n                         'expected_output') and problem.expected_output:\n                expected_output = problem.expected_output\n\n            # Third priority: legacy question.expectedOutput for backward compatibility\n            elif problem.question and isinstance(problem.question, dict):\n                expected_output = problem.question.get('expectedOutput', [])\n\n            if expected_output:\n                result = await self._execute_query_fast(sandbox, query)\n\n                if result.get('success'):\n                    user_results = result.get('results', [])\n\n                    # Enhanced comparison with detailed feedback\n                    is_correct, comparison_details = self._compare_results_detailed(\n                        user_results, expected_output)\n\n                    feedback = []\n                    if is_correct:\n                        feedback.append(\n                            'Results match expected output perfectly')\n                    else:\n                        feedback.extend(comparison_details)\n\n                    # Create detailed validation structure for frontend\n                    validation_details = self._create_validation_details(\n                        user_results, expected_output)\n\n                    return [\n                        self._build_validation_result(\n                            test_case_id=f\"{problem_id}_expected_output\",\n                            test_case_name='Expected Output Check',\n                            is_correct=is_correct,\n                            feedback=feedback,\n                            execution_time_ms=result.get(\n                                'execution_time_ms', 0),\n                            user_output=user_results,\n                            expected_output=expected_output,\n                            validation_details=validation_details,\n                            output_matches=is_correct)\n                    ]\n                else:\n                    return [\n                        self._build_validation_result(\n                            test_case_id=f\"{problem_id}_expected_output\",\n                            test_case_name='Expected Output Check',\n                            is_correct=False,\n                            feedback=[\n                                result.get('error', 'Query execution failed')\n                            ],\n                            validation_details={\n                                'row_comparisons': [],\n                                'matching_row_count':\n                                0,\n                                'total_row_count':\n                                0,\n                                'comparison_differences': [\n                                    result.get('error',\n                                               'Query execution failed')\n                                ]\n                            })\n                    ]\n\n            # Fallback: just execute query and return success\n            result = await self._execute_query_fast(sandbox, query)\n\n            if result.get('success'):\n                return [\n                    self._build_validation_result(\n                        test_case_id='basic_execution',\n                        test_case_name='Query Execution',\n                        is_correct=True,\n                        feedback=['Query executed successfully'],\n                        execution_time_ms=result.get('execution_time_ms', 0),\n                        user_output=result.get('results', []))\n                ]\n            else:\n                return [\n                    self._build_validation_result(\n                        test_case_id='execution_error',\n                        test_case_name='Query Execution',\n                        is_correct=False,\n                        feedback=[result.get('error', 'Query failed')],\n                        validation_details={\n                            'row_comparisons': [],\n                            'matching_row_count':\n                            0,\n                            'total_row_count':\n                            0,\n                            'comparison_differences':\n                            [result.get('error', 'Query failed')]\n                        })\n                ]\n\n        except Exception as e:\n            logger.error(f\"Validation failed: {e}\")\n            return [\n                self._build_validation_result(\n                    test_case_id='validation_error',\n                    test_case_name='Validation Error',\n                    is_correct=False,\n                    feedback=[f'Validation error: {str(e)}'],\n                    validation_details={\n                        'row_comparisons': [],\n                        'matching_row_count': 0,\n                        'total_row_count': 0,\n                        'comparison_differences':\n                        [f'Validation error: {str(e)}']\n                    })\n            ]\n\n    async def _execute_test_cases_fast(\n            self, sandbox: DuckDBSandbox, query: str,\n            test_cases: List[TestCase]) -> List[Dict[str, Any]]:\n        \"\"\"Fast execution against traditional test cases\"\"\"\n        results = []\n\n        for test_case in test_cases:\n            try:\n                # Execute query\n                result = await self._execute_query_fast(sandbox, query)\n\n                if result.get('success'):\n                    user_output = result.get('results', [])\n                    expected_output = test_case.expected_output or []\n\n                    # Use expected_output directly from database (Neon migration - removed S3 dependency)\n\n                    # Apply 6-step validation pipeline for enhanced comparison\n                    is_correct, comparison_details = self._six_step_validation_pipeline(\n                        user_output, expected_output,\n                        test_case.validation_rules or {})\n\n                    feedback = []\n                    if is_correct:\n                        feedback.append(\n                            'Results match expected output perfectly')\n                    else:\n                        feedback.extend(comparison_details)\n\n                    # Create detailed validation structure for frontend\n                    validation_details = self._create_validation_details(\n                        user_output, expected_output)\n\n                    results.append(\n                        self._build_validation_result(\n                            test_case_id=test_case.id,\n                            test_case_name=test_case.name,\n                            is_hidden=test_case.is_hidden,\n                            is_correct=is_correct,\n                            score=100.0 if is_correct else 0.0,\n                            feedback=feedback,\n                            execution_time_ms=result.get(\n                                'execution_time_ms', 0),\n                            execution_status=ExecutionStatus.SUCCESS.value,\n                            validation_details=validation_details,\n                            user_output=user_output,\n                            expected_output=expected_output,\n                            output_matches=is_correct))\n                else:\n                    results.append(\n                        self._build_validation_result(\n                            test_case_id=test_case.id,\n                            test_case_name=test_case.name,\n                            is_hidden=test_case.is_hidden,\n                            is_correct=False,\n                            feedback=[\n                                result.get('error', 'Query execution failed')\n                            ],\n                            execution_status=ExecutionStatus.ERROR.value,\n                            validation_details={\n                                'row_comparisons': [],\n                                'matching_row_count':\n                                0,\n                                'total_row_count':\n                                0,\n                                'comparison_differences': [\n                                    result.get('error',\n                                               'Query execution failed')\n                                ]\n                            }))\n\n            except Exception as e:\n                logger.error(f\"Test case execution failed: {e}\")\n                results.append(\n                    self._build_validation_result(\n                        test_case_id=test_case.id,\n                        test_case_name=test_case.name,\n                        is_hidden=test_case.is_hidden,\n                        is_correct=False,\n                        feedback=[f'Test execution error: {str(e)}'],\n                        execution_status=ExecutionStatus.ERROR.value,\n                        validation_details={\n                            'row_comparisons': [],\n                            'matching_row_count':\n                            0,\n                            'total_row_count':\n                            0,\n                            'comparison_differences':\n                            [f'Test execution error: {str(e)}']\n                        }))\n\n        return results\n\n    async def _hash_validation_fast(self, problem: Problem,\n                                    sandbox: DuckDBSandbox,\n                                    query: str) -> List[Dict[str, Any]]:\n        \"\"\"Fast hash-based validation\"\"\"\n        try:\n            # Execute user query\n            result = await self._execute_query_fast(sandbox, query)\n\n            if not result.get('success'):\n                return [{\n                    'test_case_id':\n                    'hash_validation',\n                    'test_case_name':\n                    'Hash Validation',\n                    'is_hidden':\n                    False,\n                    'is_correct':\n                    False,\n                    'score':\n                    0.0,\n                    'feedback':\n                    [result.get('error', 'Query execution failed')],\n                    'execution_time_ms':\n                    0,\n                    'user_output': [],\n                    'expected_output': [],\n                    'output_matches':\n                    False,\n                    'validation_details': {\n                        'row_comparisons': [],\n                        'matching_row_count':\n                        0,\n                        'total_row_count':\n                        0,\n                        'comparison_differences':\n                        [result.get('error', 'Query execution failed')]\n                    }\n                }]\n\n            user_results = result.get('results', [])\n\n            # Fast hash comparison\n            user_hash = self._compute_result_hash_fast(user_results)\n            expected_hash = problem.expected_hash\n\n            is_correct = user_hash == expected_hash\n\n            return [\n                self._build_validation_result(\n                    test_case_id='hash_validation',\n                    test_case_name='Result Hash Validation',\n                    is_correct=is_correct,\n                    feedback=['Query results match expected pattern']\n                    if is_correct else\n                    ['Query results do not match expected pattern'],\n                    execution_time_ms=result.get('execution_time_ms', 0),\n                    user_output=user_results,\n                    validation_details={\n                        'row_comparisons': [],\n                        'matching_row_count':\n                        1 if is_correct else 0,\n                        'total_row_count':\n                        1,\n                        'comparison_differences': [\n                            'Hash-based validation - row-by-row comparison not applicable'\n                        ] if is_correct else\n                        ['Hash mismatch indicates data differences'],\n                        'user_hash':\n                        user_hash,\n                        'expected_hash':\n                        expected_hash\n                    },\n                    output_matches=is_correct)\n            ]\n\n        except Exception as e:\n            logger.error(f\"Hash validation failed: {e}\")\n            return [\n                self._build_validation_result(\n                    test_case_id='hash_validation_error',\n                    test_case_name='Hash Validation Error',\n                    is_correct=False,\n                    feedback=[f'Hash validation error: {str(e)}'],\n                    validation_details={\n                        'row_comparisons': [],\n                        'matching_row_count':\n                        0,\n                        'total_row_count':\n                        0,\n                        'comparison_differences':\n                        [f'Hash validation error: {str(e)}']\n                    })\n            ]\n\n    async def _verify_with_neon_solution(self, sandbox: DuckDBSandbox,\n                                         problem: Problem, query: str,\n                                         user_results: List[Dict[str, Any]],\n                                         db: Session) -> List[Dict[str, Any]]:\n        \"\"\"6-step validation pipeline for Neon database expected results\"\"\"\n        try:\n            # Get test cases from database\n            test_cases = db.query(TestCase).filter(\n                TestCase.problem_id == problem.id).all()\n\n            if not test_cases:\n                return [{\n                    'test_case_id': 'no_test_cases',\n                    'test_case_name': 'No Test Cases',\n                    'is_hidden': False,\n                    'is_correct': False,\n                    'score': 0.0,\n                    'feedback': ['No test cases found for validation'],\n                    'execution_time_ms': 0,\n                    'user_output': user_results,\n                    'expected_output': [],\n                    'output_matches': False,\n                    'validation_details': {\n                        'row_comparisons': [],\n                        'matching_row_count': 0,\n                        'total_row_count': 0,\n                        'comparison_differences': ['No test cases found']\n                    }\n                }]\n\n            results = []\n            for test_case in test_cases:\n                # Get expected output from test case\n                expected_results = test_case.expected_output or []\n\n                # Apply 6-step validation pipeline\n                is_correct, feedback_details = self._six_step_validation_pipeline(\n                    user_results, expected_results, test_case.validation_rules\n                    or {})\n\n                # Create detailed validation structure for frontend\n                validation_details = self._create_validation_details(\n                    user_results, expected_results)\n\n                results.append(\n                    self._build_validation_result(\n                        test_case_id=test_case.id,\n                        test_case_name=test_case.name,\n                        is_hidden=test_case.is_hidden or False,\n                        is_correct=is_correct,\n                        score=100.0 if is_correct else 0.0,\n                        feedback=feedback_details,\n                        user_output=user_results,\n                        expected_output=expected_results,\n                        validation_details=validation_details,\n                        output_matches=is_correct))\n\n            return results\n\n        except Exception as e:\n            logger.error(f\"Neon solution verification failed: {e}\")\n            return [{\n                'test_case_id': 'neon_solution_error',\n                'test_case_name': 'Neon Solution Error',\n                'is_hidden': False,\n                'is_correct': False,\n                'score': 0.0,\n                'feedback': [f'Neon verification error: {str(e)}'],\n                'execution_time_ms': 0,\n                'user_output': user_results,\n                'expected_output': [],\n                'output_matches': False,\n                'validation_details': {\n                    'row_comparisons': [],\n                    'matching_row_count':\n                    0,\n                    'total_row_count':\n                    0,\n                    'comparison_differences':\n                    [f'Neon verification error: {str(e)}']\n                }\n            }]\n\n    def _six_step_validation_pipeline(\n            self, user_results: List[Dict[str, Any]],\n            expected_results: List[Dict[str, Any]],\n            validation_rules: Dict[str, Any]) -> Tuple[bool, List[str]]:\n        \"\"\"\n        6-step validation pipeline for Neon expected results:\n        1. Column names (case-insensitive, ignore order)\n        2. Row count\n        3. Row data (normalized to JSON, ignoring order unless problem specifies)\n        4. Data type normalization (int vs float, NULL handling)\n        5. Optional tolerances (for numeric aggregates)\n        6. Optional strict ordering (if required by question)\n        \"\"\"\n        feedback = []\n\n        try:\n            # Step 1: Column names (case-insensitive, ignore order)\n            if not self._validate_column_names(user_results, expected_results,\n                                               feedback):\n                return False, feedback\n\n            # Step 2: Row count\n            if not self._validate_row_count(user_results, expected_results,\n                                            feedback):\n                return False, feedback\n\n            # Step 3 & 4: Row data with data type normalization\n            if not self._validate_row_data_with_normalization(\n                    user_results, expected_results, validation_rules,\n                    feedback):\n                return False, feedback\n\n            # Step 5: Optional tolerances (for numeric aggregates)\n            if validation_rules.get('numeric_tolerance'):\n                if not self._validate_numeric_tolerance(\n                        user_results, expected_results, validation_rules,\n                        feedback):\n                    return False, feedback\n\n            # Step 6: Optional strict ordering (if required by question)\n            if validation_rules.get('strict_ordering', False):\n                if not self._validate_strict_ordering(\n                        user_results, expected_results, feedback):\n                    return False, feedback\n\n            feedback.append(\n                'All validation steps passed - results match perfectly')\n            return True, feedback\n\n        except Exception as e:\n            logger.error(f\"Six-step validation pipeline error: {e}\")\n            feedback.append(f'Validation pipeline error: {str(e)}')\n            return False, feedback\n\n    def _validate_column_names(self, user_results: List[Dict[str, Any]],\n                               expected_results: List[Dict[str, Any]],\n                               feedback: List[str]) -> bool:\n        \"\"\"Step 1: Validate column names (case-insensitive, ignore order)\"\"\"\n        if not user_results or not expected_results:\n            return True  # Skip if either is empty\n\n        user_columns = set(col.lower() for col in user_results[0].keys())\n        expected_columns = set(col.lower()\n                               for col in expected_results[0].keys())\n\n        if user_columns != expected_columns:\n            missing_cols = expected_columns - user_columns\n            extra_cols = user_columns - expected_columns\n\n            if missing_cols:\n                feedback.append(\n                    f\"Missing columns: {', '.join(sorted(missing_cols))}\")\n            if extra_cols:\n                feedback.append(\n                    f\"Unexpected columns: {', '.join(sorted(extra_cols))}\")\n\n            return False\n\n        return True\n\n    def _validate_row_count(self, user_results: List[Dict[str, Any]],\n                            expected_results: List[Dict[str, Any]],\n                            feedback: List[str]) -> bool:\n        \"\"\"Step 2: Validate row count\"\"\"\n        user_count = len(user_results)\n        expected_count = len(expected_results)\n\n        if user_count != expected_count:\n            feedback.append(\n                f\"Row count mismatch: got {user_count} rows, expected {expected_count} rows\"\n            )\n            return False\n\n        return True\n\n    def _validate_row_data_with_normalization(self, user_results: List[Dict[\n        str, Any]], expected_results: List[Dict[str, Any]],\n                                              validation_rules: Dict[str, Any],\n                                              feedback: List[str]) -> bool:\n        \"\"\"Steps 3 & 4: Validate row data with normalization (ignoring order unless specified)\"\"\"\n        if not user_results and not expected_results:\n            return True\n\n        # Normalize data types for comparison\n        normalized_user = self._normalize_data_types(user_results)\n        normalized_expected = self._normalize_data_types(expected_results)\n\n        # Check if strict ordering is required\n        ignore_order = not validation_rules.get('strict_ordering', False)\n\n        if ignore_order:\n            # Sort both datasets for comparison (ignoring order)\n            try:\n                sorted_user = sorted(normalized_user,\n                                     key=lambda x: str(sorted(x.items())))\n                sorted_expected = sorted(normalized_expected,\n                                         key=lambda x: str(sorted(x.items())))\n            except Exception:\n                # Fallback to unsorted comparison if sorting fails\n                sorted_user = normalized_user\n                sorted_expected = normalized_expected\n        else:\n            sorted_user = normalized_user\n            sorted_expected = normalized_expected\n\n        # Compare the data\n        for i, (user_row,\n                expected_row) in enumerate(zip(sorted_user, sorted_expected)):\n            if user_row != expected_row:\n                # Find specific differences\n                differences = []\n                for col in expected_row.keys():\n                    if col in user_row:\n                        user_val = user_row[col]\n                        expected_val = expected_row[col]\n                        if user_val != expected_val:\n                            differences.append(\n                                f\"{col}: got '{user_val}', expected '{expected_val}'\"\n                            )\n\n                if differences and len(feedback) < 5:  # Limit feedback\n                    if i < 3:  # Show details for first few rows\n                        feedback.append(\n                            f\"Row {i + 1} differs - {'; '.join(differences[:3])}\"\n                        )\n                    elif i == 3:  # Summarize if many differences\n                        feedback.append(f\"... and more rows with differences\")\n                        break\n\n                return False\n\n        return True\n\n    def _normalize_data_types(\n            self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Step 4: Normalize data types (int vs float, NULL handling)\"\"\"\n        normalized = []\n\n        for row in results:\n            normalized_row = {}\n            for key, value in row.items():\n                # Handle None/NULL values\n                if value is None:\n                    normalized_row[key] = None\n                # Normalize numeric types\n                elif isinstance(value, (int, float)):\n                    # Convert int to float for consistent comparison\n                    if isinstance(value, int) and not isinstance(value, bool):\n                        normalized_row[key] = float(value)\n                    else:\n                        normalized_row[key] = value\n                # Handle string representations of numbers\n                elif isinstance(value, str):\n                    try:\n                        # Try to convert to number if it's a numeric string\n                        if '.' in value:\n                            normalized_row[key] = float(value)\n                        else:\n                            normalized_row[key] = float(int(value))\n                    except (ValueError, TypeError):\n                        # Keep as string if not numeric\n                        normalized_row[key] = value\n                else:\n                    normalized_row[key] = value\n\n            normalized.append(normalized_row)\n\n        return normalized\n\n    def _validate_numeric_tolerance(self, user_results: List[Dict[str, Any]],\n                                    expected_results: List[Dict[str, Any]],\n                                    validation_rules: Dict[str, Any],\n                                    feedback: List[str]) -> bool:\n        \"\"\"Step 5: Validate with numeric tolerances for aggregates\"\"\"\n        tolerance = validation_rules.get('numeric_tolerance',\n                                         0.001)  # Default 0.1% tolerance\n\n        for i, (user_row,\n                expected_row) in enumerate(zip(user_results,\n                                               expected_results)):\n            for col in expected_row.keys():\n                if col in user_row:\n                    user_val = user_row[col]\n                    expected_val = expected_row[col]\n\n                    # Apply tolerance for numeric values\n                    if isinstance(user_val, (int, float)) and isinstance(\n                            expected_val, (int, float)):\n                        if expected_val == 0:\n                            # For zero values, use absolute tolerance\n                            if abs(user_val) > tolerance:\n                                feedback.append(\n                                    f\"Row {i + 1}, column {col}: value {user_val} exceeds tolerance for expected 0\"\n                                )\n                                return False\n                        else:\n                            # For non-zero values, use relative tolerance\n                            relative_diff = abs(\n                                (user_val - expected_val) / expected_val)\n                            if relative_diff > tolerance:\n                                feedback.append(\n                                    f\"Row {i + 1}, column {col}: value {user_val} differs from expected {expected_val} by {relative_diff*100:.2f}% (tolerance: {tolerance*100:.2f}%)\"\n                                )\n                                return False\n\n        return True\n\n    def _validate_strict_ordering(self, user_results: List[Dict[str, Any]],\n                                  expected_results: List[Dict[str, Any]],\n                                  feedback: List[str]) -> bool:\n        \"\"\"Step 6: Validate strict ordering if required\"\"\"\n        for i, (user_row,\n                expected_row) in enumerate(zip(user_results,\n                                               expected_results)):\n            if user_row != expected_row:\n                feedback.append(\n                    f\"Strict ordering validation failed at row {i + 1}\")\n                return False\n\n        return True\n\n    async def _validate_minimal(self, sandbox: DuckDBSandbox, problem_id: str,\n                                query: str, query_results: List[Dict[str,\n                                                                     Any]],\n                                db: Session) -> List[Dict[str, Any]]:\n        \"\"\"Fast minimal validation for test queries\"\"\"\n        try:\n            # Just return basic success for test queries\n            return [{\n                'test_case_id': 'test_execution',\n                'test_case_name': 'Query Test',\n                'is_hidden': False,\n                'is_correct': True,\n                'score': 100.0,\n                'feedback': ['Query executed successfully'],\n                'execution_time_ms': 0\n            }]\n\n        except Exception as e:\n            logger.error(f\"Minimal validation failed: {e}\")\n            return [{\n                'test_case_id': 'test_error',\n                'test_case_name': 'Query Test Error',\n                'is_hidden': False,\n                'is_correct': False,\n                'score': 0.0,\n                'feedback': [f'Test error: {str(e)}'],\n                'execution_time_ms': 0\n            }]\n\n    def _compare_results_fast(self, user_results: List[Dict],\n                              expected_results: List[Dict]) -> bool:\n        \"\"\"Ultra-fast result comparison\"\"\"\n        try:\n            if len(user_results) != len(expected_results):\n                return False\n\n            # Quick comparison for small datasets\n            if len(user_results) <= 100:\n                return user_results == expected_results\n\n            # Sample comparison for large datasets\n            sample_size = min(50, len(user_results))\n            for i in range(0, len(user_results),\n                           len(user_results) // sample_size):\n                if i < len(user_results) and i < len(expected_results):\n                    if user_results[i] != expected_results[i]:\n                        return False\n\n            return True\n\n        except Exception as e:\n            logger.error(f\"Fast comparison failed: {e}\")\n            return False\n\n    def _compare_results_detailed(\n            self, user_results: List[Dict],\n            expected_results: List[Dict]) -> Tuple[bool, List[str]]:\n        \"\"\"Detailed result comparison with specific feedback\"\"\"\n        try:\n            feedback = []\n\n            # Check row count first\n            user_count = len(user_results)\n            expected_count = len(expected_results)\n\n            if user_count != expected_count:\n                feedback.append(\n                    f\"Row count mismatch: your query returned {user_count} rows, expected {expected_count} rows\"\n                )\n                return False, feedback\n\n            if user_count == 0:\n                return True, [\"Both results are empty\"]\n\n            # Check column structure\n            if user_results and expected_results:\n                user_columns = set(\n                    user_results[0].keys()) if user_results[0] else set()\n                expected_columns = set(expected_results[0].keys()\n                                       ) if expected_results[0] else set()\n\n                if user_columns != expected_columns:\n                    missing_cols = expected_columns - user_columns\n                    extra_cols = user_columns - expected_columns\n\n                    if missing_cols:\n                        feedback.append(\n                            f\"Missing columns: {', '.join(sorted(missing_cols))}\"\n                        )\n                    if extra_cols:\n                        feedback.append(\n                            f\"Unexpected columns: {', '.join(sorted(extra_cols))}\"\n                        )\n\n                    return False, feedback\n\n            # Check data content\n            for i, (user_row, expected_row) in enumerate(\n                    zip(user_results, expected_results)):\n                if user_row != expected_row:\n                    # Find specific differences\n                    differences = []\n                    for col in expected_row.keys():\n                        if col in user_row:\n                            user_val = user_row[col]\n                            expected_val = expected_row[col]\n                            if user_val != expected_val:\n                                differences.append(\n                                    f\"{col}: got '{user_val}', expected '{expected_val}'\"\n                                )\n\n                    if differences:\n                        if i < 3:  # Show details for first few rows\n                            feedback.append(\n                                f\"Row {i + 1} differs - {'; '.join(differences[:3])}\"\n                            )\n                        elif i == 3:  # Summarize if many differences\n                            feedback.append(\n                                f\"... and {user_count - i} more rows with differences\"\n                            )\n                            break\n                    else:\n                        feedback.append(\n                            f\"Row {i + 1} has subtle differences in data types or formatting\"\n                        )\n\n                    if len(feedback) >= 5:  # Limit feedback length\n                        break\n\n            if feedback:\n                return False, feedback\n            else:\n                return True, [\"Results match perfectly\"]\n\n        except Exception as e:\n            logger.error(f\"Detailed comparison failed: {e}\")\n            return False, [f\"Comparison error: {str(e)}\"]\n\n    def _create_validation_details(\n            self, user_results: List[Dict],\n            expected_results: List[Dict]) -> Dict[str, Any]:\n        \"\"\"Create detailed validation details structure for frontend display\"\"\"\n        try:\n            row_comparisons = []\n            matching_count = 0\n\n            # Handle case where lengths don't match\n            max_length = max(len(user_results), len(expected_results))\n\n            for i in range(max_length):\n                user_row = user_results[i] if i < len(user_results) else None\n                expected_row = expected_results[i] if i < len(\n                    expected_results) else {}\n\n                # Check if rows match\n                matches = user_row == expected_row if user_row is not None else False\n                if matches:\n                    matching_count += 1\n\n                # Create differences summary if they don't match\n                differences = None\n                if user_row and expected_row and not matches:\n                    diff_list = []\n                    for col in expected_row.keys():\n                        if col in user_row:\n                            user_val = user_row[col]\n                            expected_val = expected_row[col]\n                            if user_val != expected_val:\n                                diff_list.append(\n                                    f\"{col}: got '{user_val}', expected '{expected_val}'\"\n                                )\n                    differences = \"; \".join(\n                        diff_list[:3]\n                    ) if diff_list else \"Data type or formatting differences\"\n\n                row_comparisons.append({\n                    'row_index': i,\n                    'matches': matches,\n                    'actual_row': user_row,\n                    'expected_row': expected_row,\n                    'differences': differences\n                })\n\n            # Build comparison differences summary\n            comparison_differences = []\n            user_count = len(user_results)\n            expected_count = len(expected_results)\n\n            if user_count != expected_count:\n                comparison_differences.append(\n                    f\"Row count mismatch: got {user_count} rows, expected {expected_count} rows\"\n                )\n\n            if user_results and expected_results:\n                user_columns = set(\n                    user_results[0].keys()) if user_results[0] else set()\n                expected_columns = set(expected_results[0].keys()\n                                       ) if expected_results[0] else set()\n\n                if user_columns != expected_columns:\n                    missing_cols = expected_columns - user_columns\n                    extra_cols = user_columns - expected_columns\n\n                    if missing_cols:\n                        comparison_differences.append(\n                            f\"Missing columns: {', '.join(sorted(missing_cols))}\"\n                        )\n                    if extra_cols:\n                        comparison_differences.append(\n                            f\"Unexpected columns: {', '.join(sorted(extra_cols))}\"\n                        )\n\n            return {\n                'row_comparisons': row_comparisons,\n                'matching_row_count': matching_count,\n                'total_row_count': max_length,\n                'comparison_differences': comparison_differences\n            }\n\n        except Exception as e:\n            logger.error(f\"Failed to create validation details: {e}\")\n            return {\n                'row_comparisons': [],\n                'matching_row_count':\n                0,\n                'total_row_count':\n                0,\n                'comparison_differences':\n                [f\"Error creating comparison details: {str(e)}\"]\n            }\n\n    def _build_validation_result(\n            self,\n            test_case_id: str,\n            test_case_name: str,\n            is_correct: bool,\n            feedback: List[str] = None,\n            execution_time_ms: int = 0,\n            is_hidden: bool = False,\n            score: float = None,\n            user_output: List[Dict] = None,\n            expected_output: List[Dict] = None,\n            validation_details: Dict[str, Any] = None,\n            execution_status: str = None,\n            output_matches: bool = None,\n            extra_fields: Dict[str, Any] = None) -> Dict[str, Any]:\n        \"\"\"Build standardized validation result with consistent schema and safe defaults\"\"\"\n\n        # Set safe defaults with proper types\n        feedback = feedback or []\n        user_output = user_output or []\n        expected_output = expected_output or []\n\n        if score is None:\n            score = 100.0 if is_correct else 0.0\n\n        if validation_details is None:\n            validation_details = {\n                'row_comparisons': [],\n                'matching_row_count': 0,\n                'total_row_count': 0,\n                'comparison_differences': []\n            }\n\n        if execution_status is None:\n            execution_status = ExecutionStatus.SUCCESS.value if is_correct else ExecutionStatus.ERROR.value\n\n        if output_matches is None:\n            output_matches = is_correct\n\n        # Sanitize outputs to prevent JSON serialization errors\n        user_output_safe = sanitize_json_data(user_output)\n        expected_output_safe = sanitize_json_data(expected_output)\n        validation_details_safe = sanitize_json_data(validation_details)\n\n        # Build canonical result structure\n        result = {\n            'test_case_id': str(test_case_id),\n            'test_case_name': test_case_name or '',\n            'is_hidden': bool(is_hidden),\n            'is_correct': bool(is_correct),\n            'score': float(score),\n            'feedback': list(feedback),\n            'execution_time_ms': int(execution_time_ms),\n            'execution_status': execution_status,\n            'validation_details': validation_details_safe,\n            'user_output': user_output_safe,\n            'expected_output': expected_output_safe,\n            'output_matches': bool(output_matches)\n        }\n\n        # Add any extra fields\n        if extra_fields:\n            # Sanitize extra fields too\n            extra_fields_safe = sanitize_json_data(extra_fields)\n            result.update(extra_fields_safe)\n\n        return result\n\n    def _compute_result_hash_fast(self, results: List[Dict[str, Any]]) -> str:\n        \"\"\"Fast hash computation for results\"\"\"\n        try:\n            # Simple hash based on result structure\n            content = json.dumps(results, sort_keys=True, default=str)\n            return hashlib.md5(content.encode()).hexdigest()\n        except Exception as e:\n            logger.error(f\"Hash computation failed: {e}\")\n            return \"error_hash\"\n\n    def _calculate_score_fast(\n            self, test_results: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"Enhanced scoring calculation with detailed feedback\"\"\"\n        if not test_results:\n            return {\n                'overall_score':\n                0.0,\n                'passed_count':\n                0,\n                'total_count':\n                0,\n                'avg_execution_time':\n                0,\n                'max_execution_time':\n                0,\n                'feedback': [\n                    'No test results available - this problem may not have test cases configured yet.'\n                ]\n            }\n\n        passed_count = sum(1 for result in test_results\n                           if result.get('is_correct', False))\n        total_count = len(test_results)\n        overall_score = (passed_count /\n                         total_count) * 100.0 if total_count > 0 else 0.0\n\n        execution_times = [\n            result.get('execution_time_ms', 0) for result in test_results\n        ]\n        avg_execution_time = sum(execution_times) / len(\n            execution_times) if execution_times else 0\n        max_execution_time = max(execution_times) if execution_times else 0\n\n        # Collect detailed feedback from all test results\n        detailed_feedback = []\n\n        # Add overall score summary\n        if passed_count == total_count:\n            detailed_feedback.append(\n                f'âœ… Excellent! All {total_count} test case(s) passed!')\n        else:\n            detailed_feedback.append(\n                f'âŒ Test case Failed check your query again')\n\n        # Add specific feedback from each test result\n        for i, result in enumerate(test_results, 1):\n            test_name = result.get('test_case_name', f'Test Case {i}')\n            is_correct = result.get('is_correct', False)\n            test_feedback = result.get('feedback', [])\n\n            if is_correct:\n                detailed_feedback.append(f'âœ“ {test_name}: PASSED')\n            else:\n                detailed_feedback.append(f'âœ— {test_name}: FAILED')\n                # Add specific failure details\n                if test_feedback:\n                    for fb in test_feedback:\n                        detailed_feedback.append(f'  â†’ {fb}')\n\n                # Add comparison details if available\n                if 'user_output' in result and 'expected_output' in result:\n                    user_rows = len(result.get('user_output', []))\n                    expected_rows = len(result.get('expected_output', []))\n                    if user_rows != expected_rows:\n                        detailed_feedback.append(\n                            f'  â†’ Row count mismatch: got {user_rows} rows, expected {expected_rows} rows'\n                        )\n                    elif user_rows > 0:\n                        detailed_feedback.append(\n                            f'  â†’ Row count matches ({user_rows} rows) but data differs'\n                        )\n\n        # Add execution time info if significant\n        if avg_execution_time > 1000:  # More than 1 second\n            detailed_feedback.append(\n                f'â±ï¸  Average execution time: {avg_execution_time:.0f}ms')\n\n        return {\n            'overall_score': overall_score,\n            'passed_count': passed_count,\n            'total_count': total_count,\n            'avg_execution_time': avg_execution_time,\n            'max_execution_time': max_execution_time,\n            'feedback': detailed_feedback\n        }\n\n    def _generate_feedback_fast(\n            self, test_results: List[Dict[str, Any]]) -> List[str]:\n        \"\"\"Fast feedback generation\"\"\"\n        if not test_results:\n            return ['No test results available']\n\n        feedback = []\n        for result in test_results:\n            if result.get('feedback'):\n                feedback.extend(result['feedback'])\n\n        return feedback if feedback else ['Query executed']\n\n    def _create_error_response(self, error_message: str) -> Dict[str, Any]:\n        \"\"\"Fast error response creation\"\"\"\n        return {\n            'success': False,\n            'is_correct': False,\n            'score': 0.0,\n            'feedback': [error_message],\n            'test_results': [],\n            'passed_tests': 0,\n            'total_tests': 0,\n            'execution_stats': {\n                'avg_time_ms': 0,\n                'max_time_ms': 0,\n                'total_time_ms': 0\n            },\n            'security_warnings': [error_message],\n            'submission_id': None\n        }\n\n    def _create_submission_fast(self, user_id: str, problem_id: str,\n                                query: str, cached_result: Dict[str, Any],\n                                db: Session) -> Submission:\n        \"\"\"Fast submission creation from cache\"\"\"\n        submission = Submission(\n            user_id=user_id,\n            problem_id=problem_id,\n            query=query,\n            is_correct=cached_result.get('is_correct', False),\n            execution_time=cached_result.get('execution_stats',\n                                             {}).get('avg_time_ms', 0))\n\n        db.add(submission)\n        db.commit()\n        db.refresh(submission)\n\n        return submission\n\n    def _update_user_progress_background(self, user_id: str, problem_id: str,\n                                         db: Session):\n        \"\"\"Background user progress update\"\"\"\n        try:\n            # Simple fire-and-forget progress update\n            self._thread_pool.submit(self._update_user_progress_sync, user_id,\n                                     problem_id, db)\n        except Exception as e:\n            logger.warning(f\"Background progress update failed: {e}\")\n\n    def _update_user_progress_sync(self, user_id: str, problem_id: str,\n                                   db: Session):\n        \"\"\"Synchronous user progress update\"\"\"\n        try:\n            # Check if this is first time solving this problem\n            existing_correct = db.query(Submission).filter(\n                Submission.user_id == user_id,\n                Submission.problem_id == problem_id,\n                Submission.is_correct == True).first()\n\n            if not existing_correct:\n                # Update user's solved count\n                user = db.query(User).filter(User.id == user_id).first()\n                if user:\n                    user.problems_solved = (user.problems_solved or 0) + 1\n                    db.commit()\n\n        except Exception as e:\n            logger.error(f\"User progress update failed: {e}\")\n\n    async def get_user_progress(self, user_id: str,\n                                db: Session) -> Dict[str, Any]:\n        \"\"\"Fast user progress retrieval\"\"\"\n        try:\n            user = db.query(User).filter(User.id == user_id).first()\n            if not user:\n                return {'success': False, 'error': 'User not found'}\n\n            # Basic progress stats\n            total_submissions = db.query(Submission).filter(\n                Submission.user_id == user_id).count()\n            correct_submissions = db.query(Submission).filter(\n                Submission.user_id == user_id,\n                Submission.is_correct == True).count()\n\n            return {\n                'success':\n                True,\n                'user_id':\n                user_id,\n                'problems_solved':\n                user.problems_solved or 0,\n                'total_submissions':\n                total_submissions,\n                'correct_submissions':\n                correct_submissions,\n                'accuracy': (correct_submissions / total_submissions *\n                             100) if total_submissions > 0 else 0\n            }\n\n        except Exception as e:\n            logger.error(f\"User progress retrieval failed: {e}\")\n            return {\n                'success': False,\n                'error': f'Progress retrieval failed: {str(e)}'\n            }\n\n\n# Global secure executor instance\nsecure_executor = SecureQueryExecutor()\n","size_bytes":69311},"api/test_validator.py":{"content":"\"\"\"\nOptimized SQL Test Case Validator\n================================\nHigh-performance validator with smart feedback and minimal overhead.\nFocuses on essential improvements while maintaining speed.\n\"\"\"\n\nimport json\nimport logging\nfrom typing import Any, Dict, List, Optional, Tuple, Union, Set\nfrom datetime import datetime, date\nfrom decimal import Decimal\nimport re\nfrom enum import Enum\nfrom dataclasses import dataclass\nfrom collections import defaultdict\n\nlogger = logging.getLogger(__name__)\n\n\nclass ComparisonMode(Enum):\n    \"\"\"Different modes for comparing query results\"\"\"\n    EXACT = \"exact\"\n    UNORDERED = \"unordered\"\n    SUBSET = \"subset\"\n    FUZZY = \"fuzzy\"\n\n\nclass ErrorCategory(Enum):\n    \"\"\"Categories of common SQL errors for targeted feedback\"\"\"\n    SYNTAX = \"syntax\"\n    LOGIC = \"logic\"\n    JOIN = \"join\"\n    AGGREGATION = \"aggregation\"\n    FILTERING = \"filtering\"\n\n\n@dataclass\nclass FeedbackContext:\n    \"\"\"Lightweight context for personalized feedback\"\"\"\n    user_level: str = \"intermediate\"  # beginner, intermediate, advanced\n    previous_attempts: int = 0\n\n\nclass OptimizedTestCaseValidator:\n    \"\"\"Performance-optimized validator with essential smart features\"\"\"\n\n    def __init__(self):\n        self.numeric_tolerance = 0.001\n\n        # Cached patterns for performance\n        self._error_keywords = {\n            'join_issues': ['cartesian', 'missing', 'duplicate'],\n            'aggregation_issues': ['sum', 'count', 'avg', 'group'],\n            'filter_issues': ['where', 'condition', 'missing']\n        }\n\n        # Pre-compiled regex patterns\n        self._sql_patterns = {\n            'select_star': re.compile(r'select\\s+\\*', re.IGNORECASE),\n            'missing_semicolon': re.compile(r'[^;]\\s*$'),\n            'cartesian_join': re.compile(r'from\\s+\\w+\\s*,\\s*\\w+',\n                                         re.IGNORECASE)\n        }\n\n    def validate_test_case(\n            self,\n            actual_result: List[Dict[str, Any]],\n            expected_result: List[Dict[str, Any]],\n            student_query: Optional[str] = None,\n            comparison_mode: ComparisonMode = ComparisonMode.EXACT,\n            context: Optional[FeedbackContext] = None) -> Dict[str, Any]:\n        \"\"\"\n        Optimized validation with smart feedback\n\n        Performance optimizations:\n        - Lazy evaluation of expensive operations\n        - Early returns for obvious cases\n        - Minimal object creation\n        - Cached computations\n        \"\"\"\n        if context is None:\n            context = FeedbackContext()\n\n        result = self._create_base_result()\n\n        try:\n            # Fast path for empty results\n            if not expected_result and not actual_result:\n                result.update({\n                    'is_correct': True,\n                    'score': 100.0,\n                    'feedback': [\"Perfect! Both results are empty.\"]\n                })\n                return result\n\n            # Fast path for obvious mismatches\n            if not expected_result or not actual_result:\n                return self._handle_missing_results(result,\n                                                    bool(expected_result),\n                                                    context)\n\n            # Quick structure validation (most performance critical)\n            structure_score = self._validate_structure_fast(\n                actual_result, expected_result, result)\n\n            # Only do expensive content validation if structure looks reasonable\n            if structure_score > 30:  # Skip expensive validation for obviously wrong queries\n                content_score = self._validate_content_fast(\n                    actual_result, expected_result, comparison_mode, result)\n            else:\n                content_score = 0.0\n\n            # Quick scoring calculation\n            final_score = self._calculate_final_score(structure_score,\n                                                      content_score, context)\n            result['score'] = round(final_score, 2)\n            result['is_correct'] = final_score >= 90.0\n\n            # Lazy smart feedback generation (only if needed)\n            if student_query and final_score < 95:\n                self._add_quick_query_feedback(student_query, result, context)\n\n            self._add_contextual_feedback(result, context)\n\n        except Exception as e:\n            logger.error(f\"Validation failed: {e}\")\n            result['errors'].append(f\"Validation error: {str(e)}\")\n\n        return result\n\n    def _create_base_result(self) -> Dict[str, Any]:\n        \"\"\"Create base result structure quickly\"\"\"\n        return {\n            'is_correct': False,\n            'score': 0.0,\n            'max_score': 100.0,\n            'feedback': [],\n            'errors': [],\n            'warnings': [],\n            'details': {\n                'row_count_match': False,\n                'column_count_match': False,\n                'column_names_match': False,\n                'data_matches': False\n            }\n        }\n\n    def _handle_missing_results(self, result: Dict[str,\n                                                   Any], has_expected: bool,\n                                context: FeedbackContext) -> Dict[str, Any]:\n        \"\"\"Fast handling of missing results\"\"\"\n        if not has_expected:\n            result['errors'].append(\"No expected result provided\")\n        else:\n            result['errors'].append(\"Query returned no results\")\n            if context.user_level == \"beginner\":\n                result['feedback'].append(\n                    \"ðŸ’¡ Your query didn't return any data. Check your FROM and WHERE clauses.\"\n                )\n            else:\n                result['feedback'].append(\n                    \"Query returned empty result set. Verify your conditions.\")\n        return result\n\n    def _validate_structure_fast(self, actual: List[Dict[str, Any]],\n                                 expected: List[Dict[str, Any]],\n                                 result: Dict[str, Any]) -> float:\n        \"\"\"Optimized structure validation with early exits\"\"\"\n        score = 0.0\n\n        # Row count (fastest check)\n        actual_rows, expected_rows = len(actual), len(expected)\n        if actual_rows == expected_rows:\n            result['details']['row_count_match'] = True\n            score += 40.0\n        else:\n            # Quick ratio calculation for partial credit\n            ratio = min(actual_rows, expected_rows) / max(\n                actual_rows, expected_rows) if max(actual_rows,\n                                                   expected_rows) > 0 else 0\n            score += 40.0 * ratio\n\n            # Fast feedback generation\n            diff = actual_rows - expected_rows\n            if diff > 0:\n                result['feedback'].append(\n                    f\"Too many rows: got {actual_rows}, expected {expected_rows}\"\n                )\n            else:\n                result['feedback'].append(\n                    f\"Too few rows: got {actual_rows}, expected {expected_rows}\"\n                )\n\n        # Column structure (only if we have data)\n        if actual and expected:\n            actual_cols = set(actual[0].keys())\n            expected_cols = set(expected[0].keys())\n\n            # Column count\n            if len(actual_cols) == len(expected_cols):\n                result['details']['column_count_match'] = True\n                score += 30.0\n            else:\n                ratio = min(len(actual_cols), len(expected_cols)) / max(\n                    len(actual_cols), len(expected_cols))\n                score += 30.0 * ratio\n\n            # Column names (using set operations for speed)\n            if actual_cols == expected_cols:\n                result['details']['column_names_match'] = True\n                score += 30.0\n            else:\n                # Fast similarity calculation\n                intersection = len(actual_cols & expected_cols)\n                union = len(actual_cols | expected_cols)\n                similarity = intersection / union if union > 0 else 0\n                score += 30.0 * similarity\n\n                # Quick feedback\n                missing = expected_cols - actual_cols\n                extra = actual_cols - expected_cols\n                if missing:\n                    result['feedback'].append(\n                        f\"Missing columns: {', '.join(list(missing)[:3])}{'...' if len(missing) > 3 else ''}\"\n                    )\n                if extra:\n                    result['feedback'].append(\n                        f\"Extra columns: {', '.join(list(extra)[:3])}{'...' if len(extra) > 3 else ''}\"\n                    )\n\n        return min(score, 100.0)\n\n    def _validate_content_fast(self, actual: List[Dict[str, Any]],\n                               expected: List[Dict[str, Any]],\n                               comparison_mode: ComparisonMode,\n                               result: Dict[str, Any]) -> float:\n        \"\"\"Optimized content validation\"\"\"\n\n        if len(actual) != len(expected):\n            return 0.0\n\n        # Fast path for small datasets\n        if len(expected) <= 10:\n            return self._validate_small_dataset(actual, expected,\n                                                comparison_mode, result)\n\n        # Optimized validation for larger datasets\n        if comparison_mode == ComparisonMode.UNORDERED:\n            return self._validate_unordered_fast(actual, expected, result)\n        else:\n            return self._validate_ordered_fast(actual, expected, result)\n\n    def _validate_small_dataset(self, actual: List[Dict[str, Any]],\n                                expected: List[Dict[str, Any]],\n                                comparison_mode: ComparisonMode,\n                                result: Dict[str, Any]) -> float:\n        \"\"\"Optimized validation for small datasets (â‰¤10 rows)\"\"\"\n\n        if comparison_mode == ComparisonMode.UNORDERED:\n            # Convert to tuples for set operations (faster than custom comparison)\n            actual_tuples = {tuple(sorted(row.items())) for row in actual}\n            expected_tuples = {tuple(sorted(row.items())) for row in expected}\n\n            matches = len(actual_tuples & expected_tuples)\n            match_ratio = matches / len(\n                expected_tuples) if expected_tuples else 0.0\n        else:\n            # Exact order comparison\n            matches = sum(1 for a, e in zip(actual, expected)\n                          if self._rows_equal_fast(a, e))\n            match_ratio = matches / len(expected) if expected else 0.0\n\n        result['details']['data_matches'] = match_ratio > 0.95\n\n        # Quick feedback for small datasets\n        if match_ratio < 1.0:\n            mismatches = len(expected) - matches\n            result['feedback'].append(\n                f\"{mismatches} row(s) don't match expected values\")\n\n        return match_ratio * 100.0\n\n    def _validate_unordered_fast(self, actual: List[Dict[str, Any]],\n                                 expected: List[Dict[str, Any]],\n                                 result: Dict[str, Any]) -> float:\n        \"\"\"Fast unordered comparison using hash-based matching\"\"\"\n\n        # Create hash signatures for faster comparison\n        actual_hashes = [self._row_hash(row) for row in actual]\n        expected_hashes = [self._row_hash(row) for row in expected]\n\n        # Count matches using hash comparison\n        actual_hash_count = defaultdict(int)\n        for h in actual_hashes:\n            actual_hash_count[h] += 1\n\n        matches = 0\n        for expected_hash in expected_hashes:\n            if actual_hash_count[expected_hash] > 0:\n                matches += 1\n                actual_hash_count[expected_hash] -= 1\n\n        match_ratio = matches / len(expected) if expected else 0.0\n        result['details']['data_matches'] = match_ratio > 0.95\n\n        return match_ratio * 100.0\n\n    def _validate_ordered_fast(self, actual: List[Dict[str, Any]],\n                               expected: List[Dict[str, Any]],\n                               result: Dict[str, Any]) -> float:\n        \"\"\"Fast ordered comparison with early termination\"\"\"\n\n        matches = 0\n        max_checks = min(len(actual), len(expected),\n                         100)  # Limit checks for very large datasets\n\n        for i in range(max_checks):\n            if self._rows_equal_fast(actual[i], expected[i]):\n                matches += 1\n            elif matches == 0 and i > 5:  # Early termination if no matches found\n                break\n\n        # Extrapolate for larger datasets\n        if len(expected) > max_checks:\n            match_ratio = matches / max_checks if max_checks > 0 else 0.0\n        else:\n            match_ratio = matches / len(expected) if expected else 0.0\n\n        result['details']['data_matches'] = match_ratio > 0.95\n\n        return match_ratio * 100.0\n\n    def _rows_equal_fast(self, row1: Dict[str, Any], row2: Dict[str,\n                                                                Any]) -> bool:\n        \"\"\"Fast row comparison with early exits\"\"\"\n\n        # Quick key count check\n        if len(row1) != len(row2):\n            return False\n\n        # Fast value comparison with early exit\n        for key in row2:\n            if key not in row1:\n                return False\n\n            val1, val2 = row1[key], row2[key]\n\n            # Fast None check\n            if val1 is None and val2 is None:\n                continue\n            if val1 is None or val2 is None:\n                return False\n\n            # Fast type-specific comparison\n            if type(val1) != type(val2):\n                # Try string conversion as fallback\n                if str(val1).strip() != str(val2).strip():\n                    return False\n            elif val1 != val2:\n                return False\n\n        return True\n\n    def _row_hash(self, row: Dict[str, Any]) -> int:\n        \"\"\"Create a fast hash for row comparison\"\"\"\n        # Simple hash based on sorted items (faster than deep comparison)\n        return hash(\n            tuple(\n                sorted((k, str(v) if v is not None else None)\n                       for k, v in row.items())))\n\n    def _calculate_final_score(self, structure_score: float,\n                               content_score: float,\n                               context: FeedbackContext) -> float:\n        \"\"\"Fast score calculation\"\"\"\n        # Simple weighted average (avoid complex calculations)\n        if context.user_level == \"beginner\":\n            return structure_score * 0.4 + content_score * 0.6\n        else:\n            return structure_score * 0.3 + content_score * 0.7\n\n    def _add_quick_query_feedback(self, query: str, result: Dict[str, Any],\n                                  context: FeedbackContext):\n        \"\"\"Add quick query-based feedback using pre-compiled patterns\"\"\"\n\n        query_lower = query.lower()\n\n        # Fast pattern matching with pre-compiled regex\n        if self._sql_patterns['select_star'].search(query):\n            if context.user_level != \"beginner\":\n                result['warnings'].append(\n                    \"Consider selecting specific columns instead of SELECT *\")\n\n        if self._sql_patterns['missing_semicolon'].search(query.strip()):\n            if context.user_level == \"beginner\":\n                result['warnings'].append(\n                    \"SQL queries should end with a semicolon (;)\")\n\n        if self._sql_patterns['cartesian_join'].search(query):\n            result['warnings'].append(\n                \"Possible Cartesian product - check your JOIN conditions\")\n\n        # Fast keyword-based detection\n        if 'join' in query_lower and result['score'] < 50:\n            result['feedback'].append(\n                \"ðŸ’¡ JOIN issue detected. Check your ON conditions.\")\n        elif 'group by' in query_lower and result['score'] < 50:\n            result['feedback'].append(\n                \"ðŸ’¡ GROUP BY issue detected. Verify your grouping columns.\")\n\n    def _add_contextual_feedback(self, result: Dict[str, Any],\n                                 context: FeedbackContext):\n        \"\"\"Add context-aware feedback quickly\"\"\"\n        score = result['score']\n\n        # Fast feedback generation based on score bands\n        if score >= 95:\n            messages = [\"ðŸŽ‰ Perfect!\", \"Excellent work!\", \"Spot on!\"]\n        elif score >= 80:\n            messages = [\"Good job!\", \"Almost perfect!\", \"Great work!\"]\n        elif score >= 60:\n            messages = [\n                \"You're on the right track\", \"Getting closer!\", \"Good attempt\"\n            ]\n        else:\n            messages = [\n                \"Needs work\", \"Review the requirements\",\n                \"Try a different approach\"\n            ]\n\n        # Add level-specific encouragement\n        base_message = messages[min(len(messages) - 1, int(score // 20))]\n\n        if context.user_level == \"beginner\" and score < 60:\n            base_message += \" - break down the problem step by step.\"\n        elif context.previous_attempts > 2 and score > 60:\n            base_message += \" - you're improving with each attempt!\"\n\n        if not result['feedback'] or score >= 95:\n            result['feedback'].insert(0, base_message)\n\n    # Keep essential methods from original for compatibility\n    def _rows_match(self, actual_row: Dict[str, Any],\n                    expected_row: Dict[str, Any]) -> bool:\n        \"\"\"Compatibility method\"\"\"\n        return self._rows_equal_fast(actual_row, expected_row)\n\n    def _get_row_differences(self, actual_row: Dict[str, Any],\n                             expected_row: Dict[str, Any]) -> str:\n        \"\"\"Quick difference detection\"\"\"\n        differences = []\n        for key in expected_row:\n            if key not in actual_row or actual_row[key] != expected_row[key]:\n                actual_val = actual_row.get(key, '<missing>')\n                expected_val = expected_row[key]\n                differences.append(\n                    f\"{key}: got '{actual_val}', expected '{expected_val}'\")\n                if len(differences) >= 3:  # Limit output for performance\n                    differences.append(\"...\")\n                    break\n        return \"; \".join(differences)\n\n    def compare_schemas(self, actual_schema: List[Dict],\n                        expected_schema: List[Dict]) -> Dict[str, Any]:\n        \"\"\"Fast schema comparison\"\"\"\n        actual_names = {table['name'] for table in actual_schema}\n        expected_names = {table['name'] for table in expected_schema}\n\n        missing = expected_names - actual_names\n        extra = actual_names - expected_names\n\n        matches = len(expected_names\n                      & actual_names) == len(expected_names) and not extra\n        score = 100.0 - (len(missing) * 20) - (len(extra) * 10)\n\n        differences = []\n        if missing:\n            differences.append(f\"Missing tables: {', '.join(missing)}\")\n        if extra:\n            differences.append(f\"Extra tables: {', '.join(extra)}\")\n\n        return {\n            'matches': matches,\n            'differences': differences,\n            'score': max(0.0, score)\n        }\n\n\n# Performance-optimized global instance\noptimized_test_validator = OptimizedTestCaseValidator()\n\n# Compatibility alias for existing code\ntest_validator = optimized_test_validator\n","size_bytes":19264},"client/src/components/SubmissionHistory.tsx":{"content":"import { useQuery } from '@tanstack/react-query';\nimport { format } from 'date-fns';\n\ninterface Submission {\n  id: string;\n  query: string;\n  is_correct: boolean;\n  execution_time: number;\n  submitted_at: string;\n  score?: number;\n}\n\ninterface SubmissionHistoryProps {\n  problemId: string;\n}\n\nexport default function SubmissionHistory({ problemId }: SubmissionHistoryProps) {\n  const { data: submissions = [], isLoading, error } = useQuery({\n    queryKey: [`/api/problems/${problemId}/submissions`],\n    enabled: !!problemId,\n  });\n\n  if (isLoading) {\n    return (\n      <div className=\"bg-white border border-gray-200 rounded-lg p-4\">\n        <div className=\"text-gray-600 text-sm\">Loading submission history...</div>\n      </div>\n    );\n  }\n\n  if (error) {\n    return (\n      <div className=\"bg-white border border-gray-200 rounded-lg p-4\">\n        <div className=\"text-red-600 text-sm\">Failed to load submission history</div>\n      </div>\n    );\n  }\n\n  if (submissions.length === 0) {\n    return (\n      <div className=\"bg-white border border-gray-200 rounded-lg p-4\">\n        <div className=\"text-gray-500 text-sm italic\">No submissions yet</div>\n      </div>\n    );\n  }\n\n  const formatTime = (dateString: string) => {\n    try {\n      return format(new Date(dateString), 'MM/dd/yyyy HH:mm');\n    } catch {\n      return dateString;\n    }\n  };\n\n  const getStatusBadge = (isCorrect: boolean, score?: number) => {\n    if (isCorrect) {\n      return (\n        <span className=\"text-green-600 font-medium text-sm\">Success</span>\n      );\n    } else {\n      return (\n        <span className=\"text-red-600 font-medium text-sm\">Error</span>\n      );\n    }\n  };\n\n  const truncateQuery = (query: string, maxLength: number = 50) => {\n    if (query.length <= maxLength) return query;\n    return query.substring(0, maxLength) + '...';\n  };\n\n  const copyToClipboard = async (query: string) => {\n    try {\n      await navigator.clipboard.writeText(query);\n      // Could add a toast notification here\n    } catch (err) {\n      console.error('Failed to copy query:', err);\n    }\n  };\n\n  return (\n    <div className=\"bg-white border border-gray-200 rounded-lg overflow-hidden\">\n      <div className=\"bg-gray-50 px-4 py-2 border-b border-gray-200\">\n        <h3 className=\"text-sm font-medium text-gray-700\">Submission History</h3>\n      </div>\n      \n      <div className=\"overflow-x-auto\">\n        <table className=\"w-full\">\n          <thead>\n            <tr className=\"bg-gray-50 border-b border-gray-200\">\n              <th className=\"px-4 py-2 text-left text-xs font-medium text-gray-500 uppercase tracking-wider\">\n                TIME\n              </th>\n              <th className=\"px-4 py-2 text-left text-xs font-medium text-gray-500 uppercase tracking-wider\">\n                STATUS\n              </th>\n              <th className=\"px-4 py-2 text-left text-xs font-medium text-gray-500 uppercase tracking-wider\">\n                YOUR SUBMISSION\n              </th>\n              <th className=\"px-4 py-2 text-left text-xs font-medium text-gray-500 uppercase tracking-wider\">\n                RUNTIME\n              </th>\n            </tr>\n          </thead>\n          <tbody className=\"bg-white divide-y divide-gray-200\">\n            {submissions.map((submission) => (\n              <tr key={submission.id} className=\"hover:bg-gray-50\" data-testid={`submission-row-${submission.id}`}>\n                <td className=\"px-4 py-2 text-sm text-gray-900\">\n                  {formatTime(submission.submitted_at)}\n                </td>\n                <td className=\"px-4 py-2 text-sm\">\n                  {getStatusBadge(submission.is_correct, submission.score)}\n                </td>\n                <td className=\"px-4 py-2 text-sm\">\n                  <div className=\"flex items-center space-x-2\">\n                    <span \n                      className=\"text-gray-900 font-mono text-xs bg-gray-100 px-2 py-1 rounded cursor-pointer hover:bg-gray-200\"\n                      onClick={() => copyToClipboard(submission.query)}\n                      title=\"Click to copy full query\"\n                      data-testid={`query-copy-${submission.id}`}\n                    >\n                      {truncateQuery(submission.query)}\n                    </span>\n                    <button\n                      onClick={() => copyToClipboard(submission.query)}\n                      className=\"text-blue-600 hover:text-blue-800 text-xs\"\n                      title=\"Copy to clipboard\"\n                      data-testid={`button-copy-${submission.id}`}\n                    >\n                      Copy To Clipboard\n                    </button>\n                  </div>\n                </td>\n                <td className=\"px-4 py-2 text-sm text-gray-900\">\n                  {submission.execution_time ? `${submission.execution_time}ms` : 'PostgreSQL 14'}\n                </td>\n              </tr>\n            ))}\n          </tbody>\n        </table>\n      </div>\n    </div>\n  );\n}","size_bytes":4957},"client/src/components/SubmissionResultPanel.tsx":{"content":"import SubmissionHistory from './SubmissionHistory';\nimport ResultComparisonTable from './ResultComparisonTable';\n\ninterface SubmissionResult {\n  success: boolean;\n  is_correct: boolean;\n  score: number;\n  feedback: string[];\n  test_results: TestResult[];\n  submission_id: string;\n  execution_stats: {\n    avg_time_ms: number;\n    max_time_ms: number;\n    memory_used_mb: number;\n  };\n}\n\ninterface TestResult {\n  test_case_id: string;\n  test_case_name: string;\n  is_hidden: boolean;\n  is_correct: boolean;\n  score: number;\n  feedback: string[];\n  execution_time_ms: number;\n  execution_status: string;\n  validation_details: any;\n  user_output: any[];\n  expected_output: any[];\n  output_matches: boolean;\n}\n\ninterface SubmissionResultPanelProps {\n  result: SubmissionResult | null;\n  isLoading: boolean;\n  problemId: string;\n}\n\n\nexport default function SubmissionResultPanel({ result, isLoading, problemId }: SubmissionResultPanelProps) {\n  if (isLoading) {\n    return (\n      <div className=\"h-full bg-gray-50 flex items-center justify-center\">\n        <div className=\"text-gray-600\">Submitting solution...</div>\n      </div>\n    );\n  }\n\n  if (!result) {\n    return (\n      <div className=\"h-full bg-gray-50 flex items-center justify-center\">\n        <div className=\"text-gray-500\">Submit your solution to see results...</div>\n      </div>\n    );\n  }\n\n  // Get the first non-hidden test result for main comparison display\n  const mainTestResult = result.test_results?.find(test => !test.is_hidden) || result.test_results?.[0];\n  const hasOutputMismatch = !result.is_correct && mainTestResult;\n  const hasNoTestCases = !result.test_results || result.test_results.length === 0;\n\n  return (\n    <div className=\"h-full bg-gray-50 flex flex-col overflow-auto\">\n      <div className=\"p-4 space-y-4 flex-1 min-h-0\">\n        {/* Mismatch Banner */}\n        {hasOutputMismatch && (\n          <div className=\"bg-red-50 border border-red-200 rounded-lg p-3\" data-testid=\"banner-mismatch\">\n            <div className=\"flex items-center space-x-2\">\n              <div className=\"w-2 h-2 bg-red-500 rounded-full\"></div>\n              <span className=\"text-red-800 font-medium text-sm\">Mismatched</span>\n            </div>\n            <p className=\"text-red-700 text-sm mt-1\">\n              Your query's output doesn't match with the solution's output!\n            </p>\n          </div>\n        )}\n\n        {/* Success Banner */}\n        {result.is_correct && (\n          <div className=\"bg-green-50 border border-green-200 rounded-lg p-3\" data-testid=\"banner-success\">\n            <div className=\"flex items-center space-x-2\">\n              <div className=\"w-2 h-2 bg-green-500 rounded-full\"></div>\n              <span className=\"text-green-800 font-medium text-sm\">Success!</span>\n            </div>\n            <p className=\"text-green-700 text-sm mt-1\">\n              Your solution is correct! Well done!\n            </p>\n          </div>\n        )}\n\n        {/* Submission Stats */}\n        <div className=\"bg-white border border-gray-200 rounded-lg p-4\">\n          <div className=\"grid grid-cols-3 gap-4 text-center\">\n            <div>\n              <div className=\"text-lg font-semibold text-gray-900\">\n                {(result.score ?? 0).toFixed(1)}%\n              </div>\n              <div className=\"text-xs text-gray-500\">Score</div>\n            </div>\n            <div>\n              <div className=\"text-lg font-semibold text-gray-900\">\n                {result.execution_stats?.avg_time_ms ?? 0}ms\n              </div>\n              <div className=\"text-xs text-gray-500\">Runtime</div>\n            </div>\n            <div>\n              <div className=\"text-lg font-semibold text-gray-900\">\n                {(result.execution_stats?.memory_used_mb ?? 0).toFixed(1)}MB\n              </div>\n              <div className=\"text-xs text-gray-500\">Memory</div>\n            </div>\n          </div>\n        </div>\n\n        {/* Feedback Messages */}\n        {result.feedback && result.feedback.length > 0 && (\n          <div className=\"bg-blue-50 border border-blue-200 rounded-lg p-3\">\n            <h4 className=\"text-sm font-medium text-blue-800 mb-2\">Feedback</h4>\n            <ul className=\"text-sm text-blue-700 space-y-1\">\n              {result.feedback.map((message, index) => (\n                <li key={index}>â€¢ {message}</li>\n              ))}\n            </ul>\n          </div>\n        )}\n\n        {/* Show message when no test cases are available */}\n        {hasNoTestCases && (\n          <div className=\"bg-yellow-50 border border-yellow-200 rounded-lg p-4\">\n            <div className=\"flex items-center space-x-2\">\n              <div className=\"w-2 h-2 bg-yellow-500 rounded-full\"></div>\n              <span className=\"text-yellow-800 font-medium text-sm\">No Test Cases Available</span>\n            </div>\n            <p className=\"text-yellow-700 text-sm mt-1\">\n              This problem doesn't have test cases configured yet. Your query was executed successfully, but we can't compare the results against expected outputs.\n            </p>\n          </div>\n        )}\n\n        {/* Detailed Result Comparison - Show for both correct and incorrect submissions */}\n        {mainTestResult?.validation_details && (\n          <ResultComparisonTable \n            validationDetails={mainTestResult.validation_details}\n            isCorrect={result.is_correct}\n          />\n        )}\n      </div>\n    </div>\n  );\n}","size_bytes":5418},"api/admin_routes.py":{"content":"\"\"\"\nAdmin routes for creating and managing problems\n\"\"\"\nfrom typing import List, Dict, Any, Optional\nfrom fastapi import APIRouter, Depends, HTTPException, status, File, UploadFile\nfrom sqlalchemy.orm import Session, joinedload\nfrom pydantic import BaseModel, Field\nimport uuid\nimport duckdb\nimport logging\nimport pandas as pd\nimport pyarrow.parquet as pq\nimport io\nimport tempfile\n\nfrom .database import get_db\nfrom .models import Problem, Topic, Solution, User, TestCase\nfrom .auth import verify_admin_access, verify_admin_user_access\nfrom .schemas import DifficultyLevel, QuestionData, TableData, TableColumn, SolutionCreate, SolutionResponse, S3AnswerSource, S3DatasetSource\nfrom .s3_service import s3_service\nfrom .file_processor import file_processor\n\n# Create admin router\nadmin_router = APIRouter(prefix=\"/api/admin\", tags=[\"admin\"])\n\n# Admin schemas for question creation\nclass AdminTableColumn(BaseModel):\n    name: str\n    type: str\n    description: str = \"\"\n\n\nclass AdminTableData(BaseModel):\n    name: str\n    columns: List[AdminTableColumn]\n    sample_data: List[Dict[str, Any]] = []\n\nclass AdminQuestionData(BaseModel):\n    description: str\n    tables: List[AdminTableData] = []\n    expected_output: Optional[List[Dict[str, Any]]] = Field(None, alias=\"expectedOutput\")  # Optional for backward compatibility\n    s3_data_source: Optional[S3DatasetSource] = None\n    \n    model_config = {\"populate_by_name\": True}\n\nclass AdminS3SolutionSource(BaseModel):\n    bucket: str\n    key: str\n    description: Optional[str] = None\n\nclass AdminProblemCreate(BaseModel):\n    title: str\n    difficulty: str\n    question: AdminQuestionData\n    master_solution: Optional[List[Dict[str, Any]]] = Field(None, alias=\"masterSolution\")  # New master solution field\n    expected_display: Optional[List[Dict[str, Any]]] = Field(None, alias=\"expectedDisplay\")  # Display output for users (not validation)\n    s3_datasets: Optional[List[S3DatasetSource]] = None  # Multiple S3 dataset sources configuration\n    tags: List[str] = []\n    company: str = \"\"\n    hints: List[str] = []\n    premium: bool = False\n    topic_id: str = \"\"\n    solution_source: str = \"neon\"  # Always use 'neon' - S3 solutions deprecated\n\nclass SchemaInfo(BaseModel):\n    \"\"\"Response model for schema information\"\"\"\n    problem_structure: Dict[str, Any]\n    example_problem: Dict[str, Any]\n    difficulty_options: List[str]\n    available_topics: List[Dict[str, str]]\n\n# Enhanced AWS S3 Question Creation Schemas\nclass S3SolutionSource(BaseModel):\n    \"\"\"Schema for S3 solution parquet file configuration\"\"\"\n    bucket: str\n    key: str  # S3 object key (file path) - must be .parquet\n    description: Optional[str] = None\n    etag: Optional[str] = None  # For cache validation\n\nclass EnhancedQuestionCreateRequest(BaseModel):\n    \"\"\"Enhanced request model for creating questions with S3 dataset and solution\"\"\"\n    problem_id: str = Field(..., description=\"Unique problem identifier (e.g., 'q101')\")\n    title: str = Field(..., description=\"Problem title\")\n    difficulty: str = Field(..., description=\"Difficulty level: BEGINNER, EASY, MEDIUM, HARD, EXPERT\")\n    tags: List[str] = Field(default=[], description=\"Problem tags (e.g., ['window-function', 'ranking'])\")\n    dataset_path: str = Field(..., description=\"S3 path to dataset (e.g., 's3://bucket/problems/q101/dataset.parquet')\")\n    solution_path: str = Field(..., description=\"S3 path to solution parquet (e.g., 's3://bucket/problems/q101/out.parquet')\")\n    description: Optional[str] = Field(None, description=\"Problem description in markdown\")\n    hints: List[str] = Field(default=[], description=\"Helpful hints for solving the problem\")\n    company: Optional[str] = Field(None, description=\"Company name associated with the problem\")\n    premium: bool = Field(default=False, description=\"Whether this is a premium problem\")\n    topic_id: Optional[str] = Field(None, description=\"Topic ID to categorize the problem\")\n\nclass EnhancedQuestionCreateResponse(BaseModel):\n    \"\"\"Response model for enhanced question creation\"\"\"\n    success: bool\n    message: str\n    problem_id: str\n    expected_hash: Optional[str] = None  # MD5 hash of sorted expected results\n    preview_rows: List[Dict[str, Any]] = Field(default=[], description=\"First 5 rows of expected output\")\n    row_count: Optional[int] = None  # Total number of rows in expected output\n    dataset_info: Optional[Dict[str, Any]] = None  # Dataset schema and sample data\n    error: Optional[str] = None\n\n# Multi-table S3 schemas\nclass MultiTableS3Dataset(BaseModel):\n    \"\"\"Schema for a single S3 dataset in multi-table configuration\"\"\"\n    bucket: str = Field(..., description=\"S3 bucket name\")\n    key: str = Field(..., description=\"S3 object key (path to parquet file)\")\n    table_name: str = Field(..., description=\"Table name for DuckDB\")\n    description: Optional[str] = Field(None, description=\"Description of the dataset\")\n\nclass MultiTableQuestionCreateRequest(BaseModel):\n    \"\"\"Request model for creating questions with multiple S3 datasets\"\"\"\n    problem_id: str = Field(..., description=\"Unique problem identifier\")\n    title: str = Field(..., description=\"Problem title\")\n    difficulty: str = Field(..., description=\"Difficulty level: BEGINNER, EASY, MEDIUM, HARD, EXPERT\")\n    tags: List[str] = Field(default=[], description=\"Problem tags\")\n    datasets: List[MultiTableS3Dataset] = Field(..., description=\"List of S3 datasets for the question\")\n    solution_path: str = Field(..., description=\"S3 path to solution parquet file\")\n    description: Optional[str] = Field(None, description=\"Problem description in markdown\")\n    hints: List[str] = Field(default=[], description=\"Helpful hints\")\n    company: Optional[str] = Field(None, description=\"Company name\")\n    premium: bool = Field(default=False, description=\"Whether this is premium\")\n    topic_id: Optional[str] = Field(None, description=\"Topic ID\")\n\nclass MultiTableValidationRequest(BaseModel):\n    \"\"\"Request model for validating multiple S3 datasets\"\"\"\n    datasets: List[MultiTableS3Dataset] = Field(..., description=\"List of S3 datasets to validate\")\n\nclass MultiTableValidationResponse(BaseModel):\n    \"\"\"Response model for multi-table S3 validation\"\"\"\n    success: bool\n    message: str\n    validated_datasets: List[Dict[str, Any]] = Field(default=[], description=\"Information about validated datasets\")\n    total_tables: int = 0\n    total_rows: int = 0\n    error: Optional[str] = None\n\n@admin_router.get(\"/schema-info\", response_model=SchemaInfo)\ndef get_schema_info(\n    _: bool = Depends(verify_admin_user_access),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get the exact schema structure and example for creating problems\"\"\"\n    \n    # Get available topics\n    topics = db.query(Topic).all()\n    available_topics = [{\"id\": topic.id, \"name\": topic.name} for topic in topics]\n    \n    problem_structure = {\n        \"title\": \"string (required) - The problem title\",\n        \"difficulty\": \"string (required) - One of: BEGINNER, EASY, MEDIUM, HARD, EXPERT\",\n        \"question\": {\n            \"description\": \"string (required) - Problem description in markdown\",\n            \"tables\": [\n                {\n                    \"name\": \"string (required) - Table name\",\n                    \"columns\": [\n                        {\n                            \"name\": \"string (required) - Column name\",\n                            \"type\": \"string (required) - SQL data type (e.g., INTEGER, VARCHAR, DATE)\",\n                            \"description\": \"string (optional) - Column description\"\n                        }\n                    ],\n                    \"sample_data\": [\n                        \"object (optional) - Array of sample data objects\"\n                    ]\n                }\n            ],\n            \"expectedOutput\": [\n                \"object (required) - Array of expected result objects\"\n            ]\n        },\n        \"tags\": [\"array of strings (optional) - Problem tags\"],\n        \"company\": \"string (optional) - Company name\",\n        \"hints\": [\"array of strings (optional) - Helpful hints\"],\n        \"premium\": \"boolean (optional) - Is premium problem\",\n        \"topic_id\": \"string (optional) - Topic ID to categorize the problem\"\n    }\n    \n    example_problem = {\n        \"title\": \"Calculate Total Sales by Region\",\n        \"difficulty\": \"Medium\",\n        \"question\": {\n            \"description\": \"\"\"\n# Calculate Total Sales by Region\n\nWrite a SQL query to calculate the total sales amount for each region. The result should include:\n- Region name\n- Total sales amount (rounded to 2 decimal places)\n- Number of orders\n\nOrder the results by total sales amount in descending order.\n\n## Requirements:\n- Use proper aggregation functions\n- Round the total sales to 2 decimal places\n- Include regions even if they have zero sales\n            \"\"\".strip(),\n            \"tables\": [\n                {\n                    \"name\": \"orders\",\n                    \"columns\": [\n                        {\"name\": \"id\", \"type\": \"INTEGER\", \"description\": \"Order ID\"},\n                        {\"name\": \"region\", \"type\": \"VARCHAR(50)\", \"description\": \"Sales region\"},\n                        {\"name\": \"amount\", \"type\": \"DECIMAL(10,2)\", \"description\": \"Order amount\"},\n                        {\"name\": \"order_date\", \"type\": \"DATE\", \"description\": \"Date of order\"}\n                    ],\n                    \"sample_data\": [\n                        {\"id\": 1, \"region\": \"North\", \"amount\": 1500.00, \"order_date\": \"2024-01-15\"},\n                        {\"id\": 2, \"region\": \"South\", \"amount\": 2300.50, \"order_date\": \"2024-01-16\"},\n                        {\"id\": 3, \"region\": \"North\", \"amount\": 800.25, \"order_date\": \"2024-01-17\"},\n                        {\"id\": 4, \"region\": \"East\", \"amount\": 1200.00, \"order_date\": \"2024-01-18\"}\n                    ]\n                }\n            ],\n            \"expectedOutput\": [\n                {\"region\": \"South\", \"total_sales\": 2300.50, \"order_count\": 1},\n                {\"region\": \"North\", \"total_sales\": 2300.25, \"order_count\": 2},\n                {\"region\": \"East\", \"total_sales\": 1200.00, \"order_count\": 1}\n            ]\n        },\n        \"tags\": [\"aggregation\", \"group-by\", \"sum\", \"count\"],\n        \"company\": \"TechCorp\",\n        \"hints\": [\n            \"Use GROUP BY to group by region\",\n            \"Use SUM() to calculate total sales\",\n            \"Use COUNT() to count orders\",\n            \"Use ROUND() to round to 2 decimal places\",\n            \"Use ORDER BY with DESC for descending order\"\n        ],\n        \"premium\": False,\n        \"topic_id\": \"\"\n    }\n    \n    return SchemaInfo(\n        problem_structure=problem_structure,\n        example_problem=example_problem,\n        difficulty_options=[\"BEGINNER\", \"EASY\", \"MEDIUM\", \"HARD\", \"EXPERT\"],\n        available_topics=available_topics\n    )\n\n\ndef _map_duckdb_type_to_sql(duckdb_type: str) -> str:\n    \"\"\"Map DuckDB data types to standard SQL types for problem creation\"\"\"\n    type_lower = duckdb_type.lower().strip()\n    \n    # Integer types (including unsigned variants)\n    if 'hugeint' in type_lower:\n        return 'BIGINT'  # Closest equivalent\n    elif 'bigint' in type_lower or 'int64' in type_lower:\n        return 'BIGINT'\n    elif 'ubigint' in type_lower:\n        return 'BIGINT'  # Unsigned, but map to signed equivalent\n    elif 'int' in type_lower or 'integer' in type_lower:\n        return 'INTEGER'\n    elif 'uinteger' in type_lower:\n        return 'INTEGER'\n    elif 'smallint' in type_lower or 'int16' in type_lower:\n        return 'SMALLINT'\n    elif 'usmallint' in type_lower:\n        return 'SMALLINT'\n    elif 'tinyint' in type_lower or 'int8' in type_lower:\n        return 'TINYINT'\n    elif 'utinyint' in type_lower:\n        return 'TINYINT'\n    \n    # Floating point types\n    elif 'double' in type_lower or 'float64' in type_lower:\n        return 'DOUBLE'\n    elif 'float' in type_lower or 'real' in type_lower or 'float32' in type_lower:\n        return 'FLOAT'\n    \n    # Decimal/numeric types (preserve precision if possible)\n    elif 'decimal' in type_lower or 'numeric' in type_lower:\n        # Try to preserve precision/scale if specified\n        if '(' in duckdb_type:\n            return duckdb_type.upper()  # Keep original precision\n        return 'DECIMAL'\n    \n    # String types\n    elif 'varchar' in type_lower or 'string' in type_lower or 'text' in type_lower:\n        # Preserve length if specified\n        if '(' in duckdb_type and 'varchar' in type_lower:\n            return duckdb_type.upper()\n        return 'VARCHAR'\n    elif 'char' in type_lower:\n        if '(' in duckdb_type:\n            return duckdb_type.upper()\n        return 'CHAR'\n    elif 'clob' in type_lower:\n        return 'TEXT'\n    \n    # Binary types\n    elif 'blob' in type_lower or 'binary' in type_lower or 'bytea' in type_lower:\n        return 'BLOB'\n    elif 'varbinary' in type_lower:\n        return 'VARBINARY'\n    \n    # Date/time types\n    elif 'timestamptz' in type_lower or 'timestamp with time zone' in type_lower:\n        return 'TIMESTAMPTZ'\n    elif 'timestamp' in type_lower:\n        return 'TIMESTAMP'\n    elif 'date' in type_lower:\n        return 'DATE'\n    elif 'time' in type_lower:\n        return 'TIME'\n    elif 'interval' in type_lower:\n        return 'INTERVAL'\n    \n    # UUID type\n    elif 'uuid' in type_lower:\n        return 'UUID'\n    \n    # Boolean type\n    elif 'bool' in type_lower or 'boolean' in type_lower:\n        return 'BOOLEAN'\n    \n    # JSON and structured types\n    elif 'json' in type_lower:\n        return 'JSON'\n    elif any(x in type_lower for x in ['list', 'array', '[]']):\n        return 'JSON'  # Lists/arrays map to JSON\n    elif 'struct' in type_lower or 'row(' in type_lower:\n        return 'JSON'  # Structs map to JSON\n    elif 'map' in type_lower:\n        return 'JSON'  # Maps map to JSON\n    elif 'union' in type_lower:\n        return 'JSON'  # Unions map to JSON\n    \n    # Fallback to VARCHAR for unknown types\n    else:\n        return 'VARCHAR'\n\n\n\ndef _normalize_sql_type(sql_type: str) -> str:\n    \"\"\"Normalize SQL types by removing parameters and handling synonyms\"\"\"\n    normalized = sql_type.upper().strip()\n    \n    # Remove parameters (everything in parentheses)\n    if '(' in normalized:\n        normalized = normalized.split('(')[0]\n    \n    # Handle common synonyms\n    synonyms = {\n        'INT': 'INTEGER',\n        'BOOL': 'BOOLEAN', \n        'REAL': 'FLOAT',\n        'STRING': 'VARCHAR',\n        'TEXT': 'VARCHAR',\n        'CLOB': 'VARCHAR',\n        'NUMERIC': 'DECIMAL',\n        'BYTEA': 'BLOB',\n        'BINARY': 'BLOB',\n        'VARBINARY': 'BLOB'\n    }\n    \n    return synonyms.get(normalized, normalized)\n\ndef _types_compatible(type1: str, type2: str) -> bool:\n    \"\"\"Check if two SQL types are compatible\"\"\"\n    norm1 = _normalize_sql_type(type1)\n    norm2 = _normalize_sql_type(type2)\n    \n    # Exact match after normalization\n    if norm1 == norm2:\n        return True\n    \n    # Integer family compatibility\n    int_types = {'INTEGER', 'BIGINT', 'SMALLINT', 'TINYINT'}\n    if norm1 in int_types and norm2 in int_types:\n        return True\n    \n    # Float family compatibility \n    float_types = {'FLOAT', 'DOUBLE'}\n    if norm1 in float_types and norm2 in float_types:\n        return True\n    \n    # String family compatibility\n    string_types = {'VARCHAR', 'CHAR'}\n    if norm1 in string_types and norm2 in string_types:\n        return True\n    \n    # Binary family compatibility\n    binary_types = {'BLOB', 'VARBINARY'}\n    if norm1 in binary_types and norm2 in binary_types:\n        return True\n    \n    # Timestamp compatibility (with and without timezone)\n    timestamp_types = {'TIMESTAMP', 'TIMESTAMPTZ'}\n    if norm1 in timestamp_types and norm2 in timestamp_types:\n        return True\n    \n    return False\n\n@admin_router.post(\"/problems\")\ndef create_problem(\n    problem_data: AdminProblemCreate,\n    _: bool = Depends(verify_admin_user_access),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Create a new problem with the provided data\"\"\"\n    \n    # Validate difficulty\n    valid_difficulties = [\"BEGINNER\", \"EASY\", \"MEDIUM\", \"HARD\", \"EXPERT\"]\n    if problem_data.difficulty not in valid_difficulties:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=f\"Invalid difficulty. Must be one of: {valid_difficulties}\"\n        )\n    \n    # Validate topic if provided\n    if problem_data.topic_id:\n        topic = db.query(Topic).filter(Topic.id == problem_data.topic_id).first()\n        if not topic:\n            raise HTTPException(\n                status_code=status.HTTP_400_BAD_REQUEST,\n                detail=\"Invalid topic_id\"\n            )\n    \n    \n    # Convert AdminQuestionData to the format expected by the database\n    # Note: expectedOutput is now stored in dedicated expected_output column\n    question_data = {\n        \"description\": problem_data.question.description,\n        \"tables\": [\n            {\n                \"name\": table.name,\n                \"columns\": [\n                    {\"name\": col.name, \"type\": col.type}\n                    for col in table.columns\n                ],\n                \"sampleData\": table.sample_data\n            }\n            for table in problem_data.question.tables\n        ]\n        # expectedOutput removed - now stored in dedicated expected_output column\n    }\n    \n    # Extract S3 data source if present (legacy single dataset)\n    s3_data_source = None\n    if hasattr(problem_data.question, 's3_data_source') and problem_data.question.s3_data_source:\n        s3_data_source = {\n            \"bucket\": problem_data.question.s3_data_source.bucket,\n            \"key\": problem_data.question.s3_data_source.key,\n            \"table_name\": problem_data.question.s3_data_source.table_name,\n            \"description\": problem_data.question.s3_data_source.description\n        }\n\n    # Extract multiple S3 datasets if present\n    s3_datasets = None\n    if hasattr(problem_data, 's3_datasets') and problem_data.s3_datasets:\n        s3_datasets = [\n            {\n                \"bucket\": dataset.bucket,\n                \"key\": dataset.key,\n                \"table_name\": dataset.table_name,\n                \"description\": dataset.description or \"\"\n            }\n            for dataset in problem_data.s3_datasets\n        ]\n    \n    \n    # Solution source is always 'neon' - S3 solutions deprecated\n    s3_solution_source = None\n\n    # Normalize master solution: prefer masterSolution, fallback to expectedOutput\n    master_solution_data = None\n    if problem_data.master_solution:\n        master_solution_data = problem_data.master_solution\n    elif problem_data.question.expected_output:\n        master_solution_data = problem_data.question.expected_output\n    \n    # Create the problem\n    problem = Problem(\n        id=str(uuid.uuid4()),\n        title=problem_data.title,\n        difficulty=problem_data.difficulty,\n        question=question_data,\n        master_solution=master_solution_data,  # Use normalized master solution\n        expected_display=problem_data.expected_display,  # Display output for users (not validation)\n        s3_data_source=s3_data_source,  # Legacy single dataset\n        s3_datasets=s3_datasets,  # New multiple datasets field\n        tags=problem_data.tags,\n        company=problem_data.company if problem_data.company else None,\n        hints=problem_data.hints,\n        premium=problem_data.premium,\n        topic_id=problem_data.topic_id if problem_data.topic_id else None\n    )\n    \n    db.add(problem)\n    db.commit()\n    db.refresh(problem)\n    \n    return {\n        \"success\": True,\n        \"message\": \"Problem created successfully\",\n        \"problem_id\": problem.id,\n        \"title\": problem.title\n    }\n\n@admin_router.get(\"/problems\")\ndef list_problems(\n    _: bool = Depends(verify_admin_access),\n    db: Session = Depends(get_db)\n):\n    \"\"\"List all problems for admin management\"\"\"\n    problems = db.query(Problem).order_by(Problem.created_at.desc()).all()\n    \n    return [\n        {\n            \"id\": problem.id,\n            \"title\": problem.title,\n            \"difficulty\": problem.difficulty,\n            \"tags\": problem.tags,\n            \"company\": problem.company,\n            \"premium\": problem.premium,\n            \"created_at\": problem.created_at.isoformat()\n        }\n        for problem in problems\n    ]\n\n@admin_router.delete(\"/problems/{problem_id}\")\ndef delete_problem(\n    problem_id: str,\n    _: bool = Depends(verify_admin_access),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Delete a problem\"\"\"\n    problem = db.query(Problem).filter(Problem.id == problem_id).first()\n    if not problem:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Problem not found\"\n        )\n    \n    db.delete(problem)\n    db.commit()\n    \n    return {\"success\": True, \"message\": \"Problem deleted successfully\"}\n\n@admin_router.get(\"/validate-json\")\ndef validate_problem_json(\n    _: bool = Depends(verify_admin_access)\n):\n    \"\"\"Validate problem JSON structure\"\"\"\n    return {\n        \"message\": \"Use the POST /api/admin/problems endpoint to validate and create problems\",\n        \"schema_endpoint\": \"/api/admin/schema-info\"\n    }\n\n# Solution management routes\n@admin_router.post(\"/problems/{problem_id}/solutions\", response_model=SolutionResponse)\ndef create_or_update_solution(\n    problem_id: str,\n    solution_data: SolutionCreate,\n    current_user: User = Depends(verify_admin_user_access),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Create or update the solution for a problem (one solution per problem)\"\"\"\n    # Verify problem exists\n    problem = db.query(Problem).filter(Problem.id == problem_id).first()\n    if not problem:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Problem not found\"\n        )\n    \n    # Check for existing solution for this problem\n    existing_solution = db.query(Solution).filter(\n        Solution.problem_id == problem_id\n    ).first()\n    \n    if existing_solution:\n        # Update existing solution\n        existing_solution.title = solution_data.title\n        existing_solution.content = solution_data.content\n        existing_solution.sql_code = solution_data.sql_code\n        existing_solution.is_official = True  # Always official since it's the only solution\n        \n        db.commit()\n        db.refresh(existing_solution)\n        \n        # Load creator relationship\n        solution = db.query(Solution).options(joinedload(Solution.creator)).filter(\n            Solution.id == existing_solution.id\n        ).first()\n        \n        return SolutionResponse.from_orm(solution)\n    else:\n        # Create new solution\n        solution = Solution(\n            id=str(uuid.uuid4()),\n            problem_id=problem_id,\n            created_by=current_user.id,\n            title=solution_data.title,\n            content=solution_data.content,\n            sql_code=solution_data.sql_code,\n            is_official=True  # Always official since it's the only solution\n        )\n        \n        db.add(solution)\n        db.commit()\n        db.refresh(solution)\n        \n        # Load creator relationship\n        solution = db.query(Solution).options(joinedload(Solution.creator)).filter(\n            Solution.id == solution.id\n        ).first()\n        \n        return SolutionResponse.from_orm(solution)\n\n@admin_router.get(\"/problems/{problem_id}/solution\", response_model=SolutionResponse)\ndef get_problem_solution(\n    problem_id: str,\n    _: bool = Depends(verify_admin_access),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get the single solution for a problem (admin view)\"\"\"\n    solution = db.query(Solution).options(joinedload(Solution.creator)).filter(\n        Solution.problem_id == problem_id\n    ).first()\n    \n    if not solution:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"No solution found for this problem\"\n        )\n    \n    return SolutionResponse.from_orm(solution)\n\n@admin_router.get(\"/problems/{problem_id}/solutions\", response_model=List[SolutionResponse])\ndef get_problem_solutions(\n    problem_id: str,\n    _: bool = Depends(verify_admin_access),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get all solutions for a problem (admin view) - legacy endpoint\"\"\"\n    solutions = db.query(Solution).options(joinedload(Solution.creator)).filter(\n        Solution.problem_id == problem_id\n    ).order_by(Solution.created_at.desc()).all()\n    \n    return [SolutionResponse.from_orm(solution) for solution in solutions]\n\n@admin_router.put(\"/solutions/{solution_id}\", response_model=SolutionResponse)\ndef update_solution(\n    solution_id: str,\n    solution_data: SolutionCreate,\n    current_user: User = Depends(verify_admin_user_access),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Update an existing solution\"\"\"\n    solution = db.query(Solution).filter(Solution.id == solution_id).first()\n    if not solution:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Solution not found\"\n        )\n    \n    # Update solution fields\n    solution.title = solution_data.title\n    solution.content = solution_data.content\n    solution.sql_code = solution_data.sql_code\n    solution.is_official = solution_data.is_official\n    \n    db.commit()\n    db.refresh(solution)\n    \n    # Load creator relationship\n    solution = db.query(Solution).options(joinedload(Solution.creator)).filter(\n        Solution.id == solution.id\n    ).first()\n    \n    return SolutionResponse.from_orm(solution)\n\n@admin_router.delete(\"/solutions/{solution_id}\")\ndef delete_solution(\n    solution_id: str,\n    _: bool = Depends(verify_admin_access),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Delete a solution\"\"\"\n    solution = db.query(Solution).filter(Solution.id == solution_id).first()\n    if not solution:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Solution not found\"\n        )\n    \n    db.delete(solution)\n    db.commit()\n    \n    return {\"success\": True, \"message\": \"Solution deleted successfully\"}\n\n\n# ======= Neon Solution Verification Endpoints =======\n\nclass NeonVerificationRequest(BaseModel):\n    \"\"\"Request model for Neon solution verification\"\"\"\n    problem_id: str = Field(..., description=\"Problem ID to verify Neon test cases for\")\n\nclass NeonVerificationResponse(BaseModel):\n    \"\"\"Response model for Neon solution verification\"\"\"\n    verified: bool = Field(..., description=\"Whether the problem has valid Neon test cases\")\n    source: str = Field(default=\"neon\", description=\"Always 'neon' for this verification\")\n    test_case_count: int = Field(default=0, description=\"Number of valid test cases found\")\n    message: str = Field(default=\"\", description=\"Verification status message\")\n\n@admin_router.post(\"/verify-neon-solution\", response_model=NeonVerificationResponse)\ndef verify_neon_solution(\n    request: NeonVerificationRequest,\n    _: bool = Depends(verify_admin_user_access),\n    db: Session = Depends(get_db)\n):\n    \"\"\"\n    Verify that a problem has valid Neon test cases with expected_output\n    \n    This endpoint checks if the problem has test cases with:\n    1. Non-empty expected_output JSONB field\n    2. Valid JSON structure in expected_output\n    3. At least one test case with expected results\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    \n    try:\n        # Check if problem exists\n        problem = db.query(Problem).filter(Problem.id == request.problem_id).first()\n        if not problem:\n            return NeonVerificationResponse(\n                verified=False,\n                test_case_count=0,\n                message=f\"Problem '{request.problem_id}' not found\"\n            )\n        \n        # Find test cases with valid expected_output\n        test_cases = db.query(TestCase).filter(\n            TestCase.problem_id == request.problem_id,\n            TestCase.expected_output.isnot(None)\n        ).all()\n        \n        valid_test_cases = 0\n        for test_case in test_cases:\n            # Check if expected_output has valid content\n            if test_case.expected_output:\n                try:\n                    # Ensure it's a list with at least one item\n                    if isinstance(test_case.expected_output, list) and len(test_case.expected_output) > 0:\n                        # Check if first item looks like a valid result row\n                        first_row = test_case.expected_output[0]\n                        if isinstance(first_row, dict) and len(first_row) > 0:\n                            valid_test_cases += 1\n                except Exception as e:\n                    logger.warning(f\"Invalid expected_output in test case {test_case.id}: {e}\")\n                    continue\n        \n        if valid_test_cases > 0:\n            return NeonVerificationResponse(\n                verified=True,\n                test_case_count=valid_test_cases,\n                message=f\"Found {valid_test_cases} valid Neon test case(s)\"\n            )\n        else:\n            return NeonVerificationResponse(\n                verified=False,\n                test_case_count=0,\n                message=\"No valid test cases with expected_output found\"\n            )\n            \n    except Exception as e:\n        logger.error(f\"Failed to verify Neon solution for problem {request.problem_id}: {e}\")\n        return NeonVerificationResponse(\n            verified=False,\n            test_case_count=0,\n            message=f\"Verification failed: {str(e)}\"\n        )\n\n# ======= S3 Answer File Management Endpoints =======\n\nclass S3UploadRequest(BaseModel):\n    \"\"\"Request model for S3 upload URL generation\"\"\"\n    bucket: str = Field(..., description=\"S3 bucket name\")\n    key_prefix: str = Field(..., description=\"S3 key prefix (folder path)\")\n    filename: str = Field(..., description=\"Original filename\")\n    content_type: str = Field(default=\"text/csv\", description=\"MIME type of the file\")\n    \nclass S3UploadResponse(BaseModel):\n    \"\"\"Response model for S3 upload POST\"\"\"\n    upload_url: str = Field(..., description=\"Presigned POST URL\")\n    upload_fields: Dict[str, str] = Field(..., description=\"Form fields for POST upload\")\n    bucket: str = Field(..., description=\"S3 bucket name\")\n    key: str = Field(..., description=\"Full S3 object key\")\n    expires_in: int = Field(..., description=\"URL expiration time in seconds\")\n\nclass TestCaseS3ConfigRequest(BaseModel):\n    \"\"\"Request model for configuring S3 answer source for test case\"\"\"\n    bucket: str = Field(..., description=\"S3 bucket name\")\n    key: str = Field(..., description=\"S3 object key (file path)\")\n    format: str = Field(..., description=\"File format (csv, json, parquet)\")\n    display_limit: int = Field(default=10, description=\"Number of rows to show in preview\")\n    force_refresh: bool = Field(default=False, description=\"Force refresh from S3 even if cached\")\n\nclass TestCaseS3ConfigResponse(BaseModel):\n    \"\"\"Response model for S3 configuration result\"\"\"\n    success: bool\n    message: str\n    test_case_id: str\n    s3_config: Optional[S3AnswerSource] = None\n    preview_rows: int = 0\n    total_rows: int = 0\n    error: Optional[str] = None\n\nclass S3DatasetValidationRequest(BaseModel):\n    \"\"\"Request model for S3 dataset validation\"\"\"\n    bucket: str = Field(..., description=\"S3 bucket name\")\n    key: str = Field(..., description=\"S3 object key (file path) - must be .parquet\")\n    table_name: str = Field(..., description=\"Desired table name for DuckDB\")\n\nclass S3DatasetValidationResponse(BaseModel):\n    \"\"\"Response model for S3 dataset validation\"\"\"\n    success: bool\n    message: str = \"\"\n    table_schema: Optional[List[Dict[str, str]]] = None\n    sample_data: Optional[List[Dict[str, Any]]] = None\n    row_count: Optional[int] = None\n    etag: Optional[str] = None\n    table_name: Optional[str] = None\n    data_source: Optional[str] = None\n    error: Optional[str] = None\n\nclass S3ValidationResponse(BaseModel):\n    \"\"\"Response model for S3 configuration validation\"\"\"\n    valid: bool\n    accessible: bool\n    file_format: Optional[str] = None\n    file_size_mb: Optional[float] = None\n    row_count: Optional[int] = None\n    columns: Optional[List[str]] = None\n    sample_data: Optional[List[Dict[str, Any]]] = None\n    error: Optional[str] = None\n\n@admin_router.post(\"/s3/upload-url\", response_model=S3UploadResponse)\ndef generate_s3_upload_url(\n    request: S3UploadRequest,\n    _: bool = Depends(verify_admin_user_access)\n):\n    \"\"\"Generate presigned URL for uploading answer files to S3\"\"\"\n    try:\n        # Validate bucket name (basic security check)\n        allowed_bucket_prefixes = [\"sql-learning-answers\", \"sqlplatform-answers\"]\n        if not any(request.bucket.startswith(prefix) for prefix in allowed_bucket_prefixes):\n            raise HTTPException(\n                status_code=status.HTTP_400_BAD_REQUEST,\n                detail=f\"Bucket must start with one of: {allowed_bucket_prefixes}\"\n            )\n        \n        # Validate file format\n        allowed_formats = [\"csv\", \"json\", \"parquet\"]\n        file_extension = request.filename.lower().split('.')[-1]\n        if file_extension not in allowed_formats:\n            raise HTTPException(\n                status_code=status.HTTP_400_BAD_REQUEST,\n                detail=f\"File format must be one of: {allowed_formats}\"\n            )\n        \n        # Generate safe S3 key\n        import time\n        timestamp = int(time.time())\n        safe_filename = request.filename.replace(\" \", \"_\").replace(\"/\", \"_\")\n        s3_key = f\"{request.key_prefix.strip('/')}/{timestamp}_{safe_filename}\"\n        \n        # Generate secure presigned POST with policy\n        upload_data = s3_service.get_presigned_upload_url(\n            bucket=request.bucket,\n            key=s3_key,\n            content_type=request.content_type,\n            expires_in=300  # 5 minutes for security\n        )\n        \n        return S3UploadResponse(\n            upload_url=upload_data['url'],\n            upload_fields=upload_data['fields'],\n            bucket=request.bucket,\n            key=s3_key,\n            expires_in=300\n        )\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger = logging.getLogger(__name__)\n        logger.error(f\"Failed to generate S3 upload URL: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Failed to generate upload URL: {str(e)}\"\n        )\n\n@admin_router.post(\"/s3/validate\", response_model=S3ValidationResponse)\ndef validate_s3_configuration(\n    s3_config: S3AnswerSource,\n    _: bool = Depends(verify_admin_user_access)\n):\n    \"\"\"Validate S3 configuration and preview file content\"\"\"\n    try:\n        # Validate S3 access\n        is_valid, error_msg = file_processor.validate_s3_configuration(s3_config)\n        if not is_valid:\n            return S3ValidationResponse(\n                valid=False,\n                accessible=False,\n                error=error_msg\n            )\n        \n        # Try to fetch and process the file\n        full_data, preview_data, etag, error = file_processor.process_s3_answer_file(\n            s3_config=s3_config,\n            preview_limit=5  # Small preview for validation\n        )\n        \n        if error:\n            return S3ValidationResponse(\n                valid=True,\n                accessible=True,\n                error=error\n            )\n        \n        # Get data summary\n        summary = file_processor.get_data_summary(full_data)\n        \n        return S3ValidationResponse(\n            valid=True,\n            accessible=True,\n            file_format=s3_config.format,\n            row_count=summary['row_count'],\n            columns=summary['columns'],\n            sample_data=preview_data,\n            error=None\n        )\n        \n    except Exception as e:\n        logger = logging.getLogger(__name__)\n        logger.error(f\"Failed to validate S3 configuration: {e}\")\n        return S3ValidationResponse(\n            valid=False,\n            accessible=False,\n            error=f\"Validation failed: {str(e)}\"\n        )\n\n@admin_router.post(\"/test-cases/{test_case_id}/s3-config\", response_model=TestCaseS3ConfigResponse)\ndef configure_test_case_s3_source(\n    test_case_id: str,\n    request: TestCaseS3ConfigRequest,\n    _: bool = Depends(verify_admin_user_access),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Configure S3 answer source for a test case\"\"\"\n    try:\n        # Verify test case exists\n        test_case = db.query(TestCase).filter(TestCase.id == test_case_id).first()\n        if not test_case:\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND,\n                detail=\"Test case not found\"\n            )\n        \n        # Create S3 configuration\n        s3_config = S3AnswerSource(\n            bucket=request.bucket,\n            key=request.key,\n            format=request.format\n        )\n        \n        # Process S3 file to get full and preview data\n        full_data, preview_data, etag, error = file_processor.process_s3_answer_file(\n            s3_config=s3_config,\n            preview_limit=request.display_limit\n        )\n        \n        if error:\n            return TestCaseS3ConfigResponse(\n                success=False,\n                message=\"Failed to process S3 file\",\n                test_case_id=test_case_id,\n                error=error\n            )\n        \n        # Update test case with S3 configuration\n        s3_config.etag = etag  # Store ETag for caching\n        test_case.expected_output_source = s3_config.dict()\n        test_case.preview_expected_output = preview_data\n        test_case.display_limit = request.display_limit\n        \n        # Keep backward compatibility - store preview in expected_output too\n        test_case.expected_output = preview_data\n        \n        db.commit()\n        db.refresh(test_case)\n        \n        return TestCaseS3ConfigResponse(\n            success=True,\n            message=f\"S3 source configured successfully. {len(full_data)} total rows, {len(preview_data)} preview rows.\",\n            test_case_id=test_case_id,\n            s3_config=s3_config,\n            preview_rows=len(preview_data),\n            total_rows=len(full_data)\n        )\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger = logging.getLogger(__name__)\n        logger.error(f\"Failed to configure S3 source for test case {test_case_id}: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Failed to configure S3 source: {str(e)}\"\n        )\n\n@admin_router.post(\"/test-cases/{test_case_id}/s3-refresh\", response_model=TestCaseS3ConfigResponse)\ndef refresh_test_case_s3_data(\n    test_case_id: str,\n    _: bool = Depends(verify_admin_user_access),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Refresh S3 answer data for a test case (bypass cache)\"\"\"\n    try:\n        # Verify test case exists and has S3 configuration\n        test_case = db.query(TestCase).filter(TestCase.id == test_case_id).first()\n        if not test_case:\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND,\n                detail=\"Test case not found\"\n            )\n        \n        if not test_case.expected_output_source:\n            raise HTTPException(\n                status_code=status.HTTP_400_BAD_REQUEST,\n                detail=\"Test case does not have S3 configuration\"\n            )\n        \n        # Parse existing S3 configuration\n        s3_config = S3AnswerSource(**test_case.expected_output_source)\n        \n        # Force refresh by not passing ETag\n        s3_config.etag = None\n        \n        # Process S3 file to get updated data\n        full_data, preview_data, new_etag, error = file_processor.process_s3_answer_file(\n            s3_config=s3_config,\n            preview_limit=test_case.display_limit or 10\n        )\n        \n        if error:\n            return TestCaseS3ConfigResponse(\n                success=False,\n                message=\"Failed to refresh S3 data\",\n                test_case_id=test_case_id,\n                error=error\n            )\n        \n        # Update test case with fresh data\n        s3_config.etag = new_etag\n        test_case.expected_output_source = s3_config.dict()\n        test_case.preview_expected_output = preview_data\n        test_case.expected_output = preview_data  # Backward compatibility\n        \n        db.commit()\n        db.refresh(test_case)\n        \n        return TestCaseS3ConfigResponse(\n            success=True,\n            message=f\"S3 data refreshed successfully. {len(full_data)} total rows, {len(preview_data)} preview rows.\",\n            test_case_id=test_case_id,\n            s3_config=s3_config,\n            preview_rows=len(preview_data),\n            total_rows=len(full_data)\n        )\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger = logging.getLogger(__name__)\n        logger.error(f\"Failed to refresh S3 data for test case {test_case_id}: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Failed to refresh S3 data: {str(e)}\"\n        )\n\n@admin_router.post(\"/validate-dataset-s3\", response_model=S3DatasetValidationResponse)\ndef validate_s3_dataset(\n    request: S3DatasetValidationRequest,\n    _: bool = Depends(verify_admin_access)\n):\n    \"\"\"Validate S3 dataset file and extract schema information\"\"\"\n    logger = logging.getLogger(__name__)\n    \n    try:\n        # Use S3 service to validate the dataset file\n        validation_result = s3_service.validate_dataset_file(\n            bucket=request.bucket,\n            key=request.key,\n            table_name=request.table_name\n        )\n        \n        if validation_result[\"success\"]:\n            logger.info(f\"S3 dataset validation successful: s3://{request.bucket}/{request.key}\")\n            return S3DatasetValidationResponse(\n                success=True,\n                message=f\"Dataset validation successful. {validation_result['row_count']:,} rows found.\",\n                table_schema=validation_result.get(\"schema\", []),\n                sample_data=validation_result.get(\"sample_data\", []),\n                row_count=validation_result.get(\"row_count\", 0),\n                etag=validation_result.get(\"etag\"),\n                table_name=validation_result.get(\"table_name\"),\n                data_source=f\"s3://{request.bucket}/{request.key}\"\n            )\n        else:\n            logger.warning(f\"S3 dataset validation failed: {validation_result.get('error', 'Unknown error')}\")\n            return S3DatasetValidationResponse(\n                success=False,\n                error=validation_result.get(\"error\", \"Validation failed\")\n            )\n            \n    except Exception as e:\n        logger.error(f\"Exception during S3 dataset validation: {e}\")\n        return S3DatasetValidationResponse(\n            success=False,\n            error=f\"Validation failed: {str(e)}\"\n        )\n\n@admin_router.post(\"/create_question\", response_model=EnhancedQuestionCreateResponse)\ndef create_question_enhanced(\n    request: EnhancedQuestionCreateRequest,\n    _: bool = Depends(verify_admin_user_access),\n    db: Session = Depends(get_db)\n):\n    \"\"\"\n    DEPRECATED: Enhanced question creation with S3 solution workflow\n    \n    This endpoint is deprecated as part of the migration from S3 to Neon database\n    for solution validation. Use the standard /problems endpoint with Neon-based\n    test cases instead.\n    \"\"\"\n    raise HTTPException(\n        status_code=status.HTTP_410_GONE,\n        detail=\"This endpoint is deprecated. S3 solution creation has been migrated to Neon database. Use the standard /problems endpoint with test cases instead.\"\n    )\n    logger = logging.getLogger(__name__)\n    \n    try:\n        # Validate difficulty\n        valid_difficulties = [\"BEGINNER\", \"EASY\", \"MEDIUM\", \"HARD\", \"EXPERT\"]\n        if request.difficulty not in valid_difficulties:\n            return EnhancedQuestionCreateResponse(\n                success=False,\n                message=f\"Invalid difficulty. Must be one of: {valid_difficulties}\",\n                problem_id=request.problem_id,\n                error=\"Invalid difficulty level\"\n            )\n        \n        # Parse S3 paths\n        def parse_s3_path(s3_path: str) -> tuple:\n            \"\"\"Parse s3://bucket/key format\"\"\"\n            if not s3_path.startswith('s3://'):\n                raise ValueError(f\"Invalid S3 path format: {s3_path}\")\n            path_parts = s3_path[5:].split('/', 1)  # Remove 's3://'\n            if len(path_parts) != 2:\n                raise ValueError(f\"Invalid S3 path format: {s3_path}\")\n            return path_parts[0], path_parts[1]  # bucket, key\n        \n        try:\n            dataset_bucket, dataset_key = parse_s3_path(request.dataset_path)\n            solution_bucket, solution_key = parse_s3_path(request.solution_path)\n        except ValueError as e:\n            return EnhancedQuestionCreateResponse(\n                success=False,\n                message=str(e),\n                problem_id=request.problem_id,\n                error=\"Invalid S3 path format\"\n            )\n        \n        # Step 1: Validate and load dataset from S3\n        logger.info(f\"Loading dataset from S3: {request.dataset_path}\")\n        dataset_validation = s3_service.validate_dataset_file(\n            bucket=dataset_bucket,\n            key=dataset_key,\n            table_name=\"dataset\"\n        )\n        \n        if not dataset_validation[\"success\"]:\n            return EnhancedQuestionCreateResponse(\n                success=False,\n                message=f\"Dataset validation failed: {dataset_validation['error']}\",\n                problem_id=request.problem_id,\n                error=dataset_validation[\"error\"]\n            )\n        \n        # Step 2: Fetch solution from S3 (supports both SQL and parquet)\n        logger.info(f\"Fetching solution from S3: {request.solution_path}\")\n        solution_result = s3_service.fetch_solution_sql(\n            bucket=solution_bucket,\n            key=solution_key\n        )\n        \n        if not solution_result[\"success\"]:\n            return EnhancedQuestionCreateResponse(\n                success=False,\n                message=f\"Solution fetch failed: {solution_result['error']}\",\n                problem_id=request.problem_id,\n                error=solution_result[\"error\"]\n            )\n        \n        # Step 3: Get expected results based on solution type\n        logger.info(f\"Processing solution ({solution_result['file_type']})\")\n        import duckdb\n        import tempfile\n        \n        try:\n            if solution_result[\"file_type\"] == \"sql\":\n                # SQL solution: Execute SQL on dataset\n                solution_sql = solution_result[\"sql_content\"]\n                \n                # Download dataset to temporary file\n                temp_dataset_path = s3_service.download_to_temp_file(dataset_bucket, dataset_key)\n                \n                # Create DuckDB connection and load dataset\n                conn = duckdb.connect(\":memory:\")\n                conn.execute(\"CREATE TABLE dataset AS SELECT * FROM read_parquet(?)\", [temp_dataset_path])\n                \n                # Execute solution SQL\n                result = conn.execute(solution_sql).fetchall()\n                columns = [desc[0] for desc in conn.description]\n                \n                # Convert to list of dictionaries\n                expected_results = [dict(zip(columns, row)) for row in result]\n                \n                # Clean up temporary file\n                try:\n                    os.unlink(temp_dataset_path)\n                except:\n                    pass\n                    \n            elif solution_result[\"file_type\"] == \"parquet\":\n                # Parquet solution: Use parquet data directly as expected results\n                expected_results = solution_result[\"solution_data\"]\n                logger.info(f\"Using parquet solution with {len(expected_results)} rows\")\n                \n            else:\n                raise ValueError(f\"Unsupported solution file type: {solution_result['file_type']}\")\n                \n        except Exception as e:\n            logger.error(f\"Failed to process solution: {e}\")\n            return EnhancedQuestionCreateResponse(\n                success=False,\n                message=f\"Solution processing failed: {str(e)}\",\n                problem_id=request.problem_id,\n                error=f\"Solution processing error: {str(e)}\"\n            )\n        \n        # Step 4: Generate expected hash and preview rows\n        try:\n            expected_hash = s3_service.generate_expected_result_hash(expected_results)\n            preview_rows = expected_results[:5]  # First 5 rows\n            total_rows = len(expected_results)\n            \n            logger.info(f\"Generated hash: {expected_hash}, Total rows: {total_rows}, Preview rows: {len(preview_rows)}\")\n            \n        except Exception as e:\n            logger.error(f\"Failed to generate hash: {e}\")\n            return EnhancedQuestionCreateResponse(\n                success=False,\n                message=f\"Hash generation failed: {str(e)}\",\n                problem_id=request.problem_id,\n                error=f\"Hash generation error: {str(e)}\"\n            )\n        \n        # Step 5: Store metadata in Postgres\n        try:\n            # Check if problem already exists\n            existing_problem = db.query(Problem).filter(Problem.id == request.problem_id).first()\n            if existing_problem:\n                return EnhancedQuestionCreateResponse(\n                    success=False,\n                    message=f\"Problem with ID '{request.problem_id}' already exists\",\n                    problem_id=request.problem_id,\n                    error=\"Problem ID already exists\"\n                )\n            \n            # Validate topic if provided\n            if request.topic_id:\n                topic = db.query(Topic).filter(Topic.id == request.topic_id).first()\n                if not topic:\n                    return EnhancedQuestionCreateResponse(\n                        success=False,\n                        message=\"Invalid topic_id\",\n                        problem_id=request.problem_id,\n                        error=\"Invalid topic_id\"\n                    )\n            \n            # Create S3 data source configuration\n            s3_data_source = {\n                \"bucket\": dataset_bucket,\n                \"key\": dataset_key,\n                \"table_name\": \"dataset\",\n                \"description\": f\"Dataset for problem {request.problem_id}\",\n                \"etag\": dataset_validation.get(\"etag\")\n            }\n            \n            # Create question data structure\n            question_data = {\n                \"description\": request.description or f\"# {request.title}\\n\\nSolve this SQL problem using the provided dataset.\",\n                \"tables\": [\n                    {\n                        \"name\": \"dataset\",\n                        \"columns\": [\n                            {\"name\": col[\"column\"], \"type\": col[\"type\"]}\n                            for col in dataset_validation[\"schema\"]\n                        ],\n                        \"sampleData\": dataset_validation[\"sample_data\"]\n                    }\n                ],\n                \"expectedOutput\": preview_rows\n            }\n            \n            # Create the problem\n            problem = Problem(\n                id=request.problem_id,\n                title=request.title,\n                difficulty=request.difficulty,\n                question=question_data,\n                tags=request.tags,\n                company=request.company,\n                hints=request.hints,\n                premium=request.premium,\n                topic_id=request.topic_id,\n                s3_data_source=s3_data_source,\n                expected_hash=expected_hash,\n                preview_rows=preview_rows\n            )\n            \n            db.add(problem)\n            db.commit()\n            db.refresh(problem)\n            \n            logger.info(f\"Successfully created problem: {request.problem_id}\")\n            \n            return EnhancedQuestionCreateResponse(\n                success=True,\n                message=f\"Question '{request.title}' created successfully with {total_rows} expected result rows\",\n                problem_id=request.problem_id,\n                expected_hash=expected_hash,\n                preview_rows=preview_rows,\n                row_count=total_rows,\n                dataset_info={\n                    \"schema\": dataset_validation[\"schema\"],\n                    \"sample_data\": dataset_validation[\"sample_data\"],\n                    \"row_count\": dataset_validation[\"row_count\"],\n                    \"s3_path\": request.dataset_path\n                }\n            )\n            \n        except Exception as e:\n            db.rollback()\n            logger.error(f\"Failed to create problem in database: {e}\")\n            return EnhancedQuestionCreateResponse(\n                success=False,\n                message=f\"Database error: {str(e)}\",\n                problem_id=request.problem_id,\n                error=f\"Database storage failed: {str(e)}\"\n            )\n        \n    except Exception as e:\n        logger.error(f\"Unexpected error in create_question_enhanced: {e}\")\n        return EnhancedQuestionCreateResponse(\n            success=False,\n            message=f\"Unexpected error: {str(e)}\",\n            problem_id=request.problem_id,\n            error=f\"Internal server error: {str(e)}\"\n        )\n\n# ======= Multi-table S3 Management Endpoints =======\n\n@admin_router.post(\"/validate-multitable-s3\", response_model=MultiTableValidationResponse)\nasync def validate_multitable_s3(\n    request: MultiTableValidationRequest,\n    _: bool = Depends(verify_admin_user_access)\n):\n    \"\"\"Validate multiple S3 datasets for multi-table questions\"\"\"\n    logger = logging.getLogger(__name__)\n    \n    try:\n        if not request.datasets or len(request.datasets) == 0:\n            return MultiTableValidationResponse(\n                success=False,\n                message=\"At least one dataset is required\",\n                error=\"No datasets provided\"\n            )\n        \n        if len(request.datasets) > 10:  # Limit to prevent abuse\n            return MultiTableValidationResponse(\n                success=False,\n                message=\"Too many datasets. Maximum allowed: 10\",\n                error=\"Dataset limit exceeded\"\n            )\n        \n        validated_datasets = []\n        total_rows = 0\n        \n        # Validate each dataset\n        for i, dataset in enumerate(request.datasets):\n            logger.info(f\"Validating dataset {i+1}/{len(request.datasets)}: {dataset.bucket}/{dataset.key}\")\n            \n            # Validate the S3 dataset\n            validation_result = s3_service.validate_dataset_file(\n                bucket=dataset.bucket,\n                key=dataset.key,\n                table_name=dataset.table_name\n            )\n            \n            if not validation_result[\"success\"]:\n                return MultiTableValidationResponse(\n                    success=False,\n                    message=f\"Dataset {i+1} validation failed: {validation_result['error']}\",\n                    error=validation_result[\"error\"]\n                )\n            \n            # Add dataset info to validated list\n            dataset_info = {\n                \"table_name\": dataset.table_name,\n                \"bucket\": dataset.bucket,\n                \"key\": dataset.key,\n                \"description\": dataset.description,\n                \"schema\": validation_result[\"schema\"],\n                \"sample_data\": validation_result[\"sample_data\"][:3],  # Only first 3 rows\n                \"row_count\": validation_result[\"row_count\"],\n                \"etag\": validation_result.get(\"etag\")\n            }\n            validated_datasets.append(dataset_info)\n            total_rows += validation_result[\"row_count\"]\n        \n        logger.info(f\"Successfully validated {len(validated_datasets)} datasets with {total_rows} total rows\")\n        \n        return MultiTableValidationResponse(\n            success=True,\n            message=f\"Successfully validated {len(validated_datasets)} datasets\",\n            validated_datasets=validated_datasets,\n            total_tables=len(validated_datasets),\n            total_rows=total_rows\n        )\n        \n    except Exception as e:\n        logger.error(f\"Failed to validate multi-table S3: {e}\")\n        return MultiTableValidationResponse(\n            success=False,\n            message=f\"Validation failed: {str(e)}\",\n            error=f\"Internal server error: {str(e)}\"\n        )\n\n@admin_router.post(\"/create-multitable-question\", response_model=EnhancedQuestionCreateResponse)\nasync def create_multitable_question(\n    request: MultiTableQuestionCreateRequest,\n    db: Session = Depends(get_db),\n    _: bool = Depends(verify_admin_user_access)\n):\n    \"\"\"Create a question with multiple S3 datasets\"\"\"\n    logger = logging.getLogger(__name__)\n    \n    try:\n        # Validate difficulty\n        valid_difficulties = [\"BEGINNER\", \"EASY\", \"MEDIUM\", \"HARD\", \"EXPERT\"]\n        if request.difficulty not in valid_difficulties:\n            return EnhancedQuestionCreateResponse(\n                success=False,\n                message=f\"Invalid difficulty. Must be one of: {valid_difficulties}\",\n                problem_id=request.problem_id,\n                error=\"Invalid difficulty level\"\n            )\n        \n        # Check if problem_id already exists\n        existing_problem = db.query(Problem).filter(Problem.id == request.problem_id).first()\n        if existing_problem:\n            return EnhancedQuestionCreateResponse(\n                success=False,\n                message=f\"Problem ID '{request.problem_id}' already exists\",\n                problem_id=request.problem_id,\n                error=\"Problem ID already exists\"\n            )\n        \n        # Validate datasets\n        if not request.datasets or len(request.datasets) == 0:\n            return EnhancedQuestionCreateResponse(\n                success=False,\n                message=\"At least one dataset is required\",\n                problem_id=request.problem_id,\n                error=\"No datasets provided\"\n            )\n        \n        # Validate all datasets\n        validated_datasets = []\n        question_tables = []\n        \n        for i, dataset in enumerate(request.datasets):\n            # Validate the S3 dataset\n            validation_result = s3_service.validate_dataset_file(\n                bucket=dataset.bucket,\n                key=dataset.key,\n                table_name=dataset.table_name\n            )\n            \n            if not validation_result[\"success\"]:\n                return EnhancedQuestionCreateResponse(\n                    success=False,\n                    message=f\"Dataset {i+1} validation failed: {validation_result['error']}\",\n                    problem_id=request.problem_id,\n                    error=validation_result[\"error\"]\n                )\n            \n            # Store validated dataset info\n            dataset_info = {\n                \"bucket\": dataset.bucket,\n                \"key\": dataset.key,\n                \"table_name\": dataset.table_name,\n                \"description\": dataset.description,\n                \"etag\": validation_result.get(\"etag\")\n            }\n            validated_datasets.append(dataset_info)\n            \n            # Create table definition for question\n            table_def = {\n                \"name\": dataset.table_name,\n                \"columns\": [\n                    {\"name\": col[\"column\"], \"type\": col[\"type\"]}\n                    for col in validation_result[\"schema\"]\n                ],\n                \"sampleData\": validation_result[\"sample_data\"][:5]  # First 5 rows\n            }\n            question_tables.append(table_def)\n        \n        # Parse solution path\n        if not request.solution_path.startswith('s3://'):\n            return EnhancedQuestionCreateResponse(\n                success=False,\n                message=f\"Invalid solution S3 path format: {request.solution_path}\",\n                problem_id=request.problem_id,\n                error=\"Invalid S3 path format\"\n            )\n        \n        solution_path_parts = request.solution_path[5:].split('/', 1)\n        if len(solution_path_parts) != 2:\n            return EnhancedQuestionCreateResponse(\n                success=False,\n                message=f\"Invalid solution S3 path format: {request.solution_path}\",\n                problem_id=request.problem_id,\n                error=\"Invalid S3 path format\"\n            )\n        \n        solution_bucket, solution_key = solution_path_parts\n        \n        # Fetch solution SQL or parquet from S3\n        solution_result = s3_service.fetch_solution_sql(\n            bucket=solution_bucket,\n            key=solution_key\n        )\n        \n        if not solution_result[\"success\"]:\n            return EnhancedQuestionCreateResponse(\n                success=False,\n                message=f\"Solution fetch failed: {solution_result['error']}\",\n                problem_id=request.problem_id,\n                error=solution_result[\"error\"]\n            )\n        \n        # Create question data structure\n        question_data = {\n            \"description\": request.description or f\"# {request.title}\\n\\nSolve this SQL problem using the provided datasets.\",\n            \"tables\": question_tables,\n            \"expectedOutput\": []  # Will be populated by solution execution\n        }\n        \n        # Validate topic if provided\n        if request.topic_id:\n            topic = db.query(Topic).filter(Topic.id == request.topic_id).first()\n            if not topic:\n                return EnhancedQuestionCreateResponse(\n                    success=False,\n                    message=\"Invalid topic_id\",\n                    problem_id=request.problem_id,\n                    error=\"Invalid topic_id\"\n                )\n        \n        # Create the problem\n        problem = Problem(\n            id=request.problem_id,\n            title=request.title,\n            difficulty=request.difficulty,\n            question=question_data,\n            tags=request.tags,\n            company=request.company,\n            hints=request.hints,\n            premium=request.premium,\n            topic_id=request.topic_id,\n            solution_source='s3',\n            s3_solution_source={\n                \"bucket\": solution_bucket,\n                \"key\": solution_key,\n                \"description\": f\"Solution for multi-table problem {request.problem_id}\"\n            }\n        )\n        \n        db.add(problem)\n        db.commit()\n        db.refresh(problem)\n        \n        logger.info(f\"Successfully created multi-table problem: {request.problem_id}\")\n        \n        return EnhancedQuestionCreateResponse(\n            success=True,\n            message=f\"Multi-table question '{request.title}' created successfully with {len(validated_datasets)} datasets\",\n            problem_id=request.problem_id,\n            dataset_info={\n                \"datasets\": validated_datasets,\n                \"table_count\": len(validated_datasets),\n                \"solution_path\": request.solution_path\n            }\n        )\n        \n    except Exception as e:\n        db.rollback()\n        logger.error(f\"Failed to create multi-table question: {e}\")\n        return EnhancedQuestionCreateResponse(\n            success=False,\n            message=f\"Failed to create question: {str(e)}\",\n            problem_id=request.problem_id,\n            error=f\"Internal server error: {str(e)}\"\n        )\n\n\n@admin_router.post(\"/convert-parquet\")\nasync def convert_parquet_to_jsonb(\n    file: UploadFile = File(...),\n    admin_key: str = Depends(verify_admin_access)\n):\n    \"\"\"\n    Convert uploaded Parquet file to JSONB format for master_solution field.\n    \n    This endpoint allows admins to upload large Parquet files which are then\n    converted to the JSONB format expected by the master_solution field.\n    Parquet files offer superior compression and performance for large datasets.\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    try:\n        # Validate file type\n        if not file.filename.endswith('.parquet'):\n            raise HTTPException(\n                status_code=400,\n                detail=\"Only Parquet files (.parquet) are supported\"\n            )\n        \n        # Read the uploaded file content\n        file_content = await file.read()\n        \n        # Validate file size (25MB limit)\n        max_size_mb = 25\n        if len(file_content) > max_size_mb * 1024 * 1024:\n            raise HTTPException(\n                status_code=400,\n                detail=f\"File size {len(file_content) / (1024 * 1024):.1f}MB exceeds maximum allowed size of {max_size_mb}MB\"\n            )\n        \n        # Validate content type (basic check)\n        if file.content_type and not file.content_type.startswith('application/'):\n            logger.warning(f\"Unexpected content type: {file.content_type}\")\n        \n        # Create a temporary file to work with pyarrow\n        temp_file_path = None\n        try:\n            with tempfile.NamedTemporaryFile(suffix='.parquet', delete=False) as temp_file:\n                temp_file_path = temp_file.name\n                temp_file.write(file_content)\n                temp_file.flush()\n            \n            # Read the parquet file using pandas\n            df = pd.read_parquet(temp_file_path)\n            \n            # Validate the data size (10k rows limit for better performance)\n            row_limit = 10000\n            if len(df) > row_limit:\n                raise HTTPException(\n                    status_code=400,\n                    detail=f\"File contains {len(df)} rows. Maximum allowed is {row_limit} rows for performance reasons.\"\n                )\n            \n            # Clean problematic float values for JSON serialization\n            import numpy as np\n            import json\n            \n            # Replace NaN, inf, -inf with None (which becomes null in JSON)\n            df = df.replace([np.inf, -np.inf], None)\n            df = df.where(pd.notna(df), None)\n            \n            # Convert to list of dictionaries (JSONB format)\n            jsonb_data = df.to_dict(orient='records')\n            \n            # Additional safety: Clean any remaining problematic values that pandas might have missed\n            def clean_value(value):\n                if isinstance(value, float):\n                    if np.isnan(value) or np.isinf(value):\n                        return None\n                return value\n            \n            # Deep clean the jsonb_data\n            for row in jsonb_data:\n                for key, value in row.items():\n                    row[key] = clean_value(value)\n            \n            # Test JSON serialization to catch any remaining issues\n            try:\n                json.dumps(jsonb_data)\n            except (ValueError, TypeError) as json_error:\n                logger.error(f\"JSON serialization test failed: {json_error}\")\n                raise HTTPException(\n                    status_code=400,\n                    detail=f\"Data contains values that cannot be converted to JSON: {str(json_error)}\"\n                )\n            \n            logger.info(f\"Successfully converted Parquet file '{file.filename}' with {len(jsonb_data)} rows\")\n            \n            return {\n                \"success\": True,\n                \"message\": f\"Parquet file converted successfully\",\n                \"data\": jsonb_data,\n                \"metadata\": {\n                    \"filename\": file.filename,\n                    \"rows\": len(jsonb_data),\n                    \"columns\": list(df.columns),\n                    \"file_size_mb\": len(file_content) / (1024 * 1024)\n                }\n            }\n            \n        except HTTPException:\n            raise\n        except Exception as e:\n            logger.error(f\"Error reading Parquet file: {e}\")\n            raise HTTPException(\n                status_code=400,\n                detail=f\"Invalid Parquet file format: {str(e)}\"\n            )\n        finally:\n            # Always clean up temporary file\n            if temp_file_path:\n                try:\n                    import os\n                    os.unlink(temp_file_path)\n                except Exception as cleanup_error:\n                    logger.warning(f\"Failed to clean up temp file {temp_file_path}: {cleanup_error}\")\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Unexpected error in Parquet conversion: {e}\")\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Internal server error: {str(e)}\"\n        )","size_bytes":68901},"client/src/pages/admin-panel.tsx":{"content":"import { useState } from 'react';\nimport { Button } from '@/components/ui/button';\nimport { Input } from '@/components/ui/input';\nimport { Label } from '@/components/ui/label';\nimport { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';\nimport { Tabs, TabsContent, TabsList, TabsTrigger } from '@/components/ui/tabs';\nimport { Shield } from 'lucide-react';\nimport { useToast } from '@/hooks/use-toast';\nimport { AdminProvider, useAdmin } from '@/contexts/AdminContext';\nimport { CreateQuestionTab } from '@/components/admin/CreateQuestionTab';\nimport { DataSourceTab } from '@/components/admin/DataSourceTab';\nimport { SolutionsTab } from '@/components/admin/SolutionsTab';\nimport { SchemaInfoTab } from '@/components/admin/SchemaInfoTab';\n\nfunction AdminPanelContent() {\n  const { state, actions } = useAdmin();\n  const [adminKey, setAdminKey] = useState('');\n\n  const handleAuthenticate = () => {\n    actions.authenticate(adminKey);\n  };\n\n  if (!state.isAuthenticated) {\n    return (\n      <div className=\"min-h-screen bg-gray-50 dark:bg-gray-900 flex items-center justify-center\">\n        <Card className=\"w-full max-w-md\">\n          <CardHeader className=\"space-y-1\">\n            <div className=\"flex items-center justify-center mb-4\">\n              <Shield className=\"h-8 w-8 text-primary\" />\n            </div>\n            <CardTitle className=\"text-2xl text-center\">Admin Panel</CardTitle>\n            <p className=\"text-center text-muted-foreground\">\n              Enter your admin key to access the management interface\n            </p>\n          </CardHeader>\n          <CardContent className=\"space-y-4\">\n            <div>\n              <Label htmlFor=\"admin-key\">Admin Key</Label>\n              <Input\n                id=\"admin-key\"\n                type=\"password\"\n                value={adminKey}\n                onChange={(e) => setAdminKey(e.target.value)}\n                onKeyPress={(e) => e.key === 'Enter' && handleAuthenticate()}\n                placeholder=\"Enter admin key\"\n                data-testid=\"input-admin-key\"\n              />\n            </div>\n            <Button \n              className=\"w-full\" \n              onClick={handleAuthenticate}\n              disabled={state.loading}\n              data-testid=\"button-authenticate\"\n            >\n              {state.loading ? 'Authenticating...' : 'Access Admin Panel'}\n            </Button>\n          </CardContent>\n        </Card>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"min-h-screen bg-gray-50 dark:bg-gray-900\">\n      <div className=\"container mx-auto p-6\">\n        <div className=\"mb-6\">\n          <div className=\"flex items-center justify-between\">\n            <div>\n              <h1 className=\"text-3xl font-bold\">Admin Panel</h1>\n              <p className=\"text-muted-foreground\">\n                Manage problems, data sources, solutions, and schema information\n              </p>\n            </div>\n            <div className=\"flex items-center space-x-2 text-sm text-muted-foreground\">\n              <Shield className=\"h-4 w-4\" />\n              <span>Authenticated</span>\n            </div>\n          </div>\n        </div>\n\n        <Tabs \n          value={state.activeTab} \n          onValueChange={actions.setActiveTab} \n          className=\"space-y-6\"\n        >\n          <TabsList className=\"grid w-full grid-cols-4\">\n            <TabsTrigger value=\"create\" data-testid=\"tab-create-question\">\n              Create Question\n            </TabsTrigger>\n            <TabsTrigger value=\"datasource\" data-testid=\"tab-data-source\">\n              Data Source\n            </TabsTrigger>\n            <TabsTrigger value=\"solutions\" data-testid=\"tab-solutions\">\n              Solutions\n            </TabsTrigger>\n            <TabsTrigger value=\"schema\" data-testid=\"tab-schema-info\">\n              Schema Info\n            </TabsTrigger>\n          </TabsList>\n\n          <TabsContent value=\"create\" className=\"space-y-6\">\n            <CreateQuestionTab />\n          </TabsContent>\n\n          <TabsContent value=\"datasource\" className=\"space-y-6\">\n            <DataSourceTab />\n          </TabsContent>\n\n          <TabsContent value=\"solutions\" className=\"space-y-6\">\n            <SolutionsTab />\n          </TabsContent>\n\n          <TabsContent value=\"schema\" className=\"space-y-6\">\n            <SchemaInfoTab />\n          </TabsContent>\n        </Tabs>\n      </div>\n    </div>\n  );\n}\n\nexport default function AdminPanel() {\n  return (\n    <AdminProvider>\n      <AdminPanelContent />\n    </AdminProvider>\n  );\n}","size_bytes":4532},"client/src/components/AnswersScreen.tsx":{"content":"import { memo } from 'react';\nimport { Trophy } from 'lucide-react';\nimport { useQuery } from \"@tanstack/react-query\";\n\ninterface User {\n  id: string;\n  username: string;\n  profileImageUrl?: string;\n}\n\ninterface Solution {\n  id: string;\n  problemId: string;\n  createdBy: string;\n  title: string;\n  content: string;\n  sqlCode: string;\n  isOfficial: boolean;\n  createdAt: string;\n  updatedAt: string;\n  creator: User;\n}\n\ninterface AnswersScreenProps {\n  problemId: string;\n  className?: string;\n}\n\nconst SolutionDisplay = memo(function SolutionDisplay({\n  solution\n}: {\n  solution: Solution;\n}) {\n\n  return (\n    <div className=\"space-y-6\" data-testid={`solution-${solution.id}`}>\n      {/* Solution Title */}\n      <div>\n        <h3 className=\"text-xl font-bold text-foreground mb-2\" data-testid={`text-solution-title-${solution.id}`}>\n          {solution.title}\n        </h3>\n      </div>\n\n      {/* Explanation */}\n      <div>\n        <h4 className=\"text-lg font-semibold mb-3 text-foreground\">Explanation:</h4>\n        <div className=\"text-foreground prose prose-sm max-w-none dark:prose-invert\">\n          <div className=\"mb-3 text-foreground leading-relaxed whitespace-pre-wrap\" data-testid={`text-solution-explanation-${solution.id}`}>\n            {solution.content}\n          </div>\n        </div>\n      </div>\n\n      {/* SQL Solution */}\n      <div>\n        <h4 className=\"text-lg font-semibold mb-3 text-foreground\">SQL Solution:</h4>\n        <pre className=\"bg-muted p-4 rounded-lg overflow-x-auto text-sm font-mono text-foreground mb-4\" data-testid={`code-solution-${solution.id}`}>\n          {solution.sqlCode}\n        </pre>\n      </div>\n    </div>\n  );\n});\n\nconst AnswersScreen = memo(function AnswersScreen({ \n  problemId, \n  className \n}: AnswersScreenProps) {\n\n  // Fetch the solution (single solution)\n  const { data: solution, isLoading: solutionsLoading, error: solutionError } = useQuery({\n    queryKey: [`/api/problems/${problemId}/official-solution`],\n    enabled: !!problemId,\n  });\n\n  return (\n    <div className={`space-y-6 ${className || ''}`}>\n      {/* Header */}\n      <div className=\"flex items-center justify-between\">\n        <div>\n          <h2 className=\"text-2xl font-bold text-foreground flex items-center space-x-2\">\n            <Trophy className=\"w-6 h-6\" />\n            <span>Solutions</span>\n          </h2>\n        </div>\n      </div>\n\n      {/* Solutions Content */}\n      <div className=\"space-y-6\">\n        {solutionsLoading && (\n          <div className=\"text-center py-8\">\n            <div className=\"animate-spin rounded-full h-8 w-8 border-b-2 border-primary mx-auto mb-4\"></div>\n            <p className=\"text-muted-foreground\">Loading solutions...</p>\n          </div>\n        )}\n\n        {!solutionsLoading && !solutionError && solution && (\n          <SolutionDisplay\n            key={solution.id}\n            solution={solution}\n          />\n        )}\n\n        {!solutionsLoading && (solutionError || !solution) && (\n          <div className=\"text-center py-12\">\n            <Trophy className=\"h-16 w-16 text-muted-foreground mx-auto mb-4\" />\n            <h3 className=\"text-lg font-semibold text-foreground mb-2\">\n              No solution yet\n            </h3>\n            <p className=\"text-muted-foreground\">\n              {solutionError?.response?.status === 404 \n                ? \"The solution hasn't been published for this problem yet.\"\n                : \"Solutions haven't been published for this problem yet.\"\n              }\n            </p>\n          </div>\n        )}\n      </div>\n    </div>\n  );\n});\n\nexport default AnswersScreen;","size_bytes":3599},"netlify.toml":{"content":"[build]\n  base = \"client/\"\n  command = \"npm run build\"\n  publish = \"dist/\"\n\n[build.environment]\n  NODE_VERSION = \"20\"\n  NPM_VERSION = \"9\"\n\n# Redirect all non-API routes to index.html for React Router\n[[redirects]]\n  from = \"/*\"\n  to = \"/index.html\"\n  status = 200\n  conditions = {Role = [\"admin\", \"editor\"], Country = [\"US\"]}\n\n# Handle API routes (if using Netlify Functions)\n[[redirects]]\n  from = \"/api/*\"\n  to = \"/.netlify/functions/:splat\"\n  status = 200\n\n# Prevent processing of certain files\n[[headers]]\n  for = \"/*\"\n  [headers.values]\n    X-Frame-Options = \"DENY\"\n    X-XSS-Protection = \"1; mode=block\"\n    X-Content-Type-Options = \"nosniff\"\n    Referrer-Policy = \"strict-origin-when-cross-origin\"\n\n# Cache static assets\n[[headers]]\n  for = \"/assets/*\"\n  [headers.values]\n    Cache-Control = \"public, max-age=31536000, immutable\"","size_bytes":836},"railway.toml":{"content":"[build]\nbuilder = \"NIXPACKS\"\n\n[deploy]\nstartCommand = \"uvicorn api.main:app --host 0.0.0.0 --port $PORT\"\n\n[env]\nPYTHONPATH = \"/app\"\n\n# Runtime settings\n[nixpacks.phases.setup]\nnixPkgs = [\"python311\", \"python311Packages.pip\"]\n\n[nixpacks.phases.install]\ncmds = [\"pip install -r requirements.txt\"]\n\n[nixpacks.phases.build]\ncmds = []\n\n# Health check configuration\n[healthcheck]\npath = \"/api/health\"\n","size_bytes":395},"api/duckdb_sandbox.py":{"content":"\"\"\"\nDuckDB Sandbox Service for SQL Learning Platform\n===============================================\nHandles SQL execution against parquet datasets from S3 for secure sandbox environments.\n\"\"\"\n\nimport duckdb\nimport os\nimport logging\nimport re\nfrom typing import Dict, Any, List, Optional, Union\nfrom fastapi import HTTPException\nfrom urllib.parse import urlparse\nimport tempfile\nimport time\nfrom concurrent.futures import ThreadPoolExecutor, TimeoutError\nfrom .s3_service import s3_service\n\nlogger = logging.getLogger(__name__)\n\nclass DuckDBSandbox:\n    \"\"\"\n    Isolated DuckDB instance for executing user SQL queries against problem datasets\n    \"\"\"\n    \n    # Security constants  \n    ALLOWED_DOMAINS = [\n        # S3 domains only - removed GitHub domains\n    ]\n    TABLE_NAME_PATTERN = re.compile(r'^[a-zA-Z_][a-zA-Z0-9_]{0,63}$')\n    \n    # Resource limits for security and performance\n    MAX_TABLES_PER_PROBLEM = 20  # Maximum number of tables per problem\n    MAX_SAMPLE_ROWS_PER_TABLE = 1000  # Maximum sample rows per table\n    \n    def __init__(self, timeout_seconds: int = 30, memory_limit_mb: int = 128, sandbox_id: str = None):\n        \"\"\"\n        Initialize DuckDB sandbox with memory and time limits\n        \n        Args:\n            timeout_seconds: Maximum query execution time\n            memory_limit_mb: Memory limit for DuckDB instance\n            sandbox_id: Unique identifier for this sandbox instance\n        \"\"\"\n        import uuid\n        self.id = sandbox_id or str(uuid.uuid4())\n        self.timeout_seconds = timeout_seconds\n        self.memory_limit_mb = memory_limit_mb\n        self.conn = None\n        # GitHub repository removed - using S3 only\n        self.loaded_table_names = set()  # Track loaded table names for security\n        \n        # Initialize DuckDB connection\n        self._initialize_connection()\n    \n    def _validate_table_name(self, table_name: str) -> bool:\n        \"\"\"Validate table name against SQL injection patterns\"\"\"\n        return bool(self.TABLE_NAME_PATTERN.match(table_name))\n    \n    # URL validation removed - using S3 only, no external URL access\n    \n    def _escape_identifier(self, identifier: str) -> str:\n        \"\"\"Escape SQL identifier to prevent injection\"\"\"\n        # Basic escaping - wrap in double quotes and escape internal quotes\n        return f'\"{identifier.replace(chr(34), chr(34)+chr(34))}\"'\n    \n    def _validate_column_type(self, col_type: str) -> str:\n        \"\"\"\n        Validate and sanitize column type to prevent DDL injection\n        \n        Args:\n            col_type: Column type string from user input\n            \n        Returns:\n            Validated and sanitized column type, or raises ValueError if invalid\n        \"\"\"\n        if not col_type or not isinstance(col_type, str):\n            return \"VARCHAR\"\n        \n        # Clean and normalize\n        col_type = col_type.upper().strip()\n        \n        # Allowed DuckDB types (strict allowlist for security)\n        allowed_types = {\n            # Integer types\n            'BOOLEAN', 'BOOL',\n            'TINYINT', 'SMALLINT', 'INTEGER', 'INT', 'BIGINT',\n            'UTINYINT', 'USMALLINT', 'UINTEGER', 'UBIGINT',\n            \n            # Floating point types\n            'REAL', 'FLOAT', 'DOUBLE',\n            \n            # String types  \n            'VARCHAR', 'CHAR', 'TEXT', 'STRING',\n            \n            # Date/time types\n            'DATE', 'TIME', 'TIMESTAMP', 'TIMESTAMPTZ',\n            \n            # Other types\n            'UUID', 'BLOB', 'JSON'\n        }\n        \n        # Handle parameterized types (preserve parameters for valid base types)\n        base_type = col_type\n        parameters = \"\"\n        if '(' in col_type:\n            base_type = col_type.split('(')[0].strip()\n            # Extract parameters but validate they contain only digits, commas, spaces\n            param_part = col_type[col_type.find('('):]\n            if re.match(r'^\\(\\s*\\d+(\\s*,\\s*\\d+)?\\s*\\)$', param_part):\n                parameters = param_part\n            else:\n                # Invalid parameters, strip them\n                parameters = \"\"\n        \n        # Check if base type is allowed\n        if base_type not in allowed_types:\n            logger.warning(f\"Invalid column type '{col_type}', defaulting to VARCHAR\")\n            return \"VARCHAR\"\n        \n        # Return validated type with parameters if valid\n        return base_type + parameters\n\n    def _create_table_from_question_schema(self, table_name: str, columns: List[Dict[str, str]], sample_data: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"\n        Create a table in DuckDB from question schema definition\n        \n        Args:\n            table_name: Name of the table to create\n            columns: List of column definitions with 'name' and 'type' keys\n            sample_data: List of sample data rows to insert\n            \n        Returns:\n            Dict with success status and table information\n        \"\"\"\n        try:\n            escaped_table_name = self._escape_identifier(table_name)\n            \n            # Begin transaction for atomicity\n            self.conn.execute(\"BEGIN TRANSACTION\")\n            \n            try:\n                # Build CREATE TABLE statement with validated types\n                column_definitions = []\n                for col in columns:\n                    col_name = col.get('name', '').strip()\n                    col_type = col.get('type', 'VARCHAR').strip()\n                    \n                    if not col_name:\n                        self.conn.execute(\"ROLLBACK\")\n                        return {\"success\": False, \"error\": f\"Column name is required for table '{table_name}'\"}\n                    \n                    # Validate column name\n                    if not self._validate_table_name(col_name):  # Reuse table name validation for column names\n                        self.conn.execute(\"ROLLBACK\")\n                        return {\"success\": False, \"error\": f\"Invalid column name '{col_name}' for table '{table_name}'\"}\n                    \n                    # CRITICAL: Validate and sanitize column type to prevent DDL injection\n                    validated_type = self._validate_column_type(col_type)\n                    \n                    # Escape column name and add validated type\n                    escaped_col_name = self._escape_identifier(col_name)\n                    column_definitions.append(f\"{escaped_col_name} {validated_type}\")\n                \n                # Create the table\n                create_sql = f\"CREATE TABLE {escaped_table_name} ({', '.join(column_definitions)})\"\n                logger.info(f\"Creating table with SQL: {create_sql}\")\n                \n                # Drop table if it exists first\n                self.conn.execute(f\"DROP TABLE IF EXISTS {escaped_table_name}\")\n                self.conn.execute(create_sql)\n                \n                # Insert sample data if provided\n                rows_inserted = 0\n                if sample_data and len(sample_data) > 0:\n                    rows_inserted = self._insert_sample_data(table_name, sample_data)\n                \n                # Commit transaction on success\n                self.conn.execute(\"COMMIT\")\n                \n                # Get table schema information for response\n                schema_result = self.conn.execute(f\"DESCRIBE {escaped_table_name}\").fetchall()\n                schema = [{\"column\": row[0], \"type\": row[1]} for row in schema_result]\n                \n                # Get actual row count\n                count_result = self.conn.execute(f\"SELECT COUNT(*) FROM {escaped_table_name}\").fetchone()\n                actual_row_count = count_result[0] if count_result else 0\n                \n                # Get sample data for display (limit to 3 rows)\n                sample_result = self.conn.execute(f\"SELECT * FROM {escaped_table_name} LIMIT 3\").fetchdf()\n                display_sample_data = sample_result.to_dict(orient=\"records\") if not sample_result.empty else []\n                \n                table_info = {\n                    \"name\": table_name,\n                    \"schema\": schema,\n                    \"row_count\": actual_row_count,\n                    \"sample_data\": display_sample_data\n                }\n                \n                logger.info(f\"Successfully created table '{table_name}' with {actual_row_count} rows\")\n                \n                return {\n                    \"success\": True,\n                    \"message\": f\"Table '{table_name}' created successfully with {actual_row_count} rows\",\n                    \"table_info\": table_info\n                }\n                \n            except Exception as inner_e:\n                # Rollback on any error during table creation\n                self.conn.execute(\"ROLLBACK\")\n                raise inner_e\n            \n        except Exception as e:\n            logger.error(f\"Failed to create table '{table_name}': {e}\")\n            return {\"success\": False, \"error\": f\"Failed to create table '{table_name}': {str(e)}\"}\n    \n    def _insert_sample_data(self, table_name: str, sample_data: List[Dict[str, Any]]) -> int:\n        \"\"\"\n        Insert sample data into a table\n        \n        Args:\n            table_name: Name of the table\n            sample_data: List of data rows to insert\n            \n        Returns:\n            Number of rows inserted\n        \"\"\"\n        try:\n            if not sample_data or len(sample_data) == 0:\n                return 0\n            \n            escaped_table_name = self._escape_identifier(table_name)\n            rows_inserted = 0\n            \n            # Get table columns to validate data\n            schema_result = self.conn.execute(f\"DESCRIBE {escaped_table_name}\").fetchall()\n            table_columns = [row[0] for row in schema_result]\n            \n            for row_data in sample_data:\n                try:\n                    # Filter data to only include columns that exist in the table\n                    filtered_data = {col: val for col, val in row_data.items() if col in table_columns}\n                    \n                    if not filtered_data:\n                        continue  # Skip empty rows\n                    \n                    # Build INSERT statement with parameterized queries for safety\n                    columns = list(filtered_data.keys())\n                    values = list(filtered_data.values())\n                    \n                    escaped_columns = [self._escape_identifier(col) for col in columns]\n                    placeholders = ', '.join(['?' for _ in values])\n                    \n                    insert_sql = f\"INSERT INTO {escaped_table_name} ({', '.join(escaped_columns)}) VALUES ({placeholders})\"\n                    self.conn.execute(insert_sql, values)\n                    rows_inserted += 1\n                    \n                except Exception as row_error:\n                    logger.warning(f\"Failed to insert row into '{table_name}': {row_error}. Row data: {row_data}\")\n                    # Continue with other rows even if one fails\n                    continue\n            \n            logger.info(f\"Inserted {rows_inserted} rows into table '{table_name}'\")\n            return rows_inserted\n            \n        except Exception as e:\n            logger.error(f\"Failed to insert sample data into '{table_name}': {e}\")\n            return 0\n    \n    def _initialize_connection(self):\n        \"\"\"Initialize DuckDB connection with security and performance settings\"\"\"\n        try:\n            # Create in-memory DuckDB instance for isolation\n            self.conn = duckdb.connect(\":memory:\")\n            \n            # Configure DuckDB settings\n            self.conn.execute(\"SET memory_limit = ?\", [f\"{self.memory_limit_mb}MB\"])\n            self.conn.execute(\"SET threads = 1\")  # Limit threads for sandbox\n            \n            # Note: httpfs is only loaded temporarily during setup_problem_data, \n            # not permanently for user queries to prevent SSRF\n            \n            logger.info(f\"DuckDB sandbox initialized with {self.memory_limit_mb}MB memory limit\")\n            \n        except Exception as e:\n            logger.error(f\"Failed to initialize DuckDB connection: {e}\")\n            raise HTTPException(status_code=500, detail=\"Failed to initialize sandbox environment\")\n    \n    async def setup_problem_data(self, problem_id: str, s3_datasets: Union[Dict[str, str], List[Dict[str, str]]] = None) -> Dict[str, Any]:\n        \"\"\"\n        Load problem dataset into DuckDB from S3 parquet files.\n        Supports both single table and multiple table configurations.\n        \n        Args:\n            problem_id: Unique identifier for the problem\n            s3_datasets: Either a single dict or list of dicts containing bucket, key, table_name, description for datasets\n            \n        Returns:\n            Dict with success status and any error messages\n        \"\"\"\n        try:\n            tables_created = []\n            total_rows = 0\n            \n            if not s3_datasets:\n                return {\"success\": False, \"error\": \"s3_datasets parameter is required\"}\n            \n            # Normalize s3_datasets to always be a list\n            if isinstance(s3_datasets, dict):\n                datasets_list = [s3_datasets]\n            else:\n                datasets_list = s3_datasets\n            \n            # Handle S3 datasets\n            if len(datasets_list) > 0:\n                # Resource limits enforcement\n                if len(datasets_list) > self.MAX_TABLES_PER_PROBLEM:\n                    return {\"success\": False, \"error\": f\"Too many S3 datasets: {len(datasets_list)}. Maximum allowed: {self.MAX_TABLES_PER_PROBLEM}\"}\n                \n                logger.info(f\"Loading {len(datasets_list)} tables from S3 datasets for problem {problem_id}\")\n                \n                # Track successes and failures for partial success support\n                dataset_errors = []\n                \n                for dataset in s3_datasets:\n                    dataset_table_name = dataset.get('table_name', 'unknown')\n                    dataset_s3_path = f\"s3://{dataset.get('bucket', 'unknown')}/{dataset.get('key', 'unknown')}\"\n                    \n                    try:\n                        bucket = dataset.get('bucket', '').strip()\n                        key = dataset.get('key', '').strip()\n                        table_name = dataset.get('table_name', '').strip()\n                        description = dataset.get('description', '')\n                        etag = dataset.get('etag', '')\n                        \n                        if not bucket or not key or not table_name:\n                            error_msg = f\"Invalid S3 dataset configuration: bucket, key, and table_name are required\"\n                            logger.error(f\"Dataset {dataset_table_name} ({dataset_s3_path}): {error_msg}\")\n                            dataset_errors.append({\"table\": dataset_table_name, \"s3_path\": dataset_s3_path, \"error\": error_msg})\n                            continue\n                        \n                        # Security validation\n                        if not self._validate_table_name(table_name):\n                            error_msg = f\"Invalid table name: {table_name}\"\n                            logger.error(f\"Dataset {dataset_table_name} ({dataset_s3_path}): {error_msg}\")\n                            dataset_errors.append({\"table\": dataset_table_name, \"s3_path\": dataset_s3_path, \"error\": error_msg})\n                            continue\n                        \n                        logger.info(f\"Loading table '{table_name}' from S3: s3://{bucket}/{key}\")\n                        \n                        # Use S3 service to download to temporary file\n                        temp_file_path = s3_service.download_to_temp_file(bucket, key)\n                        \n                        try:\n                            # Load parquet from local temp file\n                            escaped_table_name = self._escape_identifier(table_name)\n                            \n                            # Test if parquet file is readable\n                            result = self.conn.execute(\"SELECT COUNT(*) as row_count FROM read_parquet(?)\", [temp_file_path]).fetchone()\n                            \n                            if result is None:\n                                error_msg = f\"Parquet file not readable: s3://{bucket}/{key}\"\n                                logger.error(f\"Dataset {dataset_table_name} ({dataset_s3_path}): {error_msg}\")\n                                dataset_errors.append({\"table\": dataset_table_name, \"s3_path\": dataset_s3_path, \"error\": error_msg})\n                                continue\n                            \n                            # Drop table if it exists and create new one\n                            self.conn.execute(f\"DROP TABLE IF EXISTS {escaped_table_name}\")\n                            self.conn.execute(f\"CREATE TABLE {escaped_table_name} AS SELECT * FROM read_parquet(?)\", [temp_file_path])\n                            \n                            # Get table schema information\n                            schema_result = self.conn.execute(f\"DESCRIBE {escaped_table_name}\").fetchall()\n                            schema = [{\"column\": row[0], \"type\": row[1]} for row in schema_result]\n                            \n                            row_count = result[0] if result else 0\n                            total_rows += row_count\n                            \n                            # Get sample data for display (limit to 3 rows)\n                            sample_result = self.conn.execute(f\"SELECT * FROM {escaped_table_name} LIMIT 3\").fetchdf()\n                            display_sample_data = sample_result.to_dict(orient=\"records\") if not sample_result.empty else []\n                            \n                            table_info = {\n                                \"name\": table_name,\n                                \"schema\": schema,\n                                \"row_count\": row_count,\n                                \"sample_data\": display_sample_data,\n                                \"data_source\": f\"s3://{bucket}/{key}\",\n                                \"etag\": etag\n                            }\n                            \n                            tables_created.append(table_info)\n                            \n                            # Track loaded table for security validation\n                            self.loaded_table_names.add(table_name)\n                            \n                            logger.info(f\"Successfully loaded table '{table_name}' with {row_count} rows from S3\")\n                            \n                        finally:\n                            # Clean up temporary file\n                            try:\n                                os.unlink(temp_file_path)\n                            except:\n                                pass\n                        \n                    except Exception as e:\n                        error_msg = f\"Failed to load S3 dataset: {str(e)}\"\n                        logger.error(f\"Dataset {dataset_table_name} ({dataset_s3_path}): {error_msg}\", exc_info=True)\n                        dataset_errors.append({\"table\": dataset_table_name, \"s3_path\": dataset_s3_path, \"error\": error_msg})\n                        continue\n                \n                # Determine success based on partial results\n                if len(tables_created) == 0:\n                    # No tables loaded successfully - return complete failure\n                    if len(dataset_errors) > 0:\n                        consolidated_error = f\"Failed to load any S3 datasets. Errors: \" + \"; \".join([f\"{err['table']}: {err['error']}\" for err in dataset_errors])\n                    else:\n                        consolidated_error = \"Failed to load any S3 datasets due to unknown errors\"\n                    \n                    logger.error(f\"Complete failure loading S3 datasets for problem {problem_id}: {consolidated_error}\")\n                    return {\"success\": False, \"error\": consolidated_error, \"dataset_errors\": dataset_errors}\n                \n                elif len(dataset_errors) == 0:\n                    # All tables loaded successfully\n                    return {\n                        \"success\": True,\n                        \"message\": f\"Successfully loaded all {len(tables_created)} tables from S3 datasets\",\n                        \"tables\": tables_created,\n                        \"total_tables\": len(tables_created),\n                        \"total_rows\": total_rows,\n                        \"data_source\": \"s3_datasets\"\n                    }\n                \n                else:\n                    # Partial success - some tables loaded, some failed\n                    warnings_msg = f\"Loaded {len(tables_created)} of {len(s3_datasets)} tables. Failed: \" + \"; \".join([f\"{err['table']}: {err['error']}\" for err in dataset_errors])\n                    logger.warning(f\"Partial success loading S3 datasets for problem {problem_id}: {warnings_msg}\")\n                    \n                    return {\n                        \"success\": True,\n                        \"message\": f\"Partially loaded {len(tables_created)} of {len(s3_datasets)} tables from S3 datasets\",\n                        \"tables\": tables_created,\n                        \"total_tables\": len(tables_created),\n                        \"total_rows\": total_rows,\n                        \"data_source\": \"s3_datasets\",\n                        \"warnings\": warnings_msg,\n                        \"dataset_errors\": dataset_errors\n                    }\n            \n            # Fallback to S3 data source (legacy single-table support)\n            elif s3_data_source:\n                # Use S3 data source\n                bucket = s3_data_source.get('bucket', '')\n                key = s3_data_source.get('key', '')\n                table_name = s3_data_source.get('table_name', 'problem_data')\n                description = s3_data_source.get('description', '')\n                etag = s3_data_source.get('etag', '')\n                \n                logger.info(f\"Loading problem data from S3: s3://{bucket}/{key}\")\n                \n                # Security validation\n                if not self._validate_table_name(table_name):\n                    return {\"success\": False, \"error\": f\"Invalid table name: {table_name}\"}\n                \n                # Use S3 service to download to temporary file\n                try:\n                    temp_file_path = s3_service.download_to_temp_file(bucket, key)\n                    \n                    try:\n                        # Load parquet from local temp file (no remote access needed)\n                        escaped_table_name = self._escape_identifier(table_name)\n                        \n                        # Test if parquet file is readable\n                        result = self.conn.execute(\"SELECT COUNT(*) as row_count FROM read_parquet(?)\", [temp_file_path]).fetchone()\n                        \n                        if result is None:\n                            return {\"success\": False, \"error\": f\"Parquet file not readable: s3://{bucket}/{key}\"}\n                        \n                        # Drop table if it exists and create new one\n                        self.conn.execute(f\"DROP TABLE IF EXISTS {escaped_table_name}\")\n                        self.conn.execute(f\"CREATE TABLE {escaped_table_name} AS SELECT * FROM read_parquet(?)\", [temp_file_path])\n                        \n                        # Get table schema for user reference\n                        schema_result = self.conn.execute(f\"DESCRIBE {escaped_table_name}\").fetchall()\n                        schema = [{\"column\": row[0], \"type\": row[1]} for row in schema_result]\n                        \n                        row_count = result[0] if result else 0\n                        \n                        # Track loaded table for security validation\n                        self.loaded_table_names.add(table_name)\n                        \n                        return {\n                            \"success\": True,\n                            \"message\": f\"Problem data loaded successfully from S3 into {table_name}\",\n                            \"schema\": schema,\n                            \"row_count\": row_count,\n                            \"data_source\": f\"s3://{bucket}/{key}\",\n                            \"table_name\": table_name,\n                            \"etag\": etag\n                        }\n                        \n                    finally:\n                        # Clean up temporary file\n                        try:\n                            os.unlink(temp_file_path)\n                        except:\n                            pass\n                            \n                except Exception as e:\n                    logger.error(f\"Failed to load from S3: {e}\")\n                    return {\"success\": False, \"error\": f\"Failed to load S3 dataset: {str(e)}\"}\n            \n            else:\n                # No data source provided\n                return {\"success\": False, \"error\": \"Either question_tables or s3_data_source is required\"}\n            \n        except Exception as e:\n            error_msg = f\"Failed to load problem data for {problem_id}: {str(e)}\"\n            logger.error(error_msg)\n            return {\"success\": False, \"error\": error_msg}\n    \n    def analyze_execution_plan(self, query: str) -> Dict[str, Any]:\n        \"\"\"\n        Layer 2: Execution Plan Analysis - Verify queries actually scan tables and perform operations\n        \n        Args:\n            query: SQL query string to analyze\n            \n        Returns:\n            Dict containing plan analysis results and anti-hardcode validation\n        \"\"\"\n        result = {\n            'plan_valid': True,\n            'errors': [],\n            'warnings': [],\n            'analysis': {\n                'tables_scanned': [],\n                'rows_scanned': 0,\n                'has_table_scan': False,\n                'has_aggregation': False,\n                'has_join': False,\n                'is_constant_only': False\n            }\n        }\n        \n        try:\n            # Get execution plan using DuckDB's EXPLAIN\n            plan_query = f\"EXPLAIN {query}\"\n            plan_result = self.conn.execute(plan_query).fetchall()\n            \n            if not plan_result:\n                result['plan_valid'] = False\n                result['errors'].append(\"Unable to generate execution plan\")\n                return result\n            \n            # Convert plan to string for analysis\n            plan_text = '\\n'.join([str(row[0]) if isinstance(row, tuple) else str(row) for row in plan_result])\n            plan_text_upper = plan_text.upper()\n            \n            # Analyze plan for table scanning\n            if 'SEQ_SCAN' in plan_text_upper or 'TABLE_SCAN' in plan_text_upper:\n                result['analysis']['has_table_scan'] = True\n                \n                # Extract table names from scan operations\n                import re\n                table_scan_matches = re.findall(r'(?:SEQ_SCAN|TABLE_SCAN)\\s+(\\w+)', plan_text_upper)\n                result['analysis']['tables_scanned'] = table_scan_matches\n            \n            # Check for aggregation operations\n            if any(op in plan_text_upper for op in ['AGGREGATE', 'HASH_GROUP_BY', 'GROUP_BY']):\n                result['analysis']['has_aggregation'] = True\n            \n            # Check for join operations\n            if any(op in plan_text_upper for op in ['HASH_JOIN', 'NESTED_LOOP_JOIN', 'MERGE_JOIN', 'JOIN']):\n                result['analysis']['has_join'] = True\n            \n            # Check for constant-only operations (red flag for hardcoded queries)\n            if 'CONSTANT_DATA' in plan_text_upper or 'VALUES' in plan_text_upper:\n                if not result['analysis']['has_table_scan']:\n                    result['analysis']['is_constant_only'] = True\n                    result['plan_valid'] = False\n                    result['errors'].append(\"Query execution plan shows no table access - likely hardcoded constants\")\n            \n            # Verify actual data interaction\n            if result['analysis']['has_table_scan']:\n                # Get row count statistics using EXPLAIN ANALYZE (with timeout protection)\n                try:\n                    analyze_query = f\"EXPLAIN ANALYZE {query}\"\n                    analyze_result = self.conn.execute(analyze_query).fetchall()\n                    analyze_text = '\\n'.join([str(row[0]) if isinstance(row, tuple) else str(row) for row in analyze_result])\n                    \n                    # Extract row counts from EXPLAIN ANALYZE output\n                    rows_pattern = re.findall(r'(\\d+)\\s+rows', analyze_text, re.IGNORECASE)\n                    if rows_pattern:\n                        result['analysis']['rows_scanned'] = sum(int(count) for count in rows_pattern)\n                        \n                        # If no rows were actually scanned despite table references, flag as suspicious\n                        if result['analysis']['rows_scanned'] == 0 and result['analysis']['has_table_scan']:\n                            result['warnings'].append(\"Query plan shows table scan but no rows processed - verify query logic\")\n                    \n                except Exception as analyze_error:\n                    # EXPLAIN ANALYZE might fail for some queries, but that's not necessarily an error\n                    logger.warning(f\"EXPLAIN ANALYZE failed: {analyze_error}\")\n                    result['warnings'].append(\"Unable to analyze actual row processing\")\n            \n            # Final validation: queries should interact with data\n            if not result['analysis']['has_table_scan'] and not result['analysis']['is_constant_only']:\n                result['plan_valid'] = False\n                result['errors'].append(\"Query execution plan shows no data interaction\")\n                \n        except Exception as e:\n            logger.error(f\"Execution plan analysis failed: {e}\")\n            result['plan_valid'] = False\n            result['errors'].append(f\"Plan analysis error: {str(e)}\")\n        \n        return result\n\n    def create_data_variants(self, seed: int = 12345) -> Dict[str, Any]:\n        \"\"\"\n        Layer 3: Data Dependency Testing - Create slightly modified dataset variants\n        to catch hardcoded queries that don't actually analyze the data\n        \n        Args:\n            seed: Random seed for reproducible variants\n            \n        Returns:\n            Dict containing variant creation results\n        \"\"\"\n        result = {\n            'success': True,\n            'errors': [],\n            'variant_tables': [],\n            'changes_applied': []\n        }\n        \n        try:\n            import random\n            random.seed(seed)\n            \n            for table_name in self.loaded_table_names:\n                try:\n                    # Create variant table name\n                    variant_table = f\"variant_{table_name}\"\n                    \n                    # Get table schema and sample data\n                    schema_query = f\"DESCRIBE {table_name}\"\n                    schema_result = self.conn.execute(schema_query).fetchall()\n                    \n                    # Get column info\n                    columns = []\n                    numeric_columns = []\n                    text_columns = []\n                    \n                    for row in schema_result:\n                        col_name = row[0]\n                        col_type = row[1].upper()\n                        columns.append((col_name, col_type))\n                        \n                        if any(t in col_type for t in ['INT', 'NUMERIC', 'FLOAT', 'DOUBLE', 'DECIMAL']):\n                            numeric_columns.append(col_name)\n                        elif any(t in col_type for t in ['VARCHAR', 'TEXT', 'CHAR', 'STRING']):\n                            text_columns.append(col_name)\n                    \n                    # Create variant table with modified data\n                    # Strategy: Modify 1-2% of rows with small, deterministic changes\n                    \n                    # Get total row count\n                    count_result = self.conn.execute(f\"SELECT COUNT(*) FROM {table_name}\").fetchone()\n                    total_rows = count_result[0] if count_result else 0\n                    \n                    if total_rows == 0:\n                        result['errors'].append(f\"Table {table_name} is empty, cannot create variant\")\n                        continue\n                    \n                    # Calculate number of rows to modify (1-2% minimum 1 row)\n                    rows_to_modify = max(1, int(total_rows * 0.015))  # 1.5%\n                    \n                    # Create variant table as copy of original\n                    create_variant_sql = f\"CREATE TEMP TABLE {variant_table} AS SELECT * FROM {table_name}\"\n                    self.conn.execute(create_variant_sql)\n                    \n                    changes_made = []\n                    \n                    # Apply numeric modifications if possible\n                    if numeric_columns:\n                        for col in numeric_columns[:2]:  # Limit to 2 columns to avoid over-modification\n                            # Use deterministic selection based on hash\n                            update_sql = f\"\"\"\n                                UPDATE {variant_table} \n                                SET {col} = {col} + 1 \n                                WHERE ABS(HASH(CAST(rowid AS VARCHAR)) % {total_rows}) < {rows_to_modify}\n                                  AND {col} IS NOT NULL\n                            \"\"\"\n                            try:\n                                modified_count = self.conn.execute(update_sql).rowcount or 0\n                                if modified_count > 0:\n                                    changes_made.append(f\"Modified {modified_count} rows in column {col} (+1)\")\n                            except Exception as e:\n                                logger.warning(f\"Failed to modify numeric column {col}: {e}\")\n                    \n                    # Apply text modifications if possible (more subtle)\n                    if text_columns and not changes_made:  # Only if no numeric changes were made\n                        for col in text_columns[:1]:  # Limit to 1 text column\n                            # Append a small marker to string values\n                            update_sql = f\"\"\"\n                                UPDATE {variant_table} \n                                SET {col} = {col} || '_v' \n                                WHERE ABS(HASH(CAST(rowid AS VARCHAR)) % {total_rows}) < {rows_to_modify}\n                                  AND {col} IS NOT NULL\n                                  AND LENGTH({col}) < 100\n                            \"\"\"\n                            try:\n                                modified_count = self.conn.execute(update_sql).rowcount or 0\n                                if modified_count > 0:\n                                    changes_made.append(f\"Modified {modified_count} rows in column {col} (append '_v')\")\n                            except Exception as e:\n                                logger.warning(f\"Failed to modify text column {col}: {e}\")\n                    \n                    if changes_made:\n                        result['variant_tables'].append(variant_table)\n                        result['changes_applied'].extend(changes_made)\n                    else:\n                        # Drop the variant table if no changes were made\n                        self.conn.execute(f\"DROP TABLE IF EXISTS {variant_table}\")\n                        result['errors'].append(f\"Could not create meaningful variant for table {table_name}\")\n                        \n                except Exception as table_error:\n                    logger.error(f\"Failed to create variant for table {table_name}: {table_error}\")\n                    result['errors'].append(f\"Variant creation failed for {table_name}: {str(table_error)}\")\n            \n            if not result['variant_tables']:\n                result['success'] = False\n                result['errors'].append(\"No data variants could be created\")\n                \n        except Exception as e:\n            logger.error(f\"Data variant creation failed: {e}\")\n            result['success'] = False\n            result['errors'].append(f\"Variant creation error: {str(e)}\")\n        \n        return result\n\n    def test_data_dependency(self, query: str, expected_result: List[Dict], tolerance: float = 0.001) -> Dict[str, Any]:\n        \"\"\"\n        Test if query results change when using data variants (detects hardcoded answers)\n        \n        Args:\n            query: SQL query to test\n            expected_result: Expected result from original data\n            tolerance: Numeric tolerance for comparison\n            \n        Returns:\n            Dict containing dependency test results\n        \"\"\"\n        result = {\n            'is_data_dependent': True,\n            'confidence': 1.0,\n            'errors': [],\n            'warnings': [],\n            'test_details': {\n                'original_result_count': len(expected_result),\n                'variant_result_count': 0,\n                'results_differ': False,\n                'difference_details': []\n            }\n        }\n        \n        try:\n            # Create data variants\n            variant_creation = self.create_data_variants()\n            if not variant_creation['success']:\n                result['warnings'].append(\"Could not create data variants for testing\")\n                return result\n            \n            variant_tables = variant_creation['variant_tables']\n            if not variant_tables:\n                result['warnings'].append(\"No data variants available for testing\")\n                return result\n            \n            # Replace table names in query with variant table names\n            variant_query = query\n            for table_name in self.loaded_table_names:\n                variant_table = f\"variant_{table_name}\"\n                if variant_table in variant_tables:\n                    # Simple replacement - this works for most basic queries\n                    variant_query = variant_query.replace(table_name, variant_table)\n            \n            # Execute query on variant data\n            try:\n                variant_result_raw = self.conn.execute(variant_query).fetchall()\n                \n                # Convert to list of dicts for comparison\n                if variant_result_raw:\n                    # Get column names\n                    columns = [desc[0] for desc in self.conn.description]\n                    variant_result = [dict(zip(columns, row)) for row in variant_result_raw]\n                else:\n                    variant_result = []\n                \n                result['test_details']['variant_result_count'] = len(variant_result)\n                \n                # Compare results\n                if len(expected_result) != len(variant_result):\n                    result['test_details']['results_differ'] = True\n                    result['test_details']['difference_details'].append(\n                        f\"Row count differs: original={len(expected_result)}, variant={len(variant_result)}\"\n                    )\n                else:\n                    # Compare values with tolerance for numeric fields\n                    for i, (orig_row, var_row) in enumerate(zip(expected_result, variant_result)):\n                        for key in orig_row.keys():\n                            if key in var_row:\n                                orig_val = orig_row[key]\n                                var_val = var_row[key]\n                                \n                                # Numeric comparison with tolerance\n                                if isinstance(orig_val, (int, float)) and isinstance(var_val, (int, float)):\n                                    if abs(orig_val - var_val) > tolerance:\n                                        result['test_details']['results_differ'] = True\n                                        result['test_details']['difference_details'].append(\n                                            f\"Row {i}, column {key}: {orig_val} vs {var_val}\"\n                                        )\n                                        break\n                                # String comparison\n                                elif str(orig_val) != str(var_val):\n                                    result['test_details']['results_differ'] = True\n                                    result['test_details']['difference_details'].append(\n                                        f\"Row {i}, column {key}: '{orig_val}' vs '{var_val}'\"\n                                    )\n                                    break\n                \n                # Evaluate data dependency\n                if not result['test_details']['results_differ']:\n                    # Results are identical despite data changes - likely hardcoded\n                    result['is_data_dependent'] = False\n                    result['confidence'] = 0.9\n                    result['errors'].append(\n                        \"Query results unchanged despite data modifications - likely hardcoded answer\"\n                    )\n                else:\n                    # Results differ appropriately - query appears legitimate\n                    result['confidence'] = 1.0\n                    \n            except Exception as query_error:\n                # Query failed on variant data - might indicate data dependency issues\n                result['warnings'].append(f\"Query failed on variant data: {str(query_error)}\")\n                result['confidence'] = 0.7  # Lower confidence due to execution failure\n                \n        except Exception as e:\n            logger.error(f\"Data dependency test failed: {e}\")\n            result['errors'].append(f\"Dependency test error: {str(e)}\")\n            result['confidence'] = 0.0\n        \n        return result\n\n    def execute_query(self, query: str) -> Dict[str, Any]:\n        \"\"\"\n        Execute user SQL query with enhanced DuckDB sandbox allowing full DDL/DML operations\n        on in-memory data while maintaining security for external access\n        \n        Args:\n            query: SQL query string to execute\n            \n        Returns:\n            Dict containing query results or error information\n        \"\"\"\n        start_time = time.time()\n        \n        try:\n            # Security validation - block only genuinely dangerous external operations\n            import re as regex_module\n            \n            # COMPREHENSIVE security patterns - block ALL external access methods including string-literal file access\n            forbidden_patterns = [\n                # ALL file reading functions and variants (comprehensive SSRF/LFI prevention)\n                r'\\bREAD_PARQUET\\s*\\(', r'\\bREAD_CSV\\s*\\(', r'\\bREAD_JSON\\s*\\(', r'\\bREAD_CSV_AUTO\\s*\\(',\n                r'\\bREAD_JSON_AUTO\\s*\\(', r'\\bREAD_JSON_LINES\\s*\\(', r'\\bPARQUET_SCAN\\s*\\(',\n                r'\\bCSV_SCAN\\s*\\(', r'\\bJSON_SCAN\\s*\\(', r'\\bFROM\\s+READ_PARQUET\\s*\\(',\n                r'\\bFROM\\s+READ_CSV\\s*\\(', r'\\bFROM\\s+READ_JSON\\s*\\(',\n                # Generic pattern for any read/scan functions\n                r'\\b(READ_|.*_SCAN)\\s*\\(', \n                # CRITICAL: Block string-literal file/path access while preserving valid identifiers\n                r'\\b(FROM|JOIN)\\s*\\(?\\s*\\'[^\\']+\\'',  # Single-quoted strings only (avoids blocking double-quoted identifiers)\n                r'\\b(FROM|JOIN)\\s*\\(?\\s*\\'[/\\\\~]',  # Path-like single-quoted strings  \n                r'\\b(FROM|JOIN)\\s*\\(?\\s*\\'\\.+[/\\\\]',  # Relative paths in single quotes\n                r'\\b(FROM|JOIN)\\s*\\(?\\s*\\'[a-zA-Z]:[/\\\\]',  # Windows paths in single quotes\n                r'\\b(FROM|JOIN)\\s+[^\\s;()]+\\.(csv|parquet|json|txt|log|conf|ini|xml|yaml|yml)(\\b|\\s|\\)|;)',  # Unquoted file extensions\n                # ALL file/network access via COPY (comprehensive)\n                r'\\bCOPY\\b.*\\bFROM\\b', r'\\bCOPY\\b.*\\bTO\\b', r'\\bEXPORT\\b',\n                # URL/URI patterns in any context (prevent bypass via string literals)\n                r'https?://', r'file://', r'ftp://', r's3://', r'gcs://',\n                # System/extension operations  \n                r'\\bINSTALL\\b', r'\\bLOAD\\b',\n                # External connections and system functions\n                r'\\bATTACH\\b', r'\\bDETACH\\b', r'\\bS3\\b', r'\\bHTTPFS\\b',\n                # System configuration - BLOCK ALL (no allowlist to prevent resource abuse/DoS)\n                r'\\bPRAGMA\\b', \n                r'\\bSET\\b',\n                # Prevent any potential bypass attempts\n                r'\\bIMPORT\\b', r'\\bOUTFILE\\b', r'\\bINTOFILE\\b'\n            ]\n            \n            query_upper = query.upper()\n            for pattern in forbidden_patterns:\n                if regex_module.search(pattern, query_upper, regex_module.IGNORECASE):\n                    # Extract the matched keyword for error reporting\n                    match = regex_module.search(pattern, query_upper, regex_module.IGNORECASE)\n                    matched_keyword = match.group(0) if match else pattern\n                    return {\n                        \"success\": False,\n                        \"error\": f\"External operation not allowed for security: {matched_keyword.strip()}\",\n                        \"execution_time_ms\": 0\n                    }\n            \n            # Execute query with enforced timeout\n            def _execute_query():\n                return self.conn.execute(query).fetchdf()\n                \n            query_thread = None\n            executor = None\n            try:\n                executor = ThreadPoolExecutor(max_workers=1)\n                future = executor.submit(_execute_query)\n                \n                try:\n                    result_df = future.result(timeout=self.timeout_seconds)\n                    execution_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n                except TimeoutError:\n                    # Timeout occurred - interrupt connection and reset\n                    logger.warning(f\"Query timeout after {self.timeout_seconds} seconds\")\n                    \n                    # Try to interrupt DuckDB connection\n                    try:\n                        if hasattr(self.conn, 'interrupt'):\n                            self.conn.interrupt()\n                    except:\n                        pass  # Interrupt not supported in all DuckDB versions\n                    \n                    # Force shutdown without waiting\n                    executor.shutdown(wait=False)\n                    \n                    # Reset connection to prevent stuck session\n                    try:\n                        self.conn.close()\n                    except:\n                        pass\n                    self._initialize_connection()\n                    \n                    return {\n                        \"success\": False,\n                        \"error\": f\"Query timeout after {self.timeout_seconds} seconds\",\n                        \"execution_time_ms\": (time.time() - start_time) * 1000\n                    }\n                finally:\n                    if executor:\n                        executor.shutdown(wait=False)\n                \n                # Limit result size for safety\n                max_rows = 1000\n                if len(result_df) > max_rows:\n                    result_df = result_df.head(max_rows)\n                    truncated = True\n                else:\n                    truncated = False\n                \n                return {\n                    \"success\": True,\n                    \"results\": result_df.to_dict(orient=\"records\"),\n                    \"columns\": list(result_df.columns),\n                    \"row_count\": len(result_df),\n                    \"execution_time_ms\": round(execution_time, 2),\n                    \"truncated\": truncated\n                }\n                \n            except Exception as query_error:\n                execution_time = (time.time() - start_time) * 1000\n                return {\n                    \"success\": False,\n                    \"error\": str(query_error),\n                    \"execution_time_ms\": round(execution_time, 2)\n                }\n                \n        except Exception as e:\n            execution_time = (time.time() - start_time) * 1000\n            logger.error(f\"Query execution failed: {e}\")\n            return {\n                \"success\": False,\n                \"error\": f\"Query execution failed: {str(e)}\",\n                \"execution_time_ms\": round(execution_time, 2)\n            }\n    \n    def get_table_info(self) -> Dict[str, Any]:\n        \"\"\"\n        Get information about all available tables and their schemas in the sandbox\n        \n        Returns:\n            Dict containing information about all tables in the database\n        \"\"\"\n        try:\n            # Get all table names from DuckDB system catalog\n            tables_result = self.conn.execute(\"\"\"\n                SELECT table_name \n                FROM information_schema.tables \n                WHERE table_schema = 'main' \n                AND table_type = 'BASE TABLE'\n                ORDER BY table_name\n            \"\"\").fetchall()\n            \n            tables_info = []\n            \n            for table_row in tables_result:\n                table_name = table_row[0]\n                try:\n                    # Get table schema\n                    schema_result = self.conn.execute(f'DESCRIBE \"{table_name}\"').fetchall()\n                    schema = [{\"column\": row[0], \"type\": row[1]} for row in schema_result]\n                    \n                    # Get row count\n                    count_result = self.conn.execute(f'SELECT COUNT(*) FROM \"{table_name}\"').fetchone()\n                    row_count = count_result[0] if count_result else 0\n                    \n                    # Get sample data (first 3 rows to avoid overwhelming output)\n                    sample_result = self.conn.execute(f'SELECT * FROM \"{table_name}\" LIMIT 3').fetchdf()\n                    sample_data = sample_result.to_dict(orient=\"records\") if not sample_result.empty else []\n                    \n                    tables_info.append({\n                        \"name\": table_name,\n                        \"schema\": schema,\n                        \"row_count\": row_count,\n                        \"sample_data\": sample_data\n                    })\n                    \n                except Exception as table_error:\n                    # If we can't get info for a specific table, still include it with basic info\n                    logger.warning(f\"Could not get full info for table {table_name}: {table_error}\")\n                    tables_info.append({\n                        \"name\": table_name,\n                        \"schema\": [],\n                        \"row_count\": 0,\n                        \"sample_data\": [],\n                        \"error\": f\"Could not access table: {str(table_error)}\"\n                    })\n            \n            return {\n                \"success\": True,\n                \"tables\": tables_info,\n                \"total_tables\": len(tables_info)\n            }\n            \n        except Exception as e:\n            logger.error(f\"Failed to get table info: {e}\")\n            return {\n                \"success\": False,\n                \"error\": f\"Failed to get table information: {str(e)}\",\n                \"tables\": []\n            }\n    \n    def get_table_names(self) -> List[str]:\n        \"\"\"\n        Get list of all table names in the sandbox (lightweight method)\n        \n        Returns:\n            List of table names\n        \"\"\"\n        try:\n            tables_result = self.conn.execute(\"\"\"\n                SELECT table_name \n                FROM information_schema.tables \n                WHERE table_schema = 'main' \n                AND table_type = 'BASE TABLE'\n                ORDER BY table_name\n            \"\"\").fetchall()\n            return [row[0] for row in tables_result]\n        except Exception as e:\n            logger.error(f\"Failed to get table names: {e}\")\n            return []\n    \n    def get_sandbox_capabilities(self) -> Dict[str, Any]:\n        \"\"\"\n        Get information about sandbox capabilities for client applications\n        \n        Returns:\n            Dict containing sandbox feature information\n        \"\"\"\n        return {\n            \"ddl_operations\": True,  # CREATE, DROP, ALTER tables\n            \"dml_operations\": True,  # INSERT, UPDATE, DELETE data  \n            \"full_sql_support\": True,  # Complex queries, joins, CTEs, etc.\n            \"transaction_support\": True,  # BEGIN, COMMIT, ROLLBACK\n            \"temporary_tables\": True,  # CREATE TEMP TABLE\n            \"views\": True,  # CREATE VIEW\n            \"indexes\": True,  # CREATE INDEX\n            \"constraints\": True,  # PRIMARY KEY, FOREIGN KEY, CHECK\n            \"window_functions\": True,  # ROW_NUMBER(), RANK(), etc.\n            \"cte_support\": True,  # WITH clauses\n            \"subqueries\": True,  # Nested SELECT statements\n            \"data_modification\": True,  # All data can be modified safely in memory\n            \"external_access\": False,  # No external file/network access for security\n            \"persistence\": False,  # Changes don't persist after sandbox cleanup\n            \"isolation\": True,  # Each sandbox is completely isolated\n            \"memory_limit_mb\": self.memory_limit_mb,\n            \"timeout_seconds\": self.timeout_seconds,\n            \"max_result_rows\": 1000\n        }\n    \n    def execute_ddl(self, ddl_query: str) -> Dict[str, Any]:\n        \"\"\"\n        Execute DDL operations (CREATE, DROP, ALTER) with specific handling\n        \n        Args:\n            ddl_query: DDL query string to execute\n            \n        Returns:\n            Dict containing execution results\n        \"\"\"\n        start_time = time.time()\n        \n        try:\n            # Execute DDL query (no result set expected)\n            self.conn.execute(ddl_query)\n            execution_time = (time.time() - start_time) * 1000\n            \n            return {\n                \"success\": True,\n                \"message\": \"DDL operation completed successfully\",\n                \"execution_time_ms\": round(execution_time, 2),\n                \"affected_objects\": \"Schema modified\"\n            }\n            \n        except Exception as e:\n            execution_time = (time.time() - start_time) * 1000\n            logger.error(f\"DDL execution failed: {e}\")\n            return {\n                \"success\": False,\n                \"error\": f\"DDL operation failed: {str(e)}\",\n                \"execution_time_ms\": round(execution_time, 2)\n            }\n    \n    def cleanup(self):\n        \"\"\"Clean up DuckDB connection and resources\"\"\"\n        try:\n            if self.conn:\n                self.conn.close()\n                self.conn = None\n            logger.info(\"DuckDB sandbox cleaned up successfully\")\n        except Exception as e:\n            logger.error(f\"Error during sandbox cleanup: {e}\")\n\n    def __enter__(self):\n        \"\"\"Context manager entry\"\"\"\n        return self\n    \n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Context manager exit - ensure cleanup\"\"\"\n        self.cleanup()\n\n\nclass DuckDBSandboxManager:\n    \"\"\"\n    Manager for DuckDB sandbox instances with resource management\n    \"\"\"\n    \n    def __init__(self):\n        self.active_sandboxes = {}\n        self.max_concurrent_sandboxes = 10\n    \n    async def create_sandbox(self, user_id: str, problem_id: str) -> DuckDBSandbox:\n        \"\"\"\n        Create a new DuckDB sandbox for a user and problem\n        \n        Args:\n            user_id: User identifier\n            problem_id: Problem identifier\n            \n        Returns:\n            DuckDBSandbox instance\n        \"\"\"\n        sandbox_key = f\"{user_id}_{problem_id}\"\n        \n        # Clean up existing sandbox if present\n        if sandbox_key in self.active_sandboxes:\n            self.active_sandboxes[sandbox_key].cleanup()\n        \n        # Check resource limits\n        if len(self.active_sandboxes) >= self.max_concurrent_sandboxes:\n            # Clean up oldest sandbox\n            oldest_key = next(iter(self.active_sandboxes))\n            self.active_sandboxes[oldest_key].cleanup()\n            del self.active_sandboxes[oldest_key]\n        \n        # Create new sandbox with unique ID\n        sandbox = DuckDBSandbox(sandbox_id=sandbox_key)\n        self.active_sandboxes[sandbox_key] = sandbox\n        \n        return sandbox\n    \n    def get_sandbox(self, user_id: str, problem_id: str) -> Optional[DuckDBSandbox]:\n        \"\"\"Get existing sandbox for user and problem\"\"\"\n        sandbox_key = f\"{user_id}_{problem_id}\"\n        return self.active_sandboxes.get(sandbox_key)\n    \n    def cleanup_sandbox(self, user_id: str, problem_id: str):\n        \"\"\"Clean up specific sandbox\"\"\"\n        sandbox_key = f\"{user_id}_{problem_id}\"\n        if sandbox_key in self.active_sandboxes:\n            self.active_sandboxes[sandbox_key].cleanup()\n            del self.active_sandboxes[sandbox_key]\n    \n    def cleanup_all(self):\n        \"\"\"Clean up all active sandboxes\"\"\"\n        for sandbox in self.active_sandboxes.values():\n            sandbox.cleanup()\n        self.active_sandboxes.clear()\n\n\n# Global sandbox manager instance\nsandbox_manager = DuckDBSandboxManager()","size_bytes":57744},"test_duckdb_sandbox.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nTest script for enhanced DuckDB sandbox functionality\n\"\"\"\nimport sys\nimport os\n\n# Add the api directory to Python path\nsys.path.append('api')\n\nfrom duckdb_sandbox import DuckDBSandbox\nimport logging\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ndef test_enhanced_sandbox():\n    \"\"\"Test the enhanced DuckDB sandbox with DDL/DML operations\"\"\"\n    \n    print(\"ðŸ§ª Testing Enhanced DuckDB Sandbox\")\n    print(\"=\" * 50)\n    \n    # Create sandbox instance\n    sandbox = DuckDBSandbox(timeout_seconds=10, memory_limit_mb=128)\n    \n    try:\n        # Test 1: Check capabilities\n        print(\"\\n1ï¸âƒ£ Testing Sandbox Capabilities\")\n        capabilities = sandbox.get_sandbox_capabilities()\n        print(f\"âœ… DDL Operations: {capabilities['ddl_operations']}\")\n        print(f\"âœ… DML Operations: {capabilities['dml_operations']}\")\n        print(f\"âœ… Full SQL Support: {capabilities['full_sql_support']}\")\n        print(f\"âœ… Memory Limit: {capabilities['memory_limit_mb']} MB\")\n        \n        # Test 2: Create a table (DDL)\n        print(\"\\n2ï¸âƒ£ Testing DDL Operations - CREATE TABLE\")\n        create_result = sandbox.execute_query(\"\"\"\n            CREATE TABLE employees (\n                id INTEGER PRIMARY KEY,\n                name VARCHAR(100),\n                department VARCHAR(50),\n                salary DECIMAL(10,2),\n                hire_date DATE\n            )\n        \"\"\")\n        print(f\"âœ… CREATE TABLE: {create_result['success']}\")\n        if not create_result['success']:\n            print(f\"âŒ Error: {create_result['error']}\")\n            return False\n        \n        # Test 3: Insert data (DML)\n        print(\"\\n3ï¸âƒ£ Testing DML Operations - INSERT\")\n        insert_result = sandbox.execute_query(\"\"\"\n            INSERT INTO employees (id, name, department, salary, hire_date) VALUES\n            (1, 'Alice Johnson', 'Engineering', 75000.00, '2023-01-15'),\n            (2, 'Bob Smith', 'Marketing', 65000.00, '2023-02-20'),\n            (3, 'Carol Davis', 'Engineering', 80000.00, '2022-11-10'),\n            (4, 'David Wilson', 'HR', 55000.00, '2023-03-05')\n        \"\"\")\n        print(f\"âœ… INSERT: {insert_result['success']}\")\n        if not insert_result['success']:\n            print(f\"âŒ Error: {insert_result['error']}\")\n            return False\n        \n        # Test 4: Complex query with aggregations\n        print(\"\\n4ï¸âƒ£ Testing Complex Query - Aggregations & Joins\")\n        query_result = sandbox.execute_query(\"\"\"\n            SELECT \n                department,\n                COUNT(*) as employee_count,\n                AVG(salary) as avg_salary,\n                MAX(salary) as max_salary\n            FROM employees \n            GROUP BY department\n            ORDER BY avg_salary DESC\n        \"\"\")\n        print(f\"âœ… Complex Query: {query_result['success']}\")\n        if query_result['success']:\n            print(\"ðŸ“Š Results:\")\n            for row in query_result['results']:\n                print(f\"   {row['department']}: {row['employee_count']} employees, avg ${row['avg_salary']:.2f}\")\n        \n        # Test 5: Update data (DML)\n        print(\"\\n5ï¸âƒ£ Testing DML Operations - UPDATE\")\n        update_result = sandbox.execute_query(\"\"\"\n            UPDATE employees \n            SET salary = salary * 1.10 \n            WHERE department = 'Engineering'\n        \"\"\")\n        print(f\"âœ… UPDATE: {update_result['success']}\")\n        \n        # Test 6: Test table info\n        print(\"\\n6ï¸âƒ£ Testing Table Information\")\n        table_info = sandbox.get_table_info()\n        print(f\"âœ… Get Table Info: {table_info['success']}\")\n        if table_info['success']:\n            print(f\"ðŸ“‹ Found {table_info['total_tables']} table(s):\")\n            for table in table_info['tables']:\n                print(f\"   - {table['name']}: {table['row_count']} rows, {len(table['schema'])} columns\")\n        \n        # Test 7: Create another table and test with multiple tables\n        print(\"\\n7ï¸âƒ£ Testing Multiple Tables\")\n        sandbox.execute_query(\"\"\"\n            CREATE TABLE departments (\n                dept_id INTEGER PRIMARY KEY,\n                dept_name VARCHAR(50),\n                manager VARCHAR(100)\n            )\n        \"\"\")\n        \n        sandbox.execute_query(\"\"\"\n            INSERT INTO departments VALUES\n            (1, 'Engineering', 'Alice Johnson'),\n            (2, 'Marketing', 'Bob Smith'),\n            (3, 'HR', 'David Wilson')\n        \"\"\")\n        \n        # Test join between tables\n        join_result = sandbox.execute_query(\"\"\"\n            SELECT e.name, e.salary, d.dept_name, d.manager\n            FROM employees e\n            JOIN departments d ON e.department = d.dept_name\n            WHERE e.salary > 60000\n        \"\"\")\n        print(f\"âœ… JOIN Query: {join_result['success']}\")\n        if join_result['success']:\n            print(f\"ðŸ”— Join results: {len(join_result['results'])} rows\")\n        \n        # Test 8: Test that external operations are still blocked\n        print(\"\\n8ï¸âƒ£ Testing Security - External Operations Blocked\")\n        blocked_result = sandbox.execute_query(\"SELECT * FROM read_parquet('https://example.com/data.parquet')\")\n        print(f\"âœ… External operation blocked: {not blocked_result['success']}\")\n        if not blocked_result['success']:\n            print(f\"ðŸ”’ Security message: {blocked_result['error']}\")\n        \n        # Test 9: Test transaction support\n        print(\"\\n9ï¸âƒ£ Testing Transaction Support\")\n        trans_result = sandbox.execute_query(\"\"\"\n            BEGIN;\n            DELETE FROM employees WHERE salary < 60000;\n            ROLLBACK;\n        \"\"\")\n        print(f\"âœ… Transaction: {trans_result['success']}\")\n        \n        # Verify data is still there after rollback\n        count_result = sandbox.execute_query(\"SELECT COUNT(*) as total FROM employees\")\n        if count_result['success']:\n            total_count = count_result['results'][0]['total']\n            print(f\"ðŸ“Š Employees after ROLLBACK: {total_count} (should be 4)\")\n        \n        print(\"\\nðŸŽ‰ All tests completed successfully!\")\n        return True\n        \n    except Exception as e:\n        print(f\"\\nâŒ Test failed with exception: {e}\")\n        return False\n        \n    finally:\n        # Clean up\n        sandbox.cleanup()\n        print(\"\\nðŸ§¹ Sandbox cleaned up\")\n\nif __name__ == \"__main__\":\n    success = test_enhanced_sandbox()\n    print(f\"\\n{'âœ… SUCCESS' if success else 'âŒ FAILED'}: DuckDB Sandbox Test\")\n    sys.exit(0 if success else 1)","size_bytes":6564},"api/file_processor.py":{"content":"\"\"\"\nFile Processing Service\n======================\nUnified interface for processing and validating different data sources including S3 files\nand existing tabular data formats. Integrates with the S3 service and database utilities.\n\"\"\"\n\nimport logging\nfrom typing import List, Dict, Any, Optional, Tuple\nfrom api.s3_service import s3_service, CacheResult\nfrom api.database import parse_tabular_data\nfrom api.schemas import S3AnswerSource\n\nlogger = logging.getLogger(__name__)\n\nclass FileProcessingService:\n    \"\"\"\n    Service for processing files and structured data from various sources.\n    Provides unified interface for S3 files, tabular strings, and JSON data.\n    \"\"\"\n    \n    def __init__(self):\n        self.s3_service = s3_service\n    \n    def process_s3_answer_file(\n        self,\n        s3_config: S3AnswerSource,\n        preview_limit: Optional[int] = None\n    ) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]], Optional[str], Optional[str]]:\n        \"\"\"\n        Process S3 answer file and generate both full dataset and preview.\n        \n        Args:\n            s3_config: S3 configuration with bucket, key, format, etag\n            preview_limit: Number of rows for preview (defaults to 10, caller should pass test_case.display_limit when available)\n            \n        Returns:\n            Tuple of (full_data, preview_data, new_etag, error_message)\n        \"\"\"\n        try:\n            # Fetch full answer file from S3\n            result: CacheResult = self.s3_service.fetch_answer_file(\n                bucket=s3_config.bucket,\n                key=s3_config.key,\n                file_format=s3_config.format,\n                etag=s3_config.etag\n            )\n            \n            if result.status == 'cache_hit':\n                logger.info(f\"Using cached data for {s3_config.bucket}/{s3_config.key}\")\n            elif result.status == 'fetched':\n                logger.info(f\"Fetched fresh data for {s3_config.bucket}/{s3_config.key}\")\n            \n            full_data = result.data\n            \n            # Generate preview data\n            if preview_limit is None:\n                preview_limit = 10  # Default preview limit\n                \n            preview_data = self.s3_service.generate_preview_data(full_data, preview_limit)\n            \n            # Validate data structure\n            self._validate_answer_data(full_data)\n            \n            logger.info(f\"Processed S3 file: {len(full_data)} total rows, {len(preview_data)} preview rows\")\n            return full_data, preview_data, result.etag, None\n            \n        except Exception as e:\n            error_msg = f\"Failed to process S3 answer file: {str(e)}\"\n            logger.error(error_msg)\n            return [], [], None, error_msg\n    \n    def process_tabular_string(\n        self,\n        tabular_string: str,\n        preview_limit: int = 10\n    ) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]], Optional[str]]:\n        \"\"\"\n        Process pipe-delimited tabular string into structured data.\n        \n        Args:\n            tabular_string: Pipe-delimited string data\n            preview_limit: Number of rows for preview\n            \n        Returns:\n            Tuple of (full_data, preview_data, error_message)\n        \"\"\"\n        try:\n            # Use existing database parser for tabular strings\n            full_data = parse_tabular_data(tabular_string)\n            \n            # Generate preview data\n            preview_data = full_data[:preview_limit] if full_data else []\n            \n            # Validate data structure\n            self._validate_answer_data(full_data)\n            \n            logger.info(f\"Processed tabular string: {len(full_data)} total rows, {len(preview_data)} preview rows\")\n            return full_data, preview_data, None\n            \n        except Exception as e:\n            error_msg = f\"Failed to process tabular string: {str(e)}\"\n            logger.error(error_msg)\n            return [], [], error_msg\n    \n    def process_json_data(\n        self,\n        json_data: List[Dict[str, Any]],\n        preview_limit: int = 10\n    ) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]], Optional[str]]:\n        \"\"\"\n        Process and validate JSON data that's already structured.\n        \n        Args:\n            json_data: List of dictionaries\n            preview_limit: Number of rows for preview\n            \n        Returns:\n            Tuple of (full_data, preview_data, error_message)\n        \"\"\"\n        try:\n            # Validate data structure\n            self._validate_answer_data(json_data)\n            \n            # Generate preview data\n            preview_data = json_data[:preview_limit] if json_data else []\n            \n            logger.info(f\"Processed JSON data: {len(json_data)} total rows, {len(preview_data)} preview rows\")\n            return json_data, preview_data, None\n            \n        except Exception as e:\n            error_msg = f\"Failed to process JSON data: {str(e)}\"\n            logger.error(error_msg)\n            return [], [], error_msg\n    \n    def validate_s3_configuration(self, s3_config: S3AnswerSource) -> Tuple[bool, Optional[str]]:\n        \"\"\"\n        Validate S3 configuration by checking if the file exists and is accessible.\n        \n        Args:\n            s3_config: S3 configuration to validate\n            \n        Returns:\n            Tuple of (is_valid, error_message)\n        \"\"\"\n        try:\n            is_valid = self.s3_service.validate_s3_uri(s3_config.bucket, s3_config.key)\n            if not is_valid:\n                return False, f\"S3 file {s3_config.bucket}/{s3_config.key} is not accessible\"\n            \n            return True, None\n            \n        except Exception as e:\n            error_msg = f\"Failed to validate S3 configuration: {str(e)}\"\n            logger.error(error_msg)\n            return False, error_msg\n    \n    def _validate_answer_data(self, data: List[Dict[str, Any]]) -> None:\n        \"\"\"\n        Validate that answer data has consistent structure.\n        \n        Args:\n            data: List of dictionaries to validate\n            \n        Raises:\n            ValueError: If data structure is invalid\n        \"\"\"\n        if not data:\n            return  # Empty data is valid\n        \n        if not isinstance(data, list):\n            raise ValueError(\"Answer data must be a list\")\n        \n        if not all(isinstance(row, dict) for row in data):\n            raise ValueError(\"All rows must be dictionaries\")\n        \n        # Check that all rows have the same columns\n        if data:\n            first_row_keys = set(data[0].keys())\n            for i, row in enumerate(data[1:], 1):\n                row_keys = set(row.keys())\n                if row_keys != first_row_keys:\n                    logger.warning(f\"Row {i} has different columns: {row_keys} vs {first_row_keys}\")\n                    # Don't raise error, just warn - some flexibility is needed\n        \n        logger.debug(f\"Validated {len(data)} rows of answer data\")\n    \n    def get_data_summary(self, data: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"\n        Generate a summary of the data structure and content.\n        \n        Args:\n            data: List of dictionaries to summarize\n            \n        Returns:\n            Dictionary with data summary information\n        \"\"\"\n        if not data:\n            return {\n                'row_count': 0,\n                'columns': [],\n                'sample_row': None\n            }\n        \n        columns = list(data[0].keys()) if data else []\n        \n        return {\n            'row_count': len(data),\n            'columns': columns,\n            'column_count': len(columns),\n            'sample_row': data[0] if data else None\n        }\n\n# Global file processing service instance\nfile_processor = FileProcessingService()","size_bytes":7837},"api/s3_service.py":{"content":"\"\"\"\nAWS S3 Service for Answer File Management\n========================================\nHandles S3 operations for fetching answer files, caching with ETag validation,\nand supporting multiple file formats (CSV, JSON, Parquet).\n\"\"\"\n\nimport os\nimport boto3\nimport json\nimport io\nfrom typing import Dict, List, Any, Optional, Tuple, Union\nfrom datetime import datetime, timezone\nfrom botocore.exceptions import ClientError, NoCredentialsError\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n# Optional pandas import for CSV/Parquet support\ntry:\n    import pandas as pd\n    PANDAS_AVAILABLE = True\nexcept ImportError:\n    PANDAS_AVAILABLE = False\n    logger.warning(\"pandas not available - CSV and Parquet parsing will be limited\")\n\n# Configuration from environment with defaults\nMAX_FILE_SIZE_MB = int(os.getenv('S3_MAX_FILE_SIZE_MB', '5'))  # Maximum file size in MB\nMAX_ROWS = int(os.getenv('S3_MAX_ROWS', '1000'))  # Maximum number of rows to parse\nMAX_CACHE_ENTRIES = int(os.getenv('S3_MAX_CACHE_ENTRIES', '1000'))  # Maximum cache entries\n\n# Dataset-specific configuration\nS3_DATASET_MAX_FILE_SIZE_MB = int(os.getenv('S3_DATASET_MAX_FILE_SIZE_MB', '100'))  # Max dataset file size\nS3_DATASET_MAX_ROWS = int(os.getenv('S3_DATASET_MAX_ROWS', '1000000'))  # Max dataset rows\nS3_ALLOWED_BUCKETS = [bucket.strip().lower() for bucket in os.getenv('S3_ALLOWED_BUCKETS', 'sql-learning-datasets,sql-learning-answers,sqlplatform-datasets,sqlplatform-answers').split(',')]\n\nclass CacheResult:\n    \"\"\"Structured result for cached file operations\"\"\"\n    def __init__(self, status: str, data: List[Dict[str, Any]] = None, \n                 etag: str = None, last_modified: datetime = None):\n        self.status = status  # 'cache_hit', 'fetched', 'error'\n        self.data = data or []\n        self.etag = etag\n        self.last_modified = last_modified\n\nclass S3AnswerService:\n    \"\"\"Service for managing answer files stored in AWS S3\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize S3 service with lazy client creation\"\"\"\n        self._s3_client = None\n        self._cache = {}  # Simple in-memory cache: {(bucket,key): {etag, last_modified, data}}\n        logger.info(\"S3AnswerService initialized (client will be created on first use)\")\n    \n    @property\n    def s3_client(self):\n        \"\"\"Lazy initialization of S3 client\"\"\"\n        if self._s3_client is None:\n            try:\n                # Initialize S3 client - uses AWS credentials from environment\n                self._s3_client = boto3.client('s3')\n                logger.info(\"S3 client created successfully\")\n            except NoCredentialsError:\n                logger.error(\"AWS credentials not found. Set AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY\")\n                raise\n            except Exception as e:\n                logger.error(f\"Failed to create S3 client: {e}\")\n                raise\n        return self._s3_client\n    \n    def fetch_answer_file(\n        self,\n        bucket: str,\n        key: str,\n        file_format: str = None,\n        etag: Optional[str] = None,\n        format: str = None  # Backward compatibility alias\n    ) -> CacheResult:\n        \"\"\"\n        Fetch and parse answer file from S3 with ETag-based caching\n        \n        Args:\n            bucket: S3 bucket name\n            key: S3 object key (file path)\n            file_format: File format (csv, json, parquet)\n            etag: Current ETag for cache validation\n            \n        Returns:\n            CacheResult with status, data, etag, and last_modified\n            \n        Raises:\n            ClientError: If S3 operation fails\n            ValueError: If file format is unsupported or parsing fails\n        \"\"\"\n        # Handle backward compatibility for format parameter\n        if file_format is None and format is not None:\n            file_format = format\n        elif file_format is None and format is None:\n            # Auto-detect format from file extension\n            if key.endswith('.csv'):\n                file_format = 'csv'\n            elif key.endswith('.json'):\n                file_format = 'json'\n            elif key.endswith('.parquet'):\n                file_format = 'parquet'\n            else:\n                raise ValueError(f\"Cannot determine file format for key '{key}'. Please specify file_format parameter.\")\n        \n        # Validate bucket is in allowlist for security\n        if bucket.lower() not in S3_ALLOWED_BUCKETS:\n            raise ValueError(f\"Bucket '{bucket}' not allowed. Allowed buckets: {', '.join(S3_ALLOWED_BUCKETS)}\")\n        \n        cache_key = (bucket, key)\n        \n        try:\n            # Normalize ETag (remove quotes for internal comparison)\n            input_etag_stripped = etag.strip('\"') if etag else None\n            \n            # Check in-memory cache first\n            if cache_key in self._cache and input_etag_stripped:\n                cached = self._cache[cache_key]\n                if cached['etag'] == input_etag_stripped:\n                    logger.info(f\"File {bucket}/{key} served from memory cache\")\n                    return CacheResult('cache_hit', cached['data'], input_etag_stripped, cached['last_modified'])\n            \n            # Use conditional GET with If-None-Match header (S3 expects quoted ETag)\n            get_params = {'Bucket': bucket, 'Key': key}\n            if input_etag_stripped:\n                get_params['IfNoneMatch'] = f'\"{input_etag_stripped}\"'\n            \n            try:\n                obj_response = self.s3_client.get_object(**get_params)\n            except ClientError as e:\n                # Check for 304 Not Modified via HTTP status code\n                http_status = e.response.get('ResponseMetadata', {}).get('HTTPStatusCode')\n                error_code = e.response.get('Error', {}).get('Code', '')\n                \n                if http_status == 304 or error_code in ['NotModified', 'PreconditionFailed']:\n                    # Not modified - return cached data if available\n                    if cache_key in self._cache:\n                        cached = self._cache[cache_key]\n                        logger.info(f\"File {bucket}/{key} not modified (304)\")\n                        return CacheResult('cache_hit', cached['data'], input_etag_stripped, cached['last_modified'])\n                    else:\n                        # No cached data but got 304 - fetch without condition\n                        obj_response = self.s3_client.get_object(Bucket=bucket, Key=key)\n                else:\n                    raise\n            \n            # Check file size limit\n            content_length = obj_response.get('ContentLength', 0)\n            if content_length > MAX_FILE_SIZE_MB * 1024 * 1024:\n                raise ValueError(f\"File too large: {content_length / (1024*1024):.1f}MB (max: {MAX_FILE_SIZE_MB}MB)\")\n            \n            # Get metadata\n            new_etag = obj_response['ETag'].strip('\"')\n            last_modified = obj_response['LastModified']\n            \n            # Read and parse content\n            logger.info(f\"Fetching file {bucket}/{key} (format: {file_format}, size: {content_length} bytes)\")\n            file_content = obj_response['Body'].read()\n            \n            # Parse content based on format\n            parsed_data = self._parse_file_content(file_content, file_format)\n            \n            # Enforce row limit\n            if len(parsed_data) > MAX_ROWS:\n                logger.warning(f\"File {bucket}/{key} has {len(parsed_data)} rows, truncating to {MAX_ROWS}\")\n                parsed_data = parsed_data[:MAX_ROWS]\n            \n            # Update cache with eviction if needed\n            self._cache[cache_key] = {\n                'etag': new_etag,\n                'last_modified': last_modified,\n                'data': parsed_data\n            }\n            \n            # Simple cache eviction: remove oldest entries if over limit\n            if len(self._cache) > MAX_CACHE_ENTRIES:\n                # Remove 20% of oldest entries (simple LRU approximation)\n                entries_to_remove = len(self._cache) - int(MAX_CACHE_ENTRIES * 0.8)\n                oldest_keys = list(self._cache.keys())[:entries_to_remove]\n                for old_key in oldest_keys:\n                    del self._cache[old_key]\n                logger.info(f\"Cache eviction: removed {entries_to_remove} entries\")\n            \n            logger.info(f\"Successfully parsed {len(parsed_data)} rows from {bucket}/{key}\")\n            return CacheResult('fetched', parsed_data, new_etag, last_modified)\n            \n        except ClientError as e:\n            error_code = e.response.get('Error', {}).get('Code', 'Unknown')\n            if error_code == 'NoSuchBucket':\n                raise ValueError(f\"S3 bucket '{bucket}' does not exist\")\n            elif error_code == 'NoSuchKey':\n                raise ValueError(f\"File '{key}' not found in bucket '{bucket}'\")\n            else:\n                logger.error(f\"S3 error fetching {bucket}/{key}: {e}\")\n                raise\n        except Exception as e:\n            logger.error(f\"Error fetching answer file {bucket}/{key}: {e}\")\n            raise\n    \n    def _parse_file_content(self, content: bytes, file_format: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Parse file content based on format\n        \n        Args:\n            content: Raw file content bytes\n            file_format: File format (csv, json, parquet)\n            \n        Returns:\n            List of dictionaries representing rows\n            \n        Raises:\n            ValueError: If format is unsupported or parsing fails\n        \"\"\"\n        try:\n            if file_format.lower() == 'csv':\n                return self._parse_csv(content)\n            elif file_format.lower() == 'json':\n                return self._parse_json(content)\n            elif file_format.lower() == 'parquet':\n                return self._parse_parquet(content)\n            else:\n                raise ValueError(f\"Unsupported file format: {file_format}\")\n                \n        except Exception as e:\n            logger.error(f\"Failed to parse {file_format} content: {e}\")\n            raise ValueError(f\"Failed to parse {file_format} file: {e}\")\n    \n    def _decode_content(self, content: bytes) -> str:\n        \"\"\"\n        Decode bytes content to string with fallback encoding support.\n        \n        Tries multiple encodings to handle files that might not be UTF-8:\n        - utf-8 (preferred)\n        - utf-8-sig (UTF-8 with BOM)\n        - latin-1 (ISO-8859-1)\n        - cp1252 (Windows-1252)\n        - ascii\n        \n        Args:\n            content: Raw file content bytes\n            \n        Returns:\n            Decoded string content\n            \n        Raises:\n            ValueError: If content cannot be decoded with any supported encoding\n        \"\"\"\n        encodings = ['utf-8', 'utf-8-sig', 'latin-1', 'cp1252', 'ascii']\n        \n        for encoding in encodings:\n            try:\n                decoded_content = content.decode(encoding)\n                logger.debug(f\"Successfully decoded content using {encoding} encoding\")\n                return decoded_content\n            except UnicodeDecodeError:\n                logger.debug(f\"Failed to decode content using {encoding} encoding\")\n                continue\n                \n        # If all encodings fail, try with error handling\n        try:\n            decoded_content = content.decode('utf-8', errors='replace')\n            logger.warning(\"Decoded content using UTF-8 with error replacement - some characters may be corrupted\")\n            return decoded_content\n        except Exception as e:\n            raise ValueError(f\"Unable to decode file content with any supported encoding: {e}\")\n    \n    def _sanitize_sample_data(self, sample_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"\n        Sanitize sample data to ensure JSON serializability.\n        \n        Converts problematic data types like binary data, datetime objects,\n        decimal values, and other non-JSON-serializable types to strings.\n        \n        Args:\n            sample_data: Raw sample data from DuckDB query\n            \n        Returns:\n            Sanitized sample data safe for JSON serialization\n        \"\"\"\n        import decimal\n        import datetime\n        import uuid\n        \n        def sanitize_value(value):\n            \"\"\"Sanitize a single value for JSON serialization\"\"\"\n            if value is None:\n                return None\n            elif isinstance(value, (str, int, float, bool)):\n                return value\n            elif isinstance(value, bytes):\n                # Convert binary data to hex string representation\n                try:\n                    # Try to decode as UTF-8 first\n                    return value.decode('utf-8')\n                except UnicodeDecodeError:\n                    # If that fails, convert to hex\n                    return f\"<binary: {value.hex()}>\"\n            elif isinstance(value, decimal.Decimal):\n                return float(value)\n            elif isinstance(value, (datetime.date, datetime.datetime, datetime.time)):\n                return value.isoformat()\n            elif isinstance(value, uuid.UUID):\n                return str(value)\n            elif hasattr(value, '__dict__'):\n                # For complex objects, try to convert to string\n                return str(value)\n            else:\n                # For any other type, convert to string\n                return str(value)\n        \n        sanitized_data = []\n        for row in sample_data:\n            sanitized_row = {}\n            for key, value in row.items():\n                try:\n                    sanitized_row[key] = sanitize_value(value)\n                except Exception as e:\n                    # If sanitization fails, use a safe fallback\n                    logger.warning(f\"Failed to sanitize value for column {key}: {e}\")\n                    sanitized_row[key] = f\"<unsupported: {type(value).__name__}>\"\n            sanitized_data.append(sanitized_row)\n        \n        return sanitized_data\n    \n    def _parse_csv(self, content: bytes) -> List[Dict[str, Any]]:\n        \"\"\"Parse CSV content to list of dictionaries\"\"\"\n        if not PANDAS_AVAILABLE:\n            # Fallback to basic CSV parsing without pandas\n            return self._parse_csv_basic(content)\n        \n        try:\n            # Use pandas to parse CSV with automatic type inference\n            df = pd.read_csv(io.BytesIO(content))\n            \n            # Convert to list of dictionaries\n            # Handle NaN values by converting to None\n            data = df.where(pd.notnull(df), None).to_dict('records')\n            \n            return data\n            \n        except Exception as e:\n            raise ValueError(f\"Invalid CSV format: {e}\")\n    \n    def _parse_csv_basic(self, content: bytes) -> List[Dict[str, Any]]:\n        \"\"\"Basic CSV parsing without pandas\"\"\"\n        import csv\n        \n        try:\n            text_content = self._decode_content(content)\n            reader = csv.DictReader(io.StringIO(text_content))\n            data = []\n            \n            for row in reader:\n                # Convert numeric strings to numbers where possible\n                parsed_row = {}\n                for key, value in row.items():\n                    if value is None or value == '':\n                        parsed_row[key] = None\n                    else:\n                        # Try to convert to number\n                        try:\n                            if '.' in value:\n                                parsed_row[key] = float(value)\n                            else:\n                                parsed_row[key] = int(value)\n                        except (ValueError, TypeError):\n                            parsed_row[key] = value\n                data.append(parsed_row)\n            \n            return data\n            \n        except Exception as e:\n            raise ValueError(f\"Invalid CSV format: {e}\")\n    \n    def _parse_json(self, content: bytes) -> List[Dict[str, Any]]:\n        \"\"\"Parse JSON content to list of dictionaries\"\"\"\n        try:\n            text_content = self._decode_content(content)\n            data = json.loads(text_content)\n            \n            # Ensure data is a list of dictionaries\n            if isinstance(data, list):\n                if not data or all(isinstance(item, dict) for item in data):\n                    return data\n                else:\n                    raise ValueError(\"JSON must contain only dictionary objects\")\n            elif isinstance(data, dict):\n                # Single object, wrap in list\n                return [data]\n            else:\n                raise ValueError(\"JSON must be a list of objects or a single object\")\n                \n        except json.JSONDecodeError as e:\n            raise ValueError(f\"Invalid JSON format: {e}\")\n        except UnicodeDecodeError as e:\n            raise ValueError(f\"Invalid text encoding: {e}\")\n    \n    def _parse_parquet(self, content: bytes) -> List[Dict[str, Any]]:\n        \"\"\"Parse Parquet content to list of dictionaries with fallback to DuckDB\"\"\"\n        # Try pandas first if available\n        if PANDAS_AVAILABLE:\n            try:\n                # Use pandas to read Parquet from bytes\n                df = pd.read_parquet(io.BytesIO(content))\n                \n                # Convert to list of dictionaries\n                # Handle NaN values by converting to None\n                data = df.where(pd.notnull(df), None).to_dict('records')\n                \n                logger.info(\"Successfully parsed parquet using pandas\")\n                return data\n                \n            except ImportError as e:\n                logger.warning(f\"Pandas/pyarrow import failed, falling back to DuckDB: {e}\")\n            except Exception as e:\n                logger.warning(f\"Pandas parsing failed, falling back to DuckDB: {e}\")\n        \n        # Fallback to DuckDB for reliable parquet parsing\n        try:\n            import duckdb\n            import tempfile\n            import os\n            \n            # Write content to temporary file for DuckDB\n            with tempfile.NamedTemporaryFile(delete=False, suffix='.parquet') as temp_file:\n                temp_file.write(content)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Connect to DuckDB and read parquet\n                conn = duckdb.connect(\":memory:\")\n                \n                # Read parquet file and convert to list of dictionaries\n                query_result = conn.execute(f\"SELECT * FROM read_parquet('{temp_file_path}')\").fetchall()\n                column_names = [desc[0] for desc in conn.description]\n                \n                # Convert to list of dictionaries\n                data = []\n                for row in query_result:\n                    row_dict = {}\n                    for i, col_name in enumerate(column_names):\n                        # Handle None values properly\n                        value = row[i] if i < len(row) else None\n                        row_dict[col_name] = value\n                    data.append(row_dict)\n                \n                logger.info(f\"Successfully parsed parquet using DuckDB fallback ({len(data)} rows)\")\n                return data\n                \n            finally:\n                # Clean up temporary file\n                try:\n                    os.unlink(temp_file_path)\n                except:\n                    pass\n                    \n        except ImportError as e:\n            raise ValueError(f\"Parquet parsing requires either pandas+pyarrow or duckdb: {e}\")\n        except Exception as e:\n            raise ValueError(f\"Invalid Parquet format: {e}\")\n    \n    def generate_preview_data(\n        self,\n        full_data: List[Dict[str, Any]],\n        limit: int = 10\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Generate preview data by taking first N rows\n        \n        Args:\n            full_data: Complete dataset\n            limit: Number of rows to include in preview\n            \n        Returns:\n            Limited dataset for frontend display\n        \"\"\"\n        if not full_data:\n            return []\n        \n        preview = full_data[:limit]\n        logger.info(f\"Generated preview with {len(preview)} rows from {len(full_data)} total\")\n        \n        return preview\n    \n    def validate_s3_uri(self, bucket: str, key: str) -> bool:\n        \"\"\"\n        Validate that S3 object exists and is accessible\n        \n        Args:\n            bucket: S3 bucket name\n            key: S3 object key\n            \n        Returns:\n            True if object exists and is accessible\n        \"\"\"\n        try:\n            self.s3_client.head_object(Bucket=bucket, Key=key)\n            return True\n        except ClientError:\n            return False\n    \n    def get_presigned_upload_url(\n        self,\n        bucket: str,\n        key: str,\n        content_type: str = 'application/octet-stream',\n        expires_in: int = 300,  # 5 minutes for security\n        max_file_size: int = MAX_FILE_SIZE_MB * 1024 * 1024\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Generate secure presigned POST for uploading files to S3 with strict policies\n        \n        Args:\n            bucket: S3 bucket name\n            key: S3 object key\n            content_type: MIME type of the file\n            expires_in: URL expiration time in seconds (default 5 minutes)\n            max_file_size: Maximum file size in bytes\n            \n        Returns:\n            Dictionary with 'url' and 'fields' for secure POST upload\n        \"\"\"\n        try:\n            # Create secure POST policy with strict conditions\n            conditions = [\n                {'bucket': bucket},\n                {'key': key},\n                {'Content-Type': content_type},\n                {'x-amz-server-side-encryption': 'AES256'},  # Require encryption\n                ['content-length-range', 1, max_file_size]  # File size limits\n            ]\n            \n            fields = {\n                'Content-Type': content_type,\n                'x-amz-server-side-encryption': 'AES256'\n            }\n            \n            # Generate presigned POST with policy\n            response = self.s3_client.generate_presigned_post(\n                Bucket=bucket,\n                Key=key,\n                Fields=fields,\n                Conditions=conditions,\n                ExpiresIn=expires_in\n            )\n            \n            logger.info(f\"Generated secure presigned POST for {bucket}/{key} (expires in {expires_in}s)\")\n            return response\n            \n        except Exception as e:\n            logger.error(f\"Failed to generate presigned POST: {e}\")\n            raise\n\n    def download_to_temp_file(self, bucket: str, key: str) -> str:\n        \"\"\"\n        Download S3 file to a temporary file and return the path\n        \n        Args:\n            bucket: S3 bucket name\n            key: S3 object key\n            \n        Returns:\n            Path to temporary file\n            \n        Raises:\n            ValueError: If bucket not allowed or file too large\n            ClientError: If S3 operation fails\n        \"\"\"\n        import tempfile\n        \n        # Validate bucket allowlist\n        if not self._validate_dataset_bucket(bucket):\n            raise ValueError(f\"Bucket '{bucket}' not in allowed list: {S3_ALLOWED_BUCKETS}\")\n        \n        try:\n            # Check file size before downloading\n            response = self.s3_client.head_object(Bucket=bucket, Key=key)\n            file_size_mb = response['ContentLength'] / (1024 * 1024)\n            \n            if file_size_mb > S3_DATASET_MAX_FILE_SIZE_MB:\n                raise ValueError(f\"File size {file_size_mb:.1f}MB exceeds limit of {S3_DATASET_MAX_FILE_SIZE_MB}MB\")\n            \n            # Create temporary file\n            suffix = os.path.splitext(key)[1] or '.tmp'\n            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)\n            \n            # Download to temporary file\n            self.s3_client.download_fileobj(bucket, key, temp_file)\n            temp_file.close()\n            \n            logger.info(f\"Downloaded {bucket}/{key} ({file_size_mb:.1f}MB) to {temp_file.name}\")\n            return temp_file.name\n            \n        except ClientError as e:\n            logger.error(f\"Failed to download {bucket}/{key}: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Error downloading dataset file {bucket}/{key}: {e}\")\n            raise\n    \n    def download_text_file(self, bucket: str, key: str) -> str:\n        \"\"\"\n        Download S3 text file and return its content as string\n        \n        Args:\n            bucket: S3 bucket name\n            key: S3 object key\n            \n        Returns:\n            File content as string\n            \n        Raises:\n            ValueError: If bucket not allowed or file too large\n            ClientError: If S3 operation fails\n        \"\"\"\n        # Validate bucket allowlist\n        if not self._validate_dataset_bucket(bucket):\n            raise ValueError(f\"Bucket '{bucket}' not in allowed list: {S3_ALLOWED_BUCKETS}\")\n        \n        try:\n            # Check file size before downloading\n            response = self.s3_client.head_object(Bucket=bucket, Key=key)\n            file_size_mb = response['ContentLength'] / (1024 * 1024)\n            \n            # Allow smaller limit for text files like SQL\n            max_text_file_size_mb = 1.0  # 1MB should be enough for SQL files\n            if file_size_mb > max_text_file_size_mb:\n                raise ValueError(f\"Text file size {file_size_mb:.1f}MB exceeds limit of {max_text_file_size_mb}MB\")\n            \n            # Download file content directly\n            obj_response = self.s3_client.get_object(Bucket=bucket, Key=key)\n            content_bytes = obj_response['Body'].read()\n            \n            # Use robust encoding detection\n            content = self._decode_content(content_bytes)\n            \n            logger.info(f\"Downloaded text file {bucket}/{key} ({file_size_mb:.1f}MB)\")\n            return content\n            \n        except ClientError as e:\n            logger.error(f\"Failed to download text file {bucket}/{key}: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Error downloading text file {bucket}/{key}: {e}\")\n            raise\n    \n    def fetch_solution_sql(self, bucket: str, key: str) -> Dict[str, Any]:\n        \"\"\"\n        Fetch solution file from S3 and return as structured response\n        Supports both SQL files (.sql) and parquet files (.parquet) as solutions\n        \n        Args:\n            bucket: S3 bucket name\n            key: S3 object key (SQL or parquet file path)\n            \n        Returns:\n            Dict with success status, sql_content or solution_data, and error information\n        \"\"\"\n        try:\n            # Determine file type from extension\n            file_extension = os.path.splitext(key)[1].lower()\n            \n            if file_extension == '.sql':\n                # Handle SQL file - use text file download\n                sql_content = self.download_text_file(bucket, key)\n                \n                logger.info(f\"Successfully fetched solution SQL from {bucket}/{key} ({len(sql_content)} characters)\")\n                \n                return {\n                    \"success\": True,\n                    \"sql_content\": sql_content,\n                    \"file_type\": \"sql\",\n                    \"bucket\": bucket,\n                    \"key\": key\n                }\n                \n            elif file_extension == '.parquet':\n                # Handle parquet file - use existing parquet parsing logic\n                cache_result = self.fetch_answer_file(bucket=bucket, key=key, file_format='parquet')\n                \n                logger.info(f\"Successfully fetched solution parquet from {bucket}/{key} ({len(cache_result.data)} rows)\")\n                \n                return {\n                    \"success\": True,\n                    \"solution_data\": cache_result.data,\n                    \"file_type\": \"parquet\",\n                    \"bucket\": bucket,\n                    \"key\": key,\n                    \"etag\": cache_result.etag\n                }\n                \n            else:\n                # Unsupported file type\n                error_msg = f\"Unsupported solution file type: {file_extension}. Supported types: .sql, .parquet\"\n                logger.error(f\"Unsupported file type for {bucket}/{key}: {error_msg}\")\n                return {\n                    \"success\": False,\n                    \"error\": error_msg,\n                    \"bucket\": bucket,\n                    \"key\": key\n                }\n            \n        except ValueError as e:\n            # Handle validation errors (bucket not allowed, file too large, etc.)\n            logger.error(f\"Validation error fetching solution from {bucket}/{key}: {e}\")\n            return {\n                \"success\": False,\n                \"error\": str(e),\n                \"bucket\": bucket,\n                \"key\": key\n            }\n            \n        except ClientError as e:\n            # Handle S3 errors\n            error_code = e.response.get('Error', {}).get('Code', 'Unknown')\n            if error_code == 'NoSuchBucket':\n                error_msg = f\"S3 bucket '{bucket}' does not exist\"\n            elif error_code == 'NoSuchKey':\n                error_msg = f\"Solution file '{key}' not found in bucket '{bucket}'\"\n            else:\n                error_msg = f\"S3 error: {e}\"\n            \n            logger.error(f\"S3 error fetching solution from {bucket}/{key}: {error_msg}\")\n            return {\n                \"success\": False,\n                \"error\": error_msg,\n                \"bucket\": bucket,\n                \"key\": key\n            }\n            \n        except Exception as e:\n            # Handle any other errors\n            logger.error(f\"Unexpected error fetching solution from {bucket}/{key}: {e}\")\n            return {\n                \"success\": False,\n                \"error\": f\"Failed to fetch solution: {str(e)}\",\n                \"bucket\": bucket,\n                \"key\": key\n            }\n    \n    def validate_dataset_file(self, bucket: str, key: str, table_name: str) -> Dict[str, Any]:\n        \"\"\"\n        Validate S3 dataset file and extract schema information\n        \n        Args:\n            bucket: S3 bucket name\n            key: S3 object key\n            table_name: Desired table name for DuckDB\n            \n        Returns:\n            Dict with validation result, schema, sample data, row count, etag\n        \"\"\"\n        try:\n            # Validate bucket\n            if not self._validate_dataset_bucket(bucket):\n                return {\n                    \"success\": False,\n                    \"error\": f\"Bucket '{bucket}' not in allowed list: {S3_ALLOWED_BUCKETS}\"\n                }\n            \n            # Validate table name pattern (same as DuckDB sandbox)\n            import re\n            table_pattern = re.compile(r'^[a-zA-Z_][a-zA-Z0-9_]{0,63}$')\n            if not table_pattern.match(table_name):\n                return {\n                    \"success\": False,\n                    \"error\": f\"Invalid table name: {table_name}. Must start with letter/underscore, contain only alphanumeric/underscore, max 64 chars.\"\n                }\n            \n            # Download to temporary file for analysis\n            temp_file_path = self.download_to_temp_file(bucket, key)\n            \n            try:\n                # Use DuckDB to analyze the file\n                import duckdb\n                conn = duckdb.connect(\":memory:\")\n                \n                # Get file extension to determine type\n                file_ext = os.path.splitext(key)[1].lower()\n                \n                if file_ext == '.parquet':\n                    # Analyze parquet file\n                    result = conn.execute(\"SELECT COUNT(*) as row_count FROM read_parquet(?)\", [temp_file_path]).fetchone()\n                    row_count = result[0] if result else 0\n                    \n                    # Get schema\n                    schema_result = conn.execute(\"DESCRIBE SELECT * FROM read_parquet(?)\", [temp_file_path]).fetchall()\n                    schema = [{\"column\": row[0], \"type\": row[1]} for row in schema_result]\n                    \n                    # Get sample data\n                    sample_result = conn.execute(\"SELECT * FROM read_parquet(?) LIMIT 5\", [temp_file_path]).fetchall()\n                    column_names = [desc[0] for desc in conn.description]\n                    raw_sample_data = [dict(zip(column_names, row)) for row in sample_result]\n                    \n                    # Sanitize sample data to ensure JSON serializability\n                    sample_data = self._sanitize_sample_data(raw_sample_data)\n                    \n                else:\n                    return {\"success\": False, \"error\": f\"Unsupported file format: {file_ext}. Only .parquet files are supported for datasets.\"}\n                \n                # Validate row count\n                if row_count > S3_DATASET_MAX_ROWS:\n                    return {\n                        \"success\": False, \n                        \"error\": f\"Dataset has {row_count:,} rows, exceeds limit of {S3_DATASET_MAX_ROWS:,}\"\n                    }\n                \n                # Get ETag for caching\n                head_response = self.s3_client.head_object(Bucket=bucket, Key=key)\n                etag = head_response.get('ETag', '').strip('\"')\n                \n                return {\n                    \"success\": True,\n                    \"schema\": schema,\n                    \"sample_data\": sample_data,\n                    \"row_count\": row_count,\n                    \"etag\": etag,\n                    \"table_name\": table_name\n                }\n                \n            finally:\n                # Clean up temporary file\n                try:\n                    os.unlink(temp_file_path)\n                except:\n                    pass\n                    \n        except Exception as e:\n            logger.error(f\"Dataset validation failed for {bucket}/{key}: {e}\")\n            return {\"success\": False, \"error\": str(e)}\n    \n    \n    def generate_expected_result_hash(self, result_data: List[Dict[str, Any]]) -> str:\n        \"\"\"\n        Generate MD5 hash of sorted expected result for validation\n        \n        Args:\n            result_data: List of dictionaries representing query result\n            \n        Returns:\n            MD5 hash string\n        \"\"\"\n        import hashlib\n        import json\n        \n        try:\n            # Sort the data to ensure consistent hashing\n            # Sort by converting each row to string and sorting lexically\n            sorted_data = sorted(result_data, key=lambda x: json.dumps(x, sort_keys=True, default=str))\n            \n            # Convert to JSON string with consistent formatting\n            json_str = json.dumps(sorted_data, sort_keys=True, separators=(',', ':'), default=str)\n            \n            # Generate MD5 hash\n            hash_object = hashlib.md5(json_str.encode('utf-8'))\n            return hash_object.hexdigest()\n            \n        except Exception as e:\n            logger.error(f\"Failed to generate result hash: {e}\")\n            raise ValueError(f\"Hash generation failed: {str(e)}\")\n    \n    def fetch_parquet_solution(self, bucket: str, key: str, etag: Optional[str] = None) -> CacheResult:\n        \"\"\"\n        Fetch parquet solution file (out.parquet) for result validation\n        \n        Args:\n            bucket: S3 bucket name\n            key: S3 object key (should be out.parquet)\n            etag: Current ETag for cache validation\n            \n        Returns:\n            CacheResult with parsed parquet data as list of dictionaries\n            \n        Raises:\n            ValueError: If bucket not allowed, file too large, or parsing fails\n            ClientError: If S3 operation fails\n        \"\"\"\n        # Validate bucket is in allowlist for security\n        if bucket.lower() not in S3_ALLOWED_BUCKETS:\n            raise ValueError(f\"Bucket '{bucket}' not allowed. Allowed buckets: {', '.join(S3_ALLOWED_BUCKETS)}\")\n        \n        # Use higher limits for solution files than regular answer files\n        cache_key = (bucket, key)\n        \n        try:\n            # Normalize ETag (remove quotes for internal comparison)\n            input_etag_stripped = etag.strip('\"') if etag else None\n            \n            # Check in-memory cache first\n            if cache_key in self._cache and input_etag_stripped:\n                cached = self._cache[cache_key]\n                if cached['etag'] == input_etag_stripped:\n                    logger.info(f\"Solution file {bucket}/{key} served from memory cache\")\n                    return CacheResult('cache_hit', cached['data'], input_etag_stripped, cached['last_modified'])\n            \n            # Use conditional GET with If-None-Match header (S3 expects quoted ETag)\n            get_params = {'Bucket': bucket, 'Key': key}\n            if input_etag_stripped:\n                get_params['IfNoneMatch'] = f'\"{input_etag_stripped}\"'\n            \n            try:\n                obj_response = self.s3_client.get_object(**get_params)\n            except ClientError as e:\n                # Check for 304 Not Modified via HTTP status code\n                http_status = e.response.get('ResponseMetadata', {}).get('HTTPStatusCode')\n                error_code = e.response.get('Error', {}).get('Code', '')\n                \n                if http_status == 304 or error_code in ['NotModified', 'PreconditionFailed']:\n                    # Not modified - return cached data if available\n                    if cache_key in self._cache:\n                        cached = self._cache[cache_key]\n                        logger.info(f\"Solution file {bucket}/{key} not modified (304)\")\n                        return CacheResult('cache_hit', cached['data'], input_etag_stripped, cached['last_modified'])\n                    else:\n                        # No cached data but got 304 - fetch without condition\n                        obj_response = self.s3_client.get_object(Bucket=bucket, Key=key)\n                else:\n                    raise\n            \n            # Check file size limit (use dataset limit for solution files)\n            content_length = obj_response.get('ContentLength', 0)\n            max_size_bytes = S3_DATASET_MAX_FILE_SIZE_MB * 1024 * 1024\n            if content_length > max_size_bytes:\n                raise ValueError(f\"Solution file too large: {content_length / (1024*1024):.1f}MB (max: {S3_DATASET_MAX_FILE_SIZE_MB}MB)\")\n            \n            # Get metadata\n            new_etag = obj_response['ETag'].strip('\"')\n            last_modified = obj_response['LastModified']\n            \n            # Read and parse parquet content\n            logger.info(f\"Fetching solution file {bucket}/{key} (size: {content_length} bytes)\")\n            file_content = obj_response['Body'].read()\n            \n            # Parse parquet content directly\n            parsed_data = self._parse_parquet(file_content)\n            \n            # Enforce dataset row limit for solution files\n            if len(parsed_data) > S3_DATASET_MAX_ROWS:\n                logger.warning(f\"Solution file {bucket}/{key} has {len(parsed_data)} rows, truncating to {S3_DATASET_MAX_ROWS}\")\n                parsed_data = parsed_data[:S3_DATASET_MAX_ROWS]\n            \n            # Update cache with eviction if needed\n            self._cache[cache_key] = {\n                'etag': new_etag,\n                'last_modified': last_modified,\n                'data': parsed_data\n            }\n            \n            # Simple cache eviction: remove oldest entries if over limit\n            if len(self._cache) > MAX_CACHE_ENTRIES:\n                # Remove 20% of oldest entries (simple LRU approximation)\n                entries_to_remove = len(self._cache) - int(MAX_CACHE_ENTRIES * 0.8)\n                oldest_keys = list(self._cache.keys())[:entries_to_remove]\n                for old_key in oldest_keys:\n                    del self._cache[old_key]\n                logger.info(f\"Cache eviction: removed {entries_to_remove} entries\")\n            \n            logger.info(f\"Successfully parsed {len(parsed_data)} rows from solution file {bucket}/{key}\")\n            return CacheResult('fetched', parsed_data, new_etag, last_modified)\n            \n        except ClientError as e:\n            error_code = e.response.get('Error', {}).get('Code', 'Unknown')\n            if error_code == 'NoSuchBucket':\n                raise ValueError(f\"S3 bucket '{bucket}' does not exist\")\n            elif error_code == 'NoSuchKey':\n                raise ValueError(f\"Solution file '{key}' not found in bucket '{bucket}'\")\n            else:\n                logger.error(f\"S3 error fetching solution file {bucket}/{key}: {e}\")\n                raise\n        except Exception as e:\n            logger.error(f\"Error fetching solution file {bucket}/{key}: {e}\")\n            raise\n\n    def _validate_dataset_bucket(self, bucket: str) -> bool:\n        \"\"\"Validate that bucket is in the allowed list for datasets\"\"\"\n        return bucket in S3_ALLOWED_BUCKETS\n\n# Global S3 service instance\ns3_service = S3AnswerService()","size_bytes":41433},"scripts/README.md":{"content":"# Git to S3 Migration Script\n\nThis directory contains scripts to migrate parquet dataset files from Git repositories to S3 storage for the SQLGym platform.\n\n## Overview\n\nThe migration process:\n1. Identifies problems using Git-based `parquet_data_source` fields\n2. Downloads parquet files from Git URLs  \n3. Uploads files to S3 with organized structure\n4. Updates database records to use `s3_data_source` instead\n5. Maintains backward compatibility during transition\n\n## Prerequisites\n\n1. **AWS Credentials**: Configure AWS CLI or set environment variables:\n   ```bash\n   export AWS_ACCESS_KEY_ID=your_access_key\n   export AWS_SECRET_ACCESS_KEY=your_secret_key\n   export AWS_DEFAULT_REGION=us-east-1\n   ```\n\n2. **Database Access**: Set DATABASE_URL environment variable:\n   ```bash\n   export DATABASE_URL=postgresql://user:pass@host:port/database\n   ```\n\n3. **S3 Bucket**: Create an S3 bucket with appropriate permissions:\n   ```json\n   {\n     \"Version\": \"2012-10-17\", \n     \"Statement\": [\n       {\n         \"Effect\": \"Allow\",\n         \"Action\": [\n           \"s3:GetObject\",\n           \"s3:PutObject\", \n           \"s3:DeleteObject\"\n         ],\n         \"Resource\": \"arn:aws:s3:::your-bucket/*\"\n       }\n     ]\n   }\n   ```\n\n4. **Python 3.8+** with pip installed\n\n## Quick Start\n\n### Option 1: Use the Shell Wrapper (Recommended)\n\n```bash\n# Dry run first to see what would happen\n./scripts/run_migration.sh your-dataset-bucket --dry-run\n\n# Run the actual migration\n./scripts/run_migration.sh your-dataset-bucket\n```\n\n### Option 2: Run Python Script Directly\n\n```bash\n# Install dependencies\npip install -r scripts/requirements.txt\n\n# Dry run\npython3 scripts/migrate_git_to_s3.py --s3-bucket your-dataset-bucket --dry-run\n\n# Actual migration\npython3 scripts/migrate_git_to_s3.py --s3-bucket your-dataset-bucket --verbose\n```\n\n## Migration Process Details\n\n### File Organization\n\nFiles are uploaded to S3 with this structure:\n```\nyour-bucket/\nâ”œâ”€â”€ migrated-datasets/\nâ”‚   â”œâ”€â”€ problem-id-1/\nâ”‚   â”‚   â””â”€â”€ dataset.parquet\nâ”‚   â”œâ”€â”€ problem-id-2/\nâ”‚   â”‚   â””â”€â”€ sales.parquet\nâ”‚   â””â”€â”€ ...\n```\n\n### Database Changes\n\nEach migrated problem gets:\n- `s3_data_source` field populated with S3 details\n- `parquet_data_source` field set to NULL  \n- `updated_at` timestamp updated\n\nExample `s3_data_source` structure:\n```json\n{\n  \"bucket\": \"your-dataset-bucket\",\n  \"key\": \"migrated-datasets/problem-uuid/dataset.parquet\", \n  \"table_name\": \"problem_data\",\n  \"description\": \"Migrated from Git: original description\",\n  \"etag\": \"s3-file-etag-hash\"\n}\n```\n\n### Error Handling\n\nThe script includes comprehensive error handling:\n- Failed downloads are retried with exponential backoff (3 attempts)\n- S3 upload failures use boto3 adaptive retry mode\n- HTTPS-only URL validation for security\n- Per-problem error isolation (failures don't stop entire migration)\n- Temporary files are always cleaned up\n- Detailed logging for troubleshooting\n\n## Command Line Options\n\n### migrate_git_to_s3.py\n\n- `--s3-bucket BUCKET` (required): S3 bucket name for storing files\n- `--dry-run`: Preview actions without making changes\n- `--verbose, -v`: Enable detailed logging\n- `--help`: Show full help message\n\n### run_migration.sh\n\n- First argument: S3 bucket name (required)\n- `--dry-run`: Preview mode\n- Automatically handles prerequisites and dependency installation\n\n## Monitoring Progress\n\nThe script provides detailed logging:\n```\n2024-01-15 10:30:00 - INFO - Found 25 problems with Git parquet sources\n2024-01-15 10:30:01 - INFO - Processing 1/25: Calculate Total Sales\n2024-01-15 10:30:02 - INFO - Downloading from: https://github.com/.../sales.parquet\n2024-01-15 10:30:03 - INFO - Downloaded 2.3 MB to /tmp/temp_file.parquet\n2024-01-15 10:30:04 - INFO - Uploaded to s3://bucket/migrated-datasets/uuid/sales.parquet\n2024-01-15 10:30:05 - INFO - Updated problem uuid to use S3 source\n2024-01-15 10:30:06 - INFO - Successfully migrated problem uuid\n```\n\n## Rollback (If Needed)\n\nIf you need to rollback migrations:\n\n```sql\n-- View migrated problems\nSELECT id, title, s3_data_source->>'key' as s3_key \nFROM problems \nWHERE s3_data_source IS NOT NULL;\n\n-- Rollback specific problem (example)\n-- Note: This requires manually restoring parquet_data_source data\nUPDATE problems \nSET s3_data_source = NULL,\n    parquet_data_source = '{\"original\": \"data\"}'\nWHERE id = 'problem-uuid';\n```\n\n## Troubleshooting\n\n### Common Issues\n\n1. **AWS Permission Denied**\n   ```\n   Solution: Verify AWS credentials and S3 bucket permissions\n   ```\n\n2. **Database Connection Failed**  \n   ```\n   Solution: Check DATABASE_URL format and connectivity\n   ```\n\n3. **Git URL Not Accessible**\n   ```\n   Solution: Check if Git repository is public and URL is correct\n   ```\n\n4. **S3 Bucket Not Found**\n   ```\n   Solution: Create bucket or verify bucket name and region\n   ```\n\n### Getting Help\n\nCheck logs for detailed error messages. The script provides specific guidance for each type of failure.\n\n## Security Considerations\n\n- Files are encrypted at rest in S3 (AES256)\n- Database connections use the existing secure DATABASE_URL\n- AWS credentials should follow least-privilege principles  \n- Git URLs are validated before download\n- Temporary files are securely deleted after use\n\n## Post-Migration\n\nAfter successful migration:\n1. Verify problems load correctly in the admin panel\n2. Test DuckDB sandbox functionality with S3 datasets\n3. Monitor S3 costs and usage\n4. Consider removing old Git repositories if no longer needed\n5. Update documentation to reference S3 as the primary method","size_bytes":5564},"scripts/migrate_git_to_s3.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nMigration script to move parquet files from Git repositories to S3 storage.\n\nThis script:\n1. Identifies problems using Git-based parquet_data_source\n2. Downloads parquet files from Git URLs\n3. Uploads them to S3\n4. Updates database records to use s3_data_source\n\nUsage:\n    python scripts/migrate_git_to_s3.py --s3-bucket your-dataset-bucket [--dry-run]\n\nRequirements:\n    - AWS credentials configured for S3 access\n    - DATABASE_URL environment variable set\n    - S3 bucket with appropriate permissions\n\"\"\"\n\nimport os\nimport sys\nimport json\nimport argparse\nimport logging\nimport tempfile\nimport urllib.request\nfrom urllib.parse import urlparse\nfrom typing import List, Dict, Optional, Any\nimport time\nfrom urllib.error import URLError, HTTPError\n\nimport boto3\nfrom botocore.exceptions import ClientError\nfrom botocore.config import Config\nimport psycopg2\nfrom psycopg2.extras import RealDictCursor, register_default_jsonb\n\n# Setup logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(__name__)\n\nclass GitToS3Migrator:\n    \"\"\"Migrates parquet files from Git repositories to S3 storage.\"\"\"\n    \n    def __init__(self, s3_bucket: str, dry_run: bool = False):\n        self.s3_bucket = s3_bucket\n        self.dry_run = dry_run\n        \n        # Configure S3 with retries\n        s3_config = Config(\n            retries={\n                'max_attempts': 3,\n                'mode': 'adaptive'\n            },\n            connect_timeout=30,\n            read_timeout=300\n        )\n        self.s3_client = boto3.client('s3', config=s3_config)\n        \n        # Database connection\n        database_url = os.getenv('DATABASE_URL')\n        if not database_url:\n            raise ValueError(\"DATABASE_URL environment variable is required\")\n        self.db_connection = psycopg2.connect(database_url)\n        \n        # Register JSONB decoder for psycopg2\n        register_default_jsonb(self.db_connection)\n        \n        logger.info(f\"Initialized migrator - bucket: {s3_bucket}, dry_run: {dry_run}\")\n    \n    def get_git_problems(self) -> List[Dict[str, Any]]:\n        \"\"\"Fetch problems that use Git-based parquet sources.\"\"\"\n        query = \"\"\"\n            SELECT id, title, parquet_data_source, s3_data_source\n            FROM problems \n            WHERE parquet_data_source IS NOT NULL \n            AND s3_data_source IS NULL\n            ORDER BY created_at ASC\n        \"\"\"\n        \n        with self.db_connection.cursor(cursor_factory=RealDictCursor) as cursor:\n            cursor.execute(query)\n            results = cursor.fetchall()\n            logger.info(f\"Found {len(results)} problems with Git parquet sources\")\n            return [dict(row) for row in results]\n    \n    def download_parquet_file(self, git_url: str, file_path: str) -> str:\n        \"\"\"Download parquet file from Git URL to temporary file with retries.\"\"\"\n        # Construct full URL\n        full_url = f\"{git_url.rstrip('/')}/{file_path.lstrip('/')}\"\n        \n        # Basic URL validation - require HTTPS for security\n        parsed = urlparse(full_url)\n        if parsed.scheme != 'https':\n            raise ValueError(f\"Only HTTPS URLs are allowed, got: {parsed.scheme}\")\n        \n        logger.info(f\"Downloading from: {full_url}\")\n        \n        # Create temporary file\n        with tempfile.NamedTemporaryFile(delete=False, suffix='.parquet') as temp_file:\n            temp_path = temp_file.name\n        \n        # Retry logic for downloads\n        max_retries = 3\n        retry_delay = 1  # seconds\n        \n        for attempt in range(max_retries):\n            try:\n                # Create request with timeout\n                request = urllib.request.Request(full_url)\n                request.add_header('User-Agent', 'SQLGym-Migration/1.0')\n                \n                with urllib.request.urlopen(request, timeout=60) as response:\n                    with open(temp_path, 'wb') as temp_file:\n                        # Download in chunks to handle large files\n                        while True:\n                            chunk = response.read(8192)\n                            if not chunk:\n                                break\n                            temp_file.write(chunk)\n                \n                file_size = os.path.getsize(temp_path)\n                logger.info(f\"Downloaded {file_size:,} bytes to {temp_path}\")\n                return temp_path\n                \n            except (URLError, HTTPError, OSError) as e:\n                logger.warning(f\"Download attempt {attempt + 1}/{max_retries} failed: {e}\")\n                if attempt == max_retries - 1:\n                    # Clean up temp file on final failure\n                    if os.path.exists(temp_path):\n                        os.unlink(temp_path)\n                    raise Exception(f\"Failed to download {full_url} after {max_retries} attempts: {e}\")\n                \n                # Wait before retry\n                time.sleep(retry_delay)\n                retry_delay *= 2  # Exponential backoff\n    \n    def upload_to_s3(self, local_path: str, s3_key: str) -> Dict[str, str]:\n        \"\"\"Upload parquet file to S3 and return S3 details.\"\"\"\n        logger.info(f\"Uploading to s3://{self.s3_bucket}/{s3_key}\")\n        \n        if self.dry_run:\n            logger.info(\"DRY RUN: Would upload to S3\")\n            return {\n                \"bucket\": self.s3_bucket,\n                \"key\": s3_key,\n                \"etag\": \"dry-run-etag\"\n            }\n        \n        try:\n            # Upload to S3\n            self.s3_client.upload_file(\n                local_path, \n                self.s3_bucket, \n                s3_key,\n                ExtraArgs={'ServerSideEncryption': 'AES256'}\n            )\n            \n            # Get ETag\n            response = self.s3_client.head_object(Bucket=self.s3_bucket, Key=s3_key)\n            etag = response['ETag'].strip('\"')\n            \n            logger.info(f\"Successfully uploaded to S3, ETag: {etag}\")\n            return {\n                \"bucket\": self.s3_bucket,\n                \"key\": s3_key,\n                \"etag\": etag\n            }\n        except ClientError as e:\n            raise Exception(f\"Failed to upload to S3: {e}\")\n    \n    def update_problem_record(self, problem_id: str, s3_data_source: Dict[str, Any]) -> None:\n        \"\"\"Update problem record to use S3 data source.\"\"\"\n        query = \"\"\"\n            UPDATE problems \n            SET s3_data_source = %s,\n                parquet_data_source = NULL,\n                updated_at = NOW()\n            WHERE id = %s\n        \"\"\"\n        \n        if self.dry_run:\n            logger.info(f\"DRY RUN: Would update problem {problem_id} with S3 source\")\n            return\n        \n        with self.db_connection.cursor() as cursor:\n            cursor.execute(query, [json.dumps(s3_data_source), problem_id])\n            self.db_connection.commit()\n            logger.info(f\"Updated problem {problem_id} to use S3 source\")\n    \n    def generate_s3_key(self, problem_id: str, original_file_path: str) -> str:\n        \"\"\"Generate S3 key for the parquet file.\"\"\"\n        file_name = os.path.basename(original_file_path)\n        # Use problem ID to avoid conflicts and organize files\n        return f\"migrated-datasets/{problem_id}/{file_name}\"\n    \n    def migrate_problem(self, problem: Dict[str, Any]) -> bool:\n        \"\"\"Migrate a single problem from Git to S3.\"\"\"\n        problem_id = problem['id']\n        title = problem['title']\n        parquet_source = problem['parquet_data_source']\n        \n        # Handle JSONB field - might be string or already parsed dict\n        if isinstance(parquet_source, str):\n            try:\n                parquet_source = json.loads(parquet_source)\n            except json.JSONDecodeError as e:\n                logger.error(f\"Failed to parse parquet_data_source JSON for problem {problem_id}: {e}\")\n                return False\n        \n        logger.info(f\"Migrating problem: {title} (ID: {problem_id})\")\n        \n        try:\n            git_url = parquet_source['git_repo_url']\n            file_path = parquet_source['file_path']\n            table_name = parquet_source['table_name']\n            description = parquet_source.get('description', '')\n            \n            # Generate S3 key\n            s3_key = self.generate_s3_key(problem_id, file_path)\n            \n            # Download from Git\n            temp_file = self.download_parquet_file(git_url, file_path)\n            \n            try:\n                # Upload to S3\n                s3_details = self.upload_to_s3(temp_file, s3_key)\n                \n                # Create S3 data source object\n                s3_data_source = {\n                    \"bucket\": s3_details[\"bucket\"],\n                    \"key\": s3_details[\"key\"],\n                    \"table_name\": table_name,\n                    \"description\": f\"Migrated from Git: {description}\" if description else f\"Migrated from {git_url}/{file_path}\",\n                    \"etag\": s3_details[\"etag\"]\n                }\n                \n                # Update database record\n                self.update_problem_record(problem_id, s3_data_source)\n                \n                logger.info(f\"Successfully migrated problem {problem_id}\")\n                return True\n                \n            finally:\n                # Clean up temp file\n                if os.path.exists(temp_file):\n                    os.unlink(temp_file)\n                    \n        except Exception as e:\n            logger.error(f\"Failed to migrate problem {problem_id}: {e}\")\n            return False\n    \n    def run_migration(self) -> None:\n        \"\"\"Run the complete migration process.\"\"\"\n        logger.info(\"Starting Git to S3 migration\")\n        \n        # Get all problems that need migration\n        problems = self.get_git_problems()\n        if not problems:\n            logger.info(\"No problems found that need migration\")\n            return\n        \n        # Migration statistics\n        total = len(problems)\n        successful = 0\n        failed = 0\n        \n        # Migrate each problem\n        for i, problem in enumerate(problems, 1):\n            logger.info(f\"Processing {i}/{total}: {problem['title']}\")\n            \n            if self.migrate_problem(problem):\n                successful += 1\n            else:\n                failed += 1\n        \n        # Report results\n        logger.info(f\"Migration completed: {successful} successful, {failed} failed out of {total} total\")\n        \n        if failed > 0:\n            logger.warning(f\"{failed} problems failed to migrate - check logs above\")\n            sys.exit(1)\n    \n    def close(self):\n        \"\"\"Clean up resources.\"\"\"\n        if self.db_connection:\n            self.db_connection.close()\n\ndef main():\n    parser = argparse.ArgumentParser(description='Migrate parquet files from Git to S3')\n    parser.add_argument('--s3-bucket', required=True, help='S3 bucket for storing parquet files')\n    parser.add_argument('--dry-run', action='store_true', help='Show what would be done without making changes')\n    parser.add_argument('--verbose', '-v', action='store_true', help='Enable verbose logging')\n    \n    args = parser.parse_args()\n    \n    if args.verbose:\n        logging.getLogger().setLevel(logging.DEBUG)\n    \n    migrator = None\n    try:\n        migrator = GitToS3Migrator(args.s3_bucket, args.dry_run)\n        migrator.run_migration()\n        logger.info(\"Migration completed successfully\")\n    except Exception as e:\n        logger.error(f\"Migration failed: {e}\")\n        sys.exit(1)\n    finally:\n        if migrator:\n            migrator.close()\n\nif __name__ == '__main__':\n    main()","size_bytes":11719},"scripts/run_migration.sh":{"content":"#!/bin/bash\n# Git to S3 Migration Runner\n# \n# This script helps administrators migrate parquet files from Git repositories to S3 storage.\n#\n# Prerequisites:\n# 1. AWS credentials configured (AWS CLI or environment variables)\n# 2. DATABASE_URL environment variable set\n# 3. Python 3.8+ installed\n# 4. S3 bucket created with appropriate permissions\n#\n# Usage:\n#   ./scripts/run_migration.sh your-dataset-bucket [--dry-run]\n#\n\nset -e  # Exit on any error\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[0;33m'\nNC='\\033[0m' # No Color\n\n# Helper functions\ninfo() {\n    echo -e \"${GREEN}[INFO]${NC} $1\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[WARN]${NC} $1\"\n}\n\nerror() {\n    echo -e \"${RED}[ERROR]${NC} $1\"\n    exit 1\n}\n\n# Check if S3 bucket is provided\nif [ $# -eq 0 ]; then\n    error \"Usage: $0 <s3-bucket-name> [--dry-run]\"\nfi\n\nS3_BUCKET=\"$1\"\nDRY_RUN_FLAG=\"\"\nif [ \"$2\" = \"--dry-run\" ]; then\n    DRY_RUN_FLAG=\"--dry-run\"\n    warn \"Running in DRY RUN mode - no changes will be made\"\nfi\n\ninfo \"Starting Git to S3 migration for bucket: $S3_BUCKET\"\n\n# Check prerequisites\ninfo \"Checking prerequisites...\"\n\n# Check if DATABASE_URL is set\nif [ -z \"$DATABASE_URL\" ]; then\n    error \"DATABASE_URL environment variable is not set\"\nfi\n\n# Check if Python is available\nif ! command -v python3 &> /dev/null; then\n    error \"Python 3 is not installed or not in PATH\"\nfi\n\n# Check if AWS credentials are configured (lightweight check)\nif ! python3 -c \"import boto3; boto3.client('s3')\" &> /dev/null; then\n    error \"AWS credentials are not configured or boto3 is not available\"\nfi\n\n# Check if S3 bucket exists and is accessible\ninfo \"Verifying S3 bucket access...\"\nif ! python3 -c \"import boto3; boto3.client('s3').head_bucket(Bucket='$S3_BUCKET')\" &> /dev/null; then\n    error \"S3 bucket '$S3_BUCKET' does not exist or is not accessible\"\nfi\n\n# Install Python dependencies if needed\nif [ ! -f \"scripts/.migration_deps_installed\" ]; then\n    info \"Installing Python dependencies...\"\n    pip install -r scripts/requirements.txt\n    touch scripts/.migration_deps_installed\n    info \"Dependencies installed\"\nelse\n    info \"Dependencies already installed\"\nfi\n\n# Run the migration\ninfo \"Starting migration process...\"\npython3 scripts/migrate_git_to_s3.py --s3-bucket \"$S3_BUCKET\" $DRY_RUN_FLAG --verbose\n\nif [ $? -eq 0 ]; then\n    if [ \"$DRY_RUN_FLAG\" = \"--dry-run\" ]; then\n        info \"Dry run completed successfully!\"\n        info \"Run without --dry-run to perform the actual migration\"\n    else\n        info \"Migration completed successfully!\"\n        info \"All Git-based parquet files have been migrated to S3\"\n    fi\nelse\n    error \"Migration failed - check the logs above for details\"\nfi","size_bytes":2684},"client/src/components/ResultComparisonTable.tsx":{"content":"import { useMemo } from 'react';\n\ninterface RowComparison {\n  row_index: number;\n  matches: boolean;\n  actual_row: Record<string, any> | null;\n  expected_row: Record<string, any>;\n  differences?: string;\n}\n\ninterface ValidationDetails {\n  row_comparisons?: RowComparison[];\n  matching_row_count?: number;\n  total_row_count?: number;\n  comparison_differences?: string[];\n}\n\ninterface ResultComparisonTableProps {\n  validationDetails: ValidationDetails;\n  isCorrect: boolean;\n}\n\nexport default function ResultComparisonTable({ validationDetails, isCorrect }: ResultComparisonTableProps) {\n  const { headers, comparisons } = useMemo(() => {\n    const rowComparisons = validationDetails.row_comparisons || [];\n    \n    if (rowComparisons.length === 0) {\n      return { headers: [], comparisons: [] };\n    }\n    \n    // Get headers from the first expected row\n    const firstExpected = rowComparisons[0]?.expected_row;\n    const headers = firstExpected ? Object.keys(firstExpected) : [];\n    \n    return { headers, comparisons: rowComparisons };\n  }, [validationDetails]);\n\n  if (!validationDetails.row_comparisons || validationDetails.row_comparisons.length === 0) {\n    return null;\n  }\n\n  const matchingCount = validationDetails.matching_row_count || 0;\n  const totalCount = validationDetails.total_row_count || 0;\n\n  return (\n    <div className=\"bg-white border border-gray-200 rounded-lg p-4\" data-testid=\"comparison-table\">\n      <div className=\"mb-4\">\n        <h4 className=\"text-sm font-medium text-gray-900 mb-2\">Detailed Result Comparison</h4>\n        <div className=\"text-xs text-gray-600 mb-2\">\n          {matchingCount} of {totalCount} rows match\n        </div>\n        \n        {/* Legend */}\n        <div className=\"flex items-center space-x-4 text-xs mb-3\">\n          <div className=\"flex items-center space-x-1\">\n            <div className=\"w-3 h-3 bg-green-100 border border-green-200 rounded\"></div>\n            <span className=\"text-gray-600\">Matching rows</span>\n          </div>\n          <div className=\"flex items-center space-x-1\">\n            <div className=\"w-3 h-3 bg-white border border-gray-200 rounded\"></div>\n            <span className=\"text-gray-600\">Non-matching rows</span>\n          </div>\n        </div>\n      </div>\n\n      <div className=\"overflow-x-auto max-h-96\">\n        <table className=\"w-full border-collapse\">\n          <thead className=\"sticky top-0 bg-gray-50\">\n            <tr>\n              <th className=\"px-3 py-2 text-left text-xs font-medium text-gray-500 uppercase tracking-wider border-b border-gray-200\">\n                Row\n              </th>\n              <th className=\"px-3 py-2 text-left text-xs font-medium text-gray-500 uppercase tracking-wider border-b border-gray-200\">\n                Status\n              </th>\n              {headers.map((header, i) => (\n                <th \n                  key={i} \n                  className=\"px-3 py-2 text-left text-xs font-medium text-gray-500 uppercase tracking-wider border-b border-gray-200\"\n                >\n                  {header}\n                </th>\n              ))}\n            </tr>\n          </thead>\n          <tbody className=\"divide-y divide-gray-200\">\n            {comparisons.map((comparison) => {\n              const rowClass = comparison.matches \n                ? 'bg-green-50 hover:bg-green-100' \n                : 'bg-white hover:bg-gray-50';\n                \n              return (\n                <tr \n                  key={comparison.row_index} \n                  className={rowClass}\n                  data-testid={`row-comparison-${comparison.row_index}`}\n                >\n                  <td className=\"px-3 py-2 text-sm text-gray-900 font-medium\">\n                    {comparison.row_index + 1}\n                  </td>\n                  <td className=\"px-3 py-2 text-sm\">\n                    {comparison.matches ? (\n                      <span className=\"inline-flex items-center px-2 py-1 rounded-full text-xs font-medium bg-green-100 text-green-800\">\n                        âœ“ Match\n                      </span>\n                    ) : (\n                      <span className=\"inline-flex items-center px-2 py-1 rounded-full text-xs font-medium bg-red-100 text-red-800\">\n                        âœ— Different\n                      </span>\n                    )}\n                  </td>\n                  {headers.map((header, i) => {\n                    const expectedValue = comparison.expected_row[header];\n                    const actualValue = comparison.actual_row?.[header];\n                    const cellMatches = comparison.matches || (expectedValue === actualValue);\n                    \n                    return (\n                      <td \n                        key={i} \n                        className={`px-3 py-2 text-sm ${\n                          cellMatches ? 'text-gray-900' : 'text-red-700 font-medium'\n                        }`}\n                      >\n                        <div className=\"flex flex-col space-y-1\">\n                          {/* Show expected value */}\n                          <div className=\"text-xs text-gray-500\">\n                            Expected: {String(expectedValue ?? '')}\n                          </div>\n                          {/* Show actual value if different or if row doesn't match */}\n                          {(!comparison.matches || actualValue !== expectedValue) && (\n                            <div className={`text-xs ${cellMatches ? 'text-gray-700' : 'text-red-600 font-medium'}`}>\n                              Got: {actualValue !== undefined ? String(actualValue ?? '') : 'N/A'}\n                            </div>\n                          )}\n                        </div>\n                      </td>\n                    );\n                  })}\n                </tr>\n              );\n            })}\n          </tbody>\n        </table>\n      </div>\n\n      {/* Show comparison differences if any */}\n      {validationDetails.comparison_differences && validationDetails.comparison_differences.length > 0 && (\n        <div className=\"mt-4 p-3 bg-yellow-50 border border-yellow-200 rounded\">\n          <h5 className=\"text-sm font-medium text-yellow-800 mb-1\">Additional Issues:</h5>\n          <ul className=\"text-sm text-yellow-700 space-y-1\">\n            {validationDetails.comparison_differences.map((diff, index) => (\n              <li key={index}>â€¢ {diff}</li>\n            ))}\n          </ul>\n        </div>\n      )}\n    </div>\n  );\n}","size_bytes":6468},"api/secure_execution_optimized_broken.py":{"content":"\"\"\"\nSecure Query Execution System - High Performance\n===============================================\nUltra-optimized version focused on submission speed while maintaining API compatibility.\n\"\"\"\n\nimport asyncio\nimport logging\nimport json\nimport math\nimport hashlib\nimport time\nfrom typing import Dict, List, Any, Optional, Tuple, Set\nfrom datetime import datetime, timedelta\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy import text, create_engine\nfrom contextlib import asynccontextmanager\nfrom functools import lru_cache\nfrom concurrent.futures import ThreadPoolExecutor\nimport threading\nimport re\n\nfrom .query_validator import query_validator, QueryValidationError, QueryRisk\nfrom .test_validator import optimized_test_validator, ComparisonMode\nfrom .duckdb_sandbox import DuckDBSandboxManager, DuckDBSandbox\nfrom .models import (\n    User, Problem, TestCase, Submission, \n    ExecutionResult, ExecutionStatus\n)\nfrom .schemas import (\n    ExecutionResultCreate, \n    DetailedSubmissionResponse,\n    TestCaseResponse\n)\n\nlogger = logging.getLogger(__name__)\n\ndef sanitize_json_data(data: Any) -> Any:\n    \"\"\"Fast JSON sanitization optimized for speed\"\"\"\n    if isinstance(data, dict):\n        return {key: sanitize_json_data(value) for key, value in data.items()}\n    elif isinstance(data, list):\n        return [sanitize_json_data(item) for item in data]\n    elif isinstance(data, float):\n        if math.isnan(data):\n            return None\n        elif math.isinf(data):\n            return \"Infinity\" if data > 0 else \"-Infinity\"\n        else:\n            return data\n    else:\n        return data\n\nclass _FastSecurityChecker:\n    \"\"\"Minimal security checker optimized for speed\"\"\"\n    \n    def __init__(self):\n        # Only essential security checks for maximum speed\n        self.forbidden_keywords = {\n            'DROP', 'DELETE', 'INSERT', 'UPDATE', 'CREATE', 'ALTER', 'TRUNCATE'\n        }\n    \n    def is_safe(self, query: str) -> Tuple[bool, List[str]]:\n        \"\"\"Ultra-fast security check\"\"\"\n        query_upper = query.upper().strip()\n        \n        # Fast whitelist check\n        if not query_upper.startswith(('SELECT', 'WITH')):\n            first_word = query_upper.split()[0] if query_upper else 'UNKNOWN'\n            return False, [f\"Only SELECT and WITH statements allowed, found: {first_word}\"]\n        \n        # Fast keyword check\n        query_words = set(query_upper.split())\n        forbidden_found = query_words & self.forbidden_keywords\n        if forbidden_found:\n            return False, [f\"Forbidden operations detected: {', '.join(forbidden_found)}\"]\n        \n        return True, []\n\nclass _MinimalCache:\n    \"\"\"Minimal cache implementation for maximum speed\"\"\"\n    \n    def __init__(self, max_size: int = 500):\n        self.data = {}\n        self.max_size = max_size\n        self._lock = threading.Lock()\n    \n    def get(self, key: str) -> Optional[Any]:\n        with self._lock:\n            return self.data.get(key)\n    \n    def set(self, key: str, value: Any):\n        with self._lock:\n            if len(self.data) >= self.max_size:\n                # Remove oldest (simple FIFO)\n                oldest_key = next(iter(self.data))\n                del self.data[oldest_key]\n            self.data[key] = value\n    \n    def make_key(self, query: str, problem_id: str) -> str:\n        return f\"{problem_id}:{hashlib.md5(query.encode()).hexdigest()[:16]}\"\n\nclass SecureQueryExecutor:\n    \"\"\"Ultra-fast secure query executor optimized for submission speed\"\"\"\n    \n    def __init__(self):\n        self.max_execution_time = 30\n        self.max_memory_mb = 256\n        self.max_result_rows = 10000\n        self.sandbox_manager = DuckDBSandboxManager()\n        \n        # Minimal components for maximum speed\n        self._security_checker = _FastSecurityChecker()\n        self._cache = _MinimalCache()\n        self._thread_pool = ThreadPoolExecutor(max_workers=2)  # Reduced for lower overhead\n    \n    async def submit_solution(\n        self,\n        user_id: str,\n        problem_id: str,\n        query: str,\n        db: Session\n    ) -> Dict[str, Any]:\n        \"\"\"Ultra-optimized submission with minimal overhead\"\"\"\n        start_time = time.time()\n        \n        try:\n            # STEP 1: Ultra-fast security check (no external calls)\n            is_safe, security_errors = self._security_checker.is_safe(query)\n            if not is_safe:\n                return self._create_error_response(security_errors[0])\n            \n            # STEP 2: Fast cache check (skip for now to avoid complexity)\n            cache_key = self._cache.make_key(query, problem_id)\n            cached = self._cache.get(cache_key)\n            if cached and cached.get('is_correct'):\n                # Fast submission creation from cache\n                submission = self._create_submission_fast(user_id, problem_id, query, cached, db)\n                cached['submission_id'] = submission.id\n                return cached\n            \n            # STEP 3: Get sandbox (reuse existing if possible)\n            sandbox = self._get_sandbox_fast(user_id, problem_id, db)\n            if not sandbox:\n                return self._create_error_response('Failed to create execution sandbox')\n            \n            # STEP 4: Execute query with minimal validation\n            test_results = await self._execute_minimal_validation(sandbox, problem_id, query, db)\n            \n            # STEP 5: Fast scoring\n            final_score = self._calculate_score_fast(test_results)\n            is_correct = final_score['overall_score'] >= 95.0\n            \n            # STEP 6: Create submission (minimal data)\n            submission = Submission(\n                user_id=user_id,\n                problem_id=problem_id,\n                query=query,\n                is_correct=is_correct,\n                execution_time=final_score['avg_execution_time']\n            )\n            \n            db.add(submission)\n            db.commit()\n            db.refresh(submission)\n            \n            # STEP 7: Build minimal response\n            result = {\n                'success': True,\n                'submission_id': submission.id,\n                'is_correct': is_correct,\n                'score': final_score['overall_score'],\n                'feedback': final_score['feedback'],\n                'test_results': test_results,\n                'passed_tests': final_score['passed_count'],\n                'total_tests': final_score['total_count'],\n                'execution_stats': {\n                    'avg_time_ms': final_score['avg_execution_time'],\n                    'max_time_ms': final_score['max_execution_time'],\n                    'total_time_ms': int((time.time() - start_time) * 1000)\n                },\n                'security_warnings': []\n            }\n            \n            # STEP 8: Cache successful results\n            if is_correct:\n                self._cache.set(cache_key, result)\n            \n            # STEP 9: Async user progress update (fire and forget)\n            if is_correct:\n                self._update_user_progress_background(user_id, problem_id, db)\n            \n            return result\n            \n        except Exception as e:\n            logger.error(f\"Fast submission failed: {e}\")\n            return self._create_error_response(f'Execution error: {str(e)}')\n    \n    async def test_query(\n        self,\n        user_id: str,\n        problem_id: str,\n        query: str,\n        db: Session,\n        include_hidden_tests: bool = False\n    ) -> Dict[str, Any]:\n        \"\"\"Ultra-fast query testing\"\"\"\n        try:\n            # Fast security check\n            is_safe, security_errors = self._security_checker.is_safe(query)\n            if not is_safe:\n                return {\n                    'success': False,\n                    'feedback': security_errors,\n                    'security_violations': security_errors,\n                    'test_results': []\n                }\n            \n            # Get sandbox fast\n            sandbox = self._get_sandbox_fast(user_id, problem_id, db)\n            if not sandbox:\n                return {\n                    'success': False,\n                    'feedback': ['Failed to create execution sandbox'],\n                    'test_results': []\n                }\n            \n            # Execute with minimal validation\n            query_result = await self._execute_query_fast(sandbox, query)\n            \n            if not query_result.get('success'):\n                return {\n                    'success': False,\n                    'feedback': [query_result.get('error', 'Query execution failed')],\n                    'test_results': []\n                }\n            \n            # Minimal test validation\n            test_results = await self._validate_minimal(sandbox, problem_id, query, query_result.get('results', []), db)\n            \n            return {\n                'success': True,\n                'feedback': self._generate_feedback_fast(test_results),\n                'test_results': test_results,\n                'security_warnings': [],\n                'query_result': {\n                    'rows_returned': len(query_result.get('results', [])),\n                    'execution_time_ms': query_result.get('execution_time_ms', 0)\n                },\n                'execution_status': 'SUCCESS'\n            }\n            \n        except Exception as e:\n            logger.error(f\"Fast test failed: {e}\")\n            return {\n                'success': False,\n                'feedback': [f'Test execution error: {str(e)}'],\n                'test_results': []\n            }\n    \n    def _get_sandbox_fast(self, user_id: str, problem_id: str, db: Session) -> Optional[DuckDBSandbox]:\n        \"\"\"Ultra-fast sandbox retrieval with proper S3 data loading\"\"\"\n        try:\n            # Try existing sandbox first\n            sandbox = self.sandbox_manager.get_sandbox(user_id, problem_id)\n            if sandbox:\n                # Check if sandbox needs data reloading (from original logic)\n                problem = db.query(Problem.s3_data_source).filter(Problem.id == problem_id).first()\n                if problem and problem.s3_data_source:\n                    # Verify table exists\n                    table_info = sandbox.get_table_info()\n                    expected_table_name = problem.s3_data_source.get('table_name', 'problem_data')\n                    \n                    table_exists = any(\n                        table.get('name') == expected_table_name \n                        for table in table_info.get('tables', [])\n                    )\n                    \n                    if not table_exists:\n                        logger.info(f\"Reloading S3 data for existing sandbox - table {expected_table_name} not found\")\n                        # Run setup synchronously for speed\n                        loop = asyncio.new_event_loop()\n                        asyncio.set_event_loop(loop)\n                        try:\n                            setup_result = loop.run_until_complete(\n                                sandbox.setup_problem_data(\n                                    problem_id=problem_id,\n                                    s3_data_source=problem.s3_data_source\n                                )\n                            )\n                            if not setup_result.get('success', False):\n                                logger.error(f\"Failed to reload problem data: {setup_result.get('error')}\")\n                        finally:\n                            loop.close()\n                \n                return sandbox\n            \n            # Get problem info for new sandbox\n            problem = db.query(Problem.id, Problem.s3_data_source).filter(Problem.id == problem_id).first()\n            if not problem:\n                logger.error(f\"Problem {problem_id} not found\")\n                return None\n            \n            # Create sandbox synchronously for speed\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n            try:\n                sandbox = loop.run_until_complete(\n                    self.sandbox_manager.create_sandbox(user_id, problem_id)\n                )\n                \n                # Load S3 data if needed\n                if problem.s3_data_source:\n                    logger.info(f\"Loading S3 data for problem {problem_id}\")\n                    setup_result = loop.run_until_complete(\n                        sandbox.setup_problem_data(\n                            problem_id=problem_id,\n                            s3_data_source=problem.s3_data_source\n                        )\n                    )\n                    \n                    if not setup_result.get('success', False):\n                        logger.error(f\"Failed to load problem data: {setup_result.get('error')}\")\n                \n                return sandbox\n            finally:\n                loop.close()\n                \n        except Exception as e:\n            logger.error(f\"Fast sandbox creation failed: {e}\")\n            return None\n    \n    async def _execute_query_fast(self, sandbox: DuckDBSandbox, query: str) -> Dict[str, Any]:\n        \"\"\"Execute query with minimal overhead\"\"\"\n        try:\n            # Direct execution without complex timeout handling\n            result = sandbox.execute_query(query)\n            return result\n        except Exception as e:\n            return {\n                'success': False,\n                'error': str(e),\n                'execution_time_ms': 0\n            }\n    \n    async def _execute_minimal_validation(\n        self,\n        sandbox: DuckDBSandbox,\n        problem_id: str,\n        query: str,\n        db: Session\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Optimized validation that properly handles all test case types\"\"\"\n        try:\n            # Get problem with all needed fields for validation\n            problem = db.query(Problem).filter(Problem.id == problem_id).first()\n            \n            if not problem:\n                return [{\n                    'test_case_id': 'error',\n                    'test_case_name': 'Problem Not Found',\n                    'is_hidden': False,\n                    'is_correct': False,\n                    'score': 0.0,\n                    'feedback': ['Problem not found in database'],\n                    'execution_time_ms': 0,\n                    'execution_status': ExecutionStatus.ERROR.value,\n                    'validation_details': {}\n                }]\n            \n            # Check if this is an enhanced S3-based question with hash validation (fastest path)\n            if problem.expected_hash and problem.s3_data_source:\n                logger.info(f\"Using S3 hash validation for problem {problem_id}\")\n                return await self._hash_validation_fast(problem, sandbox, query)\n            \n            # Check for traditional test cases\n            test_cases = db.query(TestCase).filter(\n                TestCase.problem_id == problem_id\n            ).order_by(TestCase.order_index).all()\n            \n            if test_cases:\n                # Execute against test cases (optimized)\n                return await self._execute_test_cases_fast(sandbox, query, test_cases)\n            \n            # Check if problem has S3 solution source for verification\n            if hasattr(problem, 'solution_source') and problem.solution_source == 's3' and hasattr(problem, 's3_solution_source') and problem.s3_solution_source:\n                # Execute query and verify with S3 solution\n                result = await self._execute_query_fast(sandbox, query)\n                \n                if result.get('success'):\n                    user_results = result.get('results', [])\n                    s3_verification = await self._verify_with_s3_solution_fast(\n                        sandbox, problem, query, user_results\n                    )\n                    return s3_verification\n                else:\n                    return [{\n                        'test_case_id': 's3_verification',\n                        'test_case_name': 'S3 Solution Verification',\n                        'is_hidden': False,\n                        'is_correct': False,\n                        'score': 0.0,\n                        'feedback': [result.get('error', 'Query execution failed')],\n                        'execution_time_ms': 0\n                    }]\n            \n            # Check for expected output in problem question\n            if problem.question and isinstance(problem.question, dict):\n                expected_output = problem.question.get('expectedOutput', [])\n                if expected_output:\n                    result = await self._execute_query_fast(sandbox, query)\n                    \n                    if result.get('success'):\n                        user_results = result.get('results', [])\n                        \n                        # Fast comparison\n                        is_correct = self._compare_results_fast(user_results, expected_output)\n                        \n                        return [{\n                            'test_case_id': f\"{problem_id}_expected_output\",\n                            'test_case_name': 'Expected Output Check',\n                            'is_hidden': False,\n                            'is_correct': is_correct,\n                            'score': 100.0 if is_correct else 0.0,\n                            'feedback': ['Results match expected output'] if is_correct else ['Results differ from expected output'],\n                            'execution_time_ms': result.get('execution_time_ms', 0),\n                            'user_output': user_results,\n                            'expected_output': expected_output,\n                            'output_matches': is_correct\n                        }]\n                    else:\n                        return [{\n                            'test_case_id': f\"{problem_id}_expected_output\",\n                            'test_case_name': 'Expected Output Check',\n                            'is_hidden': False,\n                            'is_correct': False,\n                            'score': 0.0,\n                            'feedback': [result.get('error', 'Query execution failed')],\n                            'execution_time_ms': 0\n                        }]\n            \n            # Fallback: just execute query and return success\n            result = await self._execute_query_fast(sandbox, query)\n            \n            if result.get('success'):\n                return [{\n                    'test_case_id': 'basic_execution',\n                    'test_case_name': 'Query Execution',\n                    'is_hidden': False,\n                    'is_correct': True,\n                    'score': 100.0,\n                    'feedback': ['Query executed successfully'],\n                    'execution_time_ms': result.get('execution_time_ms', 0)\n                }]\n            else:\n                return [{\n                    'test_case_id': 'execution_error',\n                    'test_case_name': 'Query Execution',\n                    'is_hidden': False,\n                    'is_correct': False,\n                    'score': 0.0,\n                    'feedback': [result.get('error', 'Query failed')],\n                    'execution_time_ms': 0\n                }]\n            \n        except Exception as e:\n            logger.error(f\"Validation failed: {e}\")\n            return [{\n                'test_case_id': 'validation_error',\n                'test_case_name': 'Validation Error',\n                'is_hidden': False,\n                'is_correct': False,\n                'score': 0.0,\n                'feedback': [f'Validation error: {str(e)}'],\n                'execution_time_ms': 0\n            }]\n    \n    async def _execute_test_cases_fast(\n        self,\n        sandbox: DuckDBSandbox,\n        query: str,\n        test_cases: List[TestCase]\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Fast execution against traditional test cases\"\"\"\n        results = []\n        \n        for test_case in test_cases:\n            try:\n                # Execute query\n                result = await self._execute_query_fast(sandbox, query)\n                \n                if result.get('success'):\n                    user_output = result.get('results', [])\n                    expected_output = test_case.expected_output or []\n                    \n                    # Handle S3 expected output source if exists\n                    if test_case.expected_output_source:\n                        try:\n                            s3_config = test_case.expected_output_source\n                            if s3_config.get('bucket') and s3_config.get('key'):\n                                # Fetch from S3\n                                from .s3_service import s3_service\n                                from .schemas import S3AnswerSource\n                                \n                                s3_answer_source = S3AnswerSource(**s3_config)\n                                cache_result = s3_service.fetch_answer_file(\n                                    bucket=s3_answer_source.bucket,\n                                    key=s3_answer_source.key,\n                                    format=s3_answer_source.format,\n                                    etag=getattr(s3_answer_source, 'etag', None)\n                                )\n                                expected_output = cache_result.data\n                                logger.info(f\"Fetched {len(expected_output)} expected rows from S3\")\n                        except Exception as e:\n                            logger.error(f\"Failed to fetch S3 expected output: {e}\")\n                            # Continue with fallback expected_output\n                    \n                    # Fast comparison\n                    is_correct = self._compare_results_fast(user_output, expected_output)\n                    \n                    results.append({\n                        'test_case_id': test_case.id,\n                        'test_case_name': test_case.name,\n                        'is_hidden': test_case.is_hidden,\n                        'is_correct': is_correct,\n                        'score': 100.0 if is_correct else 0.0,\n                        'feedback': ['Results match expected output'] if is_correct else ['Results differ from expected output'],\n                        'execution_time_ms': result.get('execution_time_ms', 0),\n                        'execution_status': ExecutionStatus.SUCCESS.value,\n                        'user_output': user_output,\n                        'expected_output': expected_output,\n                        'output_matches': is_correct\n                    })\n                else:\n                    results.append({\n                        'test_case_id': test_case.id,\n                        'test_case_name': test_case.name,\n                        'is_hidden': test_case.is_hidden,\n                        'is_correct': False,\n                        'score': 0.0,\n                        'feedback': [result.get('error', 'Query execution failed')],\n                        'execution_time_ms': 0,\n                        'execution_status': ExecutionStatus.ERROR.value\n                    })\n                    \n            except Exception as e:\n                logger.error(f\"Test case execution failed: {e}\")\n                results.append({\n                    'test_case_id': test_case.id,\n                    'test_case_name': test_case.name,\n                    'is_hidden': test_case.is_hidden,\n                    'is_correct': False,\n                    'score': 0.0,\n                    'feedback': [f'Test execution error: {str(e)}'],\n                    'execution_time_ms': 0,\n                    'execution_status': ExecutionStatus.ERROR.value\n                })\n        \n        return results\n    \n    async def _hash_validation_fast(\n        self,\n        problem: Problem,\n        sandbox: DuckDBSandbox,\n        query: str\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Fast hash-based validation\"\"\"\n        try:\n            # Execute user query\n            result = await self._execute_query_fast(sandbox, query)\n            \n            if not result.get('success'):\n                return [{\n                    'test_case_id': 'hash_validation',\n                    'test_case_name': 'Hash Validation',\n                    'is_hidden': False,\n                    'is_correct': False,\n                    'score': 0.0,\n                    'feedback': [result.get('error', 'Query execution failed')],\n                    'execution_time_ms': 0\n                }]\n            \n            user_results = result.get('results', [])\n            \n            # Fast hash comparison\n            user_hash = self._compute_result_hash_fast(user_results)\n            expected_hash = problem.expected_hash\n            \n            is_correct = user_hash == expected_hash\n            \n            return [{\n                'test_case_id': 'hash_validation',\n                'test_case_name': 'Result Hash Validation',\n                'is_hidden': False,\n                'is_correct': is_correct,\n                'score': 100.0 if is_correct else 0.0,\n                'feedback': ['Query results match expected pattern'] if is_correct else ['Query results do not match expected pattern'],\n                'execution_time_ms': result.get('execution_time_ms', 0),\n                'user_hash': user_hash,\n                'expected_hash': expected_hash,\n                'hash_matches': is_correct\n            }]\n            \n        except Exception as e:\n            logger.error(f\"Hash validation failed: {e}\")\n            return [{\n                'test_case_id': 'hash_validation_error',\n                'test_case_name': 'Hash Validation Error',\n                'is_hidden': False,\n                'is_correct': False,\n                'score': 0.0,\n                'feedback': [f'Hash validation error: {str(e)}'],\n                'execution_time_ms': 0\n            }]\n    \n    async def _verify_with_s3_solution_fast(\n        self,\n        sandbox: DuckDBSandbox,\n        problem: Problem,\n        query: str,\n        user_results: List[Dict[str, Any]]\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Fast S3 solution verification\"\"\"\n        try:\n            from .s3_service import s3_service\n            \n            s3_solution_data = problem.s3_solution_source\n            bucket = s3_solution_data.get('bucket')\n            solution_key = s3_solution_data.get('key')\n            \n            # Fetch expected results from S3\n            validation_result = s3_service.validate_dataset_file(bucket, solution_key, 'solution')\n            if not validation_result.get('is_valid'):\n                return [{\n                    'test_case_id': 's3_solution_verification',\n                    'test_case_name': 'S3 Solution Verification',\n                    'is_hidden': False,\n                    'is_correct': False,\n                    'score': 0.0,\n                    'feedback': ['Failed to load expected results from S3'],\n                    'execution_time_ms': 0\n                }]\n            \n            expected_results = validation_result.get('sample_data', [])\n            \n            # Fast comparison\n            is_correct = self._compare_results_fast(user_results, expected_results)\n            \n            return [{\n                'test_case_id': 's3_solution_verification',\n                'test_case_name': 'S3 Solution Verification',\n                'is_hidden': False,\n                'is_correct': is_correct,\n                'score': 100.0 if is_correct else 0.0,\n                'feedback': ['Results match S3 solution'] if is_correct else ['Results differ from S3 solution'],\n                'execution_time_ms': 0,\n                'user_output': user_results,\n                'expected_output': expected_results,\n                'output_matches': is_correct\n            }]\n            \n        except Exception as e:\n            logger.error(f\"S3 solution verification failed: {e}\")\n            return [{\n                'test_case_id': 's3_solution_error',\n                'test_case_name': 'S3 Solution Error',\n                'is_hidden': False,\n                'is_correct': False,\n                'score': 0.0,\n                'feedback': [f'S3 verification error: {str(e)}'],\n                'execution_time_ms': 0\n            }]\n    \n    async def _validate_minimal(\n        self,\n        sandbox: DuckDBSandbox,\n        problem_id: str,\n        query: str,\n        query_results: List[Dict[str, Any]],\n        db: Session\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Fast minimal validation for test queries\"\"\"\n        try:\n            # Just return basic success for test queries\n            return [{\n                'test_case_id': 'test_execution',\n                'test_case_name': 'Query Test',\n                'is_hidden': False,\n                'is_correct': True,\n                'score': 100.0,\n                'feedback': ['Query executed successfully'],\n                'execution_time_ms': 0\n            }]\n            \n        except Exception as e:\n            logger.error(f\"Minimal validation failed: {e}\")\n            return [{\n                'test_case_id': 'test_error',\n                'test_case_name': 'Query Test Error',\n                'is_hidden': False,\n                'is_correct': False,\n                'score': 0.0,\n                'feedback': [f'Test error: {str(e)}'],\n                'execution_time_ms': 0\n            }]\n    \n    def _compare_results_fast(self, user_results: List[Dict], expected_results: List[Dict]) -> bool:\n        \"\"\"Ultra-fast result comparison\"\"\"\n        try:\n            if len(user_results) != len(expected_results):\n                return False\n            \n            # Quick comparison for small datasets\n            if len(user_results) <= 100:\n                return user_results == expected_results\n            \n            # Sample comparison for large datasets\n            sample_size = min(50, len(user_results))\n            for i in range(0, len(user_results), len(user_results) // sample_size):\n                if i < len(user_results) and i < len(expected_results):\n                    if user_results[i] != expected_results[i]:\n                        return False\n            \n            return True\n            \n        except Exception as e:\n            logger.error(f\"Fast comparison failed: {e}\")\n            return False\n    \n    def _compute_result_hash_fast(self, results: List[Dict[str, Any]]) -> str:\n        \"\"\"Fast hash computation for results\"\"\"\n        try:\n            # Simple hash based on result structure\n            content = json.dumps(results, sort_keys=True, default=str)\n            return hashlib.md5(content.encode()).hexdigest()\n        except Exception as e:\n            logger.error(f\"Hash computation failed: {e}\")\n            return \"error_hash\"\n    \n    def _calculate_score_fast(self, test_results: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"Fast scoring calculation\"\"\"\n        if not test_results:\n            return {\n                'overall_score': 0.0,\n                'passed_count': 0,\n                'total_count': 0,\n                'avg_execution_time': 0,\n                'max_execution_time': 0,\n                'feedback': ['No test results available']\n            }\n        \n        passed_count = sum(1 for result in test_results if result.get('is_correct', False))\n        total_count = len(test_results)\n        overall_score = (passed_count / total_count) * 100.0 if total_count > 0 else 0.0\n        \n        execution_times = [result.get('execution_time_ms', 0) for result in test_results]\n        avg_execution_time = sum(execution_times) / len(execution_times) if execution_times else 0\n        max_execution_time = max(execution_times) if execution_times else 0\n        \n        feedback = []\n        if passed_count == total_count:\n            feedback.append('All test cases passed!')\n        elif passed_count > 0:\n            feedback.append(f'{passed_count} of {total_count} test cases passed')\n        else:\n            feedback.append('No test cases passed')\n        \n        return {\n            'overall_score': overall_score,\n            'passed_count': passed_count,\n            'total_count': total_count,\n            'avg_execution_time': avg_execution_time,\n            'max_execution_time': max_execution_time,\n            'feedback': feedback\n        }\n    \n    def _generate_feedback_fast(self, test_results: List[Dict[str, Any]]) -> List[str]:\n        \"\"\"Fast feedback generation\"\"\"\n        if not test_results:\n            return ['No test results available']\n        \n        feedback = []\n        for result in test_results:\n            if result.get('feedback'):\n                feedback.extend(result['feedback'])\n        \n        return feedback if feedback else ['Query executed']\n    \n    def _create_error_response(self, error_message: str) -> Dict[str, Any]:\n        \"\"\"Fast error response creation\"\"\"\n        return {\n            'success': False,\n            'is_correct': False,\n            'score': 0.0,\n            'feedback': [error_message],\n            'test_results': [],\n            'passed_tests': 0,\n            'total_tests': 0,\n            'execution_stats': {\n                'avg_time_ms': 0,\n                'max_time_ms': 0,\n                'total_time_ms': 0\n            },\n            'security_warnings': [error_message],\n            'submission_id': None\n        }\n    \n    def _create_submission_fast(\n        self,\n        user_id: str,\n        problem_id: str,\n        query: str,\n        cached_result: Dict[str, Any],\n        db: Session\n    ) -> Submission:\n        \"\"\"Fast submission creation from cache\"\"\"\n        submission = Submission(\n            user_id=user_id,\n            problem_id=problem_id,\n            query=query,\n            is_correct=cached_result.get('is_correct', False),\n            execution_time=cached_result.get('execution_stats', {}).get('avg_time_ms', 0)\n        )\n        \n        db.add(submission)\n        db.commit()\n        db.refresh(submission)\n        \n        return submission\n    \n    def _update_user_progress_background(self, user_id: str, problem_id: str, db: Session):\n        \"\"\"Background user progress update\"\"\"\n        try:\n            # Simple fire-and-forget progress update\n            self._thread_pool.submit(self._update_user_progress_sync, user_id, problem_id, db)\n        except Exception as e:\n            logger.warning(f\"Background progress update failed: {e}\")\n    \n    def _update_user_progress_sync(self, user_id: str, problem_id: str, db: Session):\n        \"\"\"Synchronous user progress update\"\"\"\n        try:\n            # Check if this is first time solving this problem\n            existing_correct = db.query(Submission).filter(\n                Submission.user_id == user_id,\n                Submission.problem_id == problem_id,\n                Submission.is_correct == True\n            ).first()\n            \n            if not existing_correct:\n                # Update user's solved count\n                user = db.query(User).filter(User.id == user_id).first()\n                if user:\n                    user.problems_solved = (user.problems_solved or 0) + 1\n                    db.commit()\n                    \n        except Exception as e:\n            logger.error(f\"User progress update failed: {e}\")\n    \n    async def get_user_progress(self, user_id: str, db: Session) -> Dict[str, Any]:\n        \"\"\"Fast user progress retrieval\"\"\"\n        try:\n            user = db.query(User).filter(User.id == user_id).first()\n            if not user:\n                return {\n                    'success': False,\n                    'error': 'User not found'\n                }\n            \n            # Basic progress stats\n            total_submissions = db.query(Submission).filter(Submission.user_id == user_id).count()\n            correct_submissions = db.query(Submission).filter(\n                Submission.user_id == user_id,\n                Submission.is_correct == True\n            ).count()\n            \n            return {\n                'success': True,\n                'user_id': user_id,\n                'problems_solved': user.problems_solved or 0,\n                'total_submissions': total_submissions,\n                'correct_submissions': correct_submissions,\n                'accuracy': (correct_submissions / total_submissions * 100) if total_submissions > 0 else 0\n            }\n            \n        except Exception as e:\n            logger.error(f\"User progress retrieval failed: {e}\")\n            return {\n                'success': False,\n                'error': f'Progress retrieval failed: {str(e)}'\n            }\n\n# Global secure executor instance\nsecure_executor = SecureQueryExecutor()","size_bytes":36934},"api/secure_execution_original.py":{"content":"\"\"\"\nSecure Query Execution System - High Performance\n===============================================\nUltra-optimized version focused on submission speed while maintaining API compatibility.\n\"\"\"\n\nimport asyncio\nimport logging\nimport json\nimport math\nimport hashlib\nimport time\nfrom typing import Dict, List, Any, Optional, Tuple, Set\nfrom datetime import datetime, timedelta\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy import text, create_engine\nfrom contextlib import asynccontextmanager\nfrom functools import lru_cache\nfrom concurrent.futures import ThreadPoolExecutor\nimport threading\nimport re\n\nfrom .query_validator import query_validator, QueryValidationError, QueryRisk\nfrom .test_validator import optimized_test_validator, ComparisonMode\nfrom .duckdb_sandbox import DuckDBSandboxManager, DuckDBSandbox\nfrom .models import (\n    User, Problem, TestCase, Submission, \n    ExecutionResult, ExecutionStatus\n)\nfrom .schemas import (\n    ExecutionResultCreate, \n    DetailedSubmissionResponse,\n    TestCaseResponse\n)\n\nlogger = logging.getLogger(__name__)\n\ndef sanitize_json_data(data: Any) -> Any:\n    \"\"\"Fast JSON sanitization optimized for speed\"\"\"\n    if isinstance(data, dict):\n        return {key: sanitize_json_data(value) for key, value in data.items()}\n    elif isinstance(data, list):\n        return [sanitize_json_data(item) for item in data]\n    elif isinstance(data, float):\n        if math.isnan(data):\n            return None\n        elif math.isinf(data):\n            return \"Infinity\" if data > 0 else \"-Infinity\"\n        else:\n            return data\n    else:\n        return data\n\nclass _FastSecurityChecker:\n    \"\"\"Minimal security checker optimized for speed\"\"\"\n    \n    def __init__(self):\n        # Only essential security checks for maximum speed\n        self.forbidden_keywords = {\n            'DROP', 'DELETE', 'INSERT', 'UPDATE', 'CREATE', 'ALTER', 'TRUNCATE'\n        }\n    \n    def is_safe(self, query: str) -> Tuple[bool, List[str]]:\n        \"\"\"Ultra-fast security check\"\"\"\n        query_upper = query.upper().strip()\n        \n        # Fast whitelist check\n        if not query_upper.startswith(('SELECT', 'WITH')):\n            first_word = query_upper.split()[0] if query_upper else 'UNKNOWN'\n            return False, [f\"Only SELECT and WITH statements allowed, found: {first_word}\"]\n        \n        # Fast keyword check\n        query_words = set(query_upper.split())\n        forbidden_found = query_words & self.forbidden_keywords\n        if forbidden_found:\n            return False, [f\"Forbidden operations detected: {', '.join(forbidden_found)}\"]\n        \n        return True, []\n\nclass _MinimalCache:\n    \"\"\"Minimal cache implementation for maximum speed\"\"\"\n    \n    def __init__(self, max_size: int = 500):\n        self.data = {}\n        self.max_size = max_size\n        self._lock = threading.Lock()\n    \n    def get(self, key: str) -> Optional[Any]:\n        with self._lock:\n            return self.data.get(key)\n    \n    def set(self, key: str, value: Any):\n        with self._lock:\n            if len(self.data) >= self.max_size:\n                # Remove oldest (simple FIFO)\n                oldest_key = next(iter(self.data))\n                del self.data[oldest_key]\n            self.data[key] = value\n    \n    def make_key(self, query: str, problem_id: str) -> str:\n        return f\"{problem_id}:{hashlib.md5(query.encode()).hexdigest()[:16]}\"\n\nclass SecureQueryExecutor:\n    \"\"\"Ultra-fast secure query executor optimized for submission speed\"\"\"\n    \n    def __init__(self):\n        self.max_execution_time = 30\n        self.max_memory_mb = 256\n        self.max_result_rows = 10000\n        self.sandbox_manager = DuckDBSandboxManager()\n        \n        # Minimal components for maximum speed\n        self._security_checker = _FastSecurityChecker()\n        self._cache = _MinimalCache()\n        self._thread_pool = ThreadPoolExecutor(max_workers=2)  # Reduced for lower overhead\n    \n    async def submit_solution(\n        self,\n        user_id: str,\n        problem_id: str,\n        query: str,\n        db: Session\n    ) -> Dict[str, Any]:\n        \"\"\"Ultra-optimized submission with minimal overhead\"\"\"\n        start_time = time.time()\n        \n        try:\n            # STEP 1: Ultra-fast security check (no external calls)\n            is_safe, security_errors = self._security_checker.is_safe(query)\n            if not is_safe:\n                return self._create_error_response(security_errors[0])\n            \n            # STEP 2: Fast cache check (skip for now to avoid complexity)\n            cache_key = self._cache.make_key(query, problem_id)\n            cached = self._cache.get(cache_key)\n            if cached and cached.get('is_correct'):\n                # Fast submission creation from cache\n                submission = self._create_submission_fast(user_id, problem_id, query, cached, db)\n                cached['submission_id'] = submission.id\n                return cached\n            \n            # STEP 3: Get sandbox (reuse existing if possible)\n            sandbox = self._get_sandbox_fast(user_id, problem_id, db)\n            if not sandbox:\n                return self._create_error_response('Failed to create execution sandbox')\n            \n            # STEP 4: Execute query with minimal validation\n            test_results = await self._execute_minimal_validation(sandbox, problem_id, query, db)\n            \n            # STEP 5: Fast scoring\n            final_score = self._calculate_score_fast(test_results)\n            is_correct = final_score['overall_score'] >= 95.0\n            \n            # STEP 6: Create submission (minimal data)\n            submission = Submission(\n                user_id=user_id,\n                problem_id=problem_id,\n                query=query,\n                is_correct=is_correct,\n                execution_time=final_score['avg_execution_time']\n            )\n            \n            db.add(submission)\n            db.commit()\n            db.refresh(submission)\n            \n            # STEP 7: Build minimal response\n            result = {\n                'success': True,\n                'submission_id': submission.id,\n                'is_correct': is_correct,\n                'score': final_score['overall_score'],\n                'feedback': final_score['feedback'],\n                'test_results': test_results,\n                'passed_tests': final_score['passed_count'],\n                'total_tests': final_score['total_count'],\n                'execution_stats': {\n                    'avg_time_ms': final_score['avg_execution_time'],\n                    'max_time_ms': final_score['max_execution_time'],\n                    'total_time_ms': int((time.time() - start_time) * 1000)\n                },\n                'security_warnings': []\n            }\n            \n            # STEP 8: Cache successful results\n            if is_correct:\n                self._cache.set(cache_key, result)\n            \n            # STEP 9: Async user progress update (fire and forget)\n            if is_correct:\n                self._update_user_progress_background(user_id, problem_id, db)\n            \n            return result\n            \n        except Exception as e:\n            logger.error(f\"Fast submission failed: {e}\")\n            return self._create_error_response(f'Execution error: {str(e)}')\n    \n    async def test_query(\n        self,\n        user_id: str,\n        problem_id: str,\n        query: str,\n        db: Session,\n        include_hidden_tests: bool = False\n    ) -> Dict[str, Any]:\n        \"\"\"Ultra-fast query testing\"\"\"\n        try:\n            # Fast security check\n            is_safe, security_errors = self._security_checker.is_safe(query)\n            if not is_safe:\n                return {\n                    'success': False,\n                    'feedback': security_errors,\n                    'security_violations': security_errors,\n                    'test_results': []\n                }\n            \n            # Get sandbox fast\n            sandbox = self._get_sandbox_fast(user_id, problem_id, db)\n            if not sandbox:\n                return {\n                    'success': False,\n                    'feedback': ['Failed to create execution sandbox'],\n                    'test_results': []\n                }\n            \n            # Execute with minimal validation\n            query_result = await self._execute_query_fast(sandbox, query)\n            \n            if not query_result.get('success'):\n                return {\n                    'success': False,\n                    'feedback': [query_result.get('error', 'Query execution failed')],\n                    'test_results': []\n                }\n            \n            # Minimal test validation\n            test_results = await self._validate_minimal(sandbox, problem_id, query, query_result.get('results', []), db)\n            \n            return {\n                'success': True,\n                'feedback': self._generate_feedback_fast(test_results),\n                'test_results': test_results,\n                'security_warnings': [],\n                'query_result': {\n                    'rows_returned': len(query_result.get('results', [])),\n                    'execution_time_ms': query_result.get('execution_time_ms', 0)\n                },\n                'execution_status': 'SUCCESS'\n            }\n            \n        except Exception as e:\n            logger.error(f\"Fast test failed: {e}\")\n            return {\n                'success': False,\n                'feedback': [f'Test execution error: {str(e)}'],\n                'test_results': []\n            }\n    \n    def _get_sandbox_fast(self, user_id: str, problem_id: str, db: Session) -> Optional[DuckDBSandbox]:\n        \"\"\"Ultra-fast sandbox retrieval with proper S3 data loading\"\"\"\n        try:\n            # Try existing sandbox first\n            sandbox = self.sandbox_manager.get_sandbox(user_id, problem_id)\n            if sandbox:\n                # Check if sandbox needs data reloading (from original logic)\n                problem = db.query(Problem.s3_data_source).filter(Problem.id == problem_id).first()\n                if problem and problem.s3_data_source:\n                    # Verify table exists\n                    table_info = sandbox.get_table_info()\n                    expected_table_name = problem.s3_data_source.get('table_name', 'problem_data')\n                    \n                    table_exists = any(\n                        table.get('name') == expected_table_name \n                        for table in table_info.get('tables', [])\n                    )\n                    \n                    if not table_exists:\n                        logger.info(f\"Reloading S3 data for existing sandbox - table {expected_table_name} not found\")\n                        # Run setup synchronously for speed\n                        loop = asyncio.new_event_loop()\n                        asyncio.set_event_loop(loop)\n                        try:\n                            setup_result = loop.run_until_complete(\n                                sandbox.setup_problem_data(\n                                    problem_id=problem_id,\n                                    s3_data_source=problem.s3_data_source\n                                )\n                            )\n                            if not setup_result.get('success', False):\n                                logger.error(f\"Failed to reload problem data: {setup_result.get('error')}\")\n                        finally:\n                            loop.close()\n                \n                return sandbox\n            \n            # Get problem info for new sandbox\n            problem = db.query(Problem.id, Problem.s3_data_source).filter(Problem.id == problem_id).first()\n            if not problem:\n                logger.error(f\"Problem {problem_id} not found\")\n                return None\n            \n            # Create sandbox synchronously for speed\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n            try:\n                sandbox = loop.run_until_complete(\n                    self.sandbox_manager.create_sandbox(user_id, problem_id)\n                )\n                \n                # Load S3 data if needed\n                if problem.s3_data_source:\n                    logger.info(f\"Loading S3 data for problem {problem_id}\")\n                    setup_result = loop.run_until_complete(\n                        sandbox.setup_problem_data(\n                            problem_id=problem_id,\n                            s3_data_source=problem.s3_data_source\n                        )\n                    )\n                    \n                    if not setup_result.get('success', False):\n                        logger.error(f\"Failed to load problem data: {setup_result.get('error')}\")\n                \n                return sandbox\n            finally:\n                loop.close()\n                \n        except Exception as e:\n            logger.error(f\"Fast sandbox creation failed: {e}\")\n            return None\n    \n    async def _execute_query_fast(self, sandbox: DuckDBSandbox, query: str) -> Dict[str, Any]:\n        \"\"\"Execute query with minimal overhead\"\"\"\n        try:\n            # Direct execution without complex timeout handling\n            result = sandbox.execute_query(query)\n            return result\n        except Exception as e:\n            return {\n                'success': False,\n                'error': str(e),\n                'execution_time_ms': 0\n            }\n    \n    async def _execute_minimal_validation(\n        self,\n        sandbox: DuckDBSandbox,\n        problem_id: str,\n        query: str,\n        db: Session\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Optimized validation that properly handles all test case types\"\"\"\n        try:\n            # Get problem with all needed fields for validation\n            problem = db.query(Problem).filter(Problem.id == problem_id).first()\n            \n            if not problem:\n                return [{\n                    'test_case_id': 'error',\n                    'test_case_name': 'Problem Not Found',\n                    'is_hidden': False,\n                    'is_correct': False,\n                    'score': 0.0,\n                    'feedback': ['Problem not found in database'],\n                    'execution_time_ms': 0,\n                    'execution_status': ExecutionStatus.ERROR.value,\n                    'validation_details': {}\n                }]\n            \n            # Check if this is an enhanced S3-based question with hash validation (fastest path)\n            if problem.expected_hash and problem.s3_data_source:\n                logger.info(f\"Using S3 hash validation for problem {problem_id}\")\n                return await self._hash_validation_fast(problem, sandbox, query)\n            \n            # Check for traditional test cases\n            test_cases = db.query(TestCase).filter(\n                TestCase.problem_id == problem_id\n            ).order_by(TestCase.order_index).all()\n            \n            if test_cases:\n                # Execute against test cases (optimized)\n                return await self._execute_test_cases_fast(sandbox, query, test_cases)\n            \n            # Check if problem has S3 solution source for verification\n            if hasattr(problem, 'solution_source') and problem.solution_source == 's3' and hasattr(problem, 's3_solution_source') and problem.s3_solution_source:\n                # Execute query and verify with S3 solution\n                result = await self._execute_query_fast(sandbox, query)\n                \n                if result.get('success'):\n                    user_results = result.get('results', [])\n                    s3_verification = await self._verify_with_s3_solution_fast(\n                        sandbox, problem, query, user_results\n                    )\n                    return s3_verification\n                else:\n                    return [{\n                        'test_case_id': 's3_verification',\n                        'test_case_name': 'S3 Solution Verification',\n                        'is_hidden': False,\n                        'is_correct': False,\n                        'score': 0.0,\n                        'feedback': [result.get('error', 'Query execution failed')],\n                        'execution_time_ms': 0\n                    }]\n            \n            # Check for expected output in problem question\n            if problem.question and isinstance(problem.question, dict):\n                expected_output = problem.question.get('expectedOutput', [])\n                if expected_output:\n                    result = await self._execute_query_fast(sandbox, query)\n                    \n                    if result.get('success'):\n                        user_results = result.get('results', [])\n                        \n                        # Fast comparison\n                        is_correct = self._compare_results_fast(user_results, expected_output)\n                        \n                        return [{\n                            'test_case_id': f\"{problem_id}_expected_output\",\n                            'test_case_name': 'Expected Output Check',\n                            'is_hidden': False,\n                            'is_correct': is_correct,\n                            'score': 100.0 if is_correct else 0.0,\n                            'feedback': ['Results match expected output'] if is_correct else ['Results differ from expected output'],\n                            'execution_time_ms': result.get('execution_time_ms', 0),\n                            'user_output': user_results,\n                            'expected_output': expected_output,\n                            'output_matches': is_correct\n                        }]\n                    else:\n                        return [{\n                            'test_case_id': f\"{problem_id}_expected_output\",\n                            'test_case_name': 'Expected Output Check',\n                            'is_hidden': False,\n                            'is_correct': False,\n                            'score': 0.0,\n                            'feedback': [result.get('error', 'Query execution failed')],\n                            'execution_time_ms': 0\n                        }]\n            \n            # Fallback: just execute query and return success\n            result = await self._execute_query_fast(sandbox, query)\n            \n            if result.get('success'):\n                return [{\n                    'test_case_id': 'basic_execution',\n                    'test_case_name': 'Query Execution',\n                    'is_hidden': False,\n                    'is_correct': True,\n                    'score': 100.0,\n                    'feedback': ['Query executed successfully'],\n                    'execution_time_ms': result.get('execution_time_ms', 0)\n                }]\n            else:\n                return [{\n                    'test_case_id': 'execution_error',\n                    'test_case_name': 'Query Execution',\n                    'is_hidden': False,\n                    'is_correct': False,\n                    'score': 0.0,\n                    'feedback': [result.get('error', 'Query failed')],\n                    'execution_time_ms': 0\n                }]\n            \n        except Exception as e:\n            logger.error(f\"Validation failed: {e}\")\n            return [{\n                'test_case_id': 'validation_error',\n                'test_case_name': 'Validation Error',\n                'is_hidden': False,\n                'is_correct': False,\n                'score': 0.0,\n                'feedback': [f'Validation error: {str(e)}'],\n                'execution_time_ms': 0\n            }]\n    \n    async def _execute_test_cases_fast(\n        self,\n        sandbox: DuckDBSandbox,\n        query: str,\n        test_cases: List[TestCase]\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Fast execution against traditional test cases\"\"\"\n        results = []\n        \n        for test_case in test_cases:\n            try:\n                # Execute query\n                result = await self._execute_query_fast(sandbox, query)\n                \n                if result.get('success'):\n                    user_output = result.get('results', [])\n                    expected_output = test_case.expected_output or []\n                    \n                    # Handle S3 expected output source if exists\n                    if test_case.expected_output_source:\n                        try:\n                            s3_config = test_case.expected_output_source\n                            if s3_config.get('bucket') and s3_config.get('key'):\n                                # Fetch from S3\n                                from .s3_service import s3_service\n                                from .schemas import S3AnswerSource\n                                \n                                s3_answer_source = S3AnswerSource(**s3_config)\n                                cache_result = s3_service.fetch_answer_file(\n                                    bucket=s3_answer_source.bucket,\n                                    key=s3_answer_source.key,\n                                    format=s3_answer_source.format,\n                                    etag=getattr(s3_answer_source, 'etag', None)\n                                )\n                                expected_output = cache_result.data\n                                logger.info(f\"Fetched {len(expected_output)} expected rows from S3\")\n                        except Exception as e:\n                            logger.error(f\"Failed to fetch S3 expected output: {e}\")\n                            # Continue with fallback expected_output\n                    \n                    # Fast comparison\n                    is_correct = self._compare_results_fast(user_output, expected_output)\n                    \n                    results.append({\n                        'test_case_id': test_case.id,\n                        'test_case_name': test_case.name,\n                        'is_hidden': test_case.is_hidden,\n                        'is_correct': is_correct,\n                        'score': 100.0 if is_correct else 0.0,\n                        'feedback': ['Results match expected output'] if is_correct else ['Results differ from expected output'],\n                        'execution_time_ms': result.get('execution_time_ms', 0),\n                        'execution_status': ExecutionStatus.SUCCESS.value,\n                        'user_output': user_output,\n                        'expected_output': expected_output,\n                        'output_matches': is_correct\n                    })\n                else:\n                    results.append({\n                        'test_case_id': test_case.id,\n                        'test_case_name': test_case.name,\n                        'is_hidden': test_case.is_hidden,\n                        'is_correct': False,\n                        'score': 0.0,\n                        'feedback': [result.get('error', 'Query execution failed')],\n                        'execution_time_ms': 0,\n                        'execution_status': ExecutionStatus.ERROR.value\n                    })\n                    \n            except Exception as e:\n                logger.error(f\"Test case execution failed: {e}\")\n                results.append({\n                    'test_case_id': test_case.id,\n                    'test_case_name': test_case.name,\n                    'is_hidden': test_case.is_hidden,\n                    'is_correct': False,\n                    'score': 0.0,\n                    'feedback': [f'Test execution error: {str(e)}'],\n                    'execution_time_ms': 0,\n                    'execution_status': ExecutionStatus.ERROR.value\n                })\n        \n        return results\n    \n    async def _hash_validation_fast(\n        self,\n        problem: Problem,\n        sandbox: DuckDBSandbox,\n        query: str\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Fast hash-based validation\"\"\"\n        try:\n            # Execute user query\n            result = await self._execute_query_fast(sandbox, query)\n            \n            if not result.get('success'):\n                return [{\n                    'test_case_id': 'hash_validation',\n                    'test_case_name': 'Hash Validation',\n                    'is_hidden': False,\n                    'is_correct': False,\n                    'score': 0.0,\n                    'feedback': [result.get('error', 'Query execution failed')],\n                    'execution_time_ms': 0\n                }]\n            \n            user_results = result.get('results', [])\n            \n            # Fast hash comparison\n            user_hash = self._compute_result_hash_fast(user_results)\n            expected_hash = problem.expected_hash\n            \n            is_correct = user_hash == expected_hash\n            \n            return [{\n                'test_case_id': 'hash_validation',\n                'test_case_name': 'Result Hash Validation',\n                'is_hidden': False,\n                'is_correct': is_correct,\n                'score': 100.0 if is_correct else 0.0,\n                'feedback': ['Query results match expected pattern'] if is_correct else ['Query results do not match expected pattern'],\n                'execution_time_ms': result.get('execution_time_ms', 0),\n                'user_hash': user_hash,\n                'expected_hash': expected_hash,\n                'hash_matches': is_correct\n            }]\n            \n        except Exception as e:\n            logger.error(f\"Hash validation failed: {e}\")\n            return [{\n                'test_case_id': 'hash_validation_error',\n                'test_case_name': 'Hash Validation Error',\n                'is_hidden': False,\n                'is_correct': False,\n                'score': 0.0,\n                'feedback': [f'Hash validation error: {str(e)}'],\n                'execution_time_ms': 0\n            }]\n    \n    async def _verify_with_s3_solution_fast(\n        self,\n        sandbox: DuckDBSandbox,\n        problem: Problem,\n        query: str,\n        user_results: List[Dict[str, Any]]\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Fast S3 solution verification\"\"\"\n        try:\n            from .s3_service import s3_service\n            \n            s3_solution_data = problem.s3_solution_source\n            bucket = s3_solution_data.get('bucket')\n            solution_key = s3_solution_data.get('key')\n            \n            # Fetch expected results from S3\n            validation_result = s3_service.validate_dataset_file(bucket, solution_key, 'solution')\n            if not validation_result.get('is_valid'):\n                return [{\n                    'test_case_id': 's3_solution_verification',\n                    'test_case_name': 'S3 Solution Verification',\n                    'is_hidden': False,\n                    'is_correct': False,\n                    'score': 0.0,\n                    'feedback': ['Failed to load expected results from S3'],\n                    'execution_time_ms': 0\n                }]\n            \n            expected_results = validation_result.get('sample_data', [])\n            \n            # Fast comparison\n            is_correct = self._compare_results_fast(user_results, expected_results)\n            \n            return [{\n                'test_case_id': 's3_solution_verification',\n                'test_case_name': 'S3 Solution Verification',\n                'is_hidden': False,\n                'is_correct': is_correct,\n                'score': 100.0 if is_correct else 0.0,\n                'feedback': ['Results match S3 solution'] if is_correct else ['Results differ from S3 solution'],\n                'execution_time_ms': 0,\n                'user_output': user_results,\n                'expected_output': expected_results,\n                'output_matches': is_correct\n            }]\n            \n        except Exception as e:\n            logger.error(f\"S3 solution verification failed: {e}\")\n            return [{\n                'test_case_id': 's3_solution_error',\n                'test_case_name': 'S3 Solution Error',\n                'is_hidden': False,\n                'is_correct': False,\n                'score': 0.0,\n                'feedback': [f'S3 verification error: {str(e)}'],\n                'execution_time_ms': 0\n            }]\n    \n    async def _validate_minimal(\n        self,\n        sandbox: DuckDBSandbox,\n        problem_id: str,\n        query: str,\n        query_results: List[Dict[str, Any]],\n        db: Session\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Fast minimal validation for test queries\"\"\"\n        try:\n            # Just return basic success for test queries\n            return [{\n                'test_case_id': 'test_execution',\n                'test_case_name': 'Query Test',\n                'is_hidden': False,\n                'is_correct': True,\n                'score': 100.0,\n                'feedback': ['Query executed successfully'],\n                'execution_time_ms': 0\n            }]\n            \n        except Exception as e:\n            logger.error(f\"Minimal validation failed: {e}\")\n            return [{\n                'test_case_id': 'test_error',\n                'test_case_name': 'Query Test Error',\n                'is_hidden': False,\n                'is_correct': False,\n                'score': 0.0,\n                'feedback': [f'Test error: {str(e)}'],\n                'execution_time_ms': 0\n            }]\n    \n    def _compare_results_fast(self, user_results: List[Dict], expected_results: List[Dict]) -> bool:\n        \"\"\"Ultra-fast result comparison\"\"\"\n        try:\n            if len(user_results) != len(expected_results):\n                return False\n            \n            # Quick comparison for small datasets\n            if len(user_results) <= 100:\n                return user_results == expected_results\n            \n            # Sample comparison for large datasets\n            sample_size = min(50, len(user_results))\n            for i in range(0, len(user_results), len(user_results) // sample_size):\n                if i < len(user_results) and i < len(expected_results):\n                    if user_results[i] != expected_results[i]:\n                        return False\n            \n            return True\n            \n        except Exception as e:\n            logger.error(f\"Fast comparison failed: {e}\")\n            return False\n    \n    def _compute_result_hash_fast(self, results: List[Dict[str, Any]]) -> str:\n        \"\"\"Fast hash computation for results\"\"\"\n        try:\n            # Simple hash based on result structure\n            content = json.dumps(results, sort_keys=True, default=str)\n            return hashlib.md5(content.encode()).hexdigest()\n        except Exception as e:\n            logger.error(f\"Hash computation failed: {e}\")\n            return \"error_hash\"\n    \n    def _calculate_score_fast(self, test_results: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"Fast scoring calculation\"\"\"\n        if not test_results:\n            return {\n                'overall_score': 0.0,\n                'passed_count': 0,\n                'total_count': 0,\n                'avg_execution_time': 0,\n                'max_execution_time': 0,\n                'feedback': ['No test results available']\n            }\n        \n        passed_count = sum(1 for result in test_results if result.get('is_correct', False))\n        total_count = len(test_results)\n        overall_score = (passed_count / total_count) * 100.0 if total_count > 0 else 0.0\n        \n        execution_times = [result.get('execution_time_ms', 0) for result in test_results]\n        avg_execution_time = sum(execution_times) / len(execution_times) if execution_times else 0\n        max_execution_time = max(execution_times) if execution_times else 0\n        \n        feedback = []\n        if passed_count == total_count:\n            feedback.append('All test cases passed!')\n        elif passed_count > 0:\n            feedback.append(f'{passed_count} of {total_count} test cases passed')\n        else:\n            feedback.append('No test cases passed')\n        \n        return {\n            'overall_score': overall_score,\n            'passed_count': passed_count,\n            'total_count': total_count,\n            'avg_execution_time': avg_execution_time,\n            'max_execution_time': max_execution_time,\n            'feedback': feedback\n        }\n    \n    def _generate_feedback_fast(self, test_results: List[Dict[str, Any]]) -> List[str]:\n        \"\"\"Fast feedback generation\"\"\"\n        if not test_results:\n            return ['No test results available']\n        \n        feedback = []\n        for result in test_results:\n            if result.get('feedback'):\n                feedback.extend(result['feedback'])\n        \n        return feedback if feedback else ['Query executed']\n    \n    def _create_error_response(self, error_message: str) -> Dict[str, Any]:\n        \"\"\"Fast error response creation\"\"\"\n        return {\n            'success': False,\n            'is_correct': False,\n            'score': 0.0,\n            'feedback': [error_message],\n            'test_results': [],\n            'passed_tests': 0,\n            'total_tests': 0,\n            'execution_stats': {\n                'avg_time_ms': 0,\n                'max_time_ms': 0,\n                'total_time_ms': 0\n            },\n            'security_warnings': [error_message],\n            'submission_id': None\n        }\n    \n    def _create_submission_fast(\n        self,\n        user_id: str,\n        problem_id: str,\n        query: str,\n        cached_result: Dict[str, Any],\n        db: Session\n    ) -> Submission:\n        \"\"\"Fast submission creation from cache\"\"\"\n        submission = Submission(\n            user_id=user_id,\n            problem_id=problem_id,\n            query=query,\n            is_correct=cached_result.get('is_correct', False),\n            execution_time=cached_result.get('execution_stats', {}).get('avg_time_ms', 0)\n        )\n        \n        db.add(submission)\n        db.commit()\n        db.refresh(submission)\n        \n        return submission\n    \n    def _update_user_progress_background(self, user_id: str, problem_id: str, db: Session):\n        \"\"\"Background user progress update\"\"\"\n        try:\n            # Simple fire-and-forget progress update\n            self._thread_pool.submit(self._update_user_progress_sync, user_id, problem_id, db)\n        except Exception as e:\n            logger.warning(f\"Background progress update failed: {e}\")\n    \n    def _update_user_progress_sync(self, user_id: str, problem_id: str, db: Session):\n        \"\"\"Synchronous user progress update\"\"\"\n        try:\n            # Check if this is first time solving this problem\n            existing_correct = db.query(Submission).filter(\n                Submission.user_id == user_id,\n                Submission.problem_id == problem_id,\n                Submission.is_correct == True\n            ).first()\n            \n            if not existing_correct:\n                # Update user's solved count\n                user = db.query(User).filter(User.id == user_id).first()\n                if user:\n                    user.problems_solved = (user.problems_solved or 0) + 1\n                    db.commit()\n                    \n        except Exception as e:\n            logger.error(f\"User progress update failed: {e}\")\n    \n    async def get_user_progress(self, user_id: str, db: Session) -> Dict[str, Any]:\n        \"\"\"Fast user progress retrieval\"\"\"\n        try:\n            user = db.query(User).filter(User.id == user_id).first()\n            if not user:\n                return {\n                    'success': False,\n                    'error': 'User not found'\n                }\n            \n            # Basic progress stats\n            total_submissions = db.query(Submission).filter(Submission.user_id == user_id).count()\n            correct_submissions = db.query(Submission).filter(\n                Submission.user_id == user_id,\n                Submission.is_correct == True\n            ).count()\n            \n            return {\n                'success': True,\n                'user_id': user_id,\n                'problems_solved': user.problems_solved or 0,\n                'total_submissions': total_submissions,\n                'correct_submissions': correct_submissions,\n                'accuracy': (correct_submissions / total_submissions * 100) if total_submissions > 0 else 0\n            }\n            \n        except Exception as e:\n            logger.error(f\"User progress retrieval failed: {e}\")\n            return {\n                'success': False,\n                'error': f'Progress retrieval failed: {str(e)}'\n            }\n\n# Global secure executor instance\nsecure_executor = SecureQueryExecutor()","size_bytes":36934},"client/src/contexts/AdminContext.tsx":{"content":"import { createContext, useContext, useReducer, ReactNode } from 'react';\nimport { useToast } from '@/hooks/use-toast';\n\n// Types and interfaces\nexport interface TableColumn {\n  name: string;\n  type: string;\n  description: string;\n}\n\nexport interface TableData {\n  name: string;\n  columns: TableColumn[];\n  sample_data: Record<string, any>[];\n}\n\nexport interface QuestionData {\n  description: string;\n  tables: TableData[];\n  expectedOutput: Record<string, any>[];\n  s3_data_source?: S3DatasetSource;\n}\n\nexport interface ProblemDraft {\n  title: string;\n  difficulty: string;\n  question: QuestionData;\n  s3_datasets?: S3DatasetSource[];  // Multiple S3 dataset sources\n  tags: string[];\n  company: string;\n  hints: string[];\n  premium: boolean;\n  topic_id: string;\n  expectedDisplay?: Record<string, any>[];  // Display output for users (not validation)\n}\n\nexport interface SchemaInfo {\n  problem_structure: Record<string, any>;\n  example_problem: ProblemDraft;\n  difficulty_options: string[];\n  available_topics: { id: string; name: string }[];\n}\n\nexport interface S3DatasetSource {\n  bucket: string;\n  key: string;\n  table_name: string;\n  description: string;\n}\n\nexport interface S3DatasetValidationResponse {\n  success: boolean;\n  message?: string;\n  error?: string;\n  table_schema?: Array<{column: string; type: string}>;\n  sample_data?: Record<string, any>[];\n  row_count?: number;\n  etag?: string;\n  table_name?: string;\n  data_source?: string;\n}\n\nexport interface S3ValidatedDataset {\n  bucket: string;\n  key: string;\n  table_name: string;\n  description: string;\n  etag: string;\n  table_schema: Array<{column: string; type: string}>;\n  sample_data: Record<string, any>[];\n  row_count: number;\n}\n\nexport interface MultiTableValidationResponse {\n  success: boolean;\n  message?: string;\n  error?: string;\n  validated_datasets?: S3ValidatedDataset[];\n  total_tables?: number;\n  total_rows?: number;\n}\n\nexport interface SolutionVerificationResult {\n  verified: boolean;\n  source: 'neon';  // Only Neon supported - S3 solutions deprecated\n  message?: string;\n  test_case_count?: number;\n}\n\n// State interface\ninterface AdminState {\n  // Authentication\n  adminKey: string;\n  isAuthenticated: boolean;\n  schemaInfo: SchemaInfo | null;\n  loading: boolean;\n\n  // Problem Draft\n  problemDraft: ProblemDraft;\n  selectedProblemId: string; // For verifying existing problems\n\n  // Single S3 validation\n  s3Source: S3DatasetSource;\n  s3Validation: S3DatasetValidationResponse | null;\n  isValidatingS3: boolean;\n\n  // Multi S3 validation  \n  multiTableDatasets: Array<{\n    bucket: string;\n    key: string;\n    table_name: string;\n    description: string;\n  }>;\n  multiTableValidation: MultiTableValidationResponse | null;\n  isValidatingMultiTable: boolean;\n\n  // Unified dataset management - supports both single and multiple\n  datasets: Array<{\n    bucket: string;\n    key: string;\n    table_name: string;\n    description: string;\n  }>;\n  datasetValidation: MultiTableValidationResponse | null;\n  isValidatingDatasets: boolean;\n\n  // Solution verification\n  solutionVerification: SolutionVerificationResult | null;\n\n  // UI state\n  activeTab: string;\n}\n\n// Actions\ntype AdminAction = \n  | { type: 'SET_ADMIN_KEY'; payload: string }\n  | { type: 'SET_AUTHENTICATED'; payload: boolean }\n  | { type: 'SET_SCHEMA_INFO'; payload: SchemaInfo | null }\n  | { type: 'SET_LOADING'; payload: boolean }\n  | { type: 'UPDATE_PROBLEM_DRAFT'; payload: Partial<ProblemDraft> }\n  | { type: 'RESET_PROBLEM_DRAFT' }\n  | { type: 'SET_SELECTED_PROBLEM_ID'; payload: string }\n  | { type: 'SET_S3_SOURCE'; payload: S3DatasetSource }\n  | { type: 'SET_S3_VALIDATION'; payload: S3DatasetValidationResponse | null }\n  | { type: 'SET_VALIDATING_S3'; payload: boolean }\n  | { type: 'SET_MULTI_TABLE_DATASETS'; payload: AdminState['multiTableDatasets'] }\n  | { type: 'SET_MULTI_TABLE_VALIDATION'; payload: MultiTableValidationResponse | null }\n  | { type: 'SET_VALIDATING_MULTI_TABLE'; payload: boolean }\n  | { type: 'SET_DATASETS'; payload: AdminState['datasets'] }\n  | { type: 'SET_DATASET_VALIDATION'; payload: MultiTableValidationResponse | null }\n  | { type: 'SET_VALIDATING_DATASETS'; payload: boolean }\n  | { type: 'SET_SOLUTION_VERIFICATION'; payload: SolutionVerificationResult | null }\n  | { type: 'SET_ACTIVE_TAB'; payload: string }\n  | { type: 'APPLY_SINGLE_VALIDATION_TO_DRAFT' }\n  | { type: 'APPLY_MULTI_VALIDATION_TO_DRAFT' }\n  | { type: 'APPLY_UNIFIED_VALIDATION_TO_DRAFT' };\n\n// Initial state\nconst initialState: AdminState = {\n  adminKey: '',\n  isAuthenticated: false,\n  schemaInfo: null,\n  loading: false,\n  problemDraft: {\n    title: '',\n    difficulty: 'Easy',\n    question: {\n      description: '',\n      tables: [],\n      expectedOutput: []\n    },\n    tags: [],\n    company: '',\n    hints: [],\n    premium: false,\n    topic_id: ''\n  },\n  selectedProblemId: '',\n  s3Source: {\n    bucket: '',\n    key: '',\n    table_name: 'problem_data',\n    description: ''\n  },\n  s3Validation: null,\n  isValidatingS3: false,\n  multiTableDatasets: [],\n  multiTableValidation: null,\n  isValidatingMultiTable: false,\n  datasets: [],\n  datasetValidation: null,\n  isValidatingDatasets: false,\n  solutionVerification: null,\n  activeTab: 'create'\n};\n\n// Reducer\nfunction adminReducer(state: AdminState, action: AdminAction): AdminState {\n  switch (action.type) {\n    case 'SET_ADMIN_KEY':\n      return { ...state, adminKey: action.payload };\n    case 'SET_AUTHENTICATED':\n      return { ...state, isAuthenticated: action.payload };\n    case 'SET_SCHEMA_INFO':\n      return { ...state, schemaInfo: action.payload };\n    case 'SET_LOADING':\n      return { ...state, loading: action.payload };\n    case 'UPDATE_PROBLEM_DRAFT':\n      return { ...state, problemDraft: { ...state.problemDraft, ...action.payload } };\n    case 'RESET_PROBLEM_DRAFT':\n      return { ...state, problemDraft: state.schemaInfo?.example_problem || initialState.problemDraft };\n    case 'SET_SELECTED_PROBLEM_ID':\n      return { ...state, selectedProblemId: action.payload };\n    case 'SET_S3_SOURCE':\n      return { ...state, s3Source: action.payload };\n    case 'SET_S3_VALIDATION':\n      return { ...state, s3Validation: action.payload };\n    case 'SET_VALIDATING_S3':\n      return { ...state, isValidatingS3: action.payload };\n    case 'SET_MULTI_TABLE_DATASETS':\n      return { ...state, multiTableDatasets: action.payload };\n    case 'SET_MULTI_TABLE_VALIDATION':\n      return { ...state, multiTableValidation: action.payload };\n    case 'SET_VALIDATING_MULTI_TABLE':\n      return { ...state, isValidatingMultiTable: action.payload };\n    case 'SET_DATASETS':\n      return { ...state, datasets: action.payload };\n    case 'SET_DATASET_VALIDATION':\n      return { ...state, datasetValidation: action.payload };\n    case 'SET_VALIDATING_DATASETS':\n      return { ...state, isValidatingDatasets: action.payload };\n    case 'SET_SOLUTION_VERIFICATION':\n      return { ...state, solutionVerification: action.payload };\n    case 'SET_ACTIVE_TAB':\n      return { ...state, activeTab: action.payload };\n    case 'APPLY_SINGLE_VALIDATION_TO_DRAFT':\n      if (state.s3Validation?.success && state.s3Validation.table_schema) {\n        const suggestedTable: TableData = {\n          name: state.s3Validation.table_name || state.s3Source.table_name,\n          columns: state.s3Validation.table_schema.map(col => ({\n            name: col.column,\n            type: col.type,\n            description: `${col.column} column (${col.type})`\n          })),\n          sample_data: state.s3Validation.sample_data || []\n        };\n        return {\n          ...state,\n          problemDraft: {\n            ...state.problemDraft,\n            question: {\n              ...state.problemDraft.question,\n              tables: [suggestedTable],\n              s3_data_source: state.s3Source\n            }\n          }\n        };\n      }\n      return state;\n    case 'APPLY_MULTI_VALIDATION_TO_DRAFT':\n      if (state.multiTableValidation?.success && state.multiTableValidation.validated_datasets) {\n        const tables = state.multiTableValidation.validated_datasets.map((dataset) => ({\n          name: dataset.table_name,\n          columns: (dataset.table_schema || []).map((col) => ({\n            name: col.column,\n            type: col.type,\n            description: `${col.column} column (${col.type})`\n          })),\n          sample_data: dataset.sample_data || []\n        }));\n        return {\n          ...state,\n          problemDraft: {\n            ...state.problemDraft,\n            question: {\n              ...state.problemDraft.question,\n              tables: tables\n            }\n          }\n        };\n      }\n      return state;\n    case 'APPLY_UNIFIED_VALIDATION_TO_DRAFT':\n      if (state.datasetValidation?.success && state.datasetValidation.validated_datasets) {\n        const tables = state.datasetValidation.validated_datasets.map((dataset) => ({\n          name: dataset.table_name,\n          columns: (dataset.table_schema || []).map((col) => ({\n            name: col.column,\n            type: col.type,\n            description: `${col.column} column (${col.type})`\n          })),\n          sample_data: dataset.sample_data || []\n        }));\n        \n        // Extract S3 datasets info from validated datasets\n        const s3_datasets = state.datasets.map((dataset) => ({\n          bucket: dataset.bucket,\n          key: dataset.key,\n          table_name: dataset.table_name,\n          description: dataset.description || ''\n        }));\n        \n        return {\n          ...state,\n          problemDraft: {\n            ...state.problemDraft,\n            s3_datasets: s3_datasets,  // Include S3 datasets info\n            question: {\n              ...state.problemDraft.question,\n              tables: tables,\n              s3DataSources: state.datasets // Store the datasets for backend submission (uses camelCase alias)\n            }\n          }\n        };\n      }\n      return state;\n    default:\n      return state;\n  }\n}\n\n// Context\ninterface AdminContextType {\n  state: AdminState;\n  dispatch: React.Dispatch<AdminAction>;\n  actions: {\n    // Setter actions\n    setS3Source: (source: S3DatasetSource) => void;\n    setMultiTableDatasets: (datasets: AdminState['multiTableDatasets']) => void;\n    setDatasets: (datasets: AdminState['datasets']) => void;\n    setActiveTab: (tab: string) => void;\n    \n    // Core actions\n    authenticate: (key: string) => Promise<void>;\n    validateS3Dataset: () => Promise<void>;\n    validateMultiTableDatasets: (solutionPath: string) => Promise<void>;\n    validateDatasets: (solutionPath: string) => Promise<void>;\n    setSolutionType: (source: 'neon') => Promise<void>;\n    setSolutionVerification: (verification: SolutionVerificationResult) => void;\n    setSelectedProblemId: (problemId: string) => void;\n    verifySolution: (source: 'neon') => Promise<void>;\n    applyValidationToDraft: (type: 'single' | 'multi' | 'unified') => void;\n    resetDraft: () => void;\n    updateDraft: (updates: Partial<ProblemDraft>) => void;\n  };\n}\n\nconst AdminContext = createContext<AdminContextType | undefined>(undefined);\n\n// Provider component\nexport function AdminProvider({ children }: { children: ReactNode }) {\n  const [state, dispatch] = useReducer(adminReducer, initialState);\n  const { toast } = useToast();\n\n  const actions = {\n    // Setter actions  \n    setS3Source: (source: S3DatasetSource) => {\n      dispatch({ type: 'SET_S3_SOURCE', payload: source });\n    },\n\n    setMultiTableDatasets: (datasets: AdminState['multiTableDatasets']) => {\n      dispatch({ type: 'SET_MULTI_TABLE_DATASETS', payload: datasets });\n    },\n\n    setDatasets: (datasets: AdminState['datasets']) => {\n      dispatch({ type: 'SET_DATASETS', payload: datasets });\n    },\n\n    setActiveTab: (tab: string) => {\n      dispatch({ type: 'SET_ACTIVE_TAB', payload: tab });\n    },\n\n    setSelectedProblemId: (problemId: string) => {\n      dispatch({ type: 'SET_SELECTED_PROBLEM_ID', payload: problemId });\n    },\n\n    setSolutionVerification: (verification: SolutionVerificationResult) => {\n      dispatch({ type: 'SET_SOLUTION_VERIFICATION', payload: verification });\n    },\n\n    setSolutionType: async (source: 'neon') => {\n      // For Neon solutions, actually verify they exist instead of auto-verifying\n      if (source === 'neon') {\n        try {\n          dispatch({ type: 'SET_SOLUTION_VERIFICATION', payload: null });\n          \n          // Make API call to verify Neon solution\n          const response = await fetch('/api/admin/verify-neon-solution', {\n            method: 'POST',\n            headers: {\n              'Content-Type': 'application/json',\n              'X-Admin-Key': state.adminKey\n            },\n            body: JSON.stringify({\n              problem_id: state.selectedProblemId\n            })\n          });\n          \n          if (!response.ok) {\n            throw new Error(`Failed to verify solution: ${response.statusText}`);\n          }\n          \n          const verificationResult = await response.json();\n          \n          dispatch({ \n            type: 'SET_SOLUTION_VERIFICATION', \n            payload: {\n              verified: verificationResult.verified,\n              source: verificationResult.source,\n              message: verificationResult.message,\n              test_case_count: verificationResult.test_case_count\n            }\n          });\n          \n        } catch (error) {\n          console.error('Failed to verify Neon solution:', error);\n          toast({\n            title: \"Verification Failed\",\n            description: `Failed to verify Neon solution: ${error instanceof Error ? error.message : String(error)}`,\n            variant: \"destructive\"\n          });\n          \n          // Set failed verification\n          dispatch({ \n            type: 'SET_SOLUTION_VERIFICATION', \n            payload: {\n              verified: false,\n              source: 'neon',\n              message: `Verification failed: ${error instanceof Error ? error.message : String(error)}`\n            }\n          });\n        }\n      }\n    },\n\n    authenticate: async (key: string) => {\n      if (!key.trim()) {\n        toast({\n          title: \"Error\",\n          description: \"Please enter the admin key\",\n          variant: \"destructive\",\n        });\n        return;\n      }\n\n      dispatch({ type: 'SET_LOADING', payload: true });\n      try {\n        const response = await fetch('/api/admin/schema-info', {\n          headers: {\n            'Authorization': `Bearer ${key}`,\n          },\n        });\n\n        if (response.ok) {\n          const schema = await response.json();\n          dispatch({ type: 'SET_SCHEMA_INFO', payload: schema });\n          dispatch({ type: 'SET_AUTHENTICATED', payload: true });\n          dispatch({ type: 'SET_ADMIN_KEY', payload: key });\n          dispatch({ type: 'UPDATE_PROBLEM_DRAFT', payload: schema.example_problem });\n          toast({\n            title: \"Success\",\n            description: \"Admin access granted!\",\n          });\n        } else {\n          toast({\n            title: \"Authentication Failed\",\n            description: \"Invalid admin key\",\n            variant: \"destructive\",\n          });\n        }\n      } catch (error) {\n        toast({\n          title: \"Error\",\n          description: \"Failed to authenticate\",\n          variant: \"destructive\",\n        });\n      } finally {\n        dispatch({ type: 'SET_LOADING', payload: false });\n      }\n    },\n\n    validateS3Dataset: async () => {\n      if (!state.s3Source.bucket.trim() || !state.s3Source.key.trim()) {\n        toast({\n          title: \"Validation Error\",\n          description: \"Both bucket and key are required\",\n          variant: \"destructive\",\n        });\n        return;\n      }\n\n      dispatch({ type: 'SET_VALIDATING_S3', payload: true });\n      dispatch({ type: 'SET_S3_VALIDATION', payload: null });\n\n      try {\n        const response = await fetch('/api/admin/validate-dataset-s3', {\n          method: 'POST',\n          headers: {\n            'Content-Type': 'application/json',\n            'Authorization': `Bearer ${state.adminKey}`,\n          },\n          body: JSON.stringify(state.s3Source),\n        });\n\n        const result = await response.json();\n        dispatch({ type: 'SET_S3_VALIDATION', payload: result });\n\n        if (result.success) {\n          toast({\n            title: \"Validation Success\",\n            description: `Found ${result.row_count?.toLocaleString()} rows with ${result.table_schema?.length} columns`,\n          });\n        } else {\n          toast({\n            title: \"Validation Failed\",\n            description: result.error || \"Unknown error occurred\",\n            variant: \"destructive\",\n          });\n        }\n      } catch (error) {\n        toast({\n          title: \"Error\",\n          description: \"Failed to validate S3 dataset\",\n          variant: \"destructive\",\n        });\n      } finally {\n        dispatch({ type: 'SET_VALIDATING_S3', payload: false });\n      }\n    },\n\n    validateMultiTableDatasets: async (solutionPath: string) => {\n      dispatch({ type: 'SET_VALIDATING_MULTI_TABLE', payload: true });\n      dispatch({ type: 'SET_MULTI_TABLE_VALIDATION', payload: null });\n\n      try {\n        const response = await fetch('/api/admin/validate-multitable-s3', {\n          method: 'POST',\n          headers: {\n            'Content-Type': 'application/json',\n            'Authorization': `Bearer ${state.adminKey}`,\n          },\n          body: JSON.stringify({\n            datasets: state.multiTableDatasets,\n            solution_path: solutionPath\n          }),\n        });\n\n        const result = await response.json();\n        dispatch({ type: 'SET_MULTI_TABLE_VALIDATION', payload: result });\n\n        if (result.success) {\n          toast({\n            title: \"Multi-table Validation Success\",\n            description: `Successfully validated ${result.validated_datasets?.length} datasets`,\n          });\n        } else {\n          toast({\n            title: \"Validation Failed\",\n            description: result.error || \"Unknown error occurred\",\n            variant: \"destructive\",\n          });\n        }\n      } catch (error) {\n        toast({\n          title: \"Error\",\n          description: \"Failed to validate multi-table datasets\",\n          variant: \"destructive\",\n        });\n      } finally {\n        dispatch({ type: 'SET_VALIDATING_MULTI_TABLE', payload: false });\n      }\n    },\n\n    validateDatasets: async (solutionPath: string) => {\n      dispatch({ type: 'SET_VALIDATING_DATASETS', payload: true });\n      dispatch({ type: 'SET_DATASET_VALIDATION', payload: null });\n\n      try {\n        const response = await fetch('/api/admin/validate-multitable-s3', {\n          method: 'POST',\n          headers: {\n            'Content-Type': 'application/json',\n            'Authorization': `Bearer ${state.adminKey}`,\n          },\n          body: JSON.stringify({\n            datasets: state.datasets,\n            solution_path: solutionPath\n          }),\n        });\n\n        const result = await response.json();\n        dispatch({ type: 'SET_DATASET_VALIDATION', payload: result });\n\n        if (result.success) {\n          toast({\n            title: \"Dataset Validation Success\",\n            description: `Successfully validated ${result.validated_datasets?.length} dataset(s)`,\n          });\n        } else {\n          toast({\n            title: \"Validation Failed\",\n            description: result.error || \"Unknown error occurred\",\n            variant: \"destructive\",\n          });\n        }\n      } catch (error) {\n        toast({\n          title: \"Error\",\n          description: \"Failed to validate datasets\",\n          variant: \"destructive\",\n        });\n      } finally {\n        dispatch({ type: 'SET_VALIDATING_DATASETS', payload: false });\n      }\n    },\n\n    verifySolution: async (source: 'neon') => {\n      try {\n        // For Neon, we just mark as verified since the solution will be in the database\n        dispatch({ type: 'SET_SOLUTION_VERIFICATION', payload: { verified: true, source } });\n        toast({\n          title: \"Solution Verified\",\n          description: \"Neon database solution verification completed\",\n        });\n      } catch (error) {\n        dispatch({ type: 'SET_SOLUTION_VERIFICATION', payload: { verified: false, source } });\n        toast({\n          title: \"Error\",\n          description: \"Failed to verify solution\",\n          variant: \"destructive\",\n        });\n      }\n    },\n\n    applyValidationToDraft: (type: 'single' | 'multi' | 'unified') => {\n      let hasValidData = false;\n      \n      if (type === 'single') {\n        hasValidData = state.s3Validation?.success && !!state.s3Validation.table_schema;\n        if (hasValidData) {\n          dispatch({ type: 'APPLY_SINGLE_VALIDATION_TO_DRAFT' });\n        }\n      } else if (type === 'multi') {\n        hasValidData = state.multiTableValidation?.success && !!state.multiTableValidation.validated_datasets?.length;\n        if (hasValidData) {\n          dispatch({ type: 'APPLY_MULTI_VALIDATION_TO_DRAFT' });\n        }\n      } else if (type === 'unified') {\n        hasValidData = state.datasetValidation?.success && !!state.datasetValidation.validated_datasets?.length;\n        if (hasValidData) {\n          dispatch({ type: 'APPLY_UNIFIED_VALIDATION_TO_DRAFT' });\n        }\n      }\n\n      if (hasValidData) {\n        dispatch({ type: 'SET_ACTIVE_TAB', payload: 'create' });\n        toast({\n          title: \"Applied to Draft\",\n          description: `${type === 'single' ? 'Dataset' : 'Datasets'} applied to question draft`,\n        });\n      } else {\n        toast({\n          title: \"No Data to Apply\",\n          description: `Please validate ${type === 'single' ? 'the dataset' : 'datasets'} first`,\n          variant: \"destructive\",\n        });\n      }\n    },\n\n    resetDraft: () => {\n      dispatch({ type: 'RESET_PROBLEM_DRAFT' });\n    },\n\n    updateDraft: (updates: Partial<ProblemDraft>) => {\n      dispatch({ type: 'UPDATE_PROBLEM_DRAFT', payload: updates });\n    }\n  };\n\n  return (\n    <AdminContext.Provider value={{ state, dispatch, actions }}>\n      {children}\n    </AdminContext.Provider>\n  );\n}\n\n// Hook to use the context\nexport function useAdmin() {\n  const context = useContext(AdminContext);\n  if (context === undefined) {\n    throw new Error('useAdmin must be used within an AdminProvider');\n  }\n  return context;\n}","size_bytes":22314},"client/src/pages/admin-panel-old.tsx":{"content":"// Backup of original admin panel - to be removed after refactoring is complete","size_bytes":79},"client/src/components/admin/CreateQuestionTab.tsx":{"content":"import { useState } from 'react';\nimport { useMutation } from '@tanstack/react-query';\nimport { Button } from '@/components/ui/button';\nimport { Input } from '@/components/ui/input';\nimport { Label } from '@/components/ui/label';\nimport { Textarea } from '@/components/ui/textarea';\nimport { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';\nimport { Badge } from '@/components/ui/badge';\nimport { Alert, AlertDescription } from '@/components/ui/alert';\nimport { Trash2, Plus, Info, Eye, EyeOff } from 'lucide-react';\nimport { useAdmin } from '@/contexts/AdminContext';\nimport { useToast } from '@/hooks/use-toast';\nimport { apiRequest, queryClient } from '@/lib/queryClient';\nimport { EnhancedTablePreview } from './EnhancedTablePreview';\n\nexport function CreateQuestionTab() {\n  const { state, actions } = useAdmin();\n  const { toast } = useToast();\n  const [tagInput, setTagInput] = useState('');\n  const [hintInput, setHintInput] = useState('');\n  const [masterSolutionJson, setMasterSolutionJson] = useState('[]');\n  const [showJsonPreview, setShowJsonPreview] = useState(false);\n  const [jsonValidationError, setJsonValidationError] = useState('');\n  const [solutionInputMode, setSolutionInputMode] = useState<'json' | 'table' | 'file'>('json');\n  const [uploadedFile, setUploadedFile] = useState<File | null>(null);\n  const [isUploading, setIsUploading] = useState(false);\n  const [uploadError, setUploadError] = useState('');\n  const [tableColumns, setTableColumns] = useState<Array<{name: string, type: string}>>([]);\n  const [tableRows, setTableRows] = useState<Array<Record<string, any>>>([]);\n  \n  // Expected Display state variables\n  const [expectedDisplayJson, setExpectedDisplayJson] = useState('[]');\n  const [showDisplayPreview, setShowDisplayPreview] = useState(false);\n  const [displayJsonValidationError, setDisplayJsonValidationError] = useState('');\n  const [displayInputMode, setDisplayInputMode] = useState<'json' | 'table'>('json');\n  const [displayTableColumns, setDisplayTableColumns] = useState<Array<{name: string, type: string}>>([]);\n  const [displayTableRows, setDisplayTableRows] = useState<Array<Record<string, any>>>([]);\n\n  const createProblemMutation = useMutation({\n    mutationFn: async (problemData: any) => {\n      // Use correct apiRequest signature: (method, url, data)\n      return await apiRequest('POST', '/api/admin/problems', {\n        ...problemData,\n        solution_source: state.solutionVerification?.source || 'neon',\n        // Remove s3_solution_source to avoid 422 errors\n      });\n    },\n    onSuccess: (result) => {\n      toast({\n        title: \"Success\",\n        description: `Problem \"${state.problemDraft.title}\" created successfully!`,\n      });\n      actions.resetDraft();\n      queryClient.invalidateQueries({ queryKey: ['/api/problems'] });\n    },\n    onError: (error: Error) => {\n      toast({\n        title: \"Error\",\n        description: error.message,\n        variant: \"destructive\",\n      });\n    }\n  });\n\n  const convertParquetMutation = useMutation({\n    mutationFn: async (file: File) => {\n      const formData = new FormData();\n      formData.append('file', file);\n      \n      // Use apiRequest and validate response in mutationFn for proper error handling\n      const response = await apiRequest('POST', '/api/admin/convert-parquet', formData);\n      const result = await response.json();\n      \n      // Validate response shape in mutationFn so errors go to onError\n      if (!result || !result.data || !Array.isArray(result.data)) {\n        throw new Error('Invalid response format from Parquet conversion');\n      }\n      \n      const rows = result.data;\n      \n      // Validate data size\n      if (rows.length === 0) {\n        throw new Error('Parquet file is empty - no data was converted');\n      }\n      \n      return result;\n    },\n    onSuccess: (result) => {\n      const rows = result.data;\n      const metadata = result.metadata || {};\n      \n      // Update the master solution with converted data\n      setMasterSolutionJson(JSON.stringify(rows, null, 2));\n      actions.updateDraft({ masterSolution: rows });\n      \n      // Switch back to JSON view to show the converted data\n      setSolutionInputMode('json');\n      \n      toast({\n        title: \"Success\",\n        description: `Parquet file converted successfully! ${rows.length} rows loaded (${metadata.columns?.length || 'unknown'} columns).`,\n      });\n      \n      // Clear the uploaded file\n      setUploadedFile(null);\n      setUploadError('');\n    },\n    onError: (error: Error) => {\n      setUploadError(error.message);\n      toast({\n        title: \"Error\",\n        description: error.message,\n        variant: \"destructive\",\n      });\n    }\n  });\n\n  const handleSubmit = () => {\n    try {\n      const masterSolution = solutionInputMode === 'json' \n        ? JSON.parse(masterSolutionJson) \n        : tableRows;\n      \n      const expectedDisplay = displayInputMode === 'json' \n        ? JSON.parse(expectedDisplayJson) \n        : displayTableRows;\n      \n      const problemData = {\n        ...state.problemDraft,\n        masterSolution, // Use the new master_solution field for validation\n        expectedDisplay, // Display output for users (not validation)\n        // Include s3_datasets if they exist at the top level\n        ...(state.problemDraft.s3_datasets && {\n          s3_datasets: state.problemDraft.s3_datasets\n        }),\n        question: {\n          ...state.problemDraft.question,\n          // Include s3_data_source if it exists in the question\n          ...(state.problemDraft.question.s3_data_source && {\n            s3_data_source: state.problemDraft.question.s3_data_source\n          })\n        }\n      };\n      \n      createProblemMutation.mutate(problemData);\n    } catch (error) {\n      toast({\n        title: \"Error\",\n        description: \"Invalid JSON in master solution or expected display\",\n        variant: \"destructive\",\n      });\n    }\n  };\n\n  // Validate JSON as user types\n  const handleJsonChange = (value: string) => {\n    setMasterSolutionJson(value);\n    \n    if (!value.trim()) {\n      setJsonValidationError('');\n      return;\n    }\n    \n    try {\n      JSON.parse(value);\n      setJsonValidationError('');\n    } catch (error) {\n      setJsonValidationError(error instanceof Error ? error.message : 'Invalid JSON');\n    }\n  };\n\n  // Parse JSON for preview\n  const getParsedJson = () => {\n    if (solutionInputMode === 'table') {\n      return tableRows;\n    }\n    try {\n      return JSON.parse(masterSolutionJson);\n    } catch {\n      return null;\n    }\n  };\n\n  // Helper functions for format conversion\n  const convertJsonToTable = (jsonData: any[]) => {\n    if (!Array.isArray(jsonData) || jsonData.length === 0) return;\n    \n    const columns = Object.keys(jsonData[0]).map(key => ({\n      name: key,\n      type: typeof jsonData[0][key] === 'number' ? 'number' : \n            typeof jsonData[0][key] === 'boolean' ? 'boolean' : 'text'\n    }));\n    \n    setTableColumns(columns);\n    setTableRows(jsonData);\n  };\n\n  const convertTableToJson = () => {\n    return JSON.stringify(tableRows, null, 2);\n  };\n\n  // Expected Display helper functions\n  const handleDisplayJsonChange = (value: string) => {\n    setExpectedDisplayJson(value);\n    \n    if (!value.trim()) {\n      setDisplayJsonValidationError('');\n      return;\n    }\n    \n    try {\n      JSON.parse(value);\n      setDisplayJsonValidationError('');\n    } catch (error) {\n      setDisplayJsonValidationError(error instanceof Error ? error.message : 'Invalid JSON');\n    }\n  };\n\n  const getParsedDisplayJson = () => {\n    if (displayInputMode === 'table') {\n      return displayTableRows;\n    }\n    try {\n      return JSON.parse(expectedDisplayJson);\n    } catch {\n      return null;\n    }\n  };\n\n  const convertDisplayJsonToTable = (jsonData: any[]) => {\n    if (!Array.isArray(jsonData) || jsonData.length === 0) return;\n    \n    const columns = Object.keys(jsonData[0]).map(key => ({\n      name: key,\n      type: typeof jsonData[0][key] === 'number' ? 'number' : \n            typeof jsonData[0][key] === 'boolean' ? 'boolean' : 'text'\n    }));\n    \n    setDisplayTableColumns(columns);\n    setDisplayTableRows(jsonData);\n  };\n\n  const convertDisplayTableToJson = () => {\n    return JSON.stringify(displayTableRows, null, 2);\n  };\n\n  const addTag = () => {\n    if (tagInput.trim() && !state.problemDraft.tags.includes(tagInput.trim())) {\n      actions.updateDraft({\n        tags: [...state.problemDraft.tags, tagInput.trim()]\n      });\n      setTagInput('');\n    }\n  };\n\n  const removeTag = (tag: string) => {\n    actions.updateDraft({\n      tags: state.problemDraft.tags.filter(t => t !== tag)\n    });\n  };\n\n  const addHint = () => {\n    if (hintInput.trim()) {\n      actions.updateDraft({\n        hints: [...state.problemDraft.hints, hintInput.trim()]\n      });\n      setHintInput('');\n    }\n  };\n\n  const removeHint = (index: number) => {\n    actions.updateDraft({\n      hints: state.problemDraft.hints.filter((_, i) => i !== index)\n    });\n  };\n\n  return (\n    <div className=\"space-y-6\">\n      <Card>\n        <CardHeader>\n          <CardTitle>Create Question</CardTitle>\n          {state.problemDraft.question.tables.length > 0 && (\n            <Alert>\n              <Info className=\"h-4 w-4\" />\n              <AlertDescription>\n                ðŸ“Š {state.problemDraft.question.tables.length} table(s) loaded from validation\n              </AlertDescription>\n            </Alert>\n          )}\n        </CardHeader>\n        <CardContent className=\"space-y-4\">\n          <div>\n            <Label htmlFor=\"title\">Problem Title *</Label>\n            <Input\n              id=\"title\"\n              value={state.problemDraft.title}\n              onChange={(e) => actions.updateDraft({ title: e.target.value })}\n              placeholder=\"e.g., Calculate Total Sales by Region\"\n              data-testid=\"input-title\"\n            />\n          </div>\n\n          <div>\n            <Label htmlFor=\"difficulty\">Difficulty *</Label>\n            <select\n              id=\"difficulty\"\n              value={state.problemDraft.difficulty}\n              onChange={(e) => actions.updateDraft({ difficulty: e.target.value })}\n              className=\"w-full p-2 border rounded-md\"\n              data-testid=\"select-difficulty\"\n            >\n              {state.schemaInfo?.difficulty_options.map(diff => (\n                <option key={diff} value={diff}>{diff}</option>\n              ))}\n            </select>\n          </div>\n\n          <div>\n            <Label htmlFor=\"topic\">Topic (Optional)</Label>\n            <select\n              id=\"topic\"\n              value={state.problemDraft.topic_id}\n              onChange={(e) => actions.updateDraft({ topic_id: e.target.value })}\n              className=\"w-full p-2 border rounded-md\"\n              data-testid=\"select-topic\"\n            >\n              <option value=\"\">Select a topic (optional)</option>\n              {state.schemaInfo?.available_topics.map(topic => (\n                <option key={topic.id} value={topic.id}>{topic.name}</option>\n              ))}\n            </select>\n          </div>\n\n          <div>\n            <Label htmlFor=\"company\">Company (Optional)</Label>\n            <Input\n              id=\"company\"\n              value={state.problemDraft.company}\n              onChange={(e) => actions.updateDraft({ company: e.target.value })}\n              placeholder=\"e.g., TechCorp\"\n              data-testid=\"input-company\"\n            />\n          </div>\n\n          <div>\n            <Label>Premium Problem</Label>\n            <div className=\"flex items-center space-x-2\">\n              <input\n                type=\"checkbox\"\n                checked={state.problemDraft.premium}\n                onChange={(e) => actions.updateDraft({ premium: e.target.checked })}\n                data-testid=\"checkbox-premium\"\n              />\n              <span>Requires premium subscription</span>\n            </div>\n          </div>\n        </CardContent>\n      </Card>\n\n      <Card>\n        <CardHeader>\n          <CardTitle>Problem Description</CardTitle>\n        </CardHeader>\n        <CardContent>\n          <Textarea\n            value={state.problemDraft.question.description}\n            onChange={(e) => actions.updateDraft({\n              question: { ...state.problemDraft.question, description: e.target.value }\n            })}\n            placeholder=\"Describe the SQL problem here...\"\n            rows={8}\n            data-testid=\"textarea-description\"\n          />\n        </CardContent>\n      </Card>\n\n      {/* Enhanced Table Preview */}\n      <EnhancedTablePreview \n        tables={state.problemDraft.question.tables}\n        onTableUpdate={(updatedTables) => {\n          actions.updateDraft({\n            question: { \n              ...state.problemDraft.question, \n              tables: updatedTables \n            }\n          });\n        }}\n      />\n\n      {/* Tags */}\n      <Card>\n        <CardHeader>\n          <CardTitle>Tags</CardTitle>\n        </CardHeader>\n        <CardContent className=\"space-y-4\">\n          <div className=\"flex space-x-2\">\n            <Input\n              value={tagInput}\n              onChange={(e) => setTagInput(e.target.value)}\n              placeholder=\"Add a tag\"\n              data-testid=\"input-tag\"\n            />\n            <Button onClick={addTag} data-testid=\"button-add-tag\">\n              <Plus className=\"w-4 h-4 mr-2\" />\n              Add\n            </Button>\n          </div>\n          <div className=\"flex flex-wrap gap-2\">\n            {state.problemDraft.tags.map((tag) => (\n              <Badge key={tag} variant=\"secondary\" className=\"flex items-center space-x-1\">\n                <span>{tag}</span>\n                <button onClick={() => removeTag(tag)} data-testid={`button-remove-tag-${tag}`}>\n                  <Trash2 className=\"w-3 h-3\" />\n                </button>\n              </Badge>\n            ))}\n          </div>\n        </CardContent>\n      </Card>\n\n      {/* Hints */}\n      <Card>\n        <CardHeader>\n          <CardTitle>Hints</CardTitle>\n        </CardHeader>\n        <CardContent className=\"space-y-4\">\n          <div className=\"flex space-x-2\">\n            <Input\n              value={hintInput}\n              onChange={(e) => setHintInput(e.target.value)}\n              placeholder=\"Add a hint\"\n              data-testid=\"input-hint\"\n            />\n            <Button onClick={addHint} data-testid=\"button-add-hint\">\n              <Plus className=\"w-4 h-4 mr-2\" />\n              Add\n            </Button>\n          </div>\n          <div className=\"space-y-2\">\n            {state.problemDraft.hints.map((hint, index) => (\n              <div key={index} className=\"flex items-start space-x-2 p-2 bg-gray-50 dark:bg-gray-800 rounded\">\n                <span className=\"flex-1 text-sm\">{hint}</span>\n                <button onClick={() => removeHint(index)} data-testid={`button-remove-hint-${index}`}>\n                  <Trash2 className=\"w-4 h-4 text-red-500\" />\n                </button>\n              </div>\n            ))}\n          </div>\n        </CardContent>\n      </Card>\n\n      {/* Master Solution - Enhanced JSONB Editor with Multiple Input Modes */}\n      <Card>\n        <CardHeader>\n          <div className=\"flex items-center justify-between\">\n            <CardTitle>Master Solution</CardTitle>\n            <div className=\"flex space-x-2\">\n              <select\n                value={solutionInputMode}\n                onChange={(e) => setSolutionInputMode(e.target.value as 'json' | 'table' | 'file')}\n                className=\"text-sm border rounded px-2 py-1\"\n                data-testid=\"select-input-mode\"\n              >\n                <option value=\"json\">JSON Input</option>\n                <option value=\"table\">Table Builder</option>\n                <option value=\"file\">Parquet File Upload</option>\n              </select>\n              <Button\n                variant=\"outline\"\n                size=\"sm\"\n                onClick={() => setShowJsonPreview(!showJsonPreview)}\n                data-testid=\"button-toggle-preview\"\n              >\n                {showJsonPreview ? <EyeOff className=\"w-4 h-4 mr-2\" /> : <Eye className=\"w-4 h-4 mr-2\" />}\n                {showJsonPreview ? 'Hide Preview' : 'Show Preview'}\n              </Button>\n            </div>\n          </div>\n          <p className=\"text-sm text-muted-foreground\">\n            Define the definitive expected results for validation. This is used internally to check if user submissions are correct.\n          </p>\n        </CardHeader>\n        <CardContent className=\"space-y-4\">\n          {solutionInputMode === 'json' ? (\n            <div>\n              <Label>JSON Input</Label>\n              <Textarea\n                value={masterSolutionJson}\n                onChange={(e) => handleJsonChange(e.target.value)}\n                placeholder={`[\\n  {\"REGION\": \"North\", \"TOTAL_SALES\": 15000},\\n  {\"REGION\": \"South\", \"TOTAL_SALES\": 12000}\\n]`}\n                rows={8}\n                className={`font-mono text-sm ${jsonValidationError ? 'border-red-500' : ''}`}\n                data-testid=\"textarea-master-solution\"\n              />\n              {jsonValidationError && (\n                <Alert className=\"mt-2\">\n                  <Info className=\"h-4 w-4\" />\n                  <AlertDescription className=\"text-red-600\">\n                    <strong>JSON Error:</strong> {jsonValidationError}\n                  </AlertDescription>\n                </Alert>\n              )}\n            </div>\n          ) : solutionInputMode === 'file' ? (\n            <div>\n              <Label>Parquet File Upload</Label>\n              <p className=\"text-xs text-muted-foreground mb-2\">\n                Upload a Parquet file containing your expected results. Parquet files offer superior compression and performance for large datasets.\n              </p>\n              <div className=\"space-y-4\">\n                <div className=\"border-2 border-dashed border-gray-300 dark:border-gray-600 rounded-lg p-6\">\n                  <input\n                    type=\"file\"\n                    accept=\".parquet\"\n                    onChange={(e) => {\n                      const file = e.target.files?.[0];\n                      if (file) {\n                        setUploadedFile(file);\n                        setUploadError('');\n                      }\n                    }}\n                    className=\"hidden\"\n                    id=\"parquet-upload\"\n                    data-testid=\"input-parquet-file\"\n                  />\n                  <label\n                    htmlFor=\"parquet-upload\"\n                    className=\"cursor-pointer flex flex-col items-center space-y-2\"\n                  >\n                    <div className=\"text-4xl text-gray-400\">ðŸ“„</div>\n                    <div className=\"text-sm text-center\">\n                      <span className=\"font-medium text-blue-600 hover:text-blue-500\">\n                        Click to upload\n                      </span>{\" \"}\n                      or drag and drop\n                    </div>\n                    <div className=\"text-xs text-gray-500\">\n                      Parquet files only (.parquet)\n                    </div>\n                  </label>\n                </div>\n                \n                {uploadedFile && (\n                  <div className=\"flex items-center justify-between p-3 bg-green-50 dark:bg-green-900/20 border border-green-200 dark:border-green-800 rounded\">\n                    <div className=\"flex items-center space-x-2\">\n                      <div className=\"text-green-600\">ðŸ“„</div>\n                      <div>\n                        <div className=\"text-sm font-medium\">{uploadedFile.name}</div>\n                        <div className=\"text-xs text-gray-500\">\n                          {(uploadedFile.size / 1024 / 1024).toFixed(2)} MB\n                        </div>\n                      </div>\n                    </div>\n                    <Button\n                      variant=\"outline\"\n                      size=\"sm\"\n                      onClick={() => setUploadedFile(null)}\n                      data-testid=\"button-remove-file\"\n                    >\n                      <Trash2 className=\"w-4 h-4\" />\n                    </Button>\n                  </div>\n                )}\n\n                {uploadError && (\n                  <Alert className=\"mt-2\">\n                    <Info className=\"h-4 w-4\" />\n                    <AlertDescription className=\"text-red-600\">\n                      <strong>Upload Error:</strong> {uploadError}\n                    </AlertDescription>\n                  </Alert>\n                )}\n\n                {uploadedFile && !isUploading && (\n                  <Button\n                    onClick={() => convertParquetMutation.mutate(uploadedFile)}\n                    disabled={isUploading || convertParquetMutation.isPending}\n                    className=\"w-full\"\n                    data-testid=\"button-convert-parquet\"\n                  >\n                    {convertParquetMutation.isPending ? 'Converting...' : 'Convert to Master Solution'}\n                  </Button>\n                )}\n              </div>\n            </div>\n          ) : (\n            <div className=\"space-y-4\">\n              <div>\n                <Label>Table Builder</Label>\n                <p className=\"text-xs text-muted-foreground mb-2\">\n                  Build your expected output table by defining columns and adding rows\n                </p>\n              </div>\n              \n              {/* Column Management */}\n              <div className=\"border rounded-lg p-4\">\n                <h4 className=\"font-medium mb-2\">Columns</h4>\n                <div className=\"space-y-2\">\n                  {tableColumns.map((col, index) => (\n                    <div key={index} className=\"flex items-center space-x-2\">\n                      <Input\n                        placeholder=\"Column Name\"\n                        value={col.name}\n                        onChange={(e) => {\n                          const newColumns = [...tableColumns];\n                          newColumns[index].name = e.target.value;\n                          setTableColumns(newColumns);\n                        }}\n                        className=\"flex-1\"\n                        data-testid={`input-column-name-${index}`}\n                      />\n                      <select\n                        value={col.type}\n                        onChange={(e) => {\n                          const newColumns = [...tableColumns];\n                          newColumns[index].type = e.target.value;\n                          setTableColumns(newColumns);\n                        }}\n                        className=\"border rounded px-2 py-1\"\n                        data-testid={`select-column-type-${index}`}\n                      >\n                        <option value=\"text\">Text</option>\n                        <option value=\"number\">Number</option>\n                        <option value=\"boolean\">Boolean</option>\n                        <option value=\"date\">Date</option>\n                      </select>\n                      <Button\n                        variant=\"outline\"\n                        size=\"sm\"\n                        onClick={() => {\n                          setTableColumns(tableColumns.filter((_, i) => i !== index));\n                          // Remove this column from all rows\n                          setTableRows(tableRows.map(row => {\n                            const newRow = {...row};\n                            delete newRow[col.name];\n                            return newRow;\n                          }));\n                        }}\n                        data-testid={`button-remove-column-${index}`}\n                      >\n                        <Trash2 className=\"w-4 h-4\" />\n                      </Button>\n                    </div>\n                  ))}\n                  <Button\n                    variant=\"outline\"\n                    size=\"sm\"\n                    onClick={() => setTableColumns([...tableColumns, { name: '', type: 'text' }])}\n                    data-testid=\"button-add-column\"\n                  >\n                    <Plus className=\"w-4 h-4 mr-2\" />\n                    Add Column\n                  </Button>\n                </div>\n              </div>\n\n              {/* Row Management */}\n              {tableColumns.length > 0 && (\n                <div className=\"border rounded-lg p-4\">\n                  <div className=\"flex items-center justify-between mb-2\">\n                    <h4 className=\"font-medium\">Rows</h4>\n                    <Button\n                      variant=\"outline\"\n                      size=\"sm\"\n                      onClick={() => {\n                        const newRow: Record<string, any> = {};\n                        tableColumns.forEach(col => {\n                          newRow[col.name] = col.type === 'number' ? 0 : col.type === 'boolean' ? false : '';\n                        });\n                        setTableRows([...tableRows, newRow]);\n                      }}\n                      data-testid=\"button-add-row\"\n                    >\n                      <Plus className=\"w-4 h-4 mr-2\" />\n                      Add Row\n                    </Button>\n                  </div>\n                  <div className=\"overflow-x-auto\">\n                    <table className=\"w-full border-collapse border\">\n                      <thead>\n                        <tr>\n                          {tableColumns.map((col, index) => (\n                            <th key={index} className=\"border p-2 bg-gray-50 dark:bg-gray-800 text-left\">\n                              {col.name || 'Unnamed'}\n                            </th>\n                          ))}\n                          <th className=\"border p-2 bg-gray-50 dark:bg-gray-800 w-10\"></th>\n                        </tr>\n                      </thead>\n                      <tbody>\n                        {tableRows.map((row, rowIndex) => (\n                          <tr key={rowIndex}>\n                            {tableColumns.map((col, colIndex) => (\n                              <td key={colIndex} className=\"border p-1\">\n                                {col.type === 'boolean' ? (\n                                  <input\n                                    type=\"checkbox\"\n                                    checked={row[col.name] || false}\n                                    onChange={(e) => {\n                                      const newRows = [...tableRows];\n                                      newRows[rowIndex][col.name] = e.target.checked;\n                                      setTableRows(newRows);\n                                    }}\n                                    data-testid={`checkbox-row-${rowIndex}-col-${colIndex}`}\n                                  />\n                                ) : (\n                                  <Input\n                                    type={col.type === 'number' ? 'number' : col.type === 'date' ? 'date' : 'text'}\n                                    value={row[col.name] || ''}\n                                    onChange={(e) => {\n                                      const newRows = [...tableRows];\n                                      newRows[rowIndex][col.name] = col.type === 'number' ? Number(e.target.value) : e.target.value;\n                                      setTableRows(newRows);\n                                    }}\n                                    className=\"h-8\"\n                                    data-testid={`input-row-${rowIndex}-col-${colIndex}`}\n                                  />\n                                )}\n                              </td>\n                            ))}\n                            <td className=\"border p-1\">\n                              <Button\n                                variant=\"outline\"\n                                size=\"sm\"\n                                onClick={() => setTableRows(tableRows.filter((_, i) => i !== rowIndex))}\n                                data-testid={`button-remove-row-${rowIndex}`}\n                              >\n                                <Trash2 className=\"w-3 h-3\" />\n                              </Button>\n                            </td>\n                          </tr>\n                        ))}\n                      </tbody>\n                    </table>\n                  </div>\n                </div>\n              )}\n            </div>\n          )}\n          \n          {/* JSON Preview */}\n          {showJsonPreview && (\n            <div className=\"border rounded-md\">\n              <div className=\"bg-gray-50 dark:bg-gray-800 px-3 py-2 border-b\">\n                <h4 className=\"text-sm font-medium\">Preview</h4>\n              </div>\n              <div className=\"p-3\">\n                {getParsedJson() ? (\n                  <div className=\"space-y-2\">\n                    {Array.isArray(getParsedJson()) ? (\n                      <>\n                        <div className=\"text-sm text-gray-600 dark:text-gray-400\">\n                          {getParsedJson().length} rows found\n                        </div>\n                        {getParsedJson().length > 0 && (\n                          <div className=\"overflow-x-auto\">\n                            <table className=\"w-full text-sm border-collapse\">\n                              <thead>\n                                <tr className=\"border-b\">\n                                  {Object.keys(getParsedJson()[0]).map((key) => (\n                                    <th key={key} className=\"text-left p-2 font-medium bg-gray-50 dark:bg-gray-700\">\n                                      {key}\n                                    </th>\n                                  ))}\n                                </tr>\n                              </thead>\n                              <tbody>\n                                {getParsedJson().slice(0, 5).map((row: any, index: number) => (\n                                  <tr key={index} className=\"border-b\">\n                                    {Object.values(row).map((value: any, colIndex: number) => (\n                                      <td key={colIndex} className=\"p-2\">\n                                        {typeof value === 'object' ? JSON.stringify(value) : String(value)}\n                                      </td>\n                                    ))}\n                                  </tr>\n                                ))}\n                              </tbody>\n                            </table>\n                            {getParsedJson().length > 5 && (\n                              <div className=\"text-xs text-gray-500 mt-2\">\n                                ... and {getParsedJson().length - 5} more rows\n                              </div>\n                            )}\n                          </div>\n                        )}\n                      </>\n                    ) : (\n                      <div className=\"text-sm text-gray-600 dark:text-gray-400\">\n                        Expected output should be an array of objects\n                      </div>\n                    )}\n                  </div>\n                ) : (\n                  <div className=\"text-sm text-gray-500\">\n                    {masterSolutionJson.trim() ? 'Invalid JSON' : 'Enter valid JSON to see preview'}\n                  </div>\n                )}\n              </div>\n            </div>\n          )}\n          \n          {/* Quick Examples */}\n          <div className=\"text-xs text-gray-500 space-y-1\">\n            <div><strong>Example formats:</strong></div>\n            <div>â€¢ Simple: <code>[{\"{\\\"column\\\": \\\"value\\\"}\"}]</code></div>\n            <div>â€¢ Multiple rows: <code>[{\"{\\\"id\\\": 1, \\\"name\\\": \\\"Alice\\\"\"}, {\"{\\\"id\\\": 2, \\\"name\\\": \\\"Bob\\\"}\"}]</code></div>\n            <div>â€¢ Numbers: <code>[{\"{\\\"total\\\": 15000, \\\"count\\\": 42}\"}]</code></div>\n          </div>\n        </CardContent>\n      </Card>\n\n      {/* Expected Display - What users see on the problem page */}\n      <Card>\n        <CardHeader>\n          <div className=\"flex items-center justify-between\">\n            <CardTitle>Expected Display</CardTitle>\n            <div className=\"flex space-x-2\">\n              <select\n                value={displayInputMode}\n                onChange={(e) => setDisplayInputMode(e.target.value as 'json' | 'table')}\n                className=\"text-sm border rounded px-2 py-1\"\n                data-testid=\"select-display-input-mode\"\n              >\n                <option value=\"json\">JSON Input</option>\n                <option value=\"table\">Table Builder</option>\n              </select>\n              <Button\n                variant=\"outline\"\n                size=\"sm\"\n                onClick={() => setShowDisplayPreview(!showDisplayPreview)}\n                data-testid=\"button-toggle-display-preview\"\n              >\n                {showDisplayPreview ? <EyeOff className=\"w-4 h-4 mr-2\" /> : <Eye className=\"w-4 h-4 mr-2\" />}\n                {showDisplayPreview ? 'Hide Preview' : 'Show Preview'}\n              </Button>\n            </div>\n          </div>\n          <p className=\"text-sm text-muted-foreground\">\n            Define what users see as the expected output on the problem page. This is for display purposes only and is not used for validation.\n          </p>\n        </CardHeader>\n        <CardContent className=\"space-y-4\">\n          {displayInputMode === 'json' ? (\n            <div>\n              <Label>JSON Input</Label>\n              <Textarea\n                value={expectedDisplayJson}\n                onChange={(e) => handleDisplayJsonChange(e.target.value)}\n                placeholder={`[\\n  {\"REGION\": \"North\", \"TOTAL_SALES\": 15000},\\n  {\"REGION\": \"South\", \"TOTAL_SALES\": 12000}\\n]`}\n                rows={8}\n                className={`font-mono text-sm ${displayJsonValidationError ? 'border-red-500' : ''}`}\n                data-testid=\"textarea-expected-display\"\n              />\n              {displayJsonValidationError && (\n                <Alert className=\"mt-2\">\n                  <Info className=\"h-4 w-4\" />\n                  <AlertDescription className=\"text-red-600\">\n                    <strong>JSON Error:</strong> {displayJsonValidationError}\n                  </AlertDescription>\n                </Alert>\n              )}\n            </div>\n          ) : (\n            <div className=\"space-y-4\">\n              <div>\n                <Label>Table Builder</Label>\n                <p className=\"text-xs text-muted-foreground mb-2\">\n                  Build your expected display table by defining columns and adding rows\n                </p>\n              </div>\n              \n              {/* Column Management for Display */}\n              <div className=\"border rounded-lg p-4\">\n                <h4 className=\"font-medium mb-2\">Display Columns</h4>\n                <div className=\"space-y-2\">\n                  {displayTableColumns.map((col, index) => (\n                    <div key={index} className=\"flex items-center space-x-2\">\n                      <Input\n                        value={col.name}\n                        onChange={(e) => {\n                          const newCols = [...displayTableColumns];\n                          newCols[index].name = e.target.value;\n                          setDisplayTableColumns(newCols);\n                        }}\n                        placeholder=\"Column name\"\n                        className=\"flex-1\"\n                      />\n                      <select\n                        value={col.type}\n                        onChange={(e) => {\n                          const newCols = [...displayTableColumns];\n                          newCols[index].type = e.target.value;\n                          setDisplayTableColumns(newCols);\n                        }}\n                        className=\"w-24 p-2 border rounded\"\n                      >\n                        <option value=\"text\">Text</option>\n                        <option value=\"number\">Number</option>\n                        <option value=\"boolean\">Boolean</option>\n                      </select>\n                      <Button\n                        variant=\"outline\"\n                        size=\"sm\"\n                        onClick={() => {\n                          const newCols = displayTableColumns.filter((_, i) => i !== index);\n                          setDisplayTableColumns(newCols);\n                          // Remove this column from all rows\n                          const newRows = displayTableRows.map(row => {\n                            const newRow = { ...row };\n                            delete newRow[col.name];\n                            return newRow;\n                          });\n                          setDisplayTableRows(newRows);\n                        }}\n                      >\n                        <Trash2 className=\"w-4 h-4\" />\n                      </Button>\n                    </div>\n                  ))}\n                  <Button\n                    variant=\"outline\"\n                    onClick={() => {\n                      setDisplayTableColumns([...displayTableColumns, { name: '', type: 'text' }]);\n                    }}\n                    className=\"w-full\"\n                  >\n                    <Plus className=\"w-4 h-4 mr-2\" />\n                    Add Column\n                  </Button>\n                </div>\n              </div>\n\n              {/* Row Management for Display */}\n              {displayTableColumns.length > 0 && (\n                <div className=\"border rounded-lg p-4\">\n                  <h4 className=\"font-medium mb-2\">Display Rows</h4>\n                  <div className=\"space-y-2\">\n                    {displayTableRows.map((row, rowIndex) => (\n                      <div key={rowIndex} className=\"flex items-center space-x-2\">\n                        {displayTableColumns.map((col, colIndex) => (\n                          <Input\n                            key={colIndex}\n                            value={row[col.name] || ''}\n                            onChange={(e) => {\n                              const newRows = [...displayTableRows];\n                              newRows[rowIndex][col.name] = col.type === 'number' ? \n                                (e.target.value === '' ? '' : Number(e.target.value)) : \n                                e.target.value;\n                              setDisplayTableRows(newRows);\n                            }}\n                            placeholder={col.name}\n                            type={col.type === 'number' ? 'number' : 'text'}\n                            className=\"flex-1\"\n                          />\n                        ))}\n                        <Button\n                          variant=\"outline\"\n                          size=\"sm\"\n                          onClick={() => {\n                            const newRows = displayTableRows.filter((_, i) => i !== rowIndex);\n                            setDisplayTableRows(newRows);\n                          }}\n                        >\n                          <Trash2 className=\"w-4 h-4\" />\n                        </Button>\n                      </div>\n                    ))}\n                    <Button\n                      variant=\"outline\"\n                      onClick={() => {\n                        const newRow: Record<string, any> = {};\n                        displayTableColumns.forEach(col => {\n                          newRow[col.name] = col.type === 'number' ? 0 : '';\n                        });\n                        setDisplayTableRows([...displayTableRows, newRow]);\n                      }}\n                      className=\"w-full\"\n                    >\n                      <Plus className=\"w-4 h-4 mr-2\" />\n                      Add Row\n                    </Button>\n                  </div>\n                </div>\n              )}\n            </div>\n          )}\n          \n          {/* Display JSON Preview */}\n          {showDisplayPreview && (\n            <div className=\"border rounded-md\">\n              <div className=\"bg-gray-50 dark:bg-gray-800 px-3 py-2 border-b\">\n                <h4 className=\"text-sm font-medium\">Display Preview</h4>\n              </div>\n              <div className=\"p-3\">\n                {getParsedDisplayJson() ? (\n                  <div className=\"space-y-2\">\n                    {Array.isArray(getParsedDisplayJson()) ? (\n                      <>\n                        <div className=\"text-sm text-gray-600 dark:text-gray-400\">\n                          {getParsedDisplayJson().length} rows found\n                        </div>\n                        {getParsedDisplayJson().length > 0 && (\n                          <div className=\"overflow-x-auto\">\n                            <table className=\"w-full text-sm border-collapse\">\n                              <thead>\n                                <tr className=\"border-b\">\n                                  {Object.keys(getParsedDisplayJson()[0]).map((key) => (\n                                    <th key={key} className=\"text-left p-2 font-medium bg-gray-50 dark:bg-gray-700\">\n                                      {key}\n                                    </th>\n                                  ))}\n                                </tr>\n                              </thead>\n                              <tbody>\n                                {getParsedDisplayJson().slice(0, 5).map((row: any, index: number) => (\n                                  <tr key={index} className=\"border-b\">\n                                    {Object.values(row).map((value: any, colIndex: number) => (\n                                      <td key={colIndex} className=\"p-2\">\n                                        {typeof value === 'object' ? JSON.stringify(value) : String(value)}\n                                      </td>\n                                    ))}\n                                  </tr>\n                                ))}\n                              </tbody>\n                            </table>\n                            {getParsedDisplayJson().length > 5 && (\n                              <div className=\"text-xs text-gray-500 mt-2\">\n                                ... and {getParsedDisplayJson().length - 5} more rows\n                              </div>\n                            )}\n                          </div>\n                        )}\n                      </>\n                    ) : (\n                      <div className=\"text-sm text-gray-600 dark:text-gray-400\">\n                        Expected display should be an array of objects\n                      </div>\n                    )}\n                  </div>\n                ) : (\n                  <div className=\"text-sm text-gray-500\">\n                    Enter valid JSON or use table builder to see preview\n                  </div>\n                )}\n              </div>\n            </div>\n          )}\n        </CardContent>\n      </Card>\n\n      {/* Solution Verification Status */}\n      {state.solutionVerification && (\n        <Card>\n          <CardHeader>\n            <CardTitle>Solution Verification</CardTitle>\n          </CardHeader>\n          <CardContent>\n            <div className={`p-3 rounded-md ${\n              state.solutionVerification.verified ? 'bg-green-50 dark:bg-green-900' : 'bg-red-50 dark:bg-red-900'\n            }`}>\n              <div className=\"flex items-center space-x-2\">\n                <span className={`w-2 h-2 rounded-full ${\n                  state.solutionVerification.verified ? 'bg-green-500' : 'bg-red-500'\n                }`}></span>\n                <span className=\"text-sm\">\n                  {state.solutionVerification.verified ? 'Verified' : 'Not Verified'} - {state.solutionVerification.source.toUpperCase()}\n                </span>\n              </div>\n            </div>\n          </CardContent>\n        </Card>\n      )}\n\n      {/* Submit Button */}\n      <div className=\"flex justify-end space-x-4\">\n        <Button variant=\"outline\" onClick={actions.resetDraft} data-testid=\"button-reset\">\n          Reset Draft\n        </Button>\n        <Button \n          onClick={handleSubmit} \n          disabled={createProblemMutation.isPending || !state.problemDraft.title.trim()}\n          data-testid=\"button-create-problem\"\n        >\n          {createProblemMutation.isPending ? 'Creating...' : 'Create Problem'}\n        </Button>\n      </div>\n    </div>\n  );\n}","size_bytes":44482},"client/src/components/admin/DataSourceTab.tsx":{"content":"import { useState } from 'react';\nimport { Button } from '@/components/ui/button';\nimport { Input } from '@/components/ui/input';\nimport { Label } from '@/components/ui/label';\nimport { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';\nimport { Alert, AlertDescription } from '@/components/ui/alert';\nimport { Badge } from '@/components/ui/badge';\nimport { Trash2, Plus, CheckCircle, XCircle, Info } from 'lucide-react';\nimport { useAdmin } from '@/contexts/AdminContext';\n\nexport function DataSourceTab() {\n  const { state, actions } = useAdmin();\n  const [solutionPath, setSolutionPath] = useState('');\n\n  // Unified dataset management - supports both single and multiple datasets\n  const datasets = state.datasets.length > 0 ? state.datasets : [{ bucket: '', key: '', table_name: '', description: '' }];\n\n  const addDataset = () => {\n    actions.setDatasets([\n      ...state.datasets,\n      { bucket: '', key: '', table_name: '', description: '' }\n    ]);\n  };\n\n  const removeDataset = (index: number) => {\n    if (state.datasets.length > 1) {\n      actions.setDatasets(\n        state.datasets.filter((_, i) => i !== index)\n      );\n    }\n  };\n\n  const updateDataset = (index: number, field: string, value: string) => {\n    const updated = [...state.datasets];\n    updated[index] = { ...updated[index], [field]: value };\n    actions.setDatasets(updated);\n  };\n\n  return (\n    <div className=\"space-y-6\">\n      <Card>\n        <CardHeader>\n          <CardTitle>Data Source Management</CardTitle>\n          <p className=\"text-sm text-muted-foreground\">\n            Validate S3 datasets and configure solution verification. \n            Supports single or multiple datasets. Apply validated data to Create Question tab.\n          </p>\n        </CardHeader>\n      </Card>\n\n      <div className=\"space-y-4\">\n        <Card>\n          <CardHeader>\n            <div className=\"flex justify-between items-center\">\n              <CardTitle>S3 Dataset Configuration</CardTitle>\n              <Button\n                onClick={addDataset}\n                variant=\"outline\"\n                size=\"sm\"\n                data-testid=\"button-add-dataset\"\n              >\n                <Plus className=\"w-4 h-4 mr-1\" />\n                Add Dataset\n              </Button>\n            </div>\n            <p className=\"text-sm text-muted-foreground\">\n              Configure one or more S3 datasets. Each dataset will be loaded as a separate table.\n            </p>\n          </CardHeader>\n          <CardContent className=\"space-y-4\">\n            {datasets.map((dataset, index) => (\n              <div key={index} className=\"border rounded-lg p-4 space-y-3\">\n                <div className=\"flex justify-between items-center\">\n                  <h4 className=\"font-medium\">\n                    {datasets.length === 1 ? \"Dataset\" : `Dataset ${index + 1}`}\n                  </h4>\n                  {datasets.length > 1 && (\n                    <Button\n                      variant=\"ghost\"\n                      size=\"sm\"\n                      onClick={() => removeDataset(index)}\n                      data-testid={`button-remove-dataset-${index}`}\n                    >\n                      <Trash2 className=\"w-4 h-4\" />\n                    </Button>\n                  )}\n                </div>\n\n                <div className=\"grid grid-cols-2 gap-3\">\n                  <div>\n                    <Label>S3 Bucket Name</Label>\n                    <Input\n                      value={dataset.bucket}\n                      onChange={(e) => updateDataset(index, 'bucket', e.target.value)}\n                      placeholder=\"my-datasets-bucket\"\n                      data-testid={`input-dataset-${index}-bucket`}\n                    />\n                    <p className=\"text-xs text-muted-foreground\">\n                      The S3 bucket containing your dataset\n                    </p>\n                  </div>\n                  <div>\n                    <Label>S3 Object Key</Label>\n                    <Input\n                      value={dataset.key}\n                      onChange={(e) => updateDataset(index, 'key', e.target.value)}\n                      placeholder=\"datasets/table1.parquet\"\n                      data-testid={`input-dataset-${index}-key`}\n                    />\n                    <p className=\"text-xs text-muted-foreground\">\n                      The path to your parquet file within the bucket\n                    </p>\n                  </div>\n                  <div>\n                    <Label>Table Name in DuckDB</Label>\n                    <Input\n                      value={dataset.table_name}\n                      onChange={(e) => updateDataset(index, 'table_name', e.target.value)}\n                      placeholder={`table_${index + 1}`}\n                      data-testid={`input-dataset-${index}-table-name`}\n                    />\n                    <p className=\"text-xs text-muted-foreground\">\n                      What to call this table in the SQL environment\n                    </p>\n                  </div>\n                  <div>\n                    <Label>Description (Optional)</Label>\n                    <Input\n                      value={dataset.description}\n                      onChange={(e) => updateDataset(index, 'description', e.target.value)}\n                      placeholder=\"Dataset description\"\n                      data-testid={`input-dataset-${index}-description`}\n                    />\n                    <p className=\"text-xs text-muted-foreground\">\n                      Brief description of this dataset\n                    </p>\n                  </div>\n                </div>\n\n                <div className=\"p-3 bg-gray-50 dark:bg-gray-800 rounded-md\">\n                  <p className=\"text-sm text-gray-600 dark:text-gray-400\">\n                    <strong>S3 Data Source:</strong> s3://{dataset.bucket}/{dataset.key} â†’ {dataset.table_name}\n                  </p>\n                </div>\n              </div>\n            ))}\n\n            <div className=\"space-y-4 pt-4 border-t\">\n              <div className=\"flex gap-2\">\n                <Button\n                  onClick={() => actions.validateDatasets(solutionPath)}\n                  disabled={state.isValidatingDatasets || datasets.some(d => !d.bucket?.trim() || !d.key?.trim())}\n                  data-testid=\"button-validate-datasets\"\n                >\n                  {state.isValidatingDatasets ? 'Validating...' : 'Validate Datasets'}\n                </Button>\n                \n                {state.datasetValidation?.success && (\n                  <Button\n                    onClick={() => actions.applyValidationToDraft('unified')}\n                    variant=\"outline\"\n                    data-testid=\"button-apply-datasets\"\n                  >\n                    Apply to Draft\n                  </Button>\n                )}\n              </div>\n\n              {/* Validation Results */}\n              {state.datasetValidation && (\n                <Alert className={state.datasetValidation.success ? 'border-green-200' : 'border-red-200'}>\n                  {state.datasetValidation.success ? (\n                    <CheckCircle className=\"h-4 w-4 text-green-600\" />\n                  ) : (\n                    <XCircle className=\"h-4 w-4 text-red-600\" />\n                  )}\n                  <AlertDescription>\n                    {state.datasetValidation.success ? (\n                      <div>\n                        <p className=\"font-medium text-green-800\">âœ“ Dataset validation successful!</p>\n                        <p className=\"text-sm\">\n                          Found {state.datasetValidation.total_tables} table(s) with {state.datasetValidation.total_rows?.toLocaleString()} total rows\n                        </p>\n                        {state.datasetValidation.validated_datasets && (\n                          <div className=\"mt-2 space-y-2\">\n                            {state.datasetValidation.validated_datasets.map((dataset, i) => (\n                              <div key={i} className=\"text-sm border rounded p-2\">\n                                <p className=\"font-medium\">{dataset.table_name}: {dataset.row_count?.toLocaleString()} rows</p>\n                                <div className=\"flex flex-wrap gap-1 mt-1\">\n                                  {dataset.table_schema?.slice(0, 4).map((col, j) => (\n                                    <Badge key={j} variant=\"outline\" className=\"text-xs\">\n                                      {col.column} ({col.type})\n                                    </Badge>\n                                  ))}\n                                  {(dataset.table_schema?.length || 0) > 4 && (\n                                    <Badge variant=\"outline\" className=\"text-xs\">\n                                      +{(dataset.table_schema?.length || 0) - 4} more\n                                    </Badge>\n                                  )}\n                                </div>\n                              </div>\n                            ))}\n                          </div>\n                        )}\n                      </div>\n                    ) : (\n                      <div>\n                        <p className=\"font-medium text-red-800\">âœ— Dataset validation failed</p>\n                        <p className=\"text-sm\">{state.datasetValidation.error}</p>\n                      </div>\n                    )}\n                  </AlertDescription>\n                </Alert>\n              )}\n            </div>\n          </CardContent>\n        </Card>\n        \n        <div className=\"bg-yellow-50 dark:bg-yellow-900/20 border border-yellow-200 dark:border-yellow-800 rounded-md p-4\">\n          <div className=\"flex\">\n            <Info className=\"w-4 h-4 text-yellow-600 dark:text-yellow-400 mt-0.5 mr-2 flex-shrink-0\" />\n            <div className=\"text-sm\">\n              <p className=\"font-medium text-yellow-800 dark:text-yellow-200 mb-1\">Solution Verification Method</p>\n              <div className=\"space-y-2\">\n                <label className=\"flex items-center space-x-2\">\n                  <input\n                    type=\"radio\"\n                    name=\"solution-source\"\n                    value=\"neon\"\n                    checked={state.solutionVerification?.source === 'neon' || !state.solutionVerification}\n                    onChange={() => actions.setSolutionVerification({ source: 'neon', verified: false })}\n                  />\n                  <span className=\"text-yellow-700 dark:text-yellow-300\">Manual entry (recommended) - Enter expected results manually</span>\n                </label>\n              </div>\n            </div>\n          </div>\n        </div>\n\n        {/* Note for Neon verification */}\n        {(!state.solutionVerification || state.solutionVerification?.source === 'neon') && (\n          <div className=\"p-3 bg-blue-50 dark:bg-blue-950 rounded-md border border-blue-200 dark:border-blue-800\">\n            <p className=\"text-sm text-blue-700 dark:text-blue-200\">\n              ðŸ’¡ Using Neon database verification - solution will be validated against manually entered expected results in the Create Question tab.\n            </p>\n          </div>\n        )}\n      </div>\n    </div>\n  );\n}","size_bytes":11257},"client/src/components/admin/SchemaInfoTab.tsx":{"content":"import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';\nimport { Badge } from '@/components/ui/badge';\nimport { Alert, AlertDescription } from '@/components/ui/alert';\nimport { Button } from '@/components/ui/button';\nimport { Info, Database, Eye } from 'lucide-react';\nimport { useAdmin } from '@/contexts/AdminContext';\nimport { useState } from 'react';\n\nexport function SchemaInfoTab() {\n  const { state, actions } = useAdmin();\n  const [showExample, setShowExample] = useState(false);\n\n  const loadExample = () => {\n    if (state.schemaInfo?.example_problem) {\n      actions.updateDraft(state.schemaInfo.example_problem);\n      actions.setActiveTab('create');\n    }\n  };\n\n  if (!state.schemaInfo) {\n    return (\n      <div className=\"space-y-6\">\n        <Card>\n          <CardHeader>\n            <CardTitle>Schema Information</CardTitle>\n          </CardHeader>\n          <CardContent>\n            <Alert>\n              <Info className=\"h-4 w-4\" />\n              <AlertDescription>\n                Please authenticate with admin key to view schema information.\n              </AlertDescription>\n            </Alert>\n          </CardContent>\n        </Card>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"space-y-6\">\n      <Card>\n        <CardHeader>\n          <CardTitle>Schema Information</CardTitle>\n          <p className=\"text-sm text-muted-foreground\">\n            Database schema structure and available options for problem creation.\n          </p>\n        </CardHeader>\n      </Card>\n\n      {/* Difficulty Options */}\n      <Card>\n        <CardHeader>\n          <CardTitle className=\"flex items-center space-x-2\">\n            <Database className=\"w-5 h-5\" />\n            <span>Difficulty Options</span>\n          </CardTitle>\n        </CardHeader>\n        <CardContent>\n          <div className=\"flex flex-wrap gap-2\">\n            {state.schemaInfo.difficulty_options.map((difficulty) => (\n              <Badge key={difficulty} variant=\"outline\">\n                {difficulty}\n              </Badge>\n            ))}\n          </div>\n        </CardContent>\n      </Card>\n\n      {/* Available Topics */}\n      <Card>\n        <CardHeader>\n          <CardTitle className=\"flex items-center space-x-2\">\n            <Database className=\"w-5 h-5\" />\n            <span>Available Topics</span>\n          </CardTitle>\n        </CardHeader>\n        <CardContent>\n          <div className=\"space-y-2\">\n            {state.schemaInfo.available_topics.map((topic) => (\n              <div key={topic.id} className=\"flex items-center space-x-2 p-2 bg-gray-50 dark:bg-gray-800 rounded\">\n                <Badge variant=\"secondary\">{topic.name}</Badge>\n                <span className=\"text-sm text-gray-600 dark:text-gray-400\">\n                  ID: {topic.id}\n                </span>\n              </div>\n            ))}\n          </div>\n        </CardContent>\n      </Card>\n\n      {/* Problem Structure */}\n      <Card>\n        <CardHeader>\n          <CardTitle className=\"flex items-center space-x-2\">\n            <Database className=\"w-5 h-5\" />\n            <span>Problem Structure</span>\n          </CardTitle>\n        </CardHeader>\n        <CardContent>\n          <div className=\"bg-gray-50 dark:bg-gray-800 rounded p-4\">\n            <pre className=\"text-sm overflow-auto\">\n              {JSON.stringify(state.schemaInfo.problem_structure, null, 2)}\n            </pre>\n          </div>\n        </CardContent>\n      </Card>\n\n      {/* Example Problem */}\n      <Card>\n        <CardHeader>\n          <CardTitle className=\"flex items-center space-x-2\">\n            <Eye className=\"w-5 h-5\" />\n            <span>Example Problem</span>\n          </CardTitle>\n          <div className=\"flex space-x-2\">\n            <Button\n              variant=\"outline\"\n              size=\"sm\"\n              onClick={() => setShowExample(!showExample)}\n              data-testid=\"button-toggle-example\"\n            >\n              {showExample ? 'Hide' : 'Show'} Example\n            </Button>\n            <Button\n              size=\"sm\"\n              onClick={loadExample}\n              data-testid=\"button-load-example\"\n            >\n              Load Example to Draft\n            </Button>\n          </div>\n        </CardHeader>\n        {showExample && (\n          <CardContent>\n            <div className=\"space-y-4\">\n              {/* Basic Info */}\n              <div>\n                <h4 className=\"font-medium mb-2\">Basic Information</h4>\n                <div className=\"space-y-1 text-sm\">\n                  <div><strong>Title:</strong> {state.schemaInfo.example_problem.title}</div>\n                  <div><strong>Difficulty:</strong> {state.schemaInfo.example_problem.difficulty}</div>\n                  <div><strong>Company:</strong> {state.schemaInfo.example_problem.company || 'None'}</div>\n                  <div><strong>Premium:</strong> {state.schemaInfo.example_problem.premium ? 'Yes' : 'No'}</div>\n                </div>\n              </div>\n\n              {/* Tags */}\n              {state.schemaInfo.example_problem.tags.length > 0 && (\n                <div>\n                  <h4 className=\"font-medium mb-2\">Tags</h4>\n                  <div className=\"flex flex-wrap gap-1\">\n                    {state.schemaInfo.example_problem.tags.map((tag, index) => (\n                      <Badge key={index} variant=\"outline\" className=\"text-xs\">\n                        {tag}\n                      </Badge>\n                    ))}\n                  </div>\n                </div>\n              )}\n\n              {/* Description */}\n              <div>\n                <h4 className=\"font-medium mb-2\">Description</h4>\n                <div className=\"bg-gray-50 dark:bg-gray-800 rounded p-3 text-sm whitespace-pre-wrap\">\n                  {state.schemaInfo.example_problem.question.description}\n                </div>\n              </div>\n\n              {/* Tables */}\n              {state.schemaInfo.example_problem.question.tables.length > 0 && (\n                <div>\n                  <h4 className=\"font-medium mb-2\">Tables ({state.schemaInfo.example_problem.question.tables.length})</h4>\n                  <div className=\"space-y-3\">\n                    {state.schemaInfo.example_problem.question.tables.map((table, index) => (\n                      <div key={index} className=\"border rounded p-3\">\n                        <div className=\"font-medium mb-2\">{table.name}</div>\n                        <div className=\"text-sm text-gray-600 mb-2\">\n                          {table.columns.length} columns, {table.sample_data.length} sample rows\n                        </div>\n                        <div className=\"grid grid-cols-3 gap-2 text-xs\">\n                          {table.columns.slice(0, 6).map((col, colIndex) => (\n                            <div key={colIndex} className=\"font-medium\">\n                              {col.name} ({col.type})\n                            </div>\n                          ))}\n                          {table.columns.length > 6 && (\n                            <div className=\"text-gray-500\">...and {table.columns.length - 6} more</div>\n                          )}\n                        </div>\n                      </div>\n                    ))}\n                  </div>\n                </div>\n              )}\n\n              {/* Hints */}\n              {state.schemaInfo.example_problem.hints.length > 0 && (\n                <div>\n                  <h4 className=\"font-medium mb-2\">Hints</h4>\n                  <div className=\"space-y-2\">\n                    {state.schemaInfo.example_problem.hints.map((hint, index) => (\n                      <div key={index} className=\"text-sm p-2 bg-blue-50 dark:bg-blue-900 rounded\">\n                        {hint}\n                      </div>\n                    ))}\n                  </div>\n                </div>\n              )}\n\n              {/* Expected Output */}\n              {state.schemaInfo.example_problem.question.expectedOutput.length > 0 && (\n                <div>\n                  <h4 className=\"font-medium mb-2\">Expected Output</h4>\n                  <div className=\"bg-gray-50 dark:bg-gray-800 rounded p-3\">\n                    <pre className=\"text-xs overflow-auto\">\n                      {JSON.stringify(state.schemaInfo.example_problem.question.expectedOutput, null, 2)}\n                    </pre>\n                  </div>\n                </div>\n              )}\n            </div>\n          </CardContent>\n        )}\n      </Card>\n\n      {/* Quick Actions */}\n      <Card>\n        <CardHeader>\n          <CardTitle>Quick Actions</CardTitle>\n        </CardHeader>\n        <CardContent>\n          <div className=\"space-y-3\">\n            <Alert>\n              <Info className=\"h-4 w-4\" />\n              <AlertDescription>\n                Use the example problem as a starting point for creating new questions. \n                It demonstrates the proper structure and format.\n              </AlertDescription>\n            </Alert>\n            \n            <div className=\"flex space-x-2\">\n              <Button\n                onClick={() => actions.setActiveTab('create')}\n                data-testid=\"button-go-to-create\"\n              >\n                Go to Create Question\n              </Button>\n              <Button\n                variant=\"outline\"\n                onClick={() => actions.setActiveTab('datasource')}\n                data-testid=\"button-go-to-datasource\"\n              >\n                Go to Data Source\n              </Button>\n            </div>\n          </div>\n        </CardContent>\n      </Card>\n    </div>\n  );\n}","size_bytes":9576},"client/src/components/admin/SolutionsTab.tsx":{"content":"import { useState, useEffect } from 'react';\nimport { useQuery, useMutation } from '@tanstack/react-query';\nimport { Button } from '@/components/ui/button';\nimport { Input } from '@/components/ui/input';\nimport { Label } from '@/components/ui/label';\nimport { Textarea } from '@/components/ui/textarea';\nimport { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';\nimport { Alert, AlertDescription } from '@/components/ui/alert';\nimport { Save, FileText, Plus } from 'lucide-react';\nimport { useAdmin } from '@/contexts/AdminContext';\nimport { useToast } from '@/hooks/use-toast';\nimport { queryClient } from '@/lib/queryClient';\n\ninterface Solution {\n  id: string;\n  problem_id: string;\n  title: string;\n  content: string;\n  sql_code: string;\n  is_official: boolean;\n  created_at: string;\n  creator: {\n    id: string;\n    username: string;\n  };\n}\n\ninterface SolutionForm {\n  title: string;\n  content: string;\n  sql_code: string;\n}\n\nexport function SolutionsTab() {\n  const { state } = useAdmin();\n  const { toast } = useToast();\n  const [selectedProblemId, setSelectedProblemId] = useState('');\n  const [solutionForm, setSolutionForm] = useState<SolutionForm>({\n    title: '',\n    content: '',\n    sql_code: ''\n  });\n\n  // React Query for problems\n  const { data: problems = [], isLoading: problemsLoading } = useQuery({\n    queryKey: ['/api/problems'],\n    enabled: state.isAuthenticated\n  });\n\n  // React Query for existing solution (new endpoint)\n  const { data: existingSolution, isLoading: solutionLoading, error: solutionError } = useQuery({\n    queryKey: ['/api/admin/problems', selectedProblemId, 'solution'],\n    enabled: !!selectedProblemId && state.isAuthenticated,\n    queryFn: async () => {\n      const response = await fetch(`/api/admin/problems/${selectedProblemId}/solution`, {\n        headers: {\n          'Authorization': `Bearer ${state.adminKey}`\n        }\n      });\n      if (!response.ok) {\n        if (response.status === 404) {\n          return null; // No solution exists yet\n        }\n        throw new Error('Failed to fetch solution');\n      }\n      return response.json();\n    }\n  });\n\n  // Create or update solution mutation\n  const saveSolutionMutation = useMutation({\n    mutationFn: async (solutionData: SolutionForm) => {\n      const response = await fetch(`/api/admin/problems/${selectedProblemId}/solutions`, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${state.adminKey}`\n        },\n        body: JSON.stringify(solutionData)\n      });\n      \n      if (!response.ok) {\n        const error = await response.json();\n        throw new Error(error.detail || 'Failed to save solution');\n      }\n      \n      return response.json();\n    },\n    onSuccess: () => {\n      toast({\n        title: \"Success\",\n        description: existingSolution ? \"Solution updated successfully\" : \"Solution created successfully\"\n      });\n      queryClient.invalidateQueries({ queryKey: ['/api/admin/problems', selectedProblemId, 'solution'] });\n    },\n    onError: (error: Error) => {\n      toast({\n        title: \"Error\",\n        description: error.message,\n        variant: \"destructive\"\n      });\n    }\n  });\n\n  const handleSubmit = () => {\n    if (!selectedProblemId) {\n      toast({\n        title: \"Error\",\n        description: \"Please select a problem first\",\n        variant: \"destructive\"\n      });\n      return;\n    }\n\n    if (!solutionForm.title.trim() || !solutionForm.sql_code.trim()) {\n      toast({\n        title: \"Error\",\n        description: \"Please fill in the title and SQL code\",\n        variant: \"destructive\"\n      });\n      return;\n    }\n\n    saveSolutionMutation.mutate(solutionForm);\n  };\n\n  // Load existing solution data when problem changes\n  useEffect(() => {\n    if (existingSolution) {\n      setSolutionForm({\n        title: existingSolution.title || '',\n        content: existingSolution.content || '',\n        sql_code: existingSolution.sql_code || ''\n      });\n    } else {\n      setSolutionForm({\n        title: '',\n        content: '',\n        sql_code: ''\n      });\n    }\n  }, [existingSolution, selectedProblemId]);\n\n  return (\n    <div className=\"space-y-6\">\n      <Card>\n        <CardHeader>\n          <CardTitle>Solution Management</CardTitle>\n          <p className=\"text-sm text-muted-foreground\">\n            Create or edit solutions for problems. Each problem has one solution.\n          </p>\n        </CardHeader>\n      </Card>\n\n      {/* Problem Selection */}\n      <Card>\n        <CardHeader>\n          <CardTitle>Select Problem</CardTitle>\n        </CardHeader>\n        <CardContent>\n          <div>\n            <Label htmlFor=\"problem-select\">Choose a Problem</Label>\n            <select\n              id=\"problem-select\"\n              value={selectedProblemId}\n              onChange={(e) => setSelectedProblemId(e.target.value)}\n              className=\"w-full p-2 border rounded-md\"\n              data-testid=\"select-problem\"\n            >\n              <option value=\"\">Choose a problem...</option>\n              {problems.map((problem: any) => (\n                <option key={problem.id} value={problem.id}>\n                  {problem.title} ({problem.difficulty})\n                </option>\n              ))}\n            </select>\n          </div>\n        </CardContent>\n      </Card>\n\n      {/* Solution Form */}\n      {selectedProblemId && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"flex items-center gap-2\">\n              {existingSolution ? (\n                <>\n                  <FileText className=\"w-5 h-5\" />\n                  Edit Solution\n                </>\n              ) : (\n                <>\n                  <Plus className=\"w-5 h-5\" />\n                  Create Solution\n                </>\n              )}\n            </CardTitle>\n            {solutionLoading && (\n              <p className=\"text-sm text-muted-foreground\">Loading solution...</p>\n            )}\n            {existingSolution && (\n              <Alert>\n                <AlertDescription>\n                  Editing existing solution for this problem.\n                </AlertDescription>\n              </Alert>\n            )}\n          </CardHeader>\n          <CardContent className=\"space-y-4\">\n            <div>\n              <Label htmlFor=\"solution-title\">Solution Title</Label>\n              <Input\n                id=\"solution-title\"\n                value={solutionForm.title}\n                onChange={(e) => setSolutionForm(prev => ({ ...prev, title: e.target.value }))}\n                placeholder=\"e.g., Optimized JOIN solution\"\n                data-testid=\"input-solution-title\"\n              />\n            </div>\n\n            <div>\n              <Label htmlFor=\"solution-content\">Solution Explanation</Label>\n              <Textarea\n                id=\"solution-content\"\n                value={solutionForm.content}\n                onChange={(e) => setSolutionForm(prev => ({ ...prev, content: e.target.value }))}\n                placeholder=\"Explain the approach and key insights...\"\n                rows={4}\n                data-testid=\"textarea-solution-content\"\n              />\n            </div>\n\n            <div>\n              <Label htmlFor=\"solution-sql\">SQL Code</Label>\n              <Textarea\n                id=\"solution-sql\"\n                value={solutionForm.sql_code}\n                onChange={(e) => setSolutionForm(prev => ({ ...prev, sql_code: e.target.value }))}\n                placeholder=\"SELECT ...\"\n                rows={8}\n                className=\"font-mono text-sm\"\n                data-testid=\"textarea-solution-sql\"\n              />\n            </div>\n\n            <div className=\"flex justify-end\">\n              <Button \n                onClick={handleSubmit}\n                disabled={!solutionForm.title?.trim() || !solutionForm.sql_code?.trim() || saveSolutionMutation.isPending}\n                data-testid=\"button-submit-solution\"\n              >\n                <Save className=\"w-4 h-4 mr-2\" />\n                {saveSolutionMutation.isPending \n                  ? 'Saving...' \n                  : existingSolution \n                    ? 'Update Solution' \n                    : 'Create Solution'\n                }\n              </Button>\n            </div>\n          </CardContent>\n        </Card>\n      )}\n\n      {!selectedProblemId && (\n        <Alert>\n          <AlertDescription>\n            Please select a problem above to create or edit its solution.\n          </AlertDescription>\n        </Alert>\n      )}\n    </div>\n  );\n}","size_bytes":8569},"SECURITY_DEPLOYMENT.md":{"content":"# ðŸ” SECURITY DEPLOYMENT GUIDE\n\n## CRITICAL: Environment Variables Required\n\nThis application now requires secure environment variables to prevent the hardcoded admin key vulnerability.\n\n### Required Environment Variables\n\n1. **JWT_SECRET** - For JWT token signing\n2. **ADMIN_SECRET_KEY** - For admin authentication\n\n### Generate Secure Keys\n\n```bash\n# Generate JWT_SECRET\nexport JWT_SECRET=\"$(node -e \"console.log(require('crypto').randomBytes(32).toString('hex'))\")\"\n\n# Generate ADMIN_SECRET_KEY  \nexport ADMIN_SECRET_KEY=\"$(node -e \"console.log(require('crypto').randomBytes(32).toString('hex'))\")\"\n```\n\n### For Production Deployment\n\n**NEVER use default or hardcoded values!** \n\nSet these in your environment:\n- Replit: Add to Secrets in the sidebar\n- Other platforms: Set as environment variables in your deployment config\n\n### Security Fix Summary\n\nâœ… **Fixed**: Hardcoded admin key `\"admin-dev-key-123\"` removed\nâœ… **Fixed**: Hardcoded JWT secret `\"your-jwt-secret-key\"` removed  \nâœ… **Fixed**: Development token bypass `\"dev-token-123\"` removed\nâœ… **Fixed**: Environment variable validation added\nâœ… **Fixed**: Application fails fast if secrets are missing\n\n### What This Prevents\n\n- Unauthorized admin access to schema information\n- Access to PostgreSQL system tables via admin endpoints\n- SQL injection through privileged endpoints\n- Unauthorized database metadata exposure\n\n## âš ï¸ Breaking Change Notice\n\n**This is a breaking change!** Applications will not start without proper environment variables set.\n\nThis is intentional for security - it prevents accidental deployment with default credentials.","size_bytes":1622},"client/src/components/admin/EnhancedTablePreview.tsx":{"content":"import { useState } from 'react';\nimport { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';\nimport { Button } from '@/components/ui/button';\nimport { Input } from '@/components/ui/input';\nimport { Badge } from '@/components/ui/badge';\nimport { Table, TableBody, TableCell, TableHead, TableHeader, TableRow } from '@/components/ui/table';\nimport { Edit2, Save, X, Eye, EyeOff, Database, Columns, Hash } from 'lucide-react';\n\ninterface TableColumn {\n  name: string;\n  type: string;\n}\n\ninterface TableData {\n  name: string;\n  columns: TableColumn[];\n  sample_data: Record<string, any>[];\n}\n\ninterface EnhancedTablePreviewProps {\n  tables: TableData[];\n  onTableUpdate?: (tables: TableData[]) => void;\n  readOnly?: boolean;\n}\n\nconst COLUMN_TYPES = [\n  'VARCHAR', 'TEXT', 'INTEGER', 'BIGINT', 'DECIMAL', 'FLOAT', 'DOUBLE',\n  'BOOLEAN', 'DATE', 'TIMESTAMP', 'TIME', 'JSON', 'UUID'\n];\n\nexport function EnhancedTablePreview({ tables, onTableUpdate, readOnly = false }: EnhancedTablePreviewProps) {\n  const [editingTable, setEditingTable] = useState<number | null>(null);\n  const [showSampleData, setShowSampleData] = useState<{ [key: number]: boolean }>({});\n  const [editedTables, setEditedTables] = useState<TableData[]>([]);\n\n  // Deep clone helper function\n  const deepCloneTables = (tablesToClone: TableData[]): TableData[] => {\n    return tablesToClone.map(table => ({\n      name: table.name,\n      columns: table.columns.map(col => ({\n        name: col.name,\n        type: col.type\n      })),\n      sample_data: table.sample_data.map(row => ({ ...row }))\n    }));\n  };\n\n  const handleEditTable = (index: number) => {\n    setEditingTable(index);\n    // Create a deep clone to prevent mutations to the original data\n    setEditedTables(deepCloneTables(tables));\n  };\n\n  const handleSaveTable = (index: number) => {\n    if (onTableUpdate) {\n      // Pass the deep-cloned edited tables to the parent\n      onTableUpdate(deepCloneTables(editedTables));\n    }\n    setEditingTable(null);\n    setEditedTables([]);\n  };\n\n  const handleCancelEdit = () => {\n    setEditingTable(null);\n    // Clear the edited tables to prevent any lingering references\n    setEditedTables([]);\n  };\n\n  const handleColumnNameChange = (tableIndex: number, columnIndex: number, newName: string) => {\n    const updated = deepCloneTables(editedTables);\n    updated[tableIndex].columns[columnIndex].name = newName;\n    setEditedTables(updated);\n  };\n\n  const handleColumnTypeChange = (tableIndex: number, columnIndex: number, newType: string) => {\n    const updated = deepCloneTables(editedTables);\n    updated[tableIndex].columns[columnIndex].type = newType;\n    setEditedTables(updated);\n  };\n\n  const handleTableNameChange = (tableIndex: number, newName: string) => {\n    const updated = deepCloneTables(editedTables);\n    updated[tableIndex].name = newName;\n    setEditedTables(updated);\n  };\n\n  const toggleSampleData = (tableIndex: number) => {\n    setShowSampleData(prev => ({\n      ...prev,\n      [tableIndex]: !prev[tableIndex]\n    }));\n  };\n\n  const renderSampleData = (table: TableData) => {\n    if (!table.sample_data || table.sample_data.length === 0) return null;\n\n    const headers = Object.keys(table.sample_data[0]);\n    const displayRows = table.sample_data.slice(0, 5); // Show first 5 rows\n\n    return (\n      <div className=\"mt-4 border rounded-lg overflow-hidden\">\n        <div className=\"bg-muted/30 px-3 py-2 border-b\">\n          <h5 className=\"text-sm font-medium text-muted-foreground\">Sample Data</h5>\n        </div>\n        <div className=\"overflow-x-auto\">\n          <Table>\n            <TableHeader>\n              <TableRow className=\"bg-muted/20\">\n                {headers.map((header) => (\n                  <TableHead key={header} className=\"font-medium text-xs\">\n                    {header}\n                  </TableHead>\n                ))}\n              </TableRow>\n            </TableHeader>\n            <TableBody>\n              {displayRows.map((row, index) => (\n                <TableRow key={index} className=\"text-xs\">\n                  {headers.map((header) => (\n                    <TableCell key={header} className=\"py-1 px-2 max-w-32 truncate\">\n                      {String(row[header] ?? '')}\n                    </TableCell>\n                  ))}\n                </TableRow>\n              ))}\n            </TableBody>\n          </Table>\n        </div>\n        {table.sample_data.length > 5 && (\n          <div className=\"px-3 py-2 text-xs text-muted-foreground bg-muted/10 border-t\">\n            ... and {table.sample_data.length - 5} more rows\n          </div>\n        )}\n      </div>\n    );\n  };\n\n  if (tables.length === 0) {\n    return (\n      <Card>\n        <CardContent className=\"p-6 text-center text-muted-foreground\">\n          <Database className=\"mx-auto h-12 w-12 mb-3 opacity-50\" />\n          <p>No tables loaded yet</p>\n          <p className=\"text-sm\">Load tables from a datasource to see the preview</p>\n        </CardContent>\n      </Card>\n    );\n  }\n\n  return (\n    <div className=\"space-y-4\">\n      <div className=\"flex items-center justify-between\">\n        <h3 className=\"text-lg font-semibold flex items-center gap-2\">\n          <Database className=\"h-5 w-5\" />\n          Tables Preview ({tables.length})\n        </h3>\n        {!readOnly && (\n          <Badge variant=\"outline\" className=\"text-xs\">\n            Click table names or columns to edit\n          </Badge>\n        )}\n      </div>\n\n      {tables.map((table, tableIndex) => {\n        const isEditing = editingTable === tableIndex;\n        const currentTable = isEditing && editedTables.length > 0 ? editedTables[tableIndex] : table;\n\n        return (\n          <Card key={tableIndex} className=\"overflow-hidden\">\n            <CardHeader className=\"pb-3\">\n              <div className=\"flex items-center justify-between\">\n                <div className=\"flex items-center gap-3\">\n                  {isEditing ? (\n                    <Input\n                      value={currentTable.name}\n                      onChange={(e) => handleTableNameChange(tableIndex, e.target.value)}\n                      className=\"text-lg font-semibold h-auto py-1 px-2 w-48\"\n                      data-testid={`input-table-name-${tableIndex}`}\n                    />\n                  ) : (\n                    <CardTitle \n                      className={`flex items-center gap-2 ${!readOnly ? 'cursor-pointer hover:text-primary transition-colors' : ''}`}\n                      onClick={() => !readOnly && handleEditTable(tableIndex)}\n                      data-testid={`text-table-name-${tableIndex}`}\n                    >\n                      <Columns className=\"h-4 w-4 text-primary\" />\n                      {table.name}\n                    </CardTitle>\n                  )}\n                  \n                  <div className=\"flex items-center gap-2 text-sm text-muted-foreground\">\n                    <Badge variant=\"secondary\" className=\"text-xs bg-blue-50 text-blue-700 dark:bg-blue-900 dark:text-blue-300\">\n                      <Hash className=\"h-3 w-3 mr-1\" />\n                      {table.columns.length} column{table.columns.length !== 1 ? 's' : ''}\n                    </Badge>\n                    <Badge variant=\"secondary\" className=\"text-xs bg-green-50 text-green-700 dark:bg-green-900 dark:text-green-300\">\n                      <Database className=\"h-3 w-3 mr-1\" />\n                      {table.sample_data.length} row{table.sample_data.length !== 1 ? 's' : ''}\n                    </Badge>\n                  </div>\n                </div>\n\n                <div className=\"flex items-center gap-2\">\n                  {table.sample_data.length > 0 && (\n                    <Button\n                      variant=\"outline\"\n                      size=\"sm\"\n                      onClick={() => toggleSampleData(tableIndex)}\n                      data-testid={`button-toggle-sample-${tableIndex}`}\n                    >\n                      {showSampleData[tableIndex] ? (\n                        <>\n                          <EyeOff className=\"h-4 w-4 mr-1\" />\n                          Hide Data\n                        </>\n                      ) : (\n                        <>\n                          <Eye className=\"h-4 w-4 mr-1\" />\n                          Show Data\n                        </>\n                      )}\n                    </Button>\n                  )}\n\n                  {!readOnly && (\n                    <>\n                      {isEditing ? (\n                        <div className=\"flex gap-1\">\n                          <Button\n                            variant=\"outline\"\n                            size=\"sm\"\n                            onClick={() => handleSaveTable(tableIndex)}\n                            data-testid={`button-save-table-${tableIndex}`}\n                          >\n                            <Save className=\"h-4 w-4\" />\n                          </Button>\n                          <Button\n                            variant=\"outline\"\n                            size=\"sm\"\n                            onClick={handleCancelEdit}\n                            data-testid={`button-cancel-edit-${tableIndex}`}\n                          >\n                            <X className=\"h-4 w-4\" />\n                          </Button>\n                        </div>\n                      ) : (\n                        <Button\n                          variant=\"outline\"\n                          size=\"sm\"\n                          onClick={() => handleEditTable(tableIndex)}\n                          data-testid={`button-edit-table-${tableIndex}`}\n                        >\n                          <Edit2 className=\"h-4 w-4 mr-1\" />\n                          Edit\n                        </Button>\n                      )}\n                    </>\n                  )}\n                </div>\n              </div>\n            </CardHeader>\n\n            <CardContent className=\"pt-0\">\n              {/* Schema Display */}\n              <div className=\"border rounded-lg overflow-hidden\">\n                <div className=\"bg-muted/30 px-3 py-2 border-b\">\n                  <h5 className=\"text-sm font-medium text-muted-foreground\">Table Schema</h5>\n                </div>\n                <Table>\n                  <TableHeader>\n                    <TableRow className=\"bg-muted/20\">\n                      <TableHead className=\"font-medium\">Column Name</TableHead>\n                      <TableHead className=\"font-medium\">Data Type</TableHead>\n                    </TableRow>\n                  </TableHeader>\n                  <TableBody>\n                    {currentTable.columns.map((column, columnIndex) => (\n                      <TableRow key={columnIndex}>\n                        <TableCell className=\"py-2\">\n                          {isEditing ? (\n                            <Input\n                              value={column.name}\n                              onChange={(e) => handleColumnNameChange(tableIndex, columnIndex, e.target.value)}\n                              className=\"font-mono text-sm h-8\"\n                              data-testid={`input-column-name-${tableIndex}-${columnIndex}`}\n                            />\n                          ) : (\n                            <span \n                              className={`font-mono text-sm ${!readOnly ? 'cursor-pointer hover:text-primary' : ''}`}\n                              onClick={() => !readOnly && handleEditTable(tableIndex)}\n                              data-testid={`text-column-name-${tableIndex}-${columnIndex}`}\n                            >\n                              {column.name}\n                            </span>\n                          )}\n                        </TableCell>\n                        <TableCell className=\"py-2\">\n                          {isEditing ? (\n                            <select\n                              value={column.type}\n                              onChange={(e) => handleColumnTypeChange(tableIndex, columnIndex, e.target.value)}\n                              className=\"h-8 w-full border rounded px-2 text-sm\"\n                              data-testid={`select-column-type-${tableIndex}-${columnIndex}`}\n                            >\n                              {COLUMN_TYPES.map((type) => (\n                                <option key={type} value={type}>\n                                  {type}\n                                </option>\n                              ))}\n                            </select>\n                          ) : (\n                            <Badge \n                              variant=\"outline\" \n                              className={`text-xs ${!readOnly ? 'cursor-pointer hover:bg-primary/10' : ''}`}\n                              onClick={() => !readOnly && handleEditTable(tableIndex)}\n                              data-testid={`text-column-type-${tableIndex}-${columnIndex}`}\n                            >\n                              {column.type}\n                            </Badge>\n                          )}\n                        </TableCell>\n                      </TableRow>\n                    ))}\n                  </TableBody>\n                </Table>\n              </div>\n\n              {/* Sample Data */}\n              {showSampleData[tableIndex] && renderSampleData(table)}\n            </CardContent>\n          </Card>\n        );\n      })}\n    </div>\n  );\n}","size_bytes":13425},"scripts/migrate_to_unified_interactions.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nMigration script to merge ProblemBookmark and ProblemLike tables into ProblemInteraction\n\"\"\"\nimport os\nimport sys\nimport logging\nfrom datetime import datetime\n\n# Add the parent directory to the path to import from api\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom sqlalchemy import create_engine, MetaData, Table\nfrom sqlalchemy.orm import sessionmaker\nfrom api.database import get_database_url\nfrom api.models import ProblemBookmark, ProblemLike, ProblemInteraction\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\ndef migrate_interactions():\n    \"\"\"\n    Migrate data from ProblemBookmark and ProblemLike tables to ProblemInteraction\n    \"\"\"\n    # Get database connection\n    database_url = get_database_url()\n    engine = create_engine(database_url)\n    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n    \n    session = SessionLocal()\n    \n    try:\n        logger.info(\"Starting migration of bookmark and like data to unified interactions table\")\n        \n        # Create the new table if it doesn't exist\n        ProblemInteraction.__table__.create(engine, checkfirst=True)\n        logger.info(\"Created ProblemInteraction table if it didn't exist\")\n        \n        # Get all existing bookmarks and likes\n        bookmarks = session.query(ProblemBookmark).all()\n        likes = session.query(ProblemLike).all()\n        \n        logger.info(f\"Found {len(bookmarks)} bookmarks and {len(likes)} likes to migrate\")\n        \n        # Create a dictionary to track user-problem combinations\n        interactions = {}\n        \n        # Process bookmarks\n        for bookmark in bookmarks:\n            key = (bookmark.user_id, bookmark.problem_id)\n            if key not in interactions:\n                interactions[key] = {\n                    'user_id': bookmark.user_id,\n                    'problem_id': bookmark.problem_id,\n                    'bookmark': True,\n                    'upvote': False,\n                    'downvote': False,\n                    'created_at': bookmark.created_at\n                }\n            else:\n                # If already exists (from a like), just set bookmark = True\n                interactions[key]['bookmark'] = True\n                # Use earlier timestamp\n                if bookmark.created_at < interactions[key]['created_at']:\n                    interactions[key]['created_at'] = bookmark.created_at\n        \n        # Process likes (convert to upvotes)\n        for like in likes:\n            key = (like.user_id, like.problem_id)\n            if key not in interactions:\n                interactions[key] = {\n                    'user_id': like.user_id,\n                    'problem_id': like.problem_id,\n                    'bookmark': False,\n                    'upvote': True,\n                    'downvote': False,\n                    'created_at': like.created_at\n                }\n            else:\n                # If already exists (from a bookmark), just set upvote = True\n                interactions[key]['upvote'] = True\n                # Use earlier timestamp\n                if like.created_at < interactions[key]['created_at']:\n                    interactions[key]['created_at'] = like.created_at\n        \n        logger.info(f\"Merged into {len(interactions)} unique user-problem interactions\")\n        \n        # Insert into ProblemInteraction table\n        migrated_count = 0\n        for interaction_data in interactions.values():\n            # Check if this interaction already exists\n            existing = session.query(ProblemInteraction).filter(\n                ProblemInteraction.user_id == interaction_data['user_id'],\n                ProblemInteraction.problem_id == interaction_data['problem_id']\n            ).first()\n            \n            if not existing:\n                new_interaction = ProblemInteraction(\n                    user_id=interaction_data['user_id'],\n                    problem_id=interaction_data['problem_id'],\n                    bookmark=interaction_data['bookmark'],\n                    upvote=interaction_data['upvote'],\n                    downvote=interaction_data['downvote'],\n                    created_at=interaction_data['created_at']\n                )\n                session.add(new_interaction)\n                migrated_count += 1\n            else:\n                logger.info(f\"Interaction already exists for user {interaction_data['user_id'][:8]}... and problem {interaction_data['problem_id'][:8]}...\")\n        \n        # Commit the changes\n        session.commit()\n        logger.info(f\"Successfully migrated {migrated_count} interactions to the new table\")\n        \n        # Verify migration\n        total_interactions = session.query(ProblemInteraction).count()\n        bookmark_count = session.query(ProblemInteraction).filter(ProblemInteraction.bookmark == True).count()\n        upvote_count = session.query(ProblemInteraction).filter(ProblemInteraction.upvote == True).count()\n        \n        logger.info(f\"Migration verification:\")\n        logger.info(f\"  Total interactions: {total_interactions}\")\n        logger.info(f\"  With bookmarks: {bookmark_count}\")\n        logger.info(f\"  With upvotes: {upvote_count}\")\n        logger.info(f\"  Original bookmarks: {len(bookmarks)}\")\n        logger.info(f\"  Original likes: {len(likes)}\")\n        \n        logger.info(\"Migration completed successfully!\")\n        \n    except Exception as e:\n        logger.error(f\"Migration failed: {str(e)}\")\n        session.rollback()\n        raise\n    finally:\n        session.close()\n\nif __name__ == \"__main__\":\n    migrate_interactions()","size_bytes":5734}},"version":1}