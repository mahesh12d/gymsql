SQLGym Postgres to S3 Data Pipeline - Setup Instructions
=========================================================

PREREQUISITES:
--------------
1. AWS Account with appropriate permissions
2. AWS CLI installed and configured
3. AWS SAM CLI installed
4. Python 3.11+
5. Neon Postgres database credentials

QUICK START (PRODUCTION-READY WITH AWS SECRETS MANAGER):
--------------------------------------------------------
1. Create database secret in AWS Secrets Manager:
   python scripts/create_db_secret.py production --region us-east-1
   (Save the ARN that's displayed!)

2. Install Python dependencies:
   pip install -r requirements.txt

3. Test locally (optional):
   export DB_SECRET_NAME="production/sqlgym/database"
   python scripts/test_local.py --test connection

4. Deploy to AWS:
   make deploy ENVIRONMENT=production \
     DATABASE_SECRET_ARN="arn:aws:secretsmanager:...:secret:production/sqlgym/database-..." \
     S3_BUCKET_NAME="sqlgym-data-lake-production"

5. Invoke manually:
   ./scripts/invoke_lambda.sh production incremental

6. Monitor sync status:
   python scripts/monitor_sync.py --bucket $S3_BUCKET_NAME --hours 24

NOTE: For development/testing without Secrets Manager, see SECRETS_MANAGER_GUIDE.md

DEPLOYMENT OPTIONS:
-------------------
Option 1: Using SAM CLI (Recommended)
   ./scripts/deploy.sh production

Option 2: Using AWS CloudFormation Console
   1. Package the Lambda code
   2. Upload template.yaml to CloudFormation
   3. Configure parameters in the console

Option 3: Using Terraform (create your own .tf files)
   Convert template.yaml to Terraform configuration

CONFIGURATION:
--------------
Edit config/pipeline_config.json to:
- Enable/disable specific tables
- Set sync priorities
- Configure incremental vs full sync
- Adjust retention policies

MONITORING:
-----------
1. View Lambda logs:
   aws logs tail /aws/lambda/production-sqlgym-postgres-to-s3 --follow

2. Generate sync report:
   python scripts/monitor_sync.py --bucket $S3_BUCKET_NAME

3. List latest files for a table:
   python scripts/monitor_sync.py --bucket $S3_BUCKET_NAME --table users --list-files

4. CloudWatch Dashboard:
   Create dashboard using Lambda metrics (Invocations, Duration, Errors)

DATA VALIDATION:
----------------
Run validation checks:
   from utils.data_validator import run_validation_checks
   results = run_validation_checks('your-bucket', ['users', 'submissions'])

INCREMENTAL VS FULL SYNC:
--------------------------
Incremental Sync:
- Uses updated_at timestamp to sync only new/modified records
- More efficient for large tables
- Configured in pipeline_config.json

Full Sync:
- Syncs entire table
- Use for tables without updated_at column
- Can be forced with force_full_sync: true

SCHEDULING:
-----------
Default schedule: Every 1 hour
Modify in template.yaml (SyncSchedule parameter)

Examples:
- rate(30 minutes) - Every 30 minutes
- rate(1 hour) - Every hour
- rate(1 day) - Daily
- cron(0 12 * * ? *) - Daily at 12:00 PM UTC

COST OPTIMIZATION:
------------------
1. Use incremental sync for large tables
2. Adjust Lambda memory based on table sizes
3. Set appropriate S3 lifecycle policies
4. Monitor CloudWatch costs
5. Use reserved concurrency to limit concurrent executions

TROUBLESHOOTING:
----------------
Lambda timeout:
- Increase LAMBDA_TIMEOUT in template.yaml
- Consider splitting large tables

Out of memory:
- Increase LAMBDA_MEMORY in template.yaml
- Process tables in batches

Connection issues:
- Verify Neon credentials
- Check security groups if using VPC
- Ensure SSL/TLS is enabled

S3 upload failures:
- Verify IAM permissions
- Check bucket policies
- Ensure bucket exists in correct region

SECURITY BEST PRACTICES:
------------------------
1. ✅ Store database credentials in AWS Secrets Manager (NOW IMPLEMENTED)
2. Use IAM roles instead of access keys (configured in template.yaml)
3. Enable S3 bucket encryption
4. Restrict S3 bucket access with policies
5. Enable CloudTrail for audit logging
6. Use VPC endpoints for private connectivity

See SECRETS_MANAGER_GUIDE.md for complete security documentation.

PRODUCTION CHECKLIST:
---------------------
☑ Database credentials stored in Secrets Manager (IMPLEMENTED)
☑ IAM permissions configured for Secrets Manager (IMPLEMENTED)
☐ S3 bucket encryption enabled
☐ CloudWatch alarms configured
☐ Backup/recovery plan in place
☐ Monitoring dashboard created
☐ Cost alerts configured
☑ Documentation updated (SECRETS_MANAGER_GUIDE.md)
☐ Team trained on monitoring procedures

SUPPORT:
--------
For issues or questions:
1. Check CloudWatch logs
2. Review validation reports
3. Consult AWS Lambda documentation
4. Review Neon Postgres connection guide
